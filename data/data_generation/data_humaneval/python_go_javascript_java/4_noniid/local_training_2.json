[{"instruction": "def calculate_size(name, sequence):\n    \"\"\" Calculates the request payload size\"\"\"\n", "input": "", "output": "    data_size = 0\n    data_size += calculate_size_str(name)\n    data_size += LONG_SIZE_IN_BYTES\n    return data_size"}, {"instruction": "def task(ft):\n\t\"\"\"\n\tto create loading progress bar\n\t\"\"\"\n", "input": "", "output": "\tft.pack(expand = True,  fill = BOTH,  side = TOP)\n\tpb_hD = ttk.Progressbar(ft, orient = 'horizontal', mode = 'indeterminate')\n\tpb_hD.pack(expand = True, fill = BOTH, side = TOP)\n\tpb_hD.start(50)\n\tft.mainloop()"}, {"instruction": "Equivalent of \"main\", but non-static.", "input": "Java", "output": "public void run(String[] args) throws Exception {\n    ServerConfiguration.Builder configBuilder = ServerConfiguration.newBuilder();\n    ServerConfiguration config;\n    try {\n      config = configBuilder.build(args);\n    } catch (Exception e) {\n      System.out.println(e.getMessage());\n      configBuilder.printUsage();\n      return;\n    }\n\n    final Server server = newServer(config);\n    server.start();\n\n    System.out.println(\"QPS Server started on \" + config.address);\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n      @Override\n      @SuppressWarnings(\"CatchAndPrintStackTrace\")\n      public void run() {\n        try {\n          System.out.println(\"QPS Server shutting down\");\n          server.shutdown();\n        } catch (Exception e) {\n          e.printStackTrace();\n        }\n      }\n    });\n    server.awaitTermination();\n  }"}, {"instruction": "Start the environment specified.\n@param applicationContext the application context with the environment\n@return The environment within the context", "input": "Java", "output": "protected Environment startEnvironment(ApplicationContext applicationContext) {\n        if (!applicationContext.isRunning()) {\n            if (this instanceof PropertySource) {\n                applicationContext.getEnvironment().addPropertySource((PropertySource) this);\n            }\n\n            return applicationContext\n                    .start()\n                    .getEnvironment();\n        } else {\n            return applicationContext.getEnvironment();\n        }\n    }"}, {"instruction": "[TARGET waitFor(RetryOption...)]", "input": "Java", "output": "public boolean waitForWithOptions() throws InterruptedException {\n    try {\n      // [START ]\n      Job completedJob =\n          job.waitFor(\n              RetryOption.initialRetryDelay(Duration.ofSeconds(1)),\n              RetryOption.totalTimeout(Duration.ofMinutes(1)));\n      if (completedJob == null) {\n        // job no longer exists\n      } else if (completedJob.getStatus().getError() != null) {\n        // job failed, handle error\n      } else {\n        // job completed successfully\n      }\n      // [END ]\n    } catch (BigQueryException e) {\n      if (e.getCause() instanceof PollException) {\n        return false;\n      }\n      throw e;\n    }\n    return true;\n  }"}, {"instruction": "Is consent required ?\n\n@param service           the service\n@param registeredService the registered service\n@param authentication    the authentication\n@param requestContext    the request context\n@return the event id.", "input": "Java", "output": "protected String isConsentRequired(final Service service, final RegisteredService registeredService,\n                                       final Authentication authentication,\n                                       final RequestContext requestContext) {\n        val required = this.consentEngine.isConsentRequiredFor(service, registeredService, authentication).isRequired();\n        return required ? EVENT_ID_CONSENT_REQUIRED : null;\n    }"}, {"instruction": "Specifies the weigher to use in determining the weight of entries. Entry weight is taken into\nconsideration by {@link #maximumWeight(long)} when determining which entries to evict, and use\nof this method requires a corresponding call to {@link #maximumWeight(long)} prior to calling\n{@link #build}. Weights are measured and recorded when entries are inserted into or updated in\nthe cache, and are thus effectively static during the lifetime of a cache entry.\n<p>\nWhen the weight of an entry is zero it will not be considered for size-based eviction (though\nit still may be evicted by other means).\n<p>\n<b>Important note:</b> Instead of returning <em>this</em> as a {@code Caffeine} instance, this\nmethod returns {@code Caffeine<K1, V1>}. From this point on, either the original reference or\nthe returned reference may be used to complete configuration and build the cache, but only the\n\"generic\" one is type-safe. That is, it will properly prevent you from building caches whose\nkey or value types are incompatible with the types accepted by the weigher already provided;\nthe {@code Caffeine} type cannot do this. For best results, simply use the standard\nmethod-chaining idiom, as illustrated in the documentation at top, configuring a\n{@code Caffeine} and building your {@link Cache} all in a single statement.\n<p>\n<b>Warning:</b> if you ignore the above advice, and use this {@code Caffeine} to build a cache\nwhose key or value type is incompatible with the weigher, you will likely experience a\n{@link ClassCastException} at some <i>undefined</i> point in the future.\n\n@param weigher the weigher to use in calculating the weight of cache entries\n@param <K1> key type of the weigher\n@param <V1> value type of the weigher\n@return the cache builder reference that should be used instead of {@code this} for any\nremaining configuration and cache building\n@throws IllegalStateException if a weigher was already set", "input": "Java", "output": "@NonNull\n  public <K1 extends K, V1 extends V> Caffeine<K1, V1> weigher(\n      @NonNull Weigher<? super K1, ? super V1> weigher) {\n    requireNonNull(weigher);\n    requireState(this.weigher == null, \"weigher was already set to %s\", this.weigher);\n    requireState(!strictParsing || this.maximumSize == UNSET_INT,\n        \"weigher can not be combined with maximum size\", this.maximumSize);\n\n    @SuppressWarnings(\"unchecked\")\n    Caffeine<K1, V1> self = (Caffeine<K1, V1>) this;\n    self.weigher = weigher;\n    return self;\n  }"}, {"instruction": "Gets cas ticket granting ticket created events.\n\n@param principal the principal\n@return the cas ticket granting ticket created events for", "input": "Java", "output": "protected Collection<? extends CasEvent> getCasTicketGrantingTicketCreatedEventsFor(final String principal) {\n        val type = CasTicketGrantingTicketCreatedEvent.class.getName();\n        LOGGER.debug(\"Retrieving events of type [{}] for [{}]\", type, principal);\n\n        val date = ZonedDateTime.now(ZoneOffset.UTC)\n            .minusDays(casProperties.getAuthn().getAdaptive().getRisk().getDaysInRecentHistory());\n        return casEventRepository.getEventsOfTypeForPrincipal(type, principal, date);\n    }"}, {"instruction": "Mask the input string with a list of patterns indexed by key in string section in mask.json\nThis is usually used to mask header values, query parameters and uri parameters\n\n@param input String The source of the string that needs to be masked\n@param key   String The key that maps to a list of patterns for masking in config file\n@return Masked result", "input": "Java", "output": "public static String maskString(String input, String key) {\n        String output = input;\n        Map<String, Object> stringConfig = (Map<String, Object>) config.get(MASK_TYPE_STRING);\n        if (stringConfig != null) {\n            Map<String, Object> keyConfig = (Map<String, Object>) stringConfig.get(key);\n            if (keyConfig != null) {\n                Set<String> patterns = keyConfig.keySet();\n                for (String pattern : patterns) {\n                    output = output.replaceAll(pattern, (String) keyConfig.get(pattern));\n                }\n            }\n        }\n        return output;\n    }"}, {"instruction": "Allocates a shared slot on this TaskManager instance. This method returns {@code null}, if no slot\nis available at the moment. The shared slot will be managed by the given  SlotSharingGroupAssignment.\n\n@param sharingGroupAssignment The assignment group that manages this shared slot.\n\n@return A shared slot that represents a task slot on this TaskManager instance and can hold other\n(shared) slots, or null, if the TaskManager instance has no more slots available.\n\n@throws InstanceDiedException Thrown if the instance is no longer alive by the time the slot is allocated.", "input": "Java", "output": "public SharedSlot allocateSharedSlot(SlotSharingGroupAssignment sharingGroupAssignment)\n\t\t\tthrows InstanceDiedException {\n\n\t\tsynchronized (instanceLock) {\n\t\t\tif (isDead) {\n\t\t\t\tthrow new InstanceDiedException(this);\n\t\t\t}\n\n\t\t\tInteger nextSlot = availableSlots.poll();\n\t\t\tif (nextSlot == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSharedSlot slot = new SharedSlot(\n\t\t\t\t\tthis,\n\t\t\t\t\tlocation,\n\t\t\t\t\tnextSlot,\n\t\t\t\t\ttaskManagerGateway,\n\t\t\t\t\tsharingGroupAssignment);\n\t\t\t\tallocatedSlots.add(slot);\n\t\t\t\treturn slot;\n\t\t\t}\n\t\t}\n\t}"}, {"instruction": "\u6839\u636e\u6a21\u578b\u540d\u79f0\u83b7\u53d6crf\u6a21\u578b\n\n@param modelName\n@return", "input": "Java", "output": "public static StopRecognition get(String key) {\n        KV<String, StopRecognition> kv = STOP.get(key);\n\n        if (kv == null) {\n            if (MyStaticValue.ENV.containsKey(key)) {\n                putIfAbsent(key, MyStaticValue.ENV.get(key));\n                return get(key);\n            }\n            LOG.warn(\"STOP \" + key + \" not found in config \");\n            return null;\n        }\n        StopRecognition stopRecognition = kv.getV();\n        if (stopRecognition == null) {\n            stopRecognition = init(key, kv, false);\n        }\n        return stopRecognition;\n\n    }"}, {"instruction": "Notify all the handshake futures about the successfully handshake", "input": "Java", "output": "private void setHandshakeSuccess() {\n        handshakePromise.trySuccess(ctx.channel());\n\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"{} HANDSHAKEN: {}\", ctx.channel(), engine.getSession().getCipherSuite());\n        }\n        ctx.fireUserEventTriggered(SslHandshakeCompletionEvent.SUCCESS);\n\n        if (readDuringHandshake && !ctx.channel().config().isAutoRead()) {\n            readDuringHandshake = false;\n            ctx.read();\n        }\n    }"}, {"instruction": "For some metrics such as OpStats, Pravega generates corresponding fail metrics automatically,\nthis method is called to create the name of fail metric for a given metric.\n\nSome examples of OpStats metrics and their corresponding fail metrics:\npravega.segmentstore.bookkeeper.write_latency_ms.0\npravega.segmentstore.bookkeeper.write_latency_ms_fail.0\n\npravega.segmentstore.thread_pool.active_threads\npravega.segmentstore.thread_pool.active_threads_fail\n\nThe rule is, if the last segment of the metric is an integer, such as container id, the suffix \"_fail\"\nis appended to the preceeding segment instead of the integer itself; otherwise simply append \"_fail\"\nonto the given metric to get the fail metric.\n\n@param metricName the metric name for which fail metric is created\n@return the name of fail metric", "input": "Java", "output": "public static String failMetricName(String metricName) {\n        if (Strings.isNullOrEmpty(metricName)) {\n            return metricName;\n        }\n        String[] tags = metricName.split(\"\\\\.\");\n        if (tags.length >= 2 && Ints.tryParse(tags[tags.length - 1]) != null) {\n            tags[tags.length - 2] += \"_fail\";\n            return String.join(\".\", tags);\n        } else {\n            return metricName + \"_fail\";\n        }\n    }"}, {"instruction": "Transforms a {@code SplitTransformation}.\n\n<p>We add the output selector to previously transformed nodes.", "input": "Java", "output": "private <T> Collection<Integer> transformSplit(SplitTransformation<T> split) {\n\n\t\tStreamTransformation<T> input = split.getInput();\n\t\tCollection<Integer> resultIds = transform(input);\n\n\t\tvalidateSplitTransformation(input);\n\n\t\t// the recursive transform call might have transformed this already\n\t\tif (alreadyTransformed.containsKey(split)) {\n\t\t\treturn alreadyTransformed.get(split);\n\t\t}\n\n\t\tfor (int inputId : resultIds) {\n\t\t\tstreamGraph.addOutputSelector(inputId, split.getOutputSelector());\n\t\t}\n\n\t\treturn resultIds;\n\t}"}, {"instruction": "Joins the vertex DataSet of this graph with an input Tuple2 DataSet and applies\na user-defined transformation on the values of the matched records.\nThe vertex ID and the first field of the Tuple2 DataSet are used as the join keys.\n\n@param inputDataSet the Tuple2 DataSet to join with.\nThe first field of the Tuple2 is used as the join key and the second field is passed\nas a parameter to the transformation function.\n@param vertexJoinFunction the transformation function to apply.\nThe first parameter is the current vertex value and the second parameter is the value\nof the matched Tuple2 from the input DataSet.\n@return a new Graph, where the vertex values have been updated according to the\nresult of the vertexJoinFunction.\n\n@param <T> the type of the second field of the input Tuple2 DataSet.", "input": "Java", "output": "public <T> Graph<K, VV, EV> joinWithVertices(DataSet<Tuple2<K, T>> inputDataSet,\n\t\t\tfinal VertexJoinFunction<VV, T> vertexJoinFunction) {\n\n\t\tDataSet<Vertex<K, VV>> resultedVertices = this.getVertices()\n\t\t\t\t.coGroup(inputDataSet).where(0).equalTo(0)\n\t\t\t\t.with(new ApplyCoGroupToVertexValues<>(vertexJoinFunction))\n\t\t\t\t\t.name(\"Join with vertices\");\n\t\treturn new Graph<>(resultedVertices, this.edges, this.context);\n\t}"}, {"instruction": "Starts an Actor System at a specific port.\n@param configuration The Flink configuration.\n@param listeningAddress The address to listen at.\n@param listeningPort The port to listen at.\n@param logger the logger to output log information.\n@param actorSystemExecutorConfiguration configuration for the ActorSystem's underlying executor\n@return The ActorSystem which has been started.\n@throws Exception", "input": "Java", "output": "public static ActorSystem startActorSystem(\n\t\t\t\tConfiguration configuration,\n\t\t\t\tString listeningAddress,\n\t\t\t\tint listeningPort,\n\t\t\t\tLogger logger,\n\t\t\t\tActorSystemExecutorConfiguration actorSystemExecutorConfiguration) throws Exception {\n\t\treturn startActorSystem(\n\t\t\tconfiguration,\n\t\t\tAkkaUtils.getFlinkActorSystemName(),\n\t\t\tlisteningAddress,\n\t\t\tlisteningPort,\n\t\t\tlogger,\n\t\t\tactorSystemExecutorConfiguration);\n\t}"}, {"instruction": "Initializes the type system.", "input": "Java", "output": "@Override\n    public void typeSystemInit(TypeSystem typeSystem) throws AnalysisEngineProcessException {\n\n        // sentence type\n        this.sentenceType = AnnotatorUtil.getRequiredTypeParameter(this.context, typeSystem,\n                        UimaUtil.SENTENCE_TYPE_PARAMETER);\n\n        // token type\n        this.tokenType = AnnotatorUtil.getRequiredTypeParameter(this.context, typeSystem,\n                        UimaUtil.TOKEN_TYPE_PARAMETER);\n\n        // pos feature\n        this.posFeature = AnnotatorUtil.getRequiredFeatureParameter(this.context, this.tokenType,\n                        UimaUtil.POS_FEATURE_PARAMETER, CAS.TYPE_NAME_STRING);\n\n        this.probabilityFeature = AnnotatorUtil.getOptionalFeatureParameter(this.context, this.tokenType,\n                        UimaUtil.PROBABILITY_FEATURE_PARAMETER, CAS.TYPE_NAME_DOUBLE);\n    }"}, {"instruction": "-------------------------------------------------------------------------------", "input": "Java", "output": "public static <K, N> InternalTimersSnapshotReader<K, N> getReaderForVersion(\n\t\tint version, ClassLoader userCodeClassLoader) {\n\n\t\tswitch (version) {\n\t\t\tcase NO_VERSION:\n\t\t\t\treturn new InternalTimersSnapshotReaderPreVersioned<>(userCodeClassLoader);\n\n\t\t\tcase 1:\n\t\t\t\treturn new InternalTimersSnapshotReaderV1<>(userCodeClassLoader);\n\n\t\t\tcase InternalTimerServiceSerializationProxy.VERSION:\n\t\t\t\treturn new InternalTimersSnapshotReaderV2<>(userCodeClassLoader);\n\n\t\t\tdefault:\n\t\t\t\t// guard for future\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Unrecognized internal timers snapshot writer version: \" + version);\n\t\t}\n\t}"}, {"instruction": "Given a {@link ROC} instance, render the ROC chart and precision vs. recall charts to a stand-alone HTML file (returned as a String)\n@param roc  ROC to render", "input": "Java", "output": "public static String rocChartToHtml(ROC roc) {\n        RocCurve rocCurve = roc.getRocCurve();\n\n        Component c = getRocFromPoints(ROC_TITLE, rocCurve, roc.getCountActualPositive(), roc.getCountActualNegative(),\n                        roc.calculateAUC(), roc.calculateAUCPR());\n        Component c2 = getPRCharts(PR_TITLE, PR_THRESHOLD_TITLE, roc.getPrecisionRecallCurve());\n\n        return StaticPageUtil.renderHTML(c, c2);\n    }"}, {"instruction": "This method initializes this", "input": "Java", "output": "private void initialize() {\r\n        this.setCursor(new java.awt.Cursor(java.awt.Cursor.WAIT_CURSOR));\r\n        this.setContentPane(getJPanel());\r\n        if (Model.getSingleton().getOptionsParam().getViewParam().getWmUiHandlingOption() == 0) {\r\n        \tthis.setSize(282, 118);\r\n        }\r\n        this.setDefaultCloseOperation(javax.swing.WindowConstants.DO_NOTHING_ON_CLOSE);\r\n        this.setResizable(false);\r\n\t\t\t\r\n\t}"}, {"instruction": "This method reconnects given node to another node", "input": "Java", "output": "public synchronized void remapNode(@NonNull Node node) {\n        version++;\n\n        if (buildMode == MeshBuildMode.MESH) {\n            node.getUpstreamNode().removeFromDownstreams(node);\n\n            boolean m = false;\n            for (val n : sortedNodes) {\n                // we dont want to remap node to itself\n                if (!Objects.equals(n, node) && n.status().equals(NodeStatus.ONLINE)) {\n                    n.addDownstreamNode(node);\n                    m = true;\n                    break;\n                }\n            }\n\n            // if we were unable to find good enough node - we'll map this node to the rootNode\n            if (!m) {\n                rootNode.addDownstreamNode(node);\n            }\n\n            // i hope we won't deadlock here? :)\n            synchronized (this) {\n                Collections.sort(sortedNodes);\n            }\n        } else if (buildMode == MeshBuildMode.PLAIN) {\n            // nothing to do here\n        }\n    }"}, {"instruction": "This method returns similarity of the document to specific label, based on mean value\n\n@param rawText\n@param label\n@return", "input": "Java", "output": "@Deprecated\n    public double similarityToLabel(String rawText, String label) {\n        if (tokenizerFactory == null)\n            throw new IllegalStateException(\"TokenizerFactory should be defined, prior to predict() call\");\n\n        List<String> tokens = tokenizerFactory.create(rawText).getTokens();\n        List<VocabWord> document = new ArrayList<>();\n        for (String token : tokens) {\n            if (vocab.containsWord(token)) {\n                document.add(vocab.wordFor(token));\n            }\n        }\n        return similarityToLabel(document, label);\n    }"}, {"instruction": "function defines the last dispatched time comparator.\n\n@param weight weight of the comparator.", "input": "Java", "output": "private static FactorComparator<Executor> getLstDispatchedTimeComparator(final int weight) {\n    return FactorComparator\n        .create(LSTDISPATCHED_COMPARATOR_NAME, weight, new Comparator<Executor>() {\n\n          @Override\n          public int compare(final Executor o1, final Executor o2) {\n            final ExecutorInfo stat1 = o1.getExecutorInfo();\n            final ExecutorInfo stat2 = o2.getExecutorInfo();\n\n            final int result = 0;\n            if (statisticsObjectCheck(stat1, stat2, LSTDISPATCHED_COMPARATOR_NAME)) {\n              return result;\n            }\n            // Note: an earlier date time indicates higher weight.\n            return ((Long) stat2.getLastDispatchedTime()).compareTo(stat1.getLastDispatchedTime());\n          }\n        });\n  }"}, {"instruction": "\u8fdb\u884c\u9012\u5f52\u89e3\u6790\u6ce8\u89e3\uff0c\u76f4\u5230\u5168\u90e8\u90fd\u662f\u5143\u6ce8\u89e3\u4e3a\u6b62\n\n@param annotations Class, Method, Field\u7b49", "input": "Java", "output": "private void parseDeclared(Annotation[] annotations) {\r\n\t\tClass<? extends Annotation> annotationType;\r\n\t\t// \u76f4\u63a5\u6ce8\u89e3\r\n\t\tfor (Annotation annotation : annotations) {\r\n\t\t\tannotationType = annotation.annotationType();\r\n\t\t\tif (false == META_ANNOTATIONS.contains(annotationType)) {\r\n\t\t\t\tdeclaredAnnotationMap.put(annotationType, annotation);\r\n\t\t\t\tparseDeclared(annotationType.getDeclaredAnnotations());\r\n\t\t\t}\r\n\t\t}\r\n\t}"}, {"instruction": "${expectedBulkLength}\\r\\n <here> {data...}\\r\\n", "input": "Java", "output": "private boolean decodeBulkStringContent(ByteBuf in, List<Object> out) throws Exception {\n        final int readableBytes = in.readableBytes();\n        if (readableBytes == 0 || remainingBulkLength == 0 && readableBytes < RedisConstants.EOL_LENGTH) {\n            return false;\n        }\n\n        // if this is last frame.\n        if (readableBytes >= remainingBulkLength + RedisConstants.EOL_LENGTH) {\n            ByteBuf content = in.readSlice(remainingBulkLength);\n            readEndOfLine(in);\n            // Only call retain after readEndOfLine(...) as the method may throw an exception.\n            out.add(new DefaultLastBulkStringRedisContent(content.retain()));\n            resetDecoder();\n            return true;\n        }\n\n        // chunked write.\n        int toRead = Math.min(remainingBulkLength, readableBytes);\n        remainingBulkLength -= toRead;\n        out.add(new DefaultBulkStringRedisContent(in.readSlice(toRead).retain()));\n        return true;\n    }"}, {"instruction": "Sets the named ports for the specified instance group.\n\n<p>Sample code:\n\n<pre><code>\ntry (InstanceGroupClient instanceGroupClient = InstanceGroupClient.create()) {\nProjectZoneInstanceGroupName instanceGroup = ProjectZoneInstanceGroupName.of(\"[PROJECT]\", \"[ZONE]\", \"[INSTANCE_GROUP]\");\nInstanceGroupsSetNamedPortsRequest instanceGroupsSetNamedPortsRequestResource = InstanceGroupsSetNamedPortsRequest.newBuilder().build();\nOperation response = instanceGroupClient.setNamedPortsInstanceGroup(instanceGroup, instanceGroupsSetNamedPortsRequestResource);\n}\n</code></pre>\n\n@param instanceGroup The name of the instance group where the named ports are updated.\n@param instanceGroupsSetNamedPortsRequestResource\n@throws com.google.api.gax.rpc.ApiException if the remote call fails", "input": "Java", "output": "@BetaApi\n  public final Operation setNamedPortsInstanceGroup(\n      ProjectZoneInstanceGroupName instanceGroup,\n      InstanceGroupsSetNamedPortsRequest instanceGroupsSetNamedPortsRequestResource) {\n\n    SetNamedPortsInstanceGroupHttpRequest request =\n        SetNamedPortsInstanceGroupHttpRequest.newBuilder()\n            .setInstanceGroup(instanceGroup == null ? null : instanceGroup.toString())\n            .setInstanceGroupsSetNamedPortsRequestResource(\n                instanceGroupsSetNamedPortsRequestResource)\n            .build();\n    return setNamedPortsInstanceGroup(request);\n  }"}, {"instruction": "Returns the concatenation of 8-bit, length prefixed protocol names.\nhttp://tools.ietf.org/html/draft-agl-tls-nextprotoneg-04#page-4", "input": "Java", "output": "public static byte[] concatLengthPrefixed(List<Protocol> protocols) {\n    Buffer result = new Buffer();\n    for (int i = 0, size = protocols.size(); i < size; i++) {\n      Protocol protocol = protocols.get(i);\n      if (protocol == Protocol.HTTP_1_0) continue; // No HTTP/1.0 for ALPN.\n      result.writeByte(protocol.toString().length());\n      result.writeUtf8(protocol.toString());\n    }\n    return result.readByteArray();\n  }"}, {"instruction": "\u8f6c\u4e49\u4e0d\u53ef\u89c1\u5b57\u7b26<br>\n\u89c1\uff1ahttps://en.wikibooks.org/wiki/Unicode/Character_reference/0000-0FFF\n\n@param c \u5b57\u7b26\n@return \u8f6c\u4e49\u540e\u7684\u5b57\u7b26\u4e32", "input": "Java", "output": "private static String escape(char c) {\r\n\t\tswitch (c) {\r\n\t\tcase '\\b':\r\n\t\t\treturn \"\\\\b\";\r\n\t\tcase '\\t':\r\n\t\t\treturn \"\\\\t\";\r\n\t\tcase '\\n':\r\n\t\t\treturn \"\\\\n\";\r\n\t\tcase '\\f':\r\n\t\t\treturn \"\\\\f\";\r\n\t\tcase '\\r':\r\n\t\t\treturn \"\\\\r\";\r\n\t\tdefault:\r\n\t\t\tif (c < StrUtil.C_SPACE || //\r\n\t\t\t\t\t(c >= '\\u0080' && c <= '\\u00a0') || //\r\n\t\t\t\t\t(c >= '\\u2000' && c <= '\\u2010') || //\r\n\t\t\t\t\t(c >= '\\u2028' && c <= '\\u202F') || //\r\n\t\t\t\t\t(c >= '\\u2066' && c <= '\\u206F')//\r\n\t\t\t) {\r\n\t\t\t\treturn HexUtil.toUnicodeHex(c);\r\n\t\t\t} else {\r\n\t\t\t\treturn Character.toString(c);\r\n\t\t\t}\r\n\t\t}\r\n\t}"}, {"instruction": "Parse insert values.\n\n@param insertStatement insert statement", "input": "Java", "output": "public void parse(final InsertStatement insertStatement) {\n        Collection<Keyword> valueKeywords = new LinkedList<>();\n        valueKeywords.add(DefaultKeyword.VALUES);\n        valueKeywords.addAll(Arrays.asList(getSynonymousKeywordsForValues()));\n        if (lexerEngine.skipIfEqual(valueKeywords.toArray(new Keyword[valueKeywords.size()]))) {\n            parseValues(insertStatement);\n        }\n    }"}, {"instruction": "Adds multiple SegmentChunks.\n\n@param segmentChunks The SegmentChunks to add. These SegmentChunks must be in continuity of any existing SegmentChunks.", "input": "Java", "output": "synchronized void addChunks(List<SegmentChunk> segmentChunks) {\n        Preconditions.checkState(!this.sealed, \"Cannot add SegmentChunks for a Sealed Handle.\");\n        long expectedOffset = 0;\n        if (this.segmentChunks.size() > 0) {\n            expectedOffset = this.segmentChunks.get(this.segmentChunks.size() - 1).getLastOffset();\n        } else if (segmentChunks.size() > 0) {\n            expectedOffset = segmentChunks.get(0).getStartOffset();\n        }\n\n        for (SegmentChunk s : segmentChunks) {\n            Preconditions.checkArgument(s.getStartOffset() == expectedOffset,\n                    \"Invalid SegmentChunk StartOffset. Expected %s, given %s.\", expectedOffset, s.getStartOffset());\n            expectedOffset += s.getLength();\n        }\n\n        this.segmentChunks.addAll(segmentChunks);\n        this.activeChunkHandle = null;\n    }"}, {"instruction": "Lists time series that match a filter. This method does not require a Stackdriver account.\n\n<p>Sample code:\n\n<pre><code>\ntry (MetricServiceClient metricServiceClient = MetricServiceClient.create()) {\nProjectName name = ProjectName.of(\"[PROJECT]\");\nString filter = \"\";\nTimeInterval interval = TimeInterval.newBuilder().build();\nListTimeSeriesRequest.TimeSeriesView view = ListTimeSeriesRequest.TimeSeriesView.FULL;\nfor (TimeSeries element : metricServiceClient.listTimeSeries(name, filter, interval, view).iterateAll()) {\n// doThingsWith(element);\n}\n}\n</code></pre>\n\n@param name The project on which to execute the request. The format is\n\"projects/{project_id_or_number}\".\n@param filter A [monitoring filter](/monitoring/api/v3/filters) that specifies which time\nseries should be returned. The filter must specify a single metric type, and can\nadditionally specify metric labels and other information. For example:\n<p>metric.type = \"compute.googleapis.com/instance/cpu/usage_time\" AND\nmetric.label.instance_name = \"my-instance-name\"\n@param interval The time interval for which results should be returned. Only time series that\ncontain data points in the specified interval are included in the response.\n@param view Specifies which information is returned about the time series.\n@throws com.google.api.gax.rpc.ApiException if the remote call fails", "input": "Java", "output": "public final ListTimeSeriesPagedResponse listTimeSeries(\n      ProjectName name,\n      String filter,\n      TimeInterval interval,\n      ListTimeSeriesRequest.TimeSeriesView view) {\n    ListTimeSeriesRequest request =\n        ListTimeSeriesRequest.newBuilder()\n            .setName(name == null ? null : name.toString())\n            .setFilter(filter)\n            .setInterval(interval)\n            .setView(view)\n            .build();\n    return listTimeSeries(request);\n  }"}, {"instruction": "This method builds\n@param op", "input": "Java", "output": "public void processStackCall(Op op, long timeStart) {\n        //StackTraceElement stack[] = Thread.currentThread().getStackTrace();\n\n        long timeSpent = (System.nanoTime() - timeStart) / 1000;\n\n        /*\n           basically we want to unroll stack trace for few levels ABOVE nd4j classes\n           and update invocations list for last few levels, to keep that stat on few levels\n         */\n\n        methodsAggregator.incrementCount(timeSpent);\n    }"}, {"instruction": "Returns the class name for the given logical name and trailing name. For example \"person\" and \"Controller\" would evaluate to \"PersonController\".\n\n@param logicalName  The logical name\n@param trailingName The trailing name\n@return The class name", "input": "Java", "output": "public static String getClassName(String logicalName, String trailingName) {\n        if (isBlank(logicalName)) {\n            throw new IllegalArgumentException(\"Argument [logicalName] cannot be null or blank\");\n        }\n\n        String className = logicalName.substring(0, 1).toUpperCase(Locale.ENGLISH) + logicalName.substring(1);\n        if (trailingName != null) {\n            className = className + trailingName;\n        }\n        return className;\n    }"}, {"instruction": "\u79d2\u6570\u8f6c\u4e3a\u65f6\u95f4\u683c\u5f0f(HH:mm:ss)<br>\n\u53c2\u8003\uff1ahttps://github.com/iceroot\n\n@param seconds \u9700\u8981\u8f6c\u6362\u7684\u79d2\u6570\n@return \u8f6c\u6362\u540e\u7684\u5b57\u7b26\u4e32\n@since 3.1.2", "input": "Java", "output": "public static String secondToTime(int seconds) {\r\n\t\tif (seconds < 0) {\r\n\t\t\tthrow new IllegalArgumentException(\"Seconds must be a positive number!\");\r\n\t\t}\r\n\r\n\t\tint hour = seconds / 3600;\r\n\t\tint other = seconds % 3600;\r\n\t\tint minute = other / 60;\r\n\t\tint second = other % 60;\r\n\t\tfinal StringBuilder sb = new StringBuilder();\r\n\t\tif (hour < 10) {\r\n\t\t\tsb.append(\"0\");\r\n\t\t}\r\n\t\tsb.append(hour);\r\n\t\tsb.append(\":\");\r\n\t\tif (minute < 10) {\r\n\t\t\tsb.append(\"0\");\r\n\t\t}\r\n\t\tsb.append(minute);\r\n\t\tsb.append(\":\");\r\n\t\tif (second < 10) {\r\n\t\t\tsb.append(\"0\");\r\n\t\t}\r\n\t\tsb.append(second);\r\n\t\treturn sb.toString();\r\n\t}"}, {"instruction": "/*\nReturns the JVM-specific size of a primitive type.", "input": "Java", "output": "private static int sizeofPrimitiveType(final Class type) {\n        if (type == int.class) {\n            return INT_FIELD_SIZE;\n        } else if (type == long.class) {\n            return LONG_FIELD_SIZE;\n        } else if (type == short.class) {\n            return SHORT_FIELD_SIZE;\n        } else if (type == byte.class) {\n            return BYTE_FIELD_SIZE;\n        } else if (type == boolean.class) {\n            return BOOLEAN_FIELD_SIZE;\n        } else if (type == char.class) {\n            return CHAR_FIELD_SIZE;\n        } else if (type == double.class) {\n            return DOUBLE_FIELD_SIZE;\n        } else if (type == float.class) {\n            return FLOAT_FIELD_SIZE;\n        } else {\n            throw new IllegalArgumentException(\"not primitive: \" + type);\n        }\n    }"}, {"instruction": "Set the {@code Supplier} of {@link ClientHttpRequestFactory} that should be called\neach time we {@link #build()} a new {@link RestTemplate} instance.\n@param requestFactorySupplier the supplier for the request factory\n@return a new builder instance\n@since 2.0.0", "input": "Java", "output": "public RestTemplateBuilder requestFactory(\n\t\t\tSupplier<ClientHttpRequestFactory> requestFactorySupplier) {\n\t\tAssert.notNull(requestFactorySupplier,\n\t\t\t\t\"RequestFactory Supplier must not be null\");\n\t\treturn new RestTemplateBuilder(this.detectRequestFactory, this.rootUri,\n\t\t\t\tthis.messageConverters, requestFactorySupplier, this.uriTemplateHandler,\n\t\t\t\tthis.errorHandler, this.basicAuthentication, this.restTemplateCustomizers,\n\t\t\t\tthis.requestFactoryCustomizer, this.interceptors);\n\t}"}, {"instruction": "Gets a list from an object for the given key.  If the key is not present, this returns null.\nIf the value is not a List, throws an exception.", "input": "Java", "output": "@SuppressWarnings(\"unchecked\")\n  @Nullable\n  static List<?> getList(Map<String, ?> obj, String key) {\n    assert key != null;\n    if (!obj.containsKey(key)) {\n      return null;\n    }\n    Object value = obj.get(key);\n    if (!(value instanceof List)) {\n      throw new ClassCastException(\n          String.format(\"value '%s' for key '%s' in '%s' is not List\", value, key, obj));\n    }\n    return (List<?>) value;\n  }"}, {"instruction": "Returns type information for Java arrays of primitive type (such as <code>byte[]</code>). The array\nmust not be null.\n\n@param elementType element type of the array (e.g. Types.BOOLEAN, Types.INT, Types.DOUBLE)", "input": "Java", "output": "public static TypeInformation<?> PRIMITIVE_ARRAY(TypeInformation<?> elementType) {\n\t\tif (elementType == BOOLEAN) {\n\t\t\treturn PrimitiveArrayTypeInfo.BOOLEAN_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == BYTE) {\n\t\t\treturn PrimitiveArrayTypeInfo.BYTE_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == SHORT) {\n\t\t\treturn PrimitiveArrayTypeInfo.SHORT_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == INT) {\n\t\t\treturn PrimitiveArrayTypeInfo.INT_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == LONG) {\n\t\t\treturn PrimitiveArrayTypeInfo.LONG_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == FLOAT) {\n\t\t\treturn PrimitiveArrayTypeInfo.FLOAT_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == DOUBLE) {\n\t\t\treturn PrimitiveArrayTypeInfo.DOUBLE_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t} else if (elementType == CHAR) {\n\t\t\treturn PrimitiveArrayTypeInfo.CHAR_PRIMITIVE_ARRAY_TYPE_INFO;\n\t\t}\n\t\tthrow new IllegalArgumentException(\"Invalid element type for a primitive array.\");\n\t}"}, {"instruction": "Listen for update notifications for the auth storage", "input": "Java", "output": "@POST\n  @Path(\"/listen/{authenticatorName}\")\n  @Produces(MediaType.APPLICATION_JSON)\n  @Consumes(MediaType.APPLICATION_JSON)\n  @ResourceFilters(BasicSecurityResourceFilter.class)\n  public Response authenticatorUpdateListener(\n      @Context HttpServletRequest req,\n      @PathParam(\"authenticatorName\") final String authenticatorName,\n      byte[] serializedUserMap\n  )\n  {\n    return handler.authenticatorUpdateListener(authenticatorName, serializedUserMap);\n  }"}, {"instruction": "For callers where simplicity is desired\u00a0over flexibility. This method does it all in one call. If the request\nis unauthorized, an IllegalStateException will be thrown. Logs and metrics are emitted when the Sequence is\neither fully iterated or throws an exception.\n\n@param query                the query\n@param authenticationResult authentication result indicating identity of the requester\n@param remoteAddress        remote address, for logging; or null if unknown\n\n@return results", "input": "Java", "output": "@SuppressWarnings(\"unchecked\")\n  public <T> Sequence<T> runSimple(\n      final Query<T> query,\n      final AuthenticationResult authenticationResult,\n      @Nullable final String remoteAddress\n  )\n  {\n    initialize(query);\n\n    final Sequence<T> results;\n\n    try {\n      final Access access = authorize(authenticationResult);\n      if (!access.isAllowed()) {\n        throw new ISE(\"Unauthorized\");\n      }\n\n      final QueryLifecycle.QueryResponse queryResponse = execute();\n      results = queryResponse.getResults();\n    }\n    catch (Throwable e) {\n      emitLogsAndMetrics(e, remoteAddress, -1);\n      throw e;\n    }\n\n    return Sequences.wrap(\n        results,\n        new SequenceWrapper()\n        {\n          @Override\n          public void after(final boolean isDone, final Throwable thrown)\n          {\n            emitLogsAndMetrics(thrown, remoteAddress, -1);\n          }\n        }\n    );\n  }"}, {"instruction": "Conditionally schedules the asynchronous maintenance task after a write operation. If the\ntask status was IDLE or REQUIRED then the maintenance task is scheduled immediately. If it\nis already processing then it is set to transition to REQUIRED upon completion so that a new\nexecution is triggered by the next operation.", "input": "Java", "output": "void scheduleAfterWrite() {\n    for (;;) {\n      switch (drainStatus()) {\n        case IDLE:\n          casDrainStatus(IDLE, REQUIRED);\n          scheduleDrainBuffers();\n          return;\n        case REQUIRED:\n          scheduleDrainBuffers();\n          return;\n        case PROCESSING_TO_IDLE:\n          if (casDrainStatus(PROCESSING_TO_IDLE, PROCESSING_TO_REQUIRED)) {\n            return;\n          }\n          continue;\n        case PROCESSING_TO_REQUIRED:\n          return;\n        default:\n          throw new IllegalStateException();\n      }\n    }\n  }"}, {"instruction": "\u8fd4\u56de\u6240\u6709\u5b9e\u4f8b curl http://127.0.0.1:8081/destinations", "input": "Java", "output": "@GetMapping(\"/destinations\")\n    public List<Map<String, String>> destinations() {\n        List<Map<String, String>> result = new ArrayList<>();\n        Set<String> destinations = adapterCanalConfig.DESTINATIONS;\n        for (String destination : destinations) {\n            Map<String, String> resMap = new LinkedHashMap<>();\n            boolean status = syncSwitch.status(destination);\n            String resStatus;\n            if (status) {\n                resStatus = \"on\";\n            } else {\n                resStatus = \"off\";\n            }\n            resMap.put(\"destination\", destination);\n            resMap.put(\"status\", resStatus);\n            result.add(resMap);\n        }\n        return result;\n    }"}, {"instruction": "When a ephemeral worker node disappears from ZK, incomplete running tasks will be retried by\nthe logic in the status listener. We still have to make sure there are no tasks assigned\nto the worker but not yet running.\n\n@param worker - the removed worker", "input": "Java", "output": "private void removeWorker(final Worker worker)\n  {\n    log.info(\"Kaboom! Worker[%s] removed!\", worker.getHost());\n\n    final ZkWorker zkWorker = zkWorkers.get(worker.getHost());\n    if (zkWorker != null) {\n      try {\n        scheduleTasksCleanupForWorker(worker.getHost(), getAssignedTasks(worker));\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n      finally {\n        try {\n          zkWorker.close();\n        }\n        catch (Exception e) {\n          log.error(e, \"Exception closing worker[%s]!\", worker.getHost());\n        }\n        zkWorkers.remove(worker.getHost());\n        checkBlackListedNodes();\n      }\n    }\n    lazyWorkers.remove(worker.getHost());\n  }"}, {"instruction": "Lists all shared VPC host projects visible to the user in an organization.\n\n<p>Sample code:\n\n<pre><code>\ntry (ProjectClient projectClient = ProjectClient.create()) {\nProjectName project = ProjectName.of(\"[PROJECT]\");\nProjectsListXpnHostsRequest projectsListXpnHostsRequestResource = ProjectsListXpnHostsRequest.newBuilder().build();\nfor (Project element : projectClient.listXpnHostsProjects(project, projectsListXpnHostsRequestResource).iterateAll()) {\n// doThingsWith(element);\n}\n}\n</code></pre>\n\n@param project Project ID for this request.\n@param projectsListXpnHostsRequestResource\n@throws com.google.api.gax.rpc.ApiException if the remote call fails", "input": "Java", "output": "@BetaApi\n  public final ListXpnHostsProjectsPagedResponse listXpnHostsProjects(\n      ProjectName project, ProjectsListXpnHostsRequest projectsListXpnHostsRequestResource) {\n    ListXpnHostsProjectsHttpRequest request =\n        ListXpnHostsProjectsHttpRequest.newBuilder()\n            .setProject(project == null ? null : project.toString())\n            .setProjectsListXpnHostsRequestResource(projectsListXpnHostsRequestResource)\n            .build();\n    return listXpnHostsProjects(request);\n  }"}, {"instruction": "An expectation to check if js executable.\n\nUseful when you know that there should be a Javascript value or something at the stage.\n\n@param javaScript used as executable script\n@return true once javaScript executed without errors", "input": "Java", "output": "public static ExpectedCondition<Boolean> javaScriptThrowsNoExceptions(final String javaScript) {\n    return new ExpectedCondition<Boolean>() {\n      @Override\n      public Boolean apply(WebDriver driver) {\n        try {\n          ((JavascriptExecutor) driver).executeScript(javaScript);\n          return true;\n        } catch (WebDriverException e) {\n          return false;\n        }\n      }\n\n      @Override\n      public String toString() {\n        return String.format(\"js %s to be executable\", javaScript);\n      }\n    };\n  }"}, {"instruction": "Adds offset to the underlying {@link SortTableOperation} if it is a valid one.\n\n@param offset offset to add\n@param child should be {@link SortTableOperation}\n@return valid sort operation with applied offset", "input": "Java", "output": "public TableOperation createLimitWithOffset(int offset, TableOperation child) {\n\t\tSortTableOperation previousSort = validateAndGetChildSort(child);\n\n\t\tif (offset < 0) {\n\t\t\tthrow new ValidationException(\"Offset should be greater or equal 0\");\n\t\t}\n\n\t\tif (previousSort.getOffset() != -1) {\n\t\t\tthrow new ValidationException(\"OFFSET already defined\");\n\t\t}\n\n\t\treturn new SortTableOperation(previousSort.getOrder(), previousSort.getChild(), offset, -1);\n\t}"}, {"instruction": "Returns the unique id of the instance.\n(Note) now that id is set at creation time within the instanceProvider, why do the other checks?\nThis is still necessary for backwards compatibility when upgrading in a deployment with multiple\nclient versions (some with the change, some without).\n\n@return the unique id.", "input": "Java", "output": "@Override\n    @JsonIgnore\n    public String getId() {\n        if (instanceId != null && !instanceId.isEmpty()) {\n            return instanceId;\n        } else if (dataCenterInfo instanceof AmazonInfo) {\n            String uniqueId = ((AmazonInfo) dataCenterInfo).getId();\n            if (uniqueId != null && !uniqueId.isEmpty()) {\n                return uniqueId;\n            }\n        }\n        return hostName;\n    }"}, {"instruction": "Setup with direct executors, small payloads and the default flow-control window.", "input": "Java", "output": "@Setup(Level.Trial)\n  public void setup() throws Exception {\n    super.setup(clientExecutor,\n        ExecutorType.DIRECT,\n        MessageSize.SMALL,\n        responseSize,\n        FlowWindowSize.MEDIUM,\n        ChannelType.NIO,\n        maxConcurrentStreams,\n        channelCount);\n    callCounter = new AtomicLong();\n    completed = new AtomicBoolean();\n    record = new AtomicBoolean();\n    latch =\n        startFlowControlledStreamingCalls(maxConcurrentStreams, callCounter, record, completed, 1);\n  }"}, {"instruction": "Delete file or folder.\n\n@param file file.\n\n@return is succeed.\n\n@see #delFileOrFolder(String)", "input": "Java", "output": "public static boolean delFileOrFolder(File file) {\n        if (file == null || !file.exists()) {\n            // do nothing\n        } else if (file.isFile()) {\n            file.delete();\n        } else if (file.isDirectory()) {\n            File[] files = file.listFiles();\n            if (files != null) {\n                for (File sonFile : files) {\n                    delFileOrFolder(sonFile);\n                }\n            }\n            file.delete();\n        }\n        return true;\n    }"}, {"instruction": "Gets all.\n\n@return the all", "input": "Java", "output": "public List<RegisteredService> getAll() {\n        val scan = new ScanRequest(dynamoDbProperties.getTableName());\n        LOGGER.debug(\"Scanning table with request [{}]\", scan);\n        val result = this.amazonDynamoDBClient.scan(scan);\n        LOGGER.debug(\"Scanned table with result [{}]\", scan);\n        return result.getItems()\n            .stream()\n            .map(this::deserializeServiceFromBinaryBlob)\n            .filter(Objects::nonNull)\n            .sorted(Comparator.comparingInt(RegisteredService::getEvaluationOrder))\n            .collect(Collectors.toList());\n    }"}, {"instruction": "Signallable activity behavior", "input": "Java", "output": "public void trigger(DelegateExecution execution, String signalName, Object signalData) {\n    if (activityBehaviorInstance == null) {\n      activityBehaviorInstance = getActivityBehaviorInstance();\n    }\n\n    if (activityBehaviorInstance instanceof TriggerableActivityBehavior) {\n      ((TriggerableActivityBehavior) activityBehaviorInstance).trigger(execution, signalName, signalData);\n    } else {\n      throw new ActivitiException(\"signal() can only be called on a \" + TriggerableActivityBehavior.class.getName() + \" instance\");\n    }\n  }"}, {"instruction": "Invalidates a Hadoop authentication token file", "input": "Java", "output": "public static void cancelHadoopTokens(HadoopSecurityManager hadoopSecurityManager,\n      String userToProxy, File tokenFile, Logger log) {\n    if (tokenFile == null) {\n      return;\n    }\n    try {\n      hadoopSecurityManager.cancelTokens(tokenFile, userToProxy, log);\n    } catch (HadoopSecurityManagerException e) {\n      log.error(e.getCause() + e.getMessage());\n    } catch (Exception e) {\n      log.error(e.getCause() + e.getMessage());\n    }\n    if (tokenFile.exists()) {\n      tokenFile.delete();\n    }\n  }"}, {"instruction": "Creates a {@link PemEncoded} value from the {@link PrivateKey}.", "input": "Java", "output": "static PemEncoded toPEM(ByteBufAllocator allocator, boolean useDirect, PrivateKey key) {\n        // We can take a shortcut if the private key happens to be already\n        // PEM/PKCS#8 encoded. This is the ideal case and reason why all\n        // this exists. It allows the user to pass pre-encoded bytes straight\n        // into OpenSSL without having to do any of the extra work.\n        if (key instanceof PemEncoded) {\n            return ((PemEncoded) key).retain();\n        }\n\n        byte[] bytes = key.getEncoded();\n        if (bytes == null) {\n            throw new IllegalArgumentException(key.getClass().getName() + \" does not support encoding\");\n        }\n\n        return toPEM(allocator, useDirect, bytes);\n    }"}, {"instruction": "Create Unicode code points from a String.\n\n@param s\na String to convert to an Unicode code point array\n\n@return the corresponding array of integers representing Unicode code\npoints", "input": "Java", "output": "public static int[] stringToCodePoints(final String s) {\n        final int m = s.codePointCount(0, s.length());\n        final int[] codePoints = new int[m];\n        int j = 0;\n        for (int offset = 0; offset < s.length();) {\n            final int codepoint = s.codePointAt(offset);\n            codePoints[j++] = codepoint;\n            offset += Character.charCount(codepoint);\n        }\n        return codePoints;\n    }"}, {"instruction": "\u6839\u636e\u7279\u5f81\u51fd\u6570\u8ba1\u7b97\u8f93\u51fa\n\n@param table\n@param current\n@return", "input": "Java", "output": "protected LinkedList<double[]> computeScoreList(Table table, int current)\n    {\n        LinkedList<double[]> scoreList = new LinkedList<double[]>();\n        for (FeatureTemplate featureTemplate : featureTemplateList)\n        {\n            char[] o = featureTemplate.generateParameter(table, current);\n            FeatureFunction featureFunction = featureFunctionTrie.get(o);\n            if (featureFunction == null) continue;\n            scoreList.add(featureFunction.w);\n        }\n\n        return scoreList;\n    }"}, {"instruction": "Sets the order of keys for range partitioning.\nNOTE: Only valid for {@link PartitionMethod#RANGE}.\n\n@param orders array of orders for each specified partition key\n@return The partitioneOperator with properly set orders for given keys", "input": "Java", "output": "@PublicEvolving\n\tpublic PartitionOperator<T> withOrders(Order... orders) {\n\t\tPreconditions.checkState(pMethod == PartitionMethod.RANGE, \"Orders cannot be applied for %s partition \" +\n\t\t\t\t\"method\", pMethod);\n\t\tPreconditions.checkArgument(pKeys.getOriginalKeyFieldTypes().length == orders.length, \"The number of key \" +\n\t\t\t\t\"fields and orders should be the same.\");\n\t\tthis.orders = orders;\n\n\t\treturn this;\n\t}"}, {"instruction": "Update the internal state of RNN layers after a truncated BPTT fit call", "input": "Java", "output": "protected void rnnUpdateStateWithTBPTTState() {\n        for (int i = 0; i < layers.length; i++) {\n            if (layers[i] instanceof RecurrentLayer) {\n                RecurrentLayer l = ((RecurrentLayer) layers[i]);\n                l.rnnSetPreviousState(l.rnnGetTBPTTState());\n            } else if (layers[i] instanceof MultiLayerNetwork) {\n                ((MultiLayerNetwork) layers[i]).updateRnnStateWithTBPTTState();\n            }\n        }\n    }"}, {"instruction": "\u5378\u8f7d\u6a21\u5757\n\n@param moduleName module name", "input": "Java", "output": "public static void uninstallModule(String moduleName) {\n        Module module = INSTALLED_MODULES.get(moduleName);\n        if (module != null) {\n            try {\n                module.uninstall();\n                INSTALLED_MODULES.remove(moduleName);\n            } catch (Exception e) {\n                if (LOGGER.isWarnEnabled()) {\n                    LOGGER.warn(\"Error when uninstall module \" + moduleName, e);\n                }\n            }\n        }\n    }"}, {"instruction": "The column size for this type.\nFor numeric data this is the maximum precision.\nFor character data this is the length in characters.\nFor datetime types this is the length in characters of the String representation\n(assuming the maximum allowed precision of the fractional seconds component).\nFor binary data this is the length in bytes.\nNull is returned for data types where the column size is not applicable.", "input": "Java", "output": "public Integer getColumnSize() {\n    if (type.isNumericType()) {\n      return getPrecision();\n    }\n    switch (type) {\n    case STRING_TYPE:\n    case BINARY_TYPE:\n      return Integer.MAX_VALUE;\n    case CHAR_TYPE:\n    case VARCHAR_TYPE:\n      return typeQualifiers.getCharacterMaximumLength();\n    case DATE_TYPE:\n      return 10;\n    case TIMESTAMP_TYPE:\n      return 29;\n    default:\n      return null;\n    }\n  }"}, {"instruction": "checks whether a value part of the effective predicate is likely to be part of this bloom filter", "input": "Java", "output": "@VisibleForTesting\n    public static boolean checkInBloomFilter(BloomFilter bloomFilter, Object predicateValue, Type sqlType)\n    {\n        if (sqlType == TINYINT || sqlType == SMALLINT || sqlType == INTEGER || sqlType == BIGINT) {\n            return bloomFilter.testLong(((Number) predicateValue).longValue());\n        }\n\n        if (sqlType == DOUBLE) {\n            return bloomFilter.testDouble((Double) predicateValue);\n        }\n\n        if (sqlType instanceof VarcharType || sqlType instanceof VarbinaryType) {\n            return bloomFilter.test(((Slice) predicateValue).getBytes());\n        }\n\n        // todo support DECIMAL, FLOAT, DATE, TIMESTAMP, and CHAR\n        return true;\n    }"}, {"instruction": "Gets all the items recursively contained in this collection in a read-only view.\n<p>\nThe default implementation recursively adds the items of all contained Views\nin case this view implements {@link ViewGroup}, which should be enough for most cases.\n\n@since 1.520", "input": "Java", "output": "public Collection<TopLevelItem> getAllItems() {\n\n        if (this instanceof ViewGroup) {\n            final Collection<TopLevelItem> items = new LinkedHashSet<>(getItems());\n\n            for(View view: ((ViewGroup) this).getViews()) {\n                items.addAll(view.getAllItems());\n            }\n            return Collections.unmodifiableCollection(items);\n        } else {\n            return getItems();\n        }\n    }"}, {"instruction": "/*\nColor transition method.", "input": "Java", "output": "public Object evaluate(float fraction, Object startValue, Object endValue) {\n        int startInt = (Integer) startValue;\n        int startA = (startInt >> 24) & 0xff;\n        int startR = (startInt >> 16) & 0xff;\n        int startG = (startInt >> 8) & 0xff;\n        int startB = startInt & 0xff;\n\n        int endInt = (Integer) endValue;\n        int endA = (endInt >> 24) & 0xff;\n        int endR = (endInt >> 16) & 0xff;\n        int endG = (endInt >> 8) & 0xff;\n        int endB = endInt & 0xff;\n\n        return (int) ((startA + (int) (fraction * (endA - startA))) << 24) |\n                (int) ((startR + (int) (fraction * (endR - startR))) << 16) |\n                (int) ((startG + (int) (fraction * (endG - startG))) << 8) |\n                (int) ((startB + (int) (fraction * (endB - startB))));\n    }"}, {"instruction": "Parse RFC 7235 challenges. This is awkward because we need to look ahead to know how to\ninterpret a token.\n\n<p>For example, the first line has a parameter name/value pair and the second line has a single\ntoken68:\n\n<pre>   {@code\n\nWWW-Authenticate: Digest foo=bar\nWWW-Authenticate: Digest foo=\n}</pre>\n\n<p>Similarly, the first line has one challenge and the second line has two challenges:\n\n<pre>   {@code\n\nWWW-Authenticate: Digest ,foo=bar\nWWW-Authenticate: Digest ,foo\n}</pre>", "input": "Java", "output": "public static List<Challenge> parseChallenges(Headers responseHeaders, String headerName) {\n    List<Challenge> result = new ArrayList<>();\n    for (int h = 0; h < responseHeaders.size(); h++) {\n      if (headerName.equalsIgnoreCase(responseHeaders.name(h))) {\n        Buffer header = new Buffer().writeUtf8(responseHeaders.value(h));\n        try {\n          parseChallengeHeader(result, header);\n        } catch (EOFException e) {\n          Platform.get().log(Platform.WARN, \"Unable to parse challenge\", e);\n        }\n      }\n    }\n    return result;\n  }"}, {"instruction": "Gets the request body from the request.\n\n@param request the request\n@return the request body", "input": "Java", "output": "private static String getRequestBody(final HttpServletRequest request) {\n        val body = readRequestBodyIfAny(request);\n        if (!StringUtils.hasText(body)) {\n            LOGGER.trace(\"Looking at the request attribute [{}] to locate SAML request body\", SamlProtocolConstants.PARAMETER_SAML_REQUEST);\n            return (String) request.getAttribute(SamlProtocolConstants.PARAMETER_SAML_REQUEST);\n        }\n        return body;\n    }"}, {"instruction": "Decodes a byte from the final Run-Length Encoding stage, pulling a new byte from the\nBurrows-Wheeler Transform stage when required.\n@return The decoded byte, or -1 if there are no more bytes", "input": "Java", "output": "public int read() {\n        while (rleRepeat < 1) {\n            if (bwtBytesDecoded == bwtBlockLength) {\n                return -1;\n            }\n\n            int nextByte = decodeNextBWTByte();\n            if (nextByte != rleLastDecodedByte) {\n                // New byte, restart accumulation\n                rleLastDecodedByte = nextByte;\n                rleRepeat = 1;\n                rleAccumulator = 1;\n                crc.updateCRC(nextByte);\n            } else {\n                if (++rleAccumulator == 4) {\n                    // Accumulation complete, start repetition\n                    int rleRepeat = decodeNextBWTByte() + 1;\n                    this.rleRepeat = rleRepeat;\n                    rleAccumulator = 0;\n                    crc.updateCRC(nextByte, rleRepeat);\n                } else {\n                    rleRepeat = 1;\n                    crc.updateCRC(nextByte);\n                }\n            }\n        }\n        rleRepeat--;\n\n        return rleLastDecodedByte;\n    }"}, {"instruction": "This returns the minimized loss values for a given vector.\nIt is assumed that  the x, y pairs are at\nvector[i], vector[i+1]\n@param vector the vector of numbers to getFromOrigin the weights for\n@return a double array with w_0 and w_1 are the associated indices.", "input": "Java", "output": "public static double[] weightsFor(List<Double> vector) {\n        /* split coordinate system */\n        List<double[]> coords = coordSplit(vector);\n        /* x vals */\n        double[] x = coords.get(0);\n        /* y vals */\n        double[] y = coords.get(1);\n\n\n        double meanX = sum(x) / x.length;\n        double meanY = sum(y) / y.length;\n\n        double sumOfMeanDifferences = sumOfMeanDifferences(x, y);\n        double xDifferenceOfMean = sumOfMeanDifferencesOnePoint(x);\n\n        double w_1 = sumOfMeanDifferences / xDifferenceOfMean;\n\n        double w_0 = meanY - (w_1) * meanX;\n\n        //double w_1=(n*sumOfProducts(x,y) - sum(x) * sum(y))/(n*sumOfSquares(x) - Math.pow(sum(x),2));\n\n        //\tdouble w_0=(sum(y) - (w_1 * sum(x)))/n;\n\n        double[] ret = new double[vector.size()];\n        ret[0] = w_0;\n        ret[1] = w_1;\n\n        return ret;\n    }"}, {"instruction": "pretrain is used to build CoOccurrence matrix for GloVe algorithm\n@param iterator", "input": "Java", "output": "@Override\n    public void pretrain(@NonNull SequenceIterator<T> iterator) {\n        // CoOccurence table should be built here\n        coOccurrences = new AbstractCoOccurrences.Builder<T>()\n                        // TODO: symmetric should be handled via VectorsConfiguration\n                        .symmetric(this.symmetric).windowSize(configuration.getWindow()).iterate(iterator)\n                        .workers(workers).vocabCache(vocabCache).maxMemory(maxmemory).build();\n\n        coOccurrences.fit();\n    }"}, {"instruction": "Finds an item whose name (when referenced from the specified context) is closest to the given name.\n@param <T> the type of item being considered\n@param type same as {@code T}\n@param name the supplied name\n@param context a context to start from (used to compute relative names)\n@return the closest available item\n@since 1.538", "input": "Java", "output": "public static @CheckForNull <T extends Item> T findNearest(Class<T> type, String name, ItemGroup context) {\n        List<String> names = new ArrayList<>();\n        for (T item: Jenkins.getInstance().allItems(type)) {\n            names.add(item.getRelativeNameFrom(context));\n        }\n        String nearest = EditDistance.findNearest(name, names);\n        return Jenkins.getInstance().getItem(nearest, context, type);\n    }"}, {"instruction": "This method initializes the working Panel.\n\n@return javax.swing.JScrollPane", "input": "Java", "output": "@Override\r\n\tprotected JPanel getWorkPanel() {\r\n\t\tif (mainPanel == null) {\r\n\t\t\tmainPanel = new JPanel(new BorderLayout());\r\n\r\n\t\t\ttabbedPane = new JTabbedPane();\r\n\t\t\ttabbedPane.addTab(Constant.messages.getString(\"spider.panel.tab.urls\"), getUrlsTableScrollPane());\r\n\t\t\ttabbedPane.addTab(Constant.messages.getString(\"spider.panel.tab.addednodes\"), getAddedNodesTableScrollPane());\r\n\t\t\ttabbedPane.addTab(Constant.messages.getString(\"spider.panel.tab.messages\"), getMessagesTableScrollPanel());\r\n\t\t\ttabbedPane.setSelectedIndex(0);\r\n\r\n\t\t\tmainPanel.add(tabbedPane);\r\n\t\t}\r\n\t\treturn mainPanel;\r\n\t}"}, {"instruction": "\u83b7\u5f97\u5b57\u6bb5\u540d\u548c\u5b57\u6bb5\u63cf\u8ff0Map\u3002\u5185\u90e8\u4f7f\u7528\uff0c\u76f4\u63a5\u83b7\u53d6Bean\u7c7b\u7684PropertyDescriptor\n\n@param clazz Bean\u7c7b\n@param ignoreCase \u662f\u5426\u5ffd\u7565\u5927\u5c0f\u5199\n@return \u5b57\u6bb5\u540d\u548c\u5b57\u6bb5\u63cf\u8ff0Map\n@throws BeanException \u83b7\u53d6\u5c5e\u6027\u5f02\u5e38", "input": "Java", "output": "private static Map<String, PropertyDescriptor> internalGetPropertyDescriptorMap(Class<?> clazz, boolean ignoreCase) throws BeanException {\r\n\t\tfinal PropertyDescriptor[] propertyDescriptors = getPropertyDescriptors(clazz);\r\n\t\tfinal Map<String, PropertyDescriptor> map = ignoreCase ? new CaseInsensitiveMap<String, PropertyDescriptor>(propertyDescriptors.length, 1)\r\n\t\t\t\t: new HashMap<String, PropertyDescriptor>((int) (propertyDescriptors.length), 1);\r\n\r\n\t\tfor (PropertyDescriptor propertyDescriptor : propertyDescriptors) {\r\n\t\t\tmap.put(propertyDescriptor.getName(), propertyDescriptor);\r\n\t\t}\r\n\t\treturn map;\r\n\t}"}, {"instruction": "\u5c06\u6574\u4e2a\u6587\u4ef6\u8bfb\u53d6\u4e3a\u5b57\u8282\u6570\u7ec4\n\n@param path\n@return", "input": "Java", "output": "public static byte[] readBytes(String path)\n    {\n        try\n        {\n            if (IOAdapter == null) return readBytesFromFileInputStream(new FileInputStream(path));\n\n            InputStream is = IOAdapter.open(path);\n            if (is instanceof FileInputStream)\n                return readBytesFromFileInputStream((FileInputStream) is);\n            else\n                return readBytesFromOtherInputStream(is);\n        }\n        catch (Exception e)\n        {\n            logger.warning(\"\u8bfb\u53d6\" + path + \"\u65f6\u53d1\u751f\u5f02\u5e38\" + e);\n        }\n\n        return null;\n    }"}, {"instruction": "For a given commit, will traverse the pipeline and find the time it entered in each stage of the pipeline\n@param commit\n@param dashboard\n@param pipeline\n@return", "input": "Java", "output": "private PipelineResponseCommit applyStageTimestamps(PipelineResponseCommit commit, Dashboard dashboard, Pipeline pipeline,List<PipelineStage> pipelineStageList){\r\n        PipelineResponseCommit returnCommit = new PipelineResponseCommit(commit);\r\n\r\n        for(PipelineStage systemStage : pipelineStageList) {\r\n            //get commits for a given stage\r\n            Map<String, PipelineCommit> commitMap = findCommitsForStage(dashboard, pipeline, systemStage);\r\n\r\n            //if this commit doesnt have a processed timestamp for this stage, add one\r\n            PipelineCommit pipelineCommit = commitMap.get(commit.getScmRevisionNumber());\r\n            if(pipelineCommit != null && !returnCommit.getProcessedTimestamps().containsKey(systemStage.getName())){\r\n                Long timestamp = pipelineCommit.getTimestamp();\r\n                returnCommit.addNewPipelineProcessedTimestamp(systemStage, timestamp);\r\n            }\r\n        }\r\n        return returnCommit;\r\n    }"}, {"instruction": "\u4e0a\u4e0b\u6587\u5f80\u4e0b\u653e\u4e00\u5c42\uff08\u4f8b\u5982\u670d\u52a1\u7aefB\u63a5\u5230A\u7684\u8bf7\u6c42\u540e\u518d\u4f5c\u4e3aC\u7684\u5ba2\u6237\u7aef\u8c03\u7528\uff0c\u8c03\u7528\u524d\u8fd9\u91cc\u5c31\u5148\u628a\u653eA-B\u7684\u4e0a\u4e0b\u6587\u5b58\u8d77\u6765\uff09", "input": "Java", "output": "public static void pushContext() {\n        RpcInternalContext context = LOCAL.get();\n        if (context != null) {\n            Deque<RpcInternalContext> deque = DEQUE_LOCAL.get();\n            if (deque == null) {\n                deque = new ArrayDeque<RpcInternalContext>();\n                DEQUE_LOCAL.set(deque);\n            }\n            deque.push(context);\n            LOCAL.set(null);\n        }\n    }"}, {"instruction": "Picks up a {@link RepositoryBrowser} that matches the\ngiven {@link SCM} from existing other jobs.\n\n@return\nnull if no applicable configuration was found.", "input": "Java", "output": "private RepositoryBrowser infer() {\n        for( AbstractProject p : Jenkins.getInstance().allItems(AbstractProject.class) ) {\n            SCM scm = p.getScm();\n            if (scm!=null && scm.getClass()==owner.getClass() && scm.getBrowser()!=null &&\n                    ((SCMDescriptor)scm.getDescriptor()).isBrowserReusable(scm,owner)) {\n                return scm.getBrowser();\n            }\n        }\n        return null;\n    }"}, {"instruction": "\u7528\u4e8eModel\u5bf9\u8c61\u8f6c\u5316\u4e3aDO\u5bf9\u8c61\n\n@param canal\n@return CanalDO", "input": "Java", "output": "private CanalDO modelToDo(Canal canal) {\n        CanalDO canalDo = new CanalDO();\n        try {\n            canalDo.setId(canal.getId());\n            canalDo.setName(canal.getName());\n            canalDo.setStatus(canal.getStatus());\n            canalDo.setDescription(canal.getDesc());\n            canalDo.setParameters(canal.getCanalParameter());\n            canalDo.setGmtCreate(canal.getGmtCreate());\n            canalDo.setGmtModified(canal.getGmtModified());\n        } catch (Exception e) {\n            logger.error(\"ERROR ## change the canal Model to Do has an exception\");\n            throw new ManagerException(e);\n        }\n        return canalDo;\n    }"}, {"instruction": "Use ZipOutputStream to zip text to byte array, then convert\nbyte array to base64 string, so it can be transferred via http request.\n\n@param srcTxt the src txt\n@return the string in UTF-8 format and base64'ed, or null.", "input": "Java", "output": "@SneakyThrows\n    public static String compress(final String srcTxt) {\n        try (val rstBao = new ByteArrayOutputStream(); val zos = new GZIPOutputStream(rstBao)) {\n            zos.write(srcTxt.getBytes(StandardCharsets.UTF_8));\n            zos.flush();\n            zos.finish();\n            val bytes = rstBao.toByteArray();\n            val base64 = StringUtils.remove(EncodingUtils.encodeBase64(bytes), '\\0');\n            return new String(StandardCharsets.UTF_8.encode(base64).array(), StandardCharsets.UTF_8);\n        }\n    }"}, {"instruction": "\u8f6c\u5316\u6307\u5b9a\u5f02\u5e38\u4e3a\u6765\u81ea\u6216\u8005\u5305\u542b\u6307\u5b9a\u5f02\u5e38\n\n@param <T> \u5f02\u5e38\u7c7b\u578b\n@param throwable \u5f02\u5e38\n@param exceptionClass \u5b9a\u4e49\u7684\u5f15\u8d77\u5f02\u5e38\u7684\u7c7b\n@param checkCause \u5224\u65adcause\n@return \u7ed3\u679c\u4e3anull \u4e0d\u662f\u6765\u81ea\u6216\u8005\u5305\u542b\n@since 4.4.1", "input": "Java", "output": "@SuppressWarnings(\"unchecked\")\n\tpublic static <T extends Throwable> T convertFromOrSuppressedThrowable(Throwable throwable, Class<T> exceptionClass, boolean checkCause) {\n\t\tif (throwable == null || exceptionClass == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (exceptionClass.isAssignableFrom(throwable.getClass())) {\n\t\t\treturn (T) throwable;\n\t\t}\n\t\tif (checkCause) {\n\t\t\tThrowable cause = throwable.getCause();\n\t\t\tif (cause != null && exceptionClass.isAssignableFrom(cause.getClass())) {\n\t\t\t\treturn (T) cause;\n\t\t\t}\n\t\t}\n\t\tThrowable[] throwables = throwable.getSuppressed();\n\t\tif (ArrayUtil.isNotEmpty(throwables)) {\n\t\t\tfor (Throwable throwable1 : throwables) {\n\t\t\t\tif (exceptionClass.isAssignableFrom(throwable1.getClass())) {\n\t\t\t\t\treturn (T) throwable1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}"}, {"instruction": "Return the number of correct predictions according to top N value. For top N = 1 (default) this is equivalent to\nthe number of correct predictions\n@return Number of correct top N predictions", "input": "Java", "output": "public int getTopNCorrectCount() {\n        if (confusion == null)\n            return 0;\n        if (topN <= 1) {\n            int nClasses = confusion().getClasses().size();\n            int countCorrect = 0;\n            for (int i = 0; i < nClasses; i++) {\n                countCorrect += confusion().getCount(i, i);\n            }\n            return countCorrect;\n        }\n        return topNCorrectCount;\n    }"}, {"instruction": "{@inheritDoc}", "input": "Java", "output": "@Override\n    public long reservePermission(Duration timeoutDuration) {\n        long timeoutInNanos = timeoutDuration.toNanos();\n        State modifiedState = updateStateWithBackOff(timeoutInNanos);\n\n        boolean canAcquireImmediately = modifiedState.nanosToWait <= 0;\n        if (canAcquireImmediately) {\n            publishRateLimiterEvent(true);\n            return 0;\n        }\n\n        boolean canAcquireInTime = timeoutInNanos >= modifiedState.nanosToWait;\n        if (canAcquireInTime) {\n            publishRateLimiterEvent(true);\n            return modifiedState.nanosToWait;\n        }\n\n        publishRateLimiterEvent(false);\n        return -1;\n    }"}, {"instruction": "\u5ba2\u6237\u7aef\u5df2\u7ecf\u8d85\u65f6\u4e86\uff08\u4f8b\u5982\u5728\u4e1a\u52a1\u6267\u884c\u65f6\u95f4\u592a\u957f\uff09\uff0c\u4e22\u5f03\u8fd9\u4e2a\u8fd4\u56de\u503c\n\n@param appName       \u5e94\u7528\n@param serviceName   \u670d\u52a1\n@param remoteAddress \u8fdc\u7a0b\u5730\u5740\n@return \u4e22\u5f03\u7684\u5f02\u5e38", "input": "Java", "output": "private SofaRpcException clientTimeoutWhenSendResponse(String appName, String serviceName, String remoteAddress) {\n        String errorMsg = LogCodes.getLog(\n            LogCodes.ERROR_DISCARD_TIMEOUT_RESPONSE, serviceName, remoteAddress);\n        if (LOGGER.isWarnEnabled(appName)) {\n            LOGGER.warnWithApp(appName, errorMsg);\n        }\n        return new SofaRpcException(RpcErrorType.SERVER_UNDECLARED_ERROR, errorMsg);\n    }"}, {"instruction": "Add a {@link ChannelPromise} to this {@link ChannelFlushPromiseNotifier} which will be notified after the given\n{@code pendingDataSize} was reached.", "input": "Java", "output": "public ChannelFlushPromiseNotifier add(ChannelPromise promise, long pendingDataSize) {\n        if (promise == null) {\n            throw new NullPointerException(\"promise\");\n        }\n        checkPositiveOrZero(pendingDataSize, \"pendingDataSize\");\n        long checkpoint = writeCounter + pendingDataSize;\n        if (promise instanceof FlushCheckpoint) {\n            FlushCheckpoint cp = (FlushCheckpoint) promise;\n            cp.flushCheckpoint(checkpoint);\n            flushCheckpoints.add(cp);\n        } else {\n            flushCheckpoints.add(new DefaultFlushCheckpoint(checkpoint, promise));\n        }\n        return this;\n    }"}, {"instruction": "\u5904\u7406PlainSelect\u7c7b\u578b\u7684selectBody\n\n@param plainSelect", "input": "Java", "output": "public void processPlainSelect(PlainSelect plainSelect) {\n        if (!orderByHashParameters(plainSelect.getOrderByElements())) {\n            plainSelect.setOrderByElements(null);\n        }\n        if (plainSelect.getFromItem() != null) {\n            processFromItem(plainSelect.getFromItem());\n        }\n        if (plainSelect.getJoins() != null && plainSelect.getJoins().size() > 0) {\n            List<Join> joins = plainSelect.getJoins();\n            for (Join join : joins) {\n                if (join.getRightItem() != null) {\n                    processFromItem(join.getRightItem());\n                }\n            }\n        }\n    }"}, {"instruction": "Process one training row at a time (online learning)\n@param seed Seed is only used if reproducible mode is enabled\n@param r Row (must be dense for now)\n@param mb mini-batch internal index", "input": "Java", "output": "@Override public final void processRow(long seed, DataInfo.Row r, int mb) {\n    if (_localmodel.get_params()._reproducible) {\n      seed += _localmodel.get_processed_global(); //avoid periodicity\n    } else {\n      seed = _dropout_rng.nextLong(); // non-reproducible case - make a fast & good random number\n    }\n    _localmodel.checkMissingCats(r.binIds);\n    ((Neurons.Input) _neurons[0]).setInput(seed, r.isSparse() ? r.numIds : null, r.numVals, r.nBins, r.binIds, mb);\n  }"}, {"instruction": "Calculate percentage of instances online\n\n@param collectorItemId Collector Item Id of deploy\n@return percentage of instances online", "input": "Java", "output": "private Double fetchInstancesOnlineRatio(ObjectId collectorItemId) {\n    int totalInstances = 0, totalInstancesOnline = 0;\n    Double instancesOnlineScore = null;\n\n    List<EnvironmentStatus> statuses = environmentStatusRepository\n      .findByCollectorItemId(collectorItemId);\n\n    if (null == statuses || statuses.isEmpty()) {\n      return null;\n    }\n\n    for (EnvironmentStatus environmentStatus : statuses) {\n      totalInstances++;\n      if (environmentStatus.isOnline()) {\n        totalInstancesOnline++;\n      }\n    }\n    instancesOnlineScore = ((totalInstancesOnline * 100) / (double) totalInstances);\n    LOGGER.info(\"totalInstances \" + totalInstances + \" totalInstancesOnline \" + totalInstancesOnline + \" instancesOnlineScore \" + instancesOnlineScore);\n\n    return instancesOnlineScore;\n  }"}, {"instruction": "Create describe parser instance.\n\n@param dbType database type\n@param shardingRule databases and tables sharding rule\n@param lexerEngine lexical analysis engine.\n@return describe parser instance", "input": "Java", "output": "public static AbstractDescribeParser newInstance(final DatabaseType dbType, final ShardingRule shardingRule, final LexerEngine lexerEngine) {\n        switch (dbType) {\n            case H2:\n            case MySQL:\n                return new MySQLDescribeParser(shardingRule, lexerEngine);\n            default:\n                throw new UnsupportedOperationException(String.format(\"Cannot support database [%s].\", dbType));\n        }\n    }"}, {"instruction": "Tries to find a {@link SerializedThrowable} as the cause of the given throwable and throws its\ndeserialized value. If there is no such throwable, then the original throwable is thrown.\n\n@param throwable to check for a SerializedThrowable\n@param classLoader to be used for the deserialization of the SerializedThrowable\n@throws Throwable either the deserialized throwable or the given throwable", "input": "Java", "output": "public static void tryDeserializeAndThrow(Throwable throwable, ClassLoader classLoader) throws Throwable {\n\t\tThrowable current = throwable;\n\n\t\twhile (!(current instanceof SerializedThrowable) && current.getCause() != null) {\n\t\t\tcurrent = current.getCause();\n\t\t}\n\n\t\tif (current instanceof SerializedThrowable) {\n\t\t\tthrow ((SerializedThrowable) current).deserializeError(classLoader);\n\t\t} else {\n\t\t\tthrow throwable;\n\t\t}\n\t}"}, {"instruction": "Parse the supplied XML file data to a {@link Document}.\n@param file The file to parse.\n@param encoding The encoding of the XML in the file.\n@return The parsed document.\n@throws SAXException Error parsing the XML file data e.g. badly formed XML.\n@throws IOException Error reading from the file.\n@since 2.0", "input": "Java", "output": "public static @Nonnull Document parse(@Nonnull File file, @Nonnull String encoding) throws SAXException, IOException {\n        if (!file.exists() || !file.isFile()) {\n            throw new IllegalArgumentException(String.format(\"File %s does not exist or is not a 'normal' file.\", file.getAbsolutePath()));\n        }\n\n        try (InputStream fileInputStream = Files.newInputStream(file.toPath());\n            InputStreamReader fileReader = new InputStreamReader(fileInputStream, encoding)) {\n            return parse(fileReader);\n        } catch (InvalidPathException e) {\n            throw new IOException(e);\n        }\n    }"}, {"instruction": "/*\nthis method simulates net_kernel only for the purpose of replying to\npings.", "input": "Java", "output": "private boolean netKernel(final OtpMsg m) {\n        OtpMbox mbox = null;\n        try {\n            final OtpErlangTuple t = (OtpErlangTuple) m.getMsg();\n            final OtpErlangTuple req = (OtpErlangTuple) t.elementAt(1); // actual\n            // request\n\n            final OtpErlangPid pid = (OtpErlangPid) req.elementAt(0); // originating\n            // pid\n\n            final OtpErlangObject[] pong = new OtpErlangObject[2];\n            pong[0] = req.elementAt(1); // his #Ref\n            pong[1] = new OtpErlangAtom(\"yes\");\n\n            mbox = createMbox();\n            mbox.send(pid, new OtpErlangTuple(pong));\n            return true;\n        } catch (final Exception e) {\n        } finally {\n            closeMbox(mbox);\n        }\n        return false;\n    }"}, {"instruction": "\u4fdd\u5b58\u5230\u4e8c\u8fdb\u5236\u8f93\u51fa\u6d41\n\n@param out\n@return", "input": "Java", "output": "public boolean save(DataOutputStream out)\n    {\n        try\n        {\n            for (BaseNode node : child)\n            {\n                if (node == null)\n                {\n                    out.writeInt(0);\n                }\n                else\n                {\n                    out.writeInt(1);\n                    node.walkToSave(out);\n                }\n            }\n        }\n        catch (Exception e)\n        {\n            logger.warning(\"\u4fdd\u5b58\u5230\" + out + \"\u5931\u8d25\" + TextUtility.exceptionToString(e));\n            return false;\n        }\n\n        return true;\n    }"}, {"instruction": "\u751f\u6210\u7684Mapper\u63a5\u53e3\n\n@param interfaze\n@param topLevelClass\n@param introspectedTable\n@return", "input": "Java", "output": "@Override\n    public boolean clientGenerated(Interface interfaze, TopLevelClass topLevelClass, IntrospectedTable introspectedTable) {\n        //\u83b7\u53d6\u5b9e\u4f53\u7c7b\n        FullyQualifiedJavaType entityType = new FullyQualifiedJavaType(introspectedTable.getBaseRecordType());\n        //import\u63a5\u53e3\n        for (String mapper : mappers) {\n            interfaze.addImportedType(new FullyQualifiedJavaType(mapper));\n            interfaze.addSuperInterface(new FullyQualifiedJavaType(mapper + \"<\" + entityType.getShortName() + \">\"));\n        }\n        //import\u5b9e\u4f53\u7c7b\n        interfaze.addImportedType(entityType);\n        return true;\n    }"}, {"instruction": "Returns a slot that has been allocated from this instance. The slot needs have been canceled\nprior to calling this method.\n\n<p>The method will transition the slot to the \"released\" state. If the slot is already in state\n\"released\", this method will do nothing.</p>\n\n@param logicalSlot The slot to return.\n@return Future which is completed with true, if the slot was returned, false if not.", "input": "Java", "output": "@Override\n\tpublic void returnLogicalSlot(LogicalSlot logicalSlot) {\n\t\tcheckNotNull(logicalSlot);\n\t\tcheckArgument(logicalSlot instanceof Slot);\n\n\t\tfinal Slot slot = ((Slot) logicalSlot);\n\t\tcheckArgument(!slot.isAlive(), \"slot is still alive\");\n\t\tcheckArgument(slot.getOwner() == this, \"slot belongs to the wrong TaskManager.\");\n\n\t\tif (slot.markReleased()) {\n\t\t\tLOG.debug(\"Return allocated slot {}.\", slot);\n\t\t\tsynchronized (instanceLock) {\n\t\t\t\tif (isDead) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (this.allocatedSlots.remove(slot)) {\n\t\t\t\t\tthis.availableSlots.add(slot.getSlotNumber());\n\n\t\t\t\t\tif (this.slotAvailabilityListener != null) {\n\t\t\t\t\t\tthis.slotAvailabilityListener.newSlotAvailable(this);\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tthrow new IllegalArgumentException(\"Slot was not allocated from this TaskManager.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}"}, {"instruction": "Ipv4 String \u8f6c\u6362\u5230byte[]", "input": "Java", "output": "private static byte[] ip4StringToBytes(String ipv4Str) {\n\t\tif (ipv4Str == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tList<String> it = MoreStringUtil.split(ipv4Str, '.', 4);\n\t\tif (it.size() != 4) {\n\t\t\treturn null;\n\t\t}\n\n\t\tbyte[] byteAddress = new byte[4];\n\t\tfor (int i = 0; i < 4; i++) {\n\t\t\tint tempInt = Integer.parseInt(it.get(i));\n\t\t\tif (tempInt > 255) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tbyteAddress[i] = (byte) tempInt;\n\t\t}\n\t\treturn byteAddress;\n\t}"}, {"instruction": "TODO: remove @NonNull check here", "input": "Java", "output": "protected void handleMessage(@NonNull VoidMessage message) {\n        if (message == null) {\n            //            log.info(\"sI_{} got null message\", getShardIndex());\n            return;\n        }\n\n        if (message.getTargetId() >= 0 && message.getTargetId() != shardIndex) {\n            log.warn(\"sI_{}: Skipping message: [{}]; TargetIdx: [{}]\", shardIndex, message.getClass().getSimpleName(),\n                            message.getTargetId());\n            return;\n        }\n\n        //      log.info(\"sI_{}: Processing message: [{}]\", shardIndex, message.getClass().getSimpleName());\n\n        message.attachContext(voidConfiguration, trainer, clipboard, transport, storage, nodeRole, shardIndex);\n        message.processMessage();\n    }"}, {"instruction": "\u5207\u53d6\u90e8\u5206\u6570\u636e<br>\n\u5207\u53d6\u540e\u7684\u6808\u5c06\u51cf\u5c11\u8fd9\u4e9b\u5143\u7d20\n\n@param <T> \u96c6\u5408\u5143\u7d20\u7c7b\u578b\n@param surplusAlaDatas \u539f\u6570\u636e\n@param partSize \u6bcf\u90e8\u5206\u6570\u636e\u7684\u957f\u5ea6\n@return \u5207\u53d6\u51fa\u7684\u6570\u636e\u6216null", "input": "Java", "output": "public static <T> List<T> popPart(Stack<T> surplusAlaDatas, int partSize) {\r\n\t\tif (isEmpty(surplusAlaDatas)) {\r\n\t\t\treturn null;\r\n\t\t}\r\n\r\n\t\tfinal List<T> currentAlaDatas = new ArrayList<>();\r\n\t\tint size = surplusAlaDatas.size();\r\n\t\t// \u5207\u5272\r\n\t\tif (size > partSize) {\r\n\t\t\tfor (int i = 0; i < partSize; i++) {\r\n\t\t\t\tcurrentAlaDatas.add(surplusAlaDatas.pop());\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfor (int i = 0; i < size; i++) {\r\n\t\t\t\tcurrentAlaDatas.add(surplusAlaDatas.pop());\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn currentAlaDatas;\r\n\t}"}, {"instruction": "Computes the build cause, using RemoteCause or UserCause as appropriate.", "input": "Java", "output": "@Restricted(NoExternalUse.class)\n    public static CauseAction getBuildCause(ParameterizedJob job, StaplerRequest req) {\n        Cause cause;\n        @SuppressWarnings(\"deprecation\")\n        hudson.model.BuildAuthorizationToken authToken = job.getAuthToken();\n        if (authToken != null && authToken.getToken() != null && req.getParameter(\"token\") != null) {\n            // Optional additional cause text when starting via token\n            String causeText = req.getParameter(\"cause\");\n            cause = new Cause.RemoteCause(req.getRemoteAddr(), causeText);\n        } else {\n            cause = new Cause.UserIdCause();\n        }\n        return new CauseAction(cause);\n    }"}, {"instruction": "\u8f6c\u6362\u4e3aProperties\u5bf9\u8c61\uff0c\u539f\u5206\u7ec4\u53d8\u4e3a\u524d\u7f00\n\n@return Properties\u5bf9\u8c61", "input": "Java", "output": "public Properties toProperties() {\r\n\t\tfinal Properties properties = new Properties();\r\n\t\tString group;\r\n\t\tfor (Entry<String, LinkedHashMap<String, String>> groupEntry : this.groupedMap.entrySet()) {\r\n\t\t\tgroup = groupEntry.getKey();\r\n\t\t\tfor (Entry<String, String> entry : groupEntry.getValue().entrySet()) {\r\n\t\t\t\tproperties.setProperty(StrUtil.isEmpty(group) ? entry.getKey() : group + CharUtil.DOT + entry.getKey(), entry.getValue());\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn properties;\r\n\t}"}, {"instruction": "Adds the url to the list.\nBuild URI by components to facilitate proper encoding of querystring.\ne.g. http://example.com:8085/ca?action=crl&issuer=CN=CAS Test User CA\n<p>\n<p>If {@code uriString} is encoded, it will be decoded with {@code UTF-8}\nfirst before it's added to the list.</p>\n\n@param list      the list\n@param uriString the uri string", "input": "Java", "output": "private static void addURL(final List<URI> list, final String uriString) {\n        try {\n            try {\n                val url = new URL(URLDecoder.decode(uriString, StandardCharsets.UTF_8.name()));\n                list.add(new URI(url.getProtocol(), url.getAuthority(), url.getPath(), url.getQuery(), null));\n            } catch (final MalformedURLException e) {\n                list.add(new URI(uriString));\n            }\n        } catch (final Exception e) {\n            LOGGER.warn(\"[{}] is not a valid distribution point URI.\", uriString);\n        }\n    }"}, {"instruction": "Creates a new buffer whose content is a copy of the specified\n{@code buffer}'s current slice.  The new buffer's {@code readerIndex}\nand {@code writerIndex} are {@code 0} and {@code buffer.remaining}\nrespectively.", "input": "Java", "output": "public static ByteBuf copiedBuffer(ByteBuffer buffer) {\n        int length = buffer.remaining();\n        if (length == 0) {\n            return EMPTY_BUFFER;\n        }\n        byte[] copy = PlatformDependent.allocateUninitializedArray(length);\n        // Duplicate the buffer so we not adjust the position during our get operation.\n        // See https://github.com/netty/netty/issues/3896\n        ByteBuffer duplicate = buffer.duplicate();\n        duplicate.get(copy);\n        return wrappedBuffer(copy).order(duplicate.order());\n    }"}, {"instruction": "Gets the top nodes from the site tree which contain nodes that are \"In Scope\".\nSearches recursively starting from the root node.\nShould be used with care, as it is time-consuming, querying the database for\nevery node in the Site Tree.\n\n@return the nodes in scope from site tree", "input": "Java", "output": "public List<SiteNode> getTopNodesInScopeFromSiteTree() {\r\n\t\tList<SiteNode> nodes = new LinkedList<>();\r\n\t\tSiteNode rootNode = getSiteTree().getRoot();\r\n\t\t@SuppressWarnings(\"unchecked\")\r\n\t\tEnumeration<TreeNode> en = rootNode.children();\r\n\t\twhile (en.hasMoreElements()) {\r\n\t\t\tSiteNode sn = (SiteNode) en.nextElement();\r\n\t\t\tif (isContainsNodesInScope(sn)) {\r\n\t\t\t\tnodes.add(sn);\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nodes;\r\n\t}"}, {"instruction": "Static factory method: to be used when a new execution is created for the very first time/\nCalling this will make sure no extra db fetches are needed later on, as all collections\nwill be populated with empty collections. If they would be null, it would trigger\na database fetch for those relationship entities.", "input": "Java", "output": "public static ExecutionEntityImpl createWithEmptyRelationshipCollections() {\n    ExecutionEntityImpl execution = new ExecutionEntityImpl();\n    execution.executions = new ArrayList<ExecutionEntityImpl>(1);\n    execution.tasks = new ArrayList<TaskEntity>(1);\n    execution.variableInstances = new HashMap<String, VariableInstanceEntity>(1);\n    execution.jobs = new ArrayList<JobEntity>(1);\n    execution.timerJobs = new ArrayList<TimerJobEntity>(1);\n    execution.eventSubscriptions = new ArrayList<EventSubscriptionEntity>(1);\n    execution.identityLinks = new ArrayList<IdentityLinkEntity>(1);\n    return execution;\n  }"}, {"instruction": "Return next n bytes in this buffer.", "input": "Java", "output": "public final LogBuffer duplicate(final int len) {\r\n        if (position + len > origin + limit) throw new IllegalArgumentException(\"limit excceed: \"\r\n                                                                                + (position + len - origin));\r\n\r\n        // XXX: Do momery copy avoid buffer modified.\r\n        final int end = position + len;\r\n        byte[] buf = Arrays.copyOfRange(buffer, position, end);\r\n        LogBuffer dupBuffer = new LogBuffer(buf, 0, len);\r\n        position = end;\r\n        return dupBuffer;\r\n    }"}, {"instruction": "validates the text value using the list of validators provided by the\nuser {{@link #setValidators(ValidatorBase...)}\n\n@return true if the value is valid else false", "input": "Java", "output": "public static boolean validate(Control control) {\n        ValidationFacade facade = (ValidationFacade) control.getParent();\n        for (ValidatorBase validator : facade.validators) {\n            validator.setSrcControl(facade.controlProperty.get());\n            validator.validate();\n            if (validator.getHasErrors()) {\n                facade.activeValidator.set(validator);\n                control.pseudoClassStateChanged(PSEUDO_CLASS_ERROR, true);\n                return false;\n            }\n        }\n        control.pseudoClassStateChanged(PSEUDO_CLASS_ERROR, false);\n        facade.activeValidator.set(null);\n        return true;\n    }"}, {"instruction": "Specifies the types for the CSV fields. This method parses the CSV data to a 2-tuple\nwhich has fields of the specified types.\nThis method is overloaded for each possible length of the tuples to support type safe\ncreation of data sets through CSV parsing.\n\n@param type0 The type of CSV field 0 and the type of field 0 in the returned tuple type.\n@param type1 The type of CSV field 1 and the type of field 1 in the returned tuple type.\n@return The {@link org.apache.flink.api.java.DataSet} representing the parsed CSV data.", "input": "Java", "output": "public <T0, T1> DataSource<Tuple2<T0, T1>> types(Class<T0> type0, Class<T1> type1) {\n\t\tTupleTypeInfo<Tuple2<T0, T1>> types = TupleTypeInfo.getBasicAndBasicValueTupleTypeInfo(type0, type1);\n\t\tCsvInputFormat<Tuple2<T0, T1>> inputFormat = new TupleCsvInputFormat<Tuple2<T0, T1>>(path, types, this.includedMask);\n\t\tconfigureInputFormat(inputFormat);\n\t\treturn new DataSource<Tuple2<T0, T1>>(executionContext, inputFormat, types, Utils.getCallLocationName());\n\t}"}, {"instruction": "Gets the nodes from the site tree which are \"In Scope\". Searches recursively starting from\nthe root node. Should be used with care, as it is time-consuming, querying the database for\nevery node in the Site Tree.\n\n@return the nodes in scope from site tree", "input": "Java", "output": "public List<SiteNode> getTopNodesInContextFromSiteTree() {\r\n\t\tList<SiteNode> nodes = new LinkedList<>();\r\n\t\tSiteNode rootNode = session.getSiteTree().getRoot();\r\n\t\t@SuppressWarnings(\"unchecked\")\r\n\t\tEnumeration<TreeNode> en = rootNode.children();\r\n\t\twhile (en.hasMoreElements()) {\r\n\t\t\tSiteNode sn = (SiteNode) en.nextElement();\r\n\t\t\tif (isContainsNodesInContext(sn)) {\r\n\t\t\t\tnodes.add(sn);\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nodes;\r\n\t}"}, {"instruction": "Indicates that any modifications to the given PageWrapper have completed.\n\n@param page The PageWrapper that has been completed. This instance's offset will be adjusted to the current value\nof getIndexLength(), and the stored index length will be incremented by this PageWrapper's length.", "input": "Java", "output": "synchronized void complete(PageWrapper page) {\n        Preconditions.checkArgument(this.pageByOffset.containsKey(page.getOffset()), \"Given page is not registered.\");\n        Preconditions.checkArgument(this.incompleteNewPageOffset == PagePointer.NO_OFFSET || this.incompleteNewPageOffset == page.getOffset(),\n                \"Not expecting this page to be completed.\");\n\n        this.incompleteNewPageOffset = PagePointer.NO_OFFSET;\n        long pageOffset = this.indexLength;\n        this.indexLength += page.getPage().getLength();\n\n        this.pageByOffset.remove(page.getOffset());\n        page.setOffset(pageOffset);\n        this.pageByOffset.put(page.getOffset(), page);\n    }"}, {"instruction": "Trim the wave data\n\n@param leftTrimSecond\nSeconds trimmed from beginning\n@param rightTrimSecond\nSeconds trimmed from ending", "input": "Java", "output": "public void trim(double leftTrimSecond, double rightTrimSecond) {\n\n        int sampleRate = waveHeader.getSampleRate();\n        int bitsPerSample = waveHeader.getBitsPerSample();\n        int channels = waveHeader.getChannels();\n\n        int leftTrimNumberOfSample = (int) (sampleRate * bitsPerSample / 8 * channels * leftTrimSecond);\n        int rightTrimNumberOfSample = (int) (sampleRate * bitsPerSample / 8 * channels * rightTrimSecond);\n\n        trim(leftTrimNumberOfSample, rightTrimNumberOfSample);\n    }"}, {"instruction": "Splice from this {@link AbstractEpollStreamChannel} to another {@link AbstractEpollStreamChannel}.\nThe {@code len} is the number of bytes to splice. If using {@link Integer#MAX_VALUE} it will\nsplice until the {@link ChannelFuture} was canceled or it was failed.\n\nPlease note:\n<ul>\n<li>both channels need to be registered to the same {@link EventLoop}, otherwise an\n{@link IllegalArgumentException} is thrown. </li>\n<li>{@link EpollChannelConfig#getEpollMode()} must be {@link EpollMode#LEVEL_TRIGGERED} for this and the\ntarget {@link AbstractEpollStreamChannel}</li>\n</ul>", "input": "Java", "output": "public final ChannelFuture spliceTo(final AbstractEpollStreamChannel ch, final int len,\n                                        final ChannelPromise promise) {\n        if (ch.eventLoop() != eventLoop()) {\n            throw new IllegalArgumentException(\"EventLoops are not the same.\");\n        }\n        checkPositiveOrZero(len, \"len\");\n        if (ch.config().getEpollMode() != EpollMode.LEVEL_TRIGGERED\n                || config().getEpollMode() != EpollMode.LEVEL_TRIGGERED) {\n            throw new IllegalStateException(\"spliceTo() supported only when using \" + EpollMode.LEVEL_TRIGGERED);\n        }\n        checkNotNull(promise, \"promise\");\n        if (!isOpen()) {\n            promise.tryFailure(SPLICE_TO_CLOSED_CHANNEL_EXCEPTION);\n        } else {\n            addToSpliceQueue(new SpliceInChannelTask(ch, len, promise));\n            failSpliceIfClosed(promise);\n        }\n        return promise;\n    }"}, {"instruction": "TODO hongjun: find table from parent select statement, should find table in subquery level only", "input": "Java", "output": "public static Optional<String> findTableName(final PredicateSegment predicateSegment, final SQLStatement sqlStatement, final ShardingTableMetaData shardingTableMetaData) {\n        if (!(sqlStatement instanceof SelectStatement)) {\n            return Optional.of(sqlStatement.getTables().getSingleTableName());\n        }\n        SelectStatement currentSelectStatement = (SelectStatement) sqlStatement;\n        while (null != currentSelectStatement.getParentStatement()) {\n            currentSelectStatement = currentSelectStatement.getParentStatement();\n            Optional<String> tableName = findTableName(predicateSegment, currentSelectStatement.getTables(), shardingTableMetaData);\n            if (tableName.isPresent()) {\n                return tableName;\n            }\n        }\n        return findTableName(predicateSegment, currentSelectStatement.getTables(), shardingTableMetaData);\n    }"}, {"instruction": "Build a MultiLayerNetwork from this Keras Sequential model configuration and import weights.\n\n@return MultiLayerNetwork", "input": "Java", "output": "public MultiLayerNetwork getMultiLayerNetwork(boolean importWeights)\n            throws InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {\n        MultiLayerNetwork model = new MultiLayerNetwork(getMultiLayerConfiguration());\n        model.init();\n        if (importWeights)\n            model = (MultiLayerNetwork) KerasModelUtils.copyWeightsToModel(model, this.layers);\n        return model;\n    }"}, {"instruction": "Add a weight parameter to the layer, with the specified shape. For example, a standard fully connected layer\ncould have weight parameters with shape [numInputs, layerSize]\n\n@param paramKey   The parameter key (name) for the weight parameter\n@param paramShape Shape of the weight parameter array", "input": "Java", "output": "public void addWeightParam(@NonNull String paramKey, @NonNull long... paramShape) {\n        Preconditions.checkArgument(paramShape.length > 0, \"Provided weight parameter shape is\"\n                        + \" invalid: length 0 provided for shape. Parameter: \" + paramKey);\n        weightParams.put(paramKey, paramShape);\n        paramsList = null;\n        weightParamsList = null;\n        biasParamsList = null;\n    }"}, {"instruction": "Basically it works as low and high values were the same for source and filteringSource and just looks at NDVs.", "input": "Java", "output": "public static PlanNodeStatsEstimate computeSemiJoin(PlanNodeStatsEstimate sourceStats, PlanNodeStatsEstimate filteringSourceStats, Symbol sourceJoinSymbol, Symbol filteringSourceJoinSymbol)\n    {\n        return compute(sourceStats, filteringSourceStats, sourceJoinSymbol, filteringSourceJoinSymbol,\n                (sourceJoinSymbolStats, filteringSourceJoinSymbolStats) ->\n                        min(filteringSourceJoinSymbolStats.getDistinctValuesCount(), sourceJoinSymbolStats.getDistinctValuesCount()));\n    }"}, {"instruction": "Default value for {@link ToolInstallation#getProperties()} used in the form binding.\n@since 1.305", "input": "Java", "output": "public DescribableList<ToolProperty<?>,ToolPropertyDescriptor> getDefaultProperties() throws IOException {\n        DescribableList<ToolProperty<?>,ToolPropertyDescriptor> r\n                = new DescribableList<>(NOOP);\n\n        List<? extends ToolInstaller> installers = getDefaultInstallers();\n        if(!installers.isEmpty())\n            r.add(new InstallSourceProperty(installers));\n\n        return r;\n    }"}, {"instruction": "\u67e5\u8be2\u5168\u90e8\u7ed3\u679c\n\n@param ms\n@return", "input": "Java", "output": "public String selectAll(MappedStatement ms) {\n        final Class<?> entityClass = getEntityClass(ms);\n        //\u4fee\u6539\u8fd4\u56de\u503c\u7c7b\u578b\u4e3a\u5b9e\u4f53\u7c7b\u578b\n        setResultType(ms, entityClass);\n        StringBuilder sql = new StringBuilder();\n        sql.append(SqlHelper.selectAllColumns(entityClass));\n        sql.append(SqlHelper.fromTable(entityClass, tableName(entityClass)));\n\n        // \u903b\u8f91\u5220\u9664\u7684\u672a\u5220\u9664\u67e5\u8be2\u6761\u4ef6\n        sql.append(\"<where>\");\n        sql.append(SqlHelper.whereLogicDelete(entityClass, false));\n        sql.append(\"</where>\");\n\n        sql.append(SqlHelper.orderByDefault(entityClass));\n        return sql.toString();\n    }"}, {"instruction": "Visits a pre-destroy method injection point.\n\n@param declaringType The declaring type of the method. Either a Class or a string representing the name of the type\n@param returnType    The return type of the method\n@param methodName    The method name", "input": "Java", "output": "public void visitPreDestroyMethod(Object declaringType,\n                                      Object returnType,\n                                      String methodName) {\n        visitPreDestroyMethodDefinition();\n        final MethodVisitData methodVisitData = new MethodVisitData(\n                declaringType,\n                false,\n                returnType,\n                methodName,\n                Collections.emptyMap(),\n                Collections.emptyMap(),\n                Collections.emptyMap(),\n                AnnotationMetadata.EMPTY_METADATA);\n        preDestroyMethodVisits.add(methodVisitData);\n        visitMethodInjectionPointInternal(methodVisitData,\n                constructorVisitor,\n                preDestroyMethodVisitor,\n                preDestroyInstanceIndex,\n                ADD_PRE_DESTROY_METHOD);\n    }"}, {"instruction": "Save the user configuration.", "input": "Java", "output": "public synchronized void save() throws IOException {\n        if (!isIdOrFullnameAllowed(id)) {\n            throw FormValidation.error(Messages.User_IllegalUsername(id));\n        }\n        if (!isIdOrFullnameAllowed(fullName)) {\n            throw FormValidation.error(Messages.User_IllegalFullname(fullName));\n        }\n        if (BulkChange.contains(this)) {\n            return;\n        }\n        XmlFile xmlFile = new XmlFile(XSTREAM, constructUserConfigFile());\n        xmlFile.write(this);\n        SaveableListener.fireOnChange(this, xmlFile);\n    }"}, {"instruction": "\u5224\u65ad\u81ea\u52a8!=null\u7684\u6761\u4ef6\u7ed3\u6784\n\n@param entityName\n@param column\n@param contents\n@param empty\n@return", "input": "Java", "output": "public static String getIfNotNull(String entityName, EntityColumn column, String contents, boolean empty) {\n        StringBuilder sql = new StringBuilder();\n        sql.append(\"<if test=\\\"\");\n        if (StringUtil.isNotEmpty(entityName)) {\n            sql.append(entityName).append(\".\");\n        }\n        sql.append(column.getProperty()).append(\" != null\");\n        if (empty && column.getJavaType().equals(String.class)) {\n            sql.append(\" and \");\n            if (StringUtil.isNotEmpty(entityName)) {\n                sql.append(entityName).append(\".\");\n            }\n            sql.append(column.getProperty()).append(\" != '' \");\n        }\n        sql.append(\"\\\">\");\n        sql.append(contents);\n        sql.append(\"</if>\");\n        return sql.toString();\n    }"}, {"instruction": "This method serializaes object  into JSON string\n\n@param element\n@return", "input": "Java", "output": "@Override\n    public String serialize(T element) {\n        String json = null;\n        try {\n            json = element.toJSON();\n        } catch (Exception e) {\n            log.error(\"Direct serialization failed, falling back to jackson\");\n        }\n\n        if (json == null || json.isEmpty()) {\n            ObjectMapper mapper = SequenceElement.mapper();\n            try {\n                json = mapper.writeValueAsString(element);\n            } catch (org.nd4j.shade.jackson.core.JsonProcessingException e) {\n                throw new RuntimeException(e);\n            }\n        }\n\n        return json;\n    }"}, {"instruction": "Inserts or aggregates a value into the hash map. If the hash map does not yet contain the key,\nthis method inserts the value. If the table already contains the key (and a value) this\nmethod will use the given ReduceFunction function to combine the existing value and the\ngiven value to a new value, and store that value for the key.\n\n@param key The key to map the value.\n@param value The new value to insert, or aggregate with the existing value.\n@param aggregator The aggregator to use if a value is already contained.\n\n@return The value in the map after this operation: Either the given value, or the aggregated value.\n\n@throws java.lang.NullPointerException Thrown, if the key is null.\n@throws Exception The method forwards exceptions from the aggregation function.", "input": "Java", "output": "public final V putOrAggregate(K key, V value, ReduceFunction<V> aggregator) throws Exception {\n\t\tfinal int hash = hash(key);\n\t\tfinal int slot = indexOf(hash);\n\n\t\t// search the chain from the slot\n\t\tfor (Entry<K, V> entry = table[slot]; entry != null; entry = entry.next) {\n\t\t\tif (entry.hashCode == hash && entry.key.equals(key)) {\n\t\t\t\t// found match\n\t\t\t\tentry.value = aggregator.reduce(entry.value, value);\n\t\t\t\treturn entry.value;\n\t\t\t}\n\t\t}\n\n\t\t// no match, insert a new value\n\t\tinsertNewEntry(hash, key, value, slot);\n\t\t// return the original value\n\t\treturn value;\n\t}"}, {"instruction": "A final allocation pass with no code length limit.\n@param array The code length array", "input": "Java", "output": "private static void allocateNodeLengths(final int[] array) {\n        int firstNode = array.length - 2;\n        int nextNode = array.length - 1;\n\n        for (int currentDepth = 1, availableNodes = 2; availableNodes > 0; currentDepth++) {\n            final int lastNode = firstNode;\n            firstNode = first(array, lastNode - 1, 0);\n\n            for (int i = availableNodes - (lastNode - firstNode); i > 0; i--) {\n                array[nextNode--] = currentDepth;\n            }\n\n            availableNodes = (lastNode - firstNode) << 1;\n        }\n    }"}, {"instruction": "Example of running a query with the cache disabled.", "input": "Java", "output": "public void runUncachedQuery() throws TimeoutException, InterruptedException {\n    // [START bigquery_query_no_cache]\n    // BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n    String query = \"SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\";\n    QueryJobConfiguration queryConfig =\n        QueryJobConfiguration.newBuilder(query)\n            // Disable the query cache to force live query evaluation.\n            .setUseQueryCache(false)\n            .build();\n\n    // Print the results.\n    for (FieldValueList row : bigquery.query(queryConfig).iterateAll()) {\n      for (FieldValue val : row) {\n        System.out.printf(\"%s,\", val.toString());\n      }\n      System.out.printf(\"\\n\");\n    }\n    // [END bigquery_query_no_cache]\n  }"}, {"instruction": "}", "input": "Java", "output": "@Bean\n\t@ConditionalOnBean(AutoServiceRegistrationProperties.class)\n\t@ConditionalOnProperty(value = \"spring.cloud.service-registry.auto-registration.enabled\", matchIfMissing = true)\n\tpublic EurekaAutoServiceRegistration eurekaAutoServiceRegistration(\n\t\t\tApplicationContext context, EurekaServiceRegistry registry,\n\t\t\tEurekaRegistration registration) {\n\t\treturn new EurekaAutoServiceRegistration(context, registry, registration);\n\t}"}, {"instruction": "This method should not be public so as to not expose internals to user code.", "input": "Java", "output": "@Override\n\tOperatorStateHandle closeAndGetHandle() throws IOException {\n\t\tStreamStateHandle streamStateHandle = delegate.closeAndGetHandle();\n\n\t\tif (null == streamStateHandle) {\n\t\t\treturn null;\n\t\t}\n\n\t\tif (partitionOffsets.isEmpty() && delegate.getPos() > initialPosition) {\n\t\t\tstartNewPartition();\n\t\t}\n\n\t\tMap<String, OperatorStateHandle.StateMetaInfo> offsetsMap = new HashMap<>(1);\n\n\t\tOperatorStateHandle.StateMetaInfo metaInfo =\n\t\t\t\tnew OperatorStateHandle.StateMetaInfo(\n\t\t\t\t\t\tpartitionOffsets.toArray(),\n\t\t\t\t\tOperatorStateHandle.Mode.SPLIT_DISTRIBUTE);\n\n\t\toffsetsMap.put(DefaultOperatorStateBackend.DEFAULT_OPERATOR_STATE_NAME, metaInfo);\n\n\t\treturn new OperatorStreamStateHandle(offsetsMap, streamStateHandle);\n\t}"}, {"instruction": "Internal method that sets a variable without validating the script name.\n\n@param scriptName the name of the script.\n@param key the key of the variable.\n@param value the value of the variable.", "input": "Java", "output": "private static void setScriptVarImpl(String scriptName, String key, String value) {\t\n\t\tvalidateKey(key);\n\t\t\n\t\tMap<String, String> scVars = scriptVars\n\t\t\t\t.computeIfAbsent(scriptName, k -> Collections.synchronizedMap(new HashMap<String, String>()));\n\t\t\n\t\tif (value == null) {\n\t\t\tscVars.remove(key);\n\t\t} else {\n\t\t\tvalidateValueLength(value);\n\t\t\tif (scVars.size() > MAX_SCRIPT_VARS) {\n\t\t\t\tthrow new IllegalArgumentException(\"Maximum number of script variables reached: \" + MAX_SCRIPT_VARS);\n\t\t\t}\n\t\t\tscVars.put(key, value);\n\t\t}\n\t}"}, {"instruction": "Rebalances the min-heap by pushing values from the top down and simultaneously updating the reverse index\n\n@param heap         min-heap stored as indices into the array of values\n@param reverseIndex reverse index from the array of values into the heap\n@param start        index to start re-balancing from\n@param end          index to stop re-balancing at\n@param values       values stored in the heap", "input": "Java", "output": "private static void siftDown(int[] heap, int[] reverseIndex, int start, int end, float[] values)\n  {\n    int root = start;\n    while (root * 2 + 1 <= end) {\n      int child = root * 2 + 1;\n      int swap = root;\n      if (values[heap[swap]] > values[heap[child]]) {\n        swap = child;\n      }\n      if (child + 1 <= end && values[heap[swap]] > values[heap[child + 1]]) {\n        swap = child + 1;\n      }\n      if (swap != root) {\n        // swap\n        int tmp = heap[swap];\n        heap[swap] = heap[root];\n        heap[root] = tmp;\n\n        // heap index from delta index\n        reverseIndex[heap[swap]] = swap;\n        reverseIndex[heap[root]] = root;\n\n        root = swap;\n      } else {\n        return;\n      }\n    }\n  }"}, {"instruction": "\u5176\u4e2d\u4e00\u4e2a\u96c6\u5408\u5728\u53e6\u4e00\u4e2a\u96c6\u5408\u4e2d\u662f\u5426\u81f3\u5c11\u5305\u542b\u4e00\u4e2a\u5143\u7d20\uff0c\u65e2\u662f\u4e24\u4e2a\u96c6\u5408\u662f\u5426\u81f3\u5c11\u6709\u4e00\u4e2a\u5171\u540c\u7684\u5143\u7d20\n\n@param coll1 \u96c6\u54081\n@param coll2 \u96c6\u54082\n@return \u5176\u4e2d\u4e00\u4e2a\u96c6\u5408\u5728\u53e6\u4e00\u4e2a\u96c6\u5408\u4e2d\u662f\u5426\u81f3\u5c11\u5305\u542b\u4e00\u4e2a\u5143\u7d20\n@since 2.1\n@see #intersection", "input": "Java", "output": "public static boolean containsAny(Collection<?> coll1, Collection<?> coll2) {\r\n\t\tif (isEmpty(coll1) || isEmpty(coll2)) {\r\n\t\t\treturn false;\r\n\t\t}\r\n\t\tif (coll1.size() < coll2.size()) {\r\n\t\t\tfor (Object object : coll1) {\r\n\t\t\t\tif (coll2.contains(object)) {\r\n\t\t\t\t\treturn true;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfor (Object object : coll2) {\r\n\t\t\t\tif (coll1.contains(object)) {\r\n\t\t\t\t\treturn true;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false;\r\n\t}"}, {"instruction": "Write all values from the specified record reader to the specified record writer.\nOptionally, close the record writer on completion\n\n@param reader Record reader (source of data)\n@param writer Record writer (location to write data)\n@param closeOnCompletion if true: close the record writer once complete, via {@link RecordWriter#close()}\n@throws IOException If underlying reader/writer throws an exception", "input": "Java", "output": "public static void convert(RecordReader reader, RecordWriter writer, boolean closeOnCompletion) throws IOException {\n\n        if(!reader.hasNext()){\n            throw new UnsupportedOperationException(\"Cannot convert RecordReader: reader has no next element\");\n        }\n\n        while(reader.hasNext()){\n            writer.write(reader.next());\n        }\n\n        if(closeOnCompletion){\n            writer.close();\n        }\n    }"}, {"instruction": "Used to produce an index for particular annotation type. Method referenced by generated byte code and\nnot for public consumption. Should be called after {@link #addProperty(BeanProperty)} if required.\n\n@param annotationType The annotation type\n@param propertyName The property name", "input": "Java", "output": "@SuppressWarnings(\"unused\")\n    @Internal\n    @UsedByGeneratedCode\n    protected final void indexProperty(@Nonnull Class<? extends Annotation> annotationType, @Nonnull String propertyName) {\n        ArgumentUtils.requireNonNull(\"annotationType\", annotationType);\n        if (StringUtils.isNotEmpty(propertyName)) {\n            final BeanProperty<T, Object> property = beanProperties.get(propertyName);\n            if (property == null) {\n                throw new IllegalStateException(\"Invalid byte code generated during bean introspection. Call addProperty first!\");\n            }\n            if (indexed == null) {\n                indexed = new HashMap<>(2);\n            }\n            final List<BeanProperty<T, Object>> indexed = this.indexed.computeIfAbsent(annotationType, aClass -> new ArrayList<>(2));\n\n            indexed.add(property);\n        }\n    }"}, {"instruction": "Returns the type of column for given column index.\nThis should be overriden for any custom columns\n\n@param columnIndex the column index\n@return the column class", "input": "Java", "output": "@Override\n\tpublic Class<?> getColumnClass(int columnIndex) {\n\t\tswitch (this.columns[columnIndex]) {\n\t\tcase HREF_ID:\t\treturn Integer.class;\n\t\tcase TYPE_FLAG:\t\treturn ImageIcon.class;\n\t\tcase METHOD:\t\treturn String.class;\n\t\tcase URL:\t\t\treturn String.class;\n\t\tcase CODE:\t\t\treturn Integer.class;\n\t\tcase REASON:\t\treturn String.class;\n\t\tcase RTT:\t\t\treturn Integer.class;\n\t\tcase SIZE:\t\t\treturn Integer.class;\n\t\tcase SESSION_ID:\treturn Long.class;\n\t\tcase ALERT_FLAG:\treturn ImageIcon.class;\n\t\tcase TAGS:\t\t\treturn String.class;\n\t\tdefault:\t\t\treturn null;\n\t\t}\n\t}"}, {"instruction": "/* (non-Javadoc)\n@see org.parosproxy.paros.db.paros.TableContext#deleteAllDataForContextAndType(int, int)", "input": "Java", "output": "@Override\r\n\tpublic synchronized void deleteAllDataForContextAndType(int contextId, int type) throws DatabaseException {\r\n    \tSqlPreparedStatementWrapper psDeleteAllDataForContextAndType = null;\r\n    \ttry {\r\n        \tpsDeleteAllDataForContextAndType = DbSQL.getSingleton().getPreparedStatement(\"context.ps.deletealldataforcontexttype\");\r\n\t\t\tpsDeleteAllDataForContextAndType.getPs().setInt(1, contextId);\r\n\t\t\tpsDeleteAllDataForContextAndType.getPs().setInt(2, type);\r\n\t\t\tpsDeleteAllDataForContextAndType.getPs().executeUpdate();\r\n\t\t} catch (SQLException e) {\r\n\t\t\tthrow new DatabaseException(e);\r\n\t\t} finally {\r\n\t\t\tDbSQL.getSingleton().releasePreparedStatement(psDeleteAllDataForContextAndType);\r\n\t\t}\r\n    }"}, {"instruction": "\u62c6\u5206byte\u6570\u7ec4\u4e3a\u51e0\u4e2a\u7b49\u4efd\uff08\u6700\u540e\u4e00\u4efd\u53ef\u80fd\u5c0f\u4e8elen\uff09\n\n@param array \u6570\u7ec4\n@param len \u6bcf\u4e2a\u5c0f\u8282\u7684\u957f\u5ea6\n@return \u62c6\u5206\u540e\u7684\u6570\u7ec4", "input": "Java", "output": "public static byte[][] split(byte[] array, int len) {\r\n\t\tint x = array.length / len;\r\n\t\tint y = array.length % len;\r\n\t\tint z = 0;\r\n\t\tif (y != 0) {\r\n\t\t\tz = 1;\r\n\t\t}\r\n\t\tbyte[][] arrays = new byte[x + z][];\r\n\t\tbyte[] arr;\r\n\t\tfor (int i = 0; i < x + z; i++) {\r\n\t\t\tarr = new byte[len];\r\n\t\t\tif (i == x + z - 1 && y != 0) {\r\n\t\t\t\tSystem.arraycopy(array, i * len, arr, 0, y);\r\n\t\t\t} else {\r\n\t\t\t\tSystem.arraycopy(array, i * len, arr, 0, len);\r\n\t\t\t}\r\n\t\t\tarrays[i] = arr;\r\n\t\t}\r\n\t\treturn arrays;\r\n\t}"}, {"instruction": "Gets flow or job props from flow yaml file.\n\n@param path the flow or job path delimited by \":\", e.g. \"flow:subflow1:subflow2:job3\"\n@param flowFile the flow yaml file\n@return the props from yaml file", "input": "Java", "output": "public static Props getPropsFromYamlFile(final String path, final File flowFile) {\n    final List<Props> propsList = new ArrayList<>();\n    final NodeBeanLoader loader = new NodeBeanLoader();\n\n    try {\n      final NodeBean nodeBean = loader.load(flowFile);\n      final String[] pathList = path.split(Constants.PATH_DELIMITER);\n      if (findPropsFromNodeBean(nodeBean, pathList, 0, propsList)) {\n        if (!propsList.isEmpty()) {\n          return propsList.get(0);\n        } else {\n          logger.error(\"Error getting props for \" + path);\n        }\n      }\n    } catch (final Exception e) {\n      logger.error(\"Failed to get props, error loading flow YAML file. \", e);\n    }\n    return null;\n  }"}, {"instruction": "Should encrypt token for service?\n\n@param svc the svc\n@return the boolean", "input": "Java", "output": "@Override\n    protected boolean shouldEncryptTokenFor(final OidcRegisteredService svc) {\n        if (AlgorithmIdentifiers.NONE.equalsIgnoreCase(svc.getIdTokenEncryptionAlg())) {\n            LOGGER.warn(\"ID token encryption algorithm is set to none for [{}] and ID token will not be encrypted\", svc.getServiceId());\n            return false;\n        }\n        return svc.isEncryptIdToken() && StringUtils.isNotBlank(svc.getIdTokenEncryptionAlg()) && StringUtils.isNotBlank(svc.getIdTokenEncryptionEncoding());\n    }"}, {"instruction": "Returns the index of minimum value between {@code index} and\n{@code index + len}, or {@code -1} if {@code index} is greater than\n{@code size}.", "input": "Java", "output": "private int findMin(Comparator comparator, int index, int len)\n  {\n    if (index >= heapSize) {\n      return -1;\n    }\n    int limit = Math.min(index, heapSize - len) + len;\n    int minIndex = index;\n    for (int i = index + 1; i < limit; i++) {\n      if (comparator.compare(buf.getInt(i * Integer.BYTES), buf.getInt(minIndex * Integer.BYTES)) < 0) {\n        minIndex = i;\n      }\n    }\n    return minIndex;\n  }"}, {"instruction": "Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise", "input": "Java", "output": "public boolean isSet(_Fields field) {\n    if (field == null) {\n      throw new IllegalArgumentException();\n    }\n\n    switch (field) {\n    case SESSION_HANDLE:\n      return isSetSessionHandle();\n    case CATALOG_NAME:\n      return isSetCatalogName();\n    case SCHEMA_NAME:\n      return isSetSchemaName();\n    case TABLE_NAME:\n      return isSetTableName();\n    case TABLE_TYPES:\n      return isSetTableTypes();\n    }\n    throw new IllegalStateException();\n  }"}, {"instruction": "This method duplicates array, and stores it to all devices\n\n@param array", "input": "Java", "output": "public void broadcast(INDArray array) {\n        if (array == null)\n            return;\n\n        Nd4j.getExecutioner().commit();\n\n        val config = OpProfiler.getInstance().getConfig();\n        val locality = config.isCheckLocality();\n\n        if (locality)\n            config.setCheckLocality(false);\n\n        int numDevices = Nd4j.getAffinityManager().getNumberOfDevices();\n        for (int i = 0; i < numDevices; i++) {\n            // if current thread equal to this device - we just save it, without duplication\n            if (Nd4j.getAffinityManager().getDeviceForCurrentThread() == i) {\n                set(i, array);\n            } else {\n                set(i, Nd4j.getAffinityManager().replicateToDevice(i, array));\n            }\n\n        }\n\n        config.setCheckLocality(locality);\n    }"}, {"instruction": "Returns an AggregatorFactory that can be used to combine the output of aggregators from this factory and\nanother factory. It is used when we have some values produced by this aggregator factory, and some values produced\nby the \"other\" aggregator factory, and we want to do some additional combining of them. This happens, for example,\nwhen compacting two segments together that both have a metric column with the same name. (Even though the name of\nthe column is the same, the aggregator factory used to create it may be different from segment to segment.)\n\nThis method may throw {@link AggregatorFactoryNotMergeableException}, meaning that \"this\" and \"other\" are not\ncompatible and values from one cannot sensibly be combined with values from the other.\n\n@return a new Factory that can be used for merging the output of aggregators from this factory and other.\n\n@see #getCombiningFactory() which is equivalent to {@code foo.getMergingFactory(foo)} (when \"this\" and \"other\"\nare the same instance).", "input": "Java", "output": "public AggregatorFactory getMergingFactory(AggregatorFactory other) throws AggregatorFactoryNotMergeableException\n  {\n    final AggregatorFactory combiningFactory = this.getCombiningFactory();\n    if (other.getName().equals(this.getName()) && combiningFactory.equals(other.getCombiningFactory())) {\n      return combiningFactory;\n    } else {\n      throw new AggregatorFactoryNotMergeableException(this, other);\n    }\n  }"}, {"instruction": "The Uri Path.\n\n@return the uri path.", "input": "Java", "output": "public String path() {\n    /* build the fully qualified url with all query parameters */\n    StringBuilder path = new StringBuilder();\n    if (this.target != null) {\n      path.append(this.target);\n    }\n    if (this.uriTemplate != null) {\n      path.append(this.uriTemplate.toString());\n    }\n    if (path.length() == 0) {\n      /* no path indicates the root uri */\n      path.append(\"/\");\n    }\n    return path.toString();\n\n  }"}, {"instruction": "Reschedule a task\n\n@param task failed or cancelled task\n@return new instance of a task with \"SCHEDULED\" status", "input": "Java", "output": "private Task taskToBeRescheduled(Task task) {\n        Task taskToBeRetried = task.copy();\n        taskToBeRetried.setTaskId(IDGenerator.generate());\n        taskToBeRetried.setRetriedTaskId(task.getTaskId());\n        taskToBeRetried.setStatus(SCHEDULED);\n        taskToBeRetried.setRetryCount(task.getRetryCount() + 1);\n        taskToBeRetried.setRetried(false);\n        taskToBeRetried.setPollCount(0);\n        taskToBeRetried.setCallbackAfterSeconds(0);\n        task.setRetried(true);\n        return taskToBeRetried;\n    }"}, {"instruction": "Returns the indices of non-zero element of the vector\n\n@return indices in Databuffer", "input": "Java", "output": "@Override\n    public DataBuffer getVectorCoordinates() {\n        int idx;\n        if (isRowVector()) {\n            idx = 1;\n        } else if (isColumnVector()) {\n            idx = 0;\n        } else {\n            throw new UnsupportedOperationException();\n        }\n\n        // FIXME: int cast\n        int[] temp = new int[(int) length()];\n        for (int i = 0; i < length(); i++) {\n            temp[i] = getUnderlyingIndicesOf(i).getInt(idx);\n        }\n        return Nd4j.createBuffer(temp);\n    }"}, {"instruction": "List of the files in the given directory (path), as a {@code JavaRDD<String>}\n\n@param sc                Spark context\n@param path              Path to list files in\n@param recursive         Whether to walk the directory tree recursively (i.e., include subdirectories)\n@param allowedExtensions If null: all files will be accepted. If non-null: only files with the specified extension will be allowed.\nExclude the extension separator - i.e., use \"txt\" not \".txt\" here.\n@param config            Hadoop configuration to use. Must not be null.\n@return Paths in the directory\n@throws IOException If error occurs getting directory contents", "input": "Java", "output": "public static JavaRDD<String> listPaths(@NonNull JavaSparkContext sc, String path, boolean recursive,\n                                            Set<String> allowedExtensions, @NonNull Configuration config) throws IOException {\n        List<String> paths = new ArrayList<>();\n        FileSystem hdfs = FileSystem.get(URI.create(path), config);\n        RemoteIterator<LocatedFileStatus> fileIter = hdfs.listFiles(new org.apache.hadoop.fs.Path(path), recursive);\n\n        while (fileIter.hasNext()) {\n            String filePath = fileIter.next().getPath().toString();\n            if(allowedExtensions == null){\n                paths.add(filePath);\n            } else {\n                String ext = FilenameUtils.getExtension(path);\n                if(allowedExtensions.contains(ext)){\n                    paths.add(filePath);\n                }\n            }\n        }\n        return sc.parallelize(paths);\n    }"}, {"instruction": "\u5206\u6790\u53e5\u6cd5\n\n@param words   \u8bcd\u8bed\u5217\u8868\n@param postags \u8bcd\u6027\u5217\u8868\n@param heads   \u8f93\u51fa\u4f9d\u5b58\u6307\u5411\u5217\u8868\n@param deprels \u8f93\u51fa\u4f9d\u5b58\u540d\u79f0\u5217\u8868\n@return \u8282\u70b9\u7684\u4e2a\u6570", "input": "Java", "output": "public int parse(List<String> words, List<String> postags, List<Integer> heads, List<String> deprels)\n    {\n        Instance inst = new Instance();\n        inst.forms.add(SpecialOption.ROOT);\n        inst.postags.add(SpecialOption.ROOT);\n\n        for (int i = 0; i < words.size(); i++)\n        {\n            inst.forms.add(words.get(i));\n            inst.postags.add(postags.get(i));\n        }\n\n        parser.predict(inst, heads, deprels);\n        heads.remove(0);\n        deprels.remove(0);\n\n        return heads.size();\n    }"}, {"instruction": "Returns the double data\nfor this ndarray.\nIf possible (the offset is 0 representing the whole buffer)\nit will return a direct reference to the underlying array\n@param buf the ndarray to get the data for\n@return the double data for this ndarray", "input": "Java", "output": "public static double[] getDoubleData(INDArray buf) {\n        if (buf.data().dataType() != DataType.DOUBLE)\n            throw new IllegalArgumentException(\"Double data must be obtained from a double buffer\");\n\n        if (buf.data().allocationMode() == DataBuffer.AllocationMode.HEAP) {\n            return buf.data().asDouble();\n\n        } else {\n            double[] ret = new double[(int) buf.length()];\n            INDArray linear = buf.reshape(-1);\n            for (int i = 0; i < buf.length(); i++)\n                ret[i] = linear.getDouble(i);\n            return ret;\n\n        }\n    }"}, {"instruction": "Gets the new session button.\n\n@return the new session button", "input": "Java", "output": "private JButton getNewSessionButton() {\r\n\t\tif (newSessionButton == null) {\r\n\t\t\tnewSessionButton = new JButton();\r\n\t\t\tnewSessionButton.setText(Constant.messages.getString(\"httpsessions.toolbar.newsession.label\"));\r\n\t\t\tnewSessionButton.setIcon(DisplayUtils.getScaledIcon(new ImageIcon(HttpSessionsPanel.class.getResource(\"/resource/icon/16/103.png\"))));\r\n\t\t\tnewSessionButton.setToolTipText(Constant.messages.getString(\"httpsessions.toolbar.newsession.tooltip\"));\r\n\r\n\t\t\tnewSessionButton.addActionListener(new ActionListener() {\r\n\t\t\t\t@Override\r\n\t\t\t\tpublic void actionPerformed(ActionEvent e) {\r\n\t\t\t\t\tHttpSessionsSite site = getCurrentHttpSessionSite();\r\n\t\t\t\t\tif (site != null) {\r\n\t\t\t\t\t\tsite.createEmptySession();\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t});\r\n\r\n\t\t}\r\n\t\treturn newSessionButton;\r\n\t}"}, {"instruction": "Extracts the Win32 error message from {@link Throwable} if possible.\n\n@return\nnull if there seems to be no error code or if the platform is not Win32.", "input": "Java", "output": "@CheckForNull\n    public static String getWin32ErrorMessage(Throwable e) {\n        String msg = e.getMessage();\n        if(msg!=null) {\n            Matcher m = errorCodeParser.matcher(msg);\n            if(m.matches()) {\n                try {\n                    ResourceBundle rb = ResourceBundle.getBundle(\"/hudson/win32errors\");\n                    return rb.getString(\"error\"+m.group(1));\n                } catch (Exception ignored) {\n                    // silently recover from resource related failures\n                }\n            }\n        }\n\n        if(e.getCause()!=null)\n            return getWin32ErrorMessage(e.getCause());\n        return null; // no message\n    }"}, {"instruction": "Maintains backwards compatibility. Invoked by XStream when this object is de-serialized.", "input": "Java", "output": "@SuppressWarnings({\"unused\"})\n    private Object readResolve() {\n        if (jdks == null) {\n            jdks = new ArrayList<>();\n        }\n        if (SLAVE_AGENT_PORT_ENFORCE) {\n            slaveAgentPort = getSlaveAgentPortInitialValue(slaveAgentPort);\n        }\n        if (disabledAgentProtocols == null && _disabledAgentProtocols != null) {\n            disabledAgentProtocols = Arrays.asList(_disabledAgentProtocols);\n            _disabledAgentProtocols = null;\n        }\n        if (enabledAgentProtocols == null && _enabledAgentProtocols != null) {\n            enabledAgentProtocols = Arrays.asList(_enabledAgentProtocols);\n            _enabledAgentProtocols = null;\n        }\n        // Invalidate the protocols cache after the reload\n        agentProtocols = null;\n        return this;\n    }"}, {"instruction": "Returns staged predictions of tree algorithms (prediction probabilities of trees per iteration).\nThe output structure is for tree Tt and class Cc:\nBinomial models: [probability T1.C1, probability T2.C1, ..., Tt.C1] where Tt.C1 correspond to the the probability p0\nMultinomial models: [probability T1.C1, probability T1.C2, ..., Tt.Cc]\n@param row Input row.\n@param predsLength Length of prediction result.\n@return array of staged prediction probabilities", "input": "Java", "output": "public double[] scoreStagedPredictions(double[] row, int predsLength) {\n        int contribOffset = nclasses() == 1 ? 0 : 1;\n        double[] trees_result = new double[_ntree_groups * _ntrees_per_group];\n\n        for (int groupIndex = 0; groupIndex < _ntree_groups; groupIndex++) {\n            double[] tmpPreds = new double[predsLength];\n            scoreTreeRange(row, 0, groupIndex+1, tmpPreds);\n            unifyPreds(row, 0, tmpPreds);\n            for (int classIndex = 0; classIndex < _ntrees_per_group; classIndex++) {\n                int tree_index = groupIndex * _ntrees_per_group + classIndex;\n                trees_result[tree_index] = tmpPreds[contribOffset+classIndex];\n            }\n        }\n        return trees_result;\n    }"}, {"instruction": "Class[]\u8f6cString[] <br>\n\u6ce8\u610f\uff0c\u5f97\u5230\u7684String\u53ef\u80fd\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8eClass.forName\uff0c\u8bf7\u4f7f\u7528getClasses(String[])\u53cd\u5411\u83b7\u53d6\n\n@param types Class[]\n@param javaStyle JDK\u81ea\u5e26\u683c\u5f0f\uff0c\u4f8b\u5982 int[], true\u7684\u8bdd\u8fd4\u56de [I; false\u7684\u8bdd\u8fd4\u56deint[]\n@return \u5bf9\u8c61\u63cf\u8ff0\n@see #getClasses(String[])", "input": "Java", "output": "public static String[] getTypeStrs(Class[] types, boolean javaStyle) {\n        if (CommonUtils.isEmpty(types)) {\n            return StringUtils.EMPTY_STRING_ARRAY;\n        } else {\n            String[] strings = new String[types.length];\n            for (int i = 0; i < types.length; i++) {\n                strings[i] = javaStyle ? types[i].getName() : getTypeStr(types[i]);\n            }\n            return strings;\n        }\n    }"}, {"instruction": "Verifies that no two process definitions share the same key, to prevent database unique\nindex violation.\n\n@throws ActivitiException if any two processes have the same key", "input": "Java", "output": "public void verifyProcessDefinitionsDoNotShareKeys(\n      Collection<ProcessDefinitionEntity> processDefinitions) {\n    Set<String> keySet = new LinkedHashSet<String>();\n    for (ProcessDefinitionEntity processDefinition : processDefinitions) {\n      if (keySet.contains(processDefinition.getKey())) {\n        throw new ActivitiException(\n            \"The deployment contains process definitions with the same key (process id attribute), this is not allowed\");\n      }\n      keySet.add(processDefinition.getKey());\n    }\n  }"}, {"instruction": "Return a {@link RelaxedNames} for the given source camelCase source name.\n\n@param name the source name in camelCase\n@return the relaxed names", "input": "Java", "output": "public static RelaxedNames forCamelCase(String name) {\n        StringBuilder result = new StringBuilder();\n        for (char c : name.toCharArray()) {\n            result.append(Character.isUpperCase(c) && result.length() > 0\n                          && result.charAt(result.length() - 1) != '-' ? \"-\" + Character.toLowerCase(c) : c);\n        }\n        return new RelaxedNames(result.toString());\n    }"}, {"instruction": "Converts a map of class elements to type arguments.\n@param typeArguments The type arguments\n@return The type arguments", "input": "Java", "output": "@NotNull\n    protected Map<String, Object> toTypeArguments(@NotNull Map<String, ClassElement> typeArguments) {\n        final LinkedHashMap<String, Object> map = new LinkedHashMap<>(typeArguments.size());\n        for (Map.Entry<String, ClassElement> entry : typeArguments.entrySet()) {\n            final ClassElement ce = entry.getValue();\n            final Map<String, ClassElement> subArgs = ce.getTypeArguments();\n            if (CollectionUtils.isNotEmpty(subArgs)) {\n                map.put(entry.getKey(), toTypeArguments(subArgs));\n            } else {\n                final Type typeReference = getTypeForElement(ce);\n                map.put(entry.getKey(), typeReference);\n            }\n        }\n\n        return map;\n    }"}, {"instruction": "Returns the number of registers that are no longer zero after the value was added\n\n@param position   The position into the byte buffer, this position represents two \"registers\"\n@param offsetDiff The difference in offset between the byteToAdd and the current HyperLogLogCollector\n@param byteToAdd  The byte to merge into the current HyperLogLogCollector", "input": "Java", "output": "private static short mergeAndStoreByteRegister(\n      final ByteBuffer storageBuffer,\n      final int position,\n      final int offsetDiff,\n      final byte byteToAdd\n  )\n  {\n    if (byteToAdd == 0) {\n      return 0;\n    }\n\n    final byte currVal = storageBuffer.get(position);\n\n    final int upperNibble = currVal & 0xf0;\n    final int lowerNibble = currVal & 0x0f;\n\n    // subtract the differences so that the nibbles align\n    final int otherUpper = (byteToAdd & 0xf0) - (offsetDiff << bitsPerBucket);\n    final int otherLower = (byteToAdd & 0x0f) - offsetDiff;\n\n    final int newUpper = Math.max(upperNibble, otherUpper);\n    final int newLower = Math.max(lowerNibble, otherLower);\n\n    storageBuffer.put(position, (byte) ((newUpper | newLower) & 0xff));\n\n    short numNoLongerZero = 0;\n    if (upperNibble == 0 && newUpper > 0) {\n      ++numNoLongerZero;\n    }\n    if (lowerNibble == 0 && newLower > 0) {\n      ++numNoLongerZero;\n    }\n\n    return numNoLongerZero;\n  }"}, {"instruction": "Wait for a message to arrive for this mailbox.\n\n@param timeout\nthe time, in milliseconds, to wait for a message before\nreturning null.\n\n@return an {@link OtpErlangObject OtpErlangObject} representing the body\nof the next message waiting in this mailbox.\n\n@exception OtpErlangDecodeException\nif the message cannot be decoded.\n\n@exception OtpErlangExit\nif a linked {@link OtpErlangPid pid} has exited or has\nsent an exit signal to this mailbox.", "input": "Java", "output": "public OtpErlangObject receive(final long timeout) throws OtpErlangExit,\n            OtpErlangDecodeException {\n        try {\n            final OtpMsg m = receiveMsg(timeout);\n            if (m != null) {\n                return m.getMsg();\n            }\n        } catch (final OtpErlangExit e) {\n            throw e;\n        } catch (final OtpErlangDecodeException f) {\n            throw f;\n        } catch (final InterruptedException g) {\n        }\n        return null;\n    }"}, {"instruction": "Removes duplicate deterministic expressions. Preserves the relative order\nof the expressions in the list.", "input": "Java", "output": "private List<RowExpression> removeDuplicates(List<RowExpression> expressions)\n    {\n        Set<RowExpression> seen = new HashSet<>();\n\n        ImmutableList.Builder<RowExpression> result = ImmutableList.builder();\n        for (RowExpression expression : expressions) {\n            if (!determinismEvaluator.isDeterministic(expression)) {\n                result.add(expression);\n            }\n            else if (!seen.contains(expression)) {\n                result.add(expression);\n                seen.add(expression);\n            }\n        }\n\n        return result.build();\n    }"}, {"instruction": "Token count for a user.\n\n@param userId user to count tokens for\n@return count of the user's tokens", "input": "Java", "output": "@View(name = \"count_by_userId\", map = \"function(doc) { if(doc.token && doc.userId) { emit(doc.userId, doc) } }\", reduce = \"_count\")\n    public long countByUserId(final String userId) {\n        val view = createQuery(\"count_by_userId\").key(userId);\n        val rows = db.queryView(view).getRows();\n        if (rows.isEmpty()) {\n            return 0;\n        }\n        return rows.get(0).getValueAsInt();\n    }"}, {"instruction": "Gets authenticated profile.\n\n@param request            the request\n@param response           the response\n@param requiredPermission the required permission\n@return the authenticated profile", "input": "Java", "output": "protected CommonProfile getAuthenticatedProfile(final HttpServletRequest request,\n                                                    final HttpServletResponse response,\n                                                    final String requiredPermission) {\n        val context = new J2EContext(request, response, getUmaConfigurationContext().getSessionStore());\n        val manager = new ProfileManager<>(context, context.getSessionStore());\n        val profile = manager.get(true).orElse(null);\n        if (profile == null) {\n            throw new AuthenticationException(\"Unable to locate authenticated profile\");\n        }\n        if (!profile.getPermissions().contains(requiredPermission)) {\n            throw new AuthenticationException(\"Authenticated profile does not carry the UMA protection scope\");\n        }\n        return profile;\n    }"}, {"instruction": "\u6362\u7b97\u6cd5\uff1f MD5  SHA-1 MurMurHash???\n\n@param value the value\n@return the byte []", "input": "Java", "output": "public static byte[] messageDigest(String value) {\n        MessageDigest md5;\n        try {\n            md5 = MessageDigest.getInstance(\"MD5\");\n            md5.update(value.getBytes(\"UTF-8\"));\n            return md5.digest();\n        } catch (NoSuchAlgorithmException e) {\n            throw new SofaRpcRuntimeException(\"No such algorithm named md5\", e);\n        } catch (UnsupportedEncodingException e) {\n            throw new SofaRpcRuntimeException(\"Unsupported encoding of\" + value, e);\n        }\n    }"}, {"instruction": "Fails all pending checkpoints which have not been acknowledged by the given execution\nattempt id.\n\n@param executionAttemptId for which to discard unacknowledged pending checkpoints\n@param cause of the failure", "input": "Java", "output": "public void failUnacknowledgedPendingCheckpointsFor(ExecutionAttemptID executionAttemptId, Throwable cause) {\n\t\tsynchronized (lock) {\n\t\t\tIterator<PendingCheckpoint> pendingCheckpointIterator = pendingCheckpoints.values().iterator();\n\n\t\t\twhile (pendingCheckpointIterator.hasNext()) {\n\t\t\t\tfinal PendingCheckpoint pendingCheckpoint = pendingCheckpointIterator.next();\n\n\t\t\t\tif (!pendingCheckpoint.isAcknowledgedBy(executionAttemptId)) {\n\t\t\t\t\tpendingCheckpointIterator.remove();\n\t\t\t\t\tdiscardCheckpoint(pendingCheckpoint, cause);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}"}, {"instruction": "Handle asynchronous {@link Runnable}. This method simply executes the given {@link Runnable}\nin the context of the actor thread.\n\n@param runAsync Run async message", "input": "Java", "output": "private void handleRunAsync(RunAsync runAsync) {\n\t\tfinal long timeToRun = runAsync.getTimeNanos();\n\t\tfinal long delayNanos;\n\n\t\tif (timeToRun == 0 || (delayNanos = timeToRun - System.nanoTime()) <= 0) {\n\t\t\t// run immediately\n\t\t\ttry {\n\t\t\t\trunAsync.getRunnable().run();\n\t\t\t} catch (Throwable t) {\n\t\t\t\tlog.error(\"Caught exception while executing runnable in main thread.\", t);\n\t\t\t\tExceptionUtils.rethrowIfFatalErrorOrOOM(t);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// schedule for later. send a new message after the delay, which will then be immediately executed\n\t\t\tFiniteDuration delay = new FiniteDuration(delayNanos, TimeUnit.NANOSECONDS);\n\t\t\tRunAsync message = new RunAsync(runAsync.getRunnable(), timeToRun);\n\n\t\t\tfinal Object envelopedSelfMessage = envelopeSelfMessage(message);\n\n\t\t\tgetContext().system().scheduler().scheduleOnce(delay, getSelf(), envelopedSelfMessage,\n\t\t\t\t\tgetContext().dispatcher(), ActorRef.noSender());\n\t\t}\n\t}"}, {"instruction": "Programmatically registers the auto-configuration package names. Subsequent\ninvocations will add the given package names to those that have already been\nregistered. You can use this method to manually define the base packages that will\nbe used for a given {@link BeanDefinitionRegistry}. Generally it's recommended that\nyou don't call this method directly, but instead rely on the default convention\nwhere the package name is set from your {@code @EnableAutoConfiguration}\nconfiguration class or classes.\n@param registry the bean definition registry\n@param packageNames the package names to set", "input": "Java", "output": "public static void register(BeanDefinitionRegistry registry, String... packageNames) {\n\t\tif (registry.containsBeanDefinition(BEAN)) {\n\t\t\tBeanDefinition beanDefinition = registry.getBeanDefinition(BEAN);\n\t\t\tConstructorArgumentValues constructorArguments = beanDefinition\n\t\t\t\t\t.getConstructorArgumentValues();\n\t\t\tconstructorArguments.addIndexedArgumentValue(0,\n\t\t\t\t\taddBasePackages(constructorArguments, packageNames));\n\t\t}\n\t\telse {\n\t\t\tGenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n\t\t\tbeanDefinition.setBeanClass(BasePackages.class);\n\t\t\tbeanDefinition.getConstructorArgumentValues().addIndexedArgumentValue(0,\n\t\t\t\t\tpackageNames);\n\t\t\tbeanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\t\tregistry.registerBeanDefinition(BEAN, beanDefinition);\n\t\t}\n\t}"}, {"instruction": "\u8f6c\u6362\u4e3a\u7a7a\u683c\u5206\u5272\u65e0\u6807\u7b7e\u7684String\n\n@return", "input": "Java", "output": "public String toStringWithoutLabels()\n    {\n        StringBuilder sb = new StringBuilder(size() * 4);\n        int i = 1;\n        for (IWord word : wordList)\n        {\n            if (word instanceof CompoundWord)\n            {\n                int j = 0;\n                for (Word w : ((CompoundWord) word).innerList)\n                {\n                    sb.append(w.getValue());\n                    if (++j != ((CompoundWord) word).innerList.size())\n                        sb.append(' ');\n                }\n            }\n            else\n                sb.append(word.getValue());\n            if (i != wordList.size()) sb.append(' ');\n            ++i;\n        }\n        return sb.toString();\n    }"}, {"instruction": "Inherited.", "input": "Java", "output": "public InputStream readProtectedResource(URL url, OAuthConsumerToken accessToken, String httpMethod) throws OAuthRequestFailedException {\n    if (accessToken == null) {\n      throw new OAuthRequestFailedException(\"A valid access token must be supplied.\");\n    }\n\n    ProtectedResourceDetails resourceDetails = getProtectedResourceDetailsService().loadProtectedResourceDetailsById(accessToken.getResourceId());\n    if ((!resourceDetails.isAcceptsAuthorizationHeader()) && !\"POST\".equalsIgnoreCase(httpMethod) && !\"PUT\".equalsIgnoreCase(httpMethod)) {\n      throw new IllegalArgumentException(\"Protected resource \" + resourceDetails.getId() + \" cannot be accessed with HTTP method \" +\n        httpMethod + \" because the OAuth provider doesn't accept the OAuth Authorization header.\");\n    }\n\n    return readResource(resourceDetails, url, httpMethod, accessToken, resourceDetails.getAdditionalParameters(), null);\n  }"}, {"instruction": "The lookup handler method, maps the SEOMapper method to the request URL.\n<p>If no mapping is found, or if the URL is disabled, it will simply drop through\nto the standard 404 handling.</p>\n\n@param urlPath the path to match.\n@param request the http servlet request.\n@return The HandlerMethod if one was found.", "input": "Java", "output": "@Override\n  protected HandlerMethod lookupHandlerMethod(String urlPath, HttpServletRequest request) {\n    logger.debug(\"looking up handler for path: \" + urlPath);\n    HandlerMethod handlerMethod = handlerMethods.get(urlPath);\n    if (handlerMethod != null) {\n      return handlerMethod;\n    }\n    for (String path : handlerMethods.keySet()) {\n      UriTemplate template = new UriTemplate(path);\n      if (template.matches(urlPath)) {\n        request.setAttribute(\n            HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE,\n            template.match(urlPath));\n        return handlerMethods.get(path);\n      }\n    }\n    return null;\n  }"}, {"instruction": "Gets a list of the http cookies from this request Header.\n\n@return the http cookies\n@throws IllegalArgumentException if a problem is encountered while\nprocessing the \"Cookie: \" header line.", "input": "Java", "output": "public List<HttpCookie> getHttpCookies() {\r\n        List<HttpCookie> cookies = new LinkedList<>();\r\n        // Use getCookieParams to reduce the places we parse cookies\r\n        TreeSet<HtmlParameter> ts = getCookieParams();\r\n        Iterator<HtmlParameter> it = ts.iterator();\r\n        while (it.hasNext()) {\r\n            HtmlParameter htmlParameter = it.next();\r\n            if (!htmlParameter.getName().isEmpty()) {\r\n                try {\r\n                    cookies.add(new HttpCookie(htmlParameter.getName(), htmlParameter.getValue()));\r\n                \r\n                } catch (IllegalArgumentException e) {\r\n                    // Occurs while scanning ;)\r\n                    log.debug(e.getMessage() + \" \" + htmlParameter.getName());\r\n                }\r\n            }\r\n        }\r\n        \r\n        return cookies;\r\n    }"}, {"instruction": "Based on the ConciseSet implementation by Alessandro Colantonio", "input": "Java", "output": "private static void trimZeros(IntList set)\n  {\n    // loop over ALL_ZEROS_LITERAL words\n    int w;\n    int last = set.length() - 1;\n    do {\n      w = set.get(last);\n      if (w == ConciseSetUtils.ALL_ZEROS_LITERAL) {\n        set.set(last, 0);\n        last--;\n      } else if (ConciseSetUtils.isZeroSequence(w)) {\n        if (ConciseSetUtils.isSequenceWithNoBits(w)) {\n          set.set(last, 0);\n          last--;\n        } else {\n          // convert the sequence in a 1-bit literal word\n          set.set(last, ConciseSetUtils.getLiteral(w, false));\n          return;\n        }\n      } else {\n        // one sequence or literal\n        return;\n      }\n      if (set.isEmpty() || last == -1) {\n        return;\n      }\n    } while (true);\n  }"}, {"instruction": "* -1 if rtl scroll max is negative", "input": "JavaScript", "output": "function(base) {\n                        return isNaN(base / maxScroll) ? 0 : MATH.max(0, MATH.min(1, base / maxScroll));\n                    }"}, {"instruction": "Parses rabin chunker string\n\n@param  {String}   chunker Chunker algorithm supported formats:\n\"rabin\"\n\"rabin-{avg}\"\n\"rabin-{min}-{avg}-{max}\"\n\n@return {Object}   rabin chunker options", "input": "JavaScript", "output": "function parseRabinString (chunker) {\n  const options = {}\n  const parts = chunker.split('-')\n  switch (parts.length) {\n    case 1:\n      options.avgChunkSize = 262144\n      break\n    case 2:\n      options.avgChunkSize = parseChunkSize(parts[1], 'avg')\n      break\n    case 4:\n      options.minChunkSize = parseChunkSize(parts[1], 'min')\n      options.avgChunkSize = parseChunkSize(parts[2], 'avg')\n      options.maxChunkSize = parseChunkSize(parts[3], 'max')\n      break\n    default:\n      throw new Error('Incorrect chunker format (expected \"rabin\" \"rabin-[avg]\" or \"rabin-[min]-[avg]-[max]\"')\n  }\n\n  return options\n}"}, {"instruction": "OAuth2 Username-Password Flow (Resource Owner Password Credentials)\n\n@param {String} username - Salesforce username\n@param {String} password - Salesforce password\n@param {Callback.<TokenResponse>} [callback] - Callback function\n@returns {Promise.<TokenResponse>}", "input": "JavaScript", "output": "function(username, password, callback) {\n    return this._postParams({\n      grant_type : \"password\",\n      username : username,\n      password : password,\n      client_id : this.clientId,\n      client_secret : this.clientSecret,\n      redirect_uri : this.redirectUri\n    }, callback);\n  }"}, {"instruction": "traverse icons in a row of icon atlas extend each icon with left-top coordinates", "input": "JavaScript", "output": "function buildRowMapping(mapping, columns, yOffset) {\n  for (let i = 0; i < columns.length; i++) {\n    const {icon, xOffset} = columns[i];\n    const id = getIconId(icon);\n    mapping[id] = Object.assign({}, icon, {\n      x: xOffset,\n      y: yOffset\n    });\n  }\n}"}, {"instruction": "/* make sligthly rotated, scaled and mirrored variants of the input image /* can be useful to increase the training set in order to get better results /* but also training time increases with numJitters", "input": "JavaScript", "output": "function makeGetJitteredFaces(fr) {\n  return function(face, numJitters) {\n    if (numJitters && (face.rows !== face.cols)) {\n      throw new Error('jittering requires the face to have the same number of rows and cols')\n    }\n    return [face].concat(!numJitters ? [] : fr.jitterImage(face, numJitters))\n  }\n}"}, {"instruction": "terminate process, err (if defined) is from seneca.close", "input": "JavaScript", "output": "function(close_err) {\n            if (!undead) {\n              process.nextTick(function() {\n                if (close_err) {\n                  instance.log.fatal({\n                    kind: 'close',\n                    err: Util.inspect(close_err)\n                  })\n                }\n\n                if (test) {\n                  if (close_err) {\n                    Print.err(close_err)\n                  }\n\n                  Print.err(stderrmsg)\n                  Print.err(\n                    '\\nSENECA TERMINATED at ' +\n                      new Date().toISOString() +\n                      '. See above for error report.\\n'\n                  )\n                }\n\n                so.system.exit(1)\n              })\n            }\n          }"}, {"instruction": "Checks whether this user is the current user and has been authenticated.\n@deprecated \u5982\u679c\u8981\u5224\u65ad\u5f53\u524d\u7528\u6237\u7684\u767b\u5f55\u72b6\u6001\u662f\u5426\u6709\u6548\uff0c\u8bf7\u4f7f\u7528 currentUser.isAuthenticated().then()\uff0c\n\u5982\u679c\u8981\u5224\u65ad\u8be5\u7528\u6237\u662f\u5426\u662f\u5f53\u524d\u767b\u5f55\u7528\u6237\uff0c\u8bf7\u4f7f\u7528 user.id === currentUser.id\n@return (Boolean) whether this user is the current user and is logged in.", "input": "JavaScript", "output": "function() {\n        console.warn(\n          'DEPRECATED: \u5982\u679c\u8981\u5224\u65ad\u5f53\u524d\u7528\u6237\u7684\u767b\u5f55\u72b6\u6001\u662f\u5426\u6709\u6548\uff0c\u8bf7\u4f7f\u7528 currentUser.isAuthenticated().then()\uff0c\u5982\u679c\u8981\u5224\u65ad\u8be5\u7528\u6237\u662f\u5426\u662f\u5f53\u524d\u767b\u5f55\u7528\u6237\uff0c\u8bf7\u4f7f\u7528 user.id === currentUser.id\u3002'\n        );\n        return (\n          !!this._sessionToken &&\n          (!AV._config.disableCurrentUser &&\n            AV.User.current() &&\n            AV.User.current().id === this.id)\n        );\n      }"}, {"instruction": "return the custom message for the given element name and validation method", "input": "JavaScript", "output": "function( name, method ) {\n\t\t\tvar m = this.settings.messages[name];\n\t\t\treturn m && (m.constructor === String ? m : m[method]);\n\t\t}"}, {"instruction": "/* extract the faces from an image for given face rectangles", "input": "JavaScript", "output": "function getFacesFromLocations(img, rects, faceSize = 150) {\n      const shapes = rects.map(rect => faceLandmarkPredictor.predict(img, rect))\n      return fr.extractImageChips(img, fr.getFaceChipDetails(shapes, faceSize))\n    }"}, {"instruction": "Creates a splice record and sends an array splice notification for\nthe described mutation\n\nNote: this implementation only accepts normalized paths\n\n@param {!PropertyEffectsType} inst Instance to send notifications to\n@param {Array} array The array the mutations occurred on\n@param {string} path The path to the array that was mutated\n@param {number} index Index at which the array mutation occurred\n@param {number} addedCount Number of added items\n@param {Array} removed Array of removed items\n@return {void}\n@private", "input": "JavaScript", "output": "function notifySplice(inst, array, path, index, addedCount, removed) {\n  notifySplices(inst, array, path, [{\n    index: index,\n    addedCount: addedCount,\n    removed: removed,\n    object: array,\n    type: 'splice'\n  }]);\n}"}, {"instruction": "Returns true if the source code is intended to run in strict mode. Does not detect\n\"use strict\" if it occurs in a nested function.\n\n@param {String} src\n@return {Boolean}", "input": "JavaScript", "output": "function detectStrictMode(src) {\r\n    var singleLine;\r\n    var multiLine;\r\n\r\n    while ((singleLine = singleLineComment.test(src)) || (multiLine = multiLineComment.test(src))) {\r\n        if (singleLine) {\r\n            src = src.replace(singleLineComment, \"\");\r\n        }\r\n        if (multiLine) {\r\n            src = src.replace(multiLineComment, \"\");\r\n        }\r\n    }\r\n\r\n    return strictMode.test(src);\r\n}"}, {"instruction": "creates token objects and pushes them to a list", "input": "JavaScript", "output": "function tokener(value, type) {\n\t\tsession.tokens.push({\n\t\t\tvalue: value,\n\t\t\ttype:  type || value,\n\t\t\tstart: null,\n\t\t\tend:   null\n\t\t});\n\t}"}, {"instruction": "renders slider using CSS background ;)", "input": "JavaScript", "output": "function draw(attrsModified) {\n    calc();\n    if (isChanged && value != prevValue)\n      slider.dispatchEvent(onChange);\n    isChanged = false;\n    if (!attrsModified && value == prevValue)\n      return;\n    prevValue = value;\n    var position = range ? (value - min) / range * 100 : 0;\n    var bg = '-moz-element(#__sliderthumb__) ' + position + '% no-repeat, ';\n    style(slider, { background: bg + track });\n  }"}, {"instruction": "convert a Backbone model to JSON", "input": "JavaScript", "output": "function serialize(model) {\n    var data = model.toJSON();\n    Object.keys(data).forEach(function serializeRecur(key) {\n        var value = data[key];\n        // if any value can be serialized toJSON() then do it\n        if (value && value.toJSON) {\n            data[key] = data[key].toJSON();\n        }\n    });\n    return data;\n}"}, {"instruction": "The base implementation of `assignValue` and `assignMergeValue` without\nvalue checks.\n\n@private\n@param {Object} object The object to modify.\n@param {string} key The key of the property to assign.\n@param {*} value The value to assign.", "input": "JavaScript", "output": "function baseAssignValue(object, key, value) {\n  if (key == '__proto__') {\n    Object.defineProperty(object, key, {\n      'configurable': true,\n      'enumerable': true,\n      'value': value,\n      'writable': true\n    })\n  } else {\n    object[key] = value\n  }\n}"}, {"instruction": "Prepare i18n, load translations from plugins and book\n\n@param {Output}\n@return {Promise<Output>}", "input": "JavaScript", "output": "function prepareI18n(output) {\n    var state = output.getState();\n    var i18n = state.getI18n();\n    var searchPaths = listSearchPaths(output);\n\n    searchPaths\n        .reverse()\n        .forEach(function(searchPath) {\n            var i18nRoot = path.resolve(searchPath, '_i18n');\n\n            if (!fs.existsSync(i18nRoot)) return;\n            i18n.load(i18nRoot);\n        });\n\n    return Promise(output);\n}"}, {"instruction": "finds the given at declaration value\n@param  {Array[Object]} decls the decls from an element\n@param  {String}        the prop\n@return {Any}           the found value", "input": "JavaScript", "output": "function findAtDecl (decls, prop) {\n  const foundDecls = decls.filter((decl) => {\n    return (isPlainObject(decl) &&\n          Object.keys(decl).length > 0 &&\n          Object.keys(decl)[0] === `@${prop}`) || decl === `@${prop}`\n  })\n\n  if (foundDecls.length === 0) { return }\n\n  const decl = foundDecls[0]\n\n  return isPlainObject(decl) ? Object.values(decl)[0] : true\n}"}, {"instruction": "Need to re-render if the sort order or the contents change.", "input": "JavaScript", "output": "function (nextProps, nextState) {\n            return nextProps.forceRender ||\n                this.props.contents !== nextProps.contents ||\n                this.props.sortDirectoriesFirst !== nextProps.sortDirectoriesFirst ||\n                this.props.extensions !== nextProps.extensions;\n        }"}, {"instruction": "for output file output", "input": "JavaScript", "output": "function formatOutput(output) {\n    var indent = '  ';\n    var pad = '  ';\n    var results = [];\n    results.push('AppDir:' + output.appDir);\n    output.suites.forEach(function(suite) {\n      results.push(pad + 'Suite: ' + suite.description + ' -- ' + suite.status);\n      pad+=indent;\n      suite.specs.forEach(function(spec) {\n        results.push(pad + spec.status + ' - ' + spec.description);\n        if (spec.failedExpectations) {\n          pad+=indent;\n          spec.failedExpectations.forEach(function (fe) {\n            results.push(pad + 'message: ' + fe.message);\n          });\n          pad=pad.substr(2);\n        }\n      });\n      pad = pad.substr(2);\n      results.push('');\n    });\n    results.push('');\n    return results.join('\\n');\n  }"}, {"instruction": "/* jshint ignore:start \nInitialize the V1 version of FlexApi\n\n@constructor Twilio.FlexApi.V1\n\n@property {Twilio.FlexApi.V1.FlexFlowList} flexFlow - flexFlow resource\n@property {Twilio.FlexApi.V1.ConfigurationList} configuration -\nconfiguration resource\n\n@param {Twilio.FlexApi} domain - The twilio domain\n /* jshint ignore:end", "input": "JavaScript", "output": "function V1(domain) {\n  Version.prototype.constructor.call(this, domain, 'v1');\n\n  // Resources\n  this._flexFlow = undefined;\n  this._configuration = undefined;\n}"}, {"instruction": "# words :: String -> Array String . . Takes a string and returns the array of words the string contains . (words are delimited by whitespace characters). . . See also [`unwords`](#unwords). . . ```javascript . > S.words (' foo bar baz ') . ['foo', 'bar', 'baz'] . ```", "input": "JavaScript", "output": "function words(s) {\n    var words = s.split (/\\s+/);\n    var len = words.length;\n    return words.slice (words[0] === '' ? 1 : 0,\n                        words[len - 1] === '' ? len - 1 : len);\n  }"}, {"instruction": "We are using a 2x2 rotation matrix.", "input": "JavaScript", "output": "function applyRotationMatrix(touch, axis) {\n  const rotationMatrix = axisProperties.rotationMatrix[axis];\n\n  return {\n    pageX: rotationMatrix.x[0] * touch.pageX + rotationMatrix.x[1] * touch.pageY,\n    pageY: rotationMatrix.y[0] * touch.pageX + rotationMatrix.y[1] * touch.pageY,\n  };\n}"}, {"instruction": "Remove injected default camera from scene, if present.\n\n@param {Element} sceneEl", "input": "JavaScript", "output": "function removeDefaultCamera (sceneEl) {\n  var defaultCamera;\n  var camera = sceneEl.camera;\n  if (!camera) { return; }\n\n  // Remove default camera if present.\n  defaultCamera = sceneEl.querySelector('[' + DEFAULT_CAMERA_ATTR + ']');\n  if (!defaultCamera) { return; }\n  sceneEl.removeChild(defaultCamera);\n}"}, {"instruction": "('data.a.b', 5) => opts.data.a.b = 5", "input": "JavaScript", "output": "function (path, value) {\n    if (typeof path == 'string') {\n      path = path.split('.');\n    } else if (!Array.isArray(path)) {\n      return;\n    }\n\n    var propName = path.shift();\n    var prop = Model.allProperties[propName] || opts.extra[propName];\n    var currKey, currObj;\n\n    if (!prop) {\n      return;\n    }\n    if (path.length == 0) {\n      instance[propName] = value;\n      return;\n    }\n    currObj = instance[propName];\n\n    while(currObj && path.length > 0 ) {\n      currKey = path.shift();\n\n      if (path.length > 0) {\n        currObj = currObj[currKey];\n      } else if (currObj[currKey] !== value) {\n        currObj[currKey] = value;\n        opts.changes.push(propName);\n      }\n    }\n  }"}, {"instruction": "Left/right translate effect", "input": "JavaScript", "output": "function scrollInterpolator3 (index, carouselProps) {\n    const range = [2, 1, 0, -1];\n    const inputRange = getInputRangeFromIndexes(range, index, carouselProps);\n    const outputRange = range;\n\n    return { inputRange, outputRange };\n}"}, {"instruction": "Updates the type metadata from the current jCal type and design set.\n\n@private", "input": "JavaScript", "output": "function() {\n      var designSet = this._designSet;\n\n      if (this.type in designSet.value) {\n        var designType = designSet.value[this.type];\n\n        if ('decorate' in designSet.value[this.type]) {\n          this.isDecorated = true;\n        } else {\n          this.isDecorated = false;\n        }\n\n        if (this.name in designSet.property) {\n          this.isMultiValue = ('multiValue' in designSet.property[this.name]);\n          this.isStructuredValue = ('structuredValue' in designSet.property[this.name]);\n        }\n      }\n    }"}, {"instruction": "/* [MS-OFFCRYPTO] 2.1.6 DataSpaceMap", "input": "JavaScript", "output": "function parse_DataSpaceMap(blob) {\n\tvar o = [];\n\tblob.l += 4; // must be 0x8\n\tvar cnt = blob.read_shift(4);\n\twhile(cnt-- > 0) o.push(parse_DataSpaceMapEntry(blob));\n\treturn o;\n}"}, {"instruction": "Runs Typedoc command.\n\nAdditional config options come from ./typedoc.js", "input": "JavaScript", "output": "function runTypedoc() {\n  const typeSource = apiType === 'node' ? tempNodeSourcePath : sourceFile;\n  const command = `${repoPath}/node_modules/.bin/typedoc ${typeSource} \\\n  --out ${docPath} \\\n  --readme ${tempHomePath} \\\n  --options ${__dirname}/typedoc.js \\\n  --theme ${__dirname}/theme`;\n\n  console.log('Running command:\\n', command);\n  return exec(command);\n}"}, {"instruction": "Modified Richards and Whitby-Stevens precedence climbing method.", "input": "JavaScript", "output": "function makeTree(left, ops, rights, minPrecedence = 0) {\n  while (ops.length > 0 && precedence[ops[0]] >= minPrecedence) {\n    let op = ops.shift();\n    let right = rights.shift();\n    while (ops.length > 0 && (precedence[ops[0]] > precedence[op] ||\n        associativity[ops[0]] === 'R' && precedence[ops[0]] === precedence[op])) {\n      right = makeTree(right, ops, rights, precedence[ops[0]]);\n    }\n    left = new BinaryExpression(left, op, right);\n  }\n  return left;\n}"}, {"instruction": "# prop :: String -> a -> b . . Takes a property name and an object with known properties and returns . the value of the specified property. If for some reason the object . lacks the specified property, a type error is thrown. . . For accessing properties of uncertain objects, use [`get`](#get) instead. . For accessing string map values by key, use [`value`](#value) instead. . . ```javascript . > S.prop ('a') ({a: 1, b: 2}) . 1 . ```", "input": "JavaScript", "output": "function prop(key) {\n    return function(x) {\n      var obj = toObject (x);\n      if (key in obj) return obj[key];\n      throw new TypeError ('\u2018prop\u2019 expected object to have a property named ' +\n                           '\u2018' + key + '\u2019; ' + show (x) + ' does not');\n    };\n  }"}, {"instruction": "Convert the CSS style value to a JSX style value\n\n@param {string} value CSS style value\n@return {string} JSX style value", "input": "JavaScript", "output": "function (value) {\n    if (isNumeric(value)) {\n      return value\n    } else if (value.startsWith(\"'\") || value.startsWith(\"\\\"\")) {\n      return value\n    } else {\n      return '\\'' + value.replace(/'/g, '\"') + '\\'';\n    }\n  }"}, {"instruction": "parse json file and allow single line comments", "input": "JavaScript", "output": "async function readJSONFile(filename){\n    // load file\n    let raw = await _fs.readFile(filename, 'utf8');\n\n    // strip single line js comments\n    raw = raw.replace(/^\\s*\\/\\/.*$/gm, '');\n\n    // parse text\n    return JSON.parse(raw);\n}"}, {"instruction": "Special case getDefaultProps which should move into statics but requires\nautomatic merging.", "input": "JavaScript", "output": "function(Constructor, getDefaultProps) {\n      if (Constructor.getDefaultProps) {\n        Constructor.getDefaultProps = createMergedResultFunction(\n          Constructor.getDefaultProps,\n          getDefaultProps\n        );\n      } else {\n        Constructor.getDefaultProps = getDefaultProps;\n      }\n    }"}, {"instruction": "/*\nFeature class for features that fire (or don't) on combinations of context\nand class\nCopyright (C) 2017 Hugo W.L. ter Doest\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.", "input": "JavaScript", "output": "function Feature(f, name, parameters) {\n  this.evaluate = f;\n  this.name = name;\n  this.parameters = parameters;\n\n  var tmp = \"\";\n  parameters.forEach(function(par) {\n    tmp += par + \"|\";\n  });\n  this.parametersKey = tmp.substr(0, tmp.length - 1);\n}"}, {"instruction": "/* Returns a promise that returns true if user confirms, or false if they abort.", "input": "JavaScript", "output": "function getConfirmation(terria, viewState, confirmConversion, message) {\n  if (!confirmConversion) {\n    return when(true);\n  }\n\n  var d = when.defer(); // there's no `when.promise(resolver)` in when 1.7.1\n  viewState.notifications.push({\n    confirmText: \"Upload\",\n    denyText: \"Cancel\",\n    title: \"Use conversion service?\",\n    message: message,\n    confirmAction: function() {\n      d.resolve(true);\n    },\n    denyAction: function() {\n      d.resolve(false);\n    }\n  });\n  return d.promise;\n}"}, {"instruction": "// itemChanged returns true if the given disk file differs from the information\n// in the database and schedules that file for scanning", "input": "go language", "output": "func (f *sendReceiveFolder) itemChanged(stat fs.FileInfo, item protocol.FileInfo, hasItem bool, scanChan chan<- string) (changed bool, err error) {\n\tdefer func() {\n\t\tif changed {\n\t\t\tscanChan <- item.Name\n\t\t}\n\t}()\n\n\tif !hasItem || item.Deleted {\n\t\t// The item appeared from nowhere\n\t\treturn true, nil\n\t}\n\n\t// Check that the item on disk is what we expect it to be according\n\t// to the database. If there's a mismatch here, there might be local\n\t// changes that we don't know about yet and we should scan before\n\t// touching the item.\n\tstatItem, err := scanner.CreateFileInfo(stat, item.Name, f.fs)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"comparing item on disk to db\")\n\t}\n\n\treturn !statItem.IsEquivalentOptional(item, f.IgnorePerms, true, protocol.LocalAllFlags), nil\n}"}, {"instruction": "// FindCWD returns the current working directory from where the Hugo\n// executable is run.", "input": "go language", "output": "func FindCWD() (string, error) {\n\tserverFile, err := filepath.Abs(os.Args[0])\n\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"can't get absolute path for executable: %v\", err)\n\t}\n\n\tpath := filepath.Dir(serverFile)\n\trealFile, err := filepath.EvalSymlinks(serverFile)\n\n\tif err != nil {\n\t\tif _, err = os.Stat(serverFile + \".exe\"); err == nil {\n\t\t\trealFile = filepath.Clean(serverFile + \".exe\")\n\t\t}\n\t}\n\n\tif err == nil && realFile != serverFile {\n\t\tpath = filepath.Dir(realFile)\n\t}\n\n\treturn path, nil\n}"}, {"instruction": "// LockOpts returns a handle to a lock struct which can be used\n// to acquire and release the mutex. The key used must have\n// write permissions.", "input": "go language", "output": "func (c *Client) LockOpts(opts *LockOptions) (*Lock, error) {\n\tif opts.Key == \"\" {\n\t\treturn nil, fmt.Errorf(\"missing key\")\n\t}\n\tif opts.SessionName == \"\" {\n\t\topts.SessionName = DefaultLockSessionName\n\t}\n\tif opts.SessionTTL == \"\" {\n\t\topts.SessionTTL = DefaultLockSessionTTL\n\t} else {\n\t\tif _, err := time.ParseDuration(opts.SessionTTL); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid SessionTTL: %v\", err)\n\t\t}\n\t}\n\tif opts.MonitorRetryTime == 0 {\n\t\topts.MonitorRetryTime = DefaultMonitorRetryTime\n\t}\n\tif opts.LockWaitTime == 0 {\n\t\topts.LockWaitTime = DefaultLockWaitTime\n\t}\n\tl := &Lock{\n\t\tc:    c,\n\t\topts: opts,\n\t}\n\treturn l, nil\n}"}, {"instruction": "// newCallback turns fn (a function) into a callback object. It returns nil if the function\n// is unsuitable as an RPC callback.", "input": "go language", "output": "func newCallback(receiver, fn reflect.Value) *callback {\n\tfntype := fn.Type()\n\tc := &callback{fn: fn, rcvr: receiver, errPos: -1, isSubscribe: isPubSub(fntype)}\n\t// Determine parameter types. They must all be exported or builtin types.\n\tc.makeArgTypes()\n\tif !allExportedOrBuiltin(c.argTypes) {\n\t\treturn nil\n\t}\n\t// Verify return types. The function must return at most one error\n\t// and/or one other non-error value.\n\touts := make([]reflect.Type, fntype.NumOut())\n\tfor i := 0; i < fntype.NumOut(); i++ {\n\t\touts[i] = fntype.Out(i)\n\t}\n\tif len(outs) > 2 || !allExportedOrBuiltin(outs) {\n\t\treturn nil\n\t}\n\t// If an error is returned, it must be the last returned value.\n\tswitch {\n\tcase len(outs) == 1 && isErrorType(outs[0]):\n\t\tc.errPos = 0\n\tcase len(outs) == 2:\n\t\tif isErrorType(outs[0]) || !isErrorType(outs[1]) {\n\t\t\treturn nil\n\t\t}\n\t\tc.errPos = 1\n\t}\n\treturn c\n}"}, {"instruction": "// adds a symmetric key to the pss key pool, and optionally adds the key to the\n// collection of keys used to attempt symmetric decryption of incoming messages", "input": "go language", "output": "func (ks *KeyStore) addSymmetricKeyToPool(keyid string, topic Topic, address PssAddress, addtocache bool, protected bool) {\n\tpsp := &pssPeer{\n\t\taddress:   address,\n\t\tprotected: protected,\n\t}\n\tks.mx.Lock()\n\tif _, ok := ks.symKeyPool[keyid]; !ok {\n\t\tks.symKeyPool[keyid] = make(map[Topic]*pssPeer)\n\t}\n\tks.symKeyPool[keyid][topic] = psp\n\tks.mx.Unlock()\n\tif addtocache {\n\t\tks.symKeyDecryptCacheCursor++\n\t\tks.symKeyDecryptCache[ks.symKeyDecryptCacheCursor%cap(ks.symKeyDecryptCache)] = &keyid\n\t}\n}"}, {"instruction": "// ResolveIndices implements Plan interface.", "input": "go language", "output": "func (p *PhysicalProjection) ResolveIndices() (err error) {\n\terr = p.physicalSchemaProducer.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor i, expr := range p.Exprs {\n\t\tp.Exprs[i], err = expr.ResolveIndices(p.children[0].Schema())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tchildProj, isProj := p.children[0].(*PhysicalProjection)\n\tif !isProj {\n\t\treturn\n\t}\n\trefine4NeighbourProj(p, childProj)\n\treturn\n}"}, {"instruction": "// ResolveIndices implements Plan interface.", "input": "go language", "output": "func (p *PhysicalIndexReader) ResolveIndices() (err error) {\n\terr = p.physicalSchemaProducer.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = p.indexPlan.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor i, col := range p.OutputColumns {\n\t\tnewCol, err := col.ResolveIndices(p.indexPlan.Schema())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tp.OutputColumns[i] = newCol.(*expression.Column)\n\t}\n\treturn\n}"}, {"instruction": "// AddInstancesToTargetPool adds instances by link to the TargetPool", "input": "go language", "output": "func (g *Cloud) AddInstancesToTargetPool(name, region string, instanceRefs []*compute.InstanceReference) error {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\treq := &compute.TargetPoolsAddInstanceRequest{\n\t\tInstances: instanceRefs,\n\t}\n\tmc := newTargetPoolMetricContext(\"add_instances\", region)\n\treturn mc.Observe(g.c.TargetPools().AddInstance(ctx, meta.RegionalKey(name, region), req))\n}"}, {"instruction": "// Read reads bytes from BytesPipe.\n// Data could be read only once.", "input": "go language", "output": "func (bp *BytesPipe) Read(p []byte) (n int, err error) {\n\tbp.mu.Lock()\n\tif bp.bufLen == 0 {\n\t\tif bp.closeErr != nil {\n\t\t\tbp.mu.Unlock()\n\t\t\treturn 0, bp.closeErr\n\t\t}\n\t\tbp.wait.Wait()\n\t\tif bp.bufLen == 0 && bp.closeErr != nil {\n\t\t\terr := bp.closeErr\n\t\t\tbp.mu.Unlock()\n\t\t\treturn 0, err\n\t\t}\n\t}\n\n\tfor bp.bufLen > 0 {\n\t\tb := bp.buf[0]\n\t\tread, _ := b.Read(p) // ignore error since fixedBuffer doesn't really return an error\n\t\tn += read\n\t\tbp.bufLen -= read\n\n\t\tif b.Len() == 0 {\n\t\t\t// it's empty so return it to the pool and move to the next one\n\t\t\treturnBuffer(b)\n\t\t\tbp.buf[0] = nil\n\t\t\tbp.buf = bp.buf[1:]\n\t\t}\n\n\t\tif len(p) == read {\n\t\t\tbreak\n\t\t}\n\n\t\tp = p[read:]\n\t}\n\n\tbp.wait.Broadcast()\n\tbp.mu.Unlock()\n\treturn\n}"}, {"instruction": "// Set32 sets the 32 bytes starting at offset to the value of val, left-padded with zeroes to\n// 32 bytes.", "input": "go language", "output": "func (m *Memory) Set32(offset uint64, val *big.Int) {\n\t// length of store may never be less than offset + size.\n\t// The store should be resized PRIOR to setting the memory\n\tif offset+32 > uint64(len(m.store)) {\n\t\tpanic(\"invalid memory: store empty\")\n\t}\n\t// Zero the memory area\n\tcopy(m.store[offset:offset+32], []byte{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0})\n\t// Fill in relevant bits\n\tmath.ReadBits(val, m.store[offset:offset+32])\n}"}, {"instruction": "// DecodeIntValues is called when the current Feedback stores encoded int values.", "input": "go language", "output": "func (q *QueryFeedback) DecodeIntValues() *QueryFeedback {\n\tnq := &QueryFeedback{}\n\tnq.Feedback = make([]Feedback, 0, len(q.Feedback))\n\tfor _, fb := range q.Feedback {\n\t\t_, lowInt, err := codec.DecodeInt(fb.Lower.GetBytes())\n\t\tif err != nil {\n\t\t\tlogutil.Logger(context.Background()).Debug(\"decode feedback lower bound value to integer failed\", zap.Binary(\"value\", fb.Lower.GetBytes()), zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\t_, highInt, err := codec.DecodeInt(fb.Upper.GetBytes())\n\t\tif err != nil {\n\t\t\tlogutil.Logger(context.Background()).Debug(\"decode feedback upper bound value to integer failed\", zap.Binary(\"value\", fb.Upper.GetBytes()), zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tlow, high := types.NewIntDatum(lowInt), types.NewIntDatum(highInt)\n\t\tnq.Feedback = append(nq.Feedback, Feedback{Lower: &low, Upper: &high, Count: fb.Count})\n\t}\n\treturn nq\n}"}, {"instruction": "// PullImage is a test-spy implementation of Interface.PullImage.\n// It adds an entry \"pull\" to the internal method call record.", "input": "go language", "output": "func (f *FakeDockerClient) PullImage(image string, auth dockertypes.AuthConfig, opts dockertypes.ImagePullOptions) error {\n\tf.Lock()\n\tdefer f.Unlock()\n\tf.appendCalled(CalledDetail{name: \"pull\"})\n\terr := f.popError(\"pull\")\n\tif err == nil {\n\t\tif !f.isAuthorizedForImage(image, auth) {\n\t\t\treturn ImageNotFoundError{ID: image}\n\t\t}\n\n\t\tauthJson, _ := json.Marshal(auth)\n\t\tinspect := createImageInspectFromRef(image)\n\t\tf.ImageInspects[image] = inspect\n\t\tf.appendPulled(fmt.Sprintf(\"%s using %s\", image, string(authJson)))\n\t\tf.Images = append(f.Images, *createImageFromImageInspect(*inspect))\n\t\tf.ImagesPulled = append(f.ImagesPulled, image)\n\t}\n\treturn err\n}"}, {"instruction": "// getRelease uses `system_profiler SPSoftwareDataType` to get OSX kernel version", "input": "go language", "output": "func getRelease() (string, error) {\n\tcmd := exec.Command(\"system_profiler\", \"SPSoftwareDataType\")\n\tosName, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tvar release string\n\tdata := strings.Split(string(osName), \"\\n\")\n\tfor _, line := range data {\n\t\tif strings.Contains(line, \"Kernel Version\") {\n\t\t\t// It has the format like '      Kernel Version: Darwin 14.5.0'\n\t\t\tcontent := strings.SplitN(line, \":\", 2)\n\t\t\tif len(content) != 2 {\n\t\t\t\treturn \"\", fmt.Errorf(\"Kernel Version is invalid\")\n\t\t\t}\n\n\t\t\tprettyNames, err := shellwords.Parse(content[1])\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", fmt.Errorf(\"Kernel Version is invalid: %s\", err.Error())\n\t\t\t}\n\n\t\t\tif len(prettyNames) != 2 {\n\t\t\t\treturn \"\", fmt.Errorf(\"Kernel Version needs to be 'Darwin x.x.x' \")\n\t\t\t}\n\t\t\trelease = prettyNames[1]\n\t\t}\n\t}\n\n\treturn release, nil\n}"}, {"instruction": "// Build is used to build a specific AggFunc implementation according to the\n// input aggFuncDesc.", "input": "go language", "output": "func Build(ctx sessionctx.Context, aggFuncDesc *aggregation.AggFuncDesc, ordinal int) AggFunc {\n\tswitch aggFuncDesc.Name {\n\tcase ast.AggFuncCount:\n\t\treturn buildCount(aggFuncDesc, ordinal)\n\tcase ast.AggFuncSum:\n\t\treturn buildSum(aggFuncDesc, ordinal)\n\tcase ast.AggFuncAvg:\n\t\treturn buildAvg(aggFuncDesc, ordinal)\n\tcase ast.AggFuncFirstRow:\n\t\treturn buildFirstRow(aggFuncDesc, ordinal)\n\tcase ast.AggFuncMax:\n\t\treturn buildMaxMin(aggFuncDesc, ordinal, true)\n\tcase ast.AggFuncMin:\n\t\treturn buildMaxMin(aggFuncDesc, ordinal, false)\n\tcase ast.AggFuncGroupConcat:\n\t\treturn buildGroupConcat(ctx, aggFuncDesc, ordinal)\n\tcase ast.AggFuncBitOr:\n\t\treturn buildBitOr(aggFuncDesc, ordinal)\n\tcase ast.AggFuncBitXor:\n\t\treturn buildBitXor(aggFuncDesc, ordinal)\n\tcase ast.AggFuncBitAnd:\n\t\treturn buildBitAnd(aggFuncDesc, ordinal)\n\t}\n\treturn nil\n}"}, {"instruction": "// Create takes the representation of a customResourceDefinition and creates it.  Returns the server's representation of the customResourceDefinition, and an error, if there is any.", "input": "go language", "output": "func (c *FakeCustomResourceDefinitions) Create(customResourceDefinition *v1beta1.CustomResourceDefinition) (result *v1beta1.CustomResourceDefinition, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootCreateAction(customresourcedefinitionsResource, customResourceDefinition), &v1beta1.CustomResourceDefinition{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*v1beta1.CustomResourceDefinition), err\n}"}, {"instruction": "// getDeploymentsForReplicaSet returns a list of Deployments that potentially\n// match a ReplicaSet.", "input": "go language", "output": "func (dc *DeploymentController) getDeploymentsForReplicaSet(rs *apps.ReplicaSet) []*apps.Deployment {\n\tdeployments, err := dc.dLister.GetDeploymentsForReplicaSet(rs)\n\tif err != nil || len(deployments) == 0 {\n\t\treturn nil\n\t}\n\t// Because all ReplicaSet's belonging to a deployment should have a unique label key,\n\t// there should never be more than one deployment returned by the above method.\n\t// If that happens we should probably dynamically repair the situation by ultimately\n\t// trying to clean up one of the controllers, for now we just return the older one\n\tif len(deployments) > 1 {\n\t\t// ControllerRef will ensure we don't do anything crazy, but more than one\n\t\t// item in this list nevertheless constitutes user error.\n\t\tklog.V(4).Infof(\"user error! more than one deployment is selecting replica set %s/%s with labels: %#v, returning %s/%s\",\n\t\t\trs.Namespace, rs.Name, rs.Labels, deployments[0].Namespace, deployments[0].Name)\n\t}\n\treturn deployments\n}"}, {"instruction": "// lockInfo reads the lock file, parses its contents and returns the parsed\n// LockInfo struct.", "input": "go language", "output": "func (c *remoteClient) lockInfo() (*state.LockInfo, error) {\n\tr, err := c.lockFile().NewReader(c.storageContext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer r.Close()\n\n\trawData, err := ioutil.ReadAll(r)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinfo := &state.LockInfo{}\n\tif err := json.Unmarshal(rawData, info); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We use the Generation as the ID, so overwrite the ID in the json.\n\t// This can't be written into the Info, since the generation isn't known\n\t// until it's written.\n\tattrs, err := c.lockFile().Attrs(c.storageContext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.ID = strconv.FormatInt(attrs.Generation, 10)\n\n\treturn info, nil\n}"}, {"instruction": "// DeriveStats implement LogicalPlan DeriveStats interface.", "input": "go language", "output": "func (la *LogicalApply) DeriveStats(childStats []*property.StatsInfo) (*property.StatsInfo, error) {\n\tleftProfile := childStats[0]\n\tla.stats = &property.StatsInfo{\n\t\tRowCount:    leftProfile.RowCount,\n\t\tCardinality: make([]float64, la.schema.Len()),\n\t}\n\tcopy(la.stats.Cardinality, leftProfile.Cardinality)\n\tif la.JoinType == LeftOuterSemiJoin || la.JoinType == AntiLeftOuterSemiJoin {\n\t\tla.stats.Cardinality[len(la.stats.Cardinality)-1] = 2.0\n\t} else {\n\t\tfor i := la.children[0].Schema().Len(); i < la.schema.Len(); i++ {\n\t\t\tla.stats.Cardinality[i] = leftProfile.RowCount\n\t\t}\n\t}\n\treturn la.stats, nil\n}"}, {"instruction": "// CAProviderState is used to get the Consul CA provider state for the given ID.", "input": "go language", "output": "func (s *Store) CAProviderState(id string) (uint64, *structs.CAConsulProviderState, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the index\n\tidx := maxIndexTxn(tx, caBuiltinProviderTableName)\n\n\t// Get the provider config\n\tc, err := tx.First(caBuiltinProviderTableName, \"id\", id)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed built-in CA state lookup: %s\", err)\n\t}\n\n\tstate, ok := c.(*structs.CAConsulProviderState)\n\tif !ok {\n\t\treturn 0, nil, nil\n\t}\n\n\treturn idx, state, nil\n}"}, {"instruction": "// MergeExecDetails merges a single region execution details into self, used to print\n// the information in slow query log.", "input": "go language", "output": "func (sc *StatementContext) MergeExecDetails(details *execdetails.ExecDetails, commitDetails *execdetails.CommitDetails) {\n\tsc.mu.Lock()\n\tif details != nil {\n\t\tsc.mu.execDetails.ProcessTime += details.ProcessTime\n\t\tsc.mu.execDetails.WaitTime += details.WaitTime\n\t\tsc.mu.execDetails.BackoffTime += details.BackoffTime\n\t\tsc.mu.execDetails.RequestCount++\n\t\tsc.mu.execDetails.TotalKeys += details.TotalKeys\n\t\tsc.mu.execDetails.ProcessedKeys += details.ProcessedKeys\n\t\tsc.mu.allExecDetails = append(sc.mu.allExecDetails, details)\n\t}\n\tsc.mu.execDetails.CommitDetail = commitDetails\n\tsc.mu.Unlock()\n}"}, {"instruction": "// Manifest hack for supporting Swarm feeds from the bzz: scheme\n// see swarm/api/api.go:API.Get() for more information", "input": "go language", "output": "func (a *API) NewFeedManifest(ctx context.Context, feed *feed.Feed) (storage.Address, error) {\n\tvar manifest Manifest\n\tentry := ManifestEntry{\n\t\tFeed:        feed,\n\t\tContentType: FeedContentType,\n\t}\n\tmanifest.Entries = append(manifest.Entries, entry)\n\tdata, err := json.Marshal(&manifest)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\taddr, wait, err := a.Store(ctx, bytes.NewReader(data), int64(len(data)), false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = wait(ctx)\n\treturn addr, err\n}"}, {"instruction": "// NewWindowFuncDesc creates a window function signature descriptor.", "input": "go language", "output": "func NewWindowFuncDesc(ctx sessionctx.Context, name string, args []expression.Expression) *WindowFuncDesc {\n\tswitch strings.ToLower(name) {\n\tcase ast.WindowFuncNthValue:\n\t\tval, isNull, ok := expression.GetUint64FromConstant(args[1])\n\t\t// nth_value does not allow `0`, but allows `null`.\n\t\tif !ok || (val == 0 && !isNull) {\n\t\t\treturn nil\n\t\t}\n\tcase ast.WindowFuncNtile:\n\t\tval, isNull, ok := expression.GetUint64FromConstant(args[0])\n\t\t// ntile does not allow `0`, but allows `null`.\n\t\tif !ok || (val == 0 && !isNull) {\n\t\t\treturn nil\n\t\t}\n\tcase ast.WindowFuncLead, ast.WindowFuncLag:\n\t\tif len(args) < 2 {\n\t\t\tbreak\n\t\t}\n\t\t_, isNull, ok := expression.GetUint64FromConstant(args[1])\n\t\tif !ok || isNull {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn &WindowFuncDesc{newBaseFuncDesc(ctx, name, args)}\n}"}, {"instruction": "// CASetProviderState is used to set the current built-in CA provider state.", "input": "go language", "output": "func (s *Store) CASetProviderState(idx uint64, state *structs.CAConsulProviderState) (bool, error) {\n\ttx := s.db.Txn(true)\n\tdefer tx.Abort()\n\n\t// Check for an existing config\n\texisting, err := tx.First(caBuiltinProviderTableName, \"id\", state.ID)\n\tif err != nil {\n\t\treturn false, fmt.Errorf(\"failed built-in CA state lookup: %s\", err)\n\t}\n\n\t// Set the indexes.\n\tif existing != nil {\n\t\tstate.CreateIndex = existing.(*structs.CAConsulProviderState).CreateIndex\n\t} else {\n\t\tstate.CreateIndex = idx\n\t}\n\tstate.ModifyIndex = idx\n\n\tif err := tx.Insert(caBuiltinProviderTableName, state); err != nil {\n\t\treturn false, fmt.Errorf(\"failed updating built-in CA state: %s\", err)\n\t}\n\n\t// Update the index\n\tif err := tx.Insert(\"index\", &IndexEntry{caBuiltinProviderTableName, idx}); err != nil {\n\t\treturn false, fmt.Errorf(\"failed updating index: %s\", err)\n\t}\n\n\ttx.Commit()\n\n\treturn true, nil\n}"}, {"instruction": "// GetNextLevel returns the frequency level a next update should be placed at, provided where\n// the last update was and what time it is now.\n// This is the first nonzero bit of the XOR of 'last' and 'now', counting from the highest significant bit\n// but limited to not return a level that is smaller than the last-1", "input": "go language", "output": "func GetNextLevel(last Epoch, now uint64) uint8 {\n\t// First XOR the last epoch base time with the current clock.\n\t// This will set all the common most significant bits to zero.\n\tmix := (last.Base() ^ now)\n\n\t// Then, make sure we stop the below loop before one level below the current, by setting\n\t// that level's bit to 1.\n\t// If the next level is lower than the current one, it must be exactly level-1 and not lower.\n\tmix |= (1 << (last.Level - 1))\n\n\t// if the last update was more than 2^highestLevel seconds ago, choose the highest level\n\tif mix > (maxuint64 >> (64 - HighestLevel - 1)) {\n\t\treturn HighestLevel\n\t}\n\n\t// set up a mask to scan for nonzero bits, starting at the highest level\n\tmask := uint64(1 << (HighestLevel))\n\n\tfor i := uint8(HighestLevel); i > LowestLevel; i-- {\n\t\tif mix&mask != 0 { // if we find a nonzero bit, this is the level the next update should be at.\n\t\t\treturn i\n\t\t}\n\t\tmask = mask >> 1 // move our bit one position to the right\n\t}\n\treturn 0\n}"}, {"instruction": "// LastRevision finds the second max revision number in all replica sets (the last revision)", "input": "go language", "output": "func LastRevision(allRSs []*apps.ReplicaSet) int64 {\n\tmax, secMax := int64(0), int64(0)\n\tfor _, rs := range allRSs {\n\t\tif v, err := Revision(rs); err != nil {\n\t\t\t// Skip the replica sets when it failed to parse their revision information\n\t\t\tklog.V(4).Infof(\"Error: %v. Couldn't parse revision for replica set %#v, deployment controller will skip it when reconciling revisions.\", err, rs)\n\t\t} else if v >= max {\n\t\t\tsecMax = max\n\t\t\tmax = v\n\t\t} else if v > secMax {\n\t\t\tsecMax = v\n\t\t}\n\t}\n\treturn secMax\n}"}, {"instruction": "// MergeSchema will merge two schema into one schema. We shouldn't need to consider unique keys.\n// That will be processed in build_key_info.go.", "input": "go language", "output": "func MergeSchema(lSchema, rSchema *Schema) *Schema {\n\tif lSchema == nil && rSchema == nil {\n\t\treturn nil\n\t}\n\tif lSchema == nil {\n\t\treturn rSchema.Clone()\n\t}\n\tif rSchema == nil {\n\t\treturn lSchema.Clone()\n\t}\n\ttmpL := lSchema.Clone()\n\ttmpR := rSchema.Clone()\n\tret := NewSchema(append(tmpL.Columns, tmpR.Columns...)...)\n\tret.TblID2Handle = tmpL.TblID2Handle\n\tfor id, cols := range tmpR.TblID2Handle {\n\t\tif _, ok := ret.TblID2Handle[id]; ok {\n\t\t\tret.TblID2Handle[id] = append(ret.TblID2Handle[id], cols...)\n\t\t} else {\n\t\t\tret.TblID2Handle[id] = cols\n\t\t}\n\t}\n\treturn ret\n}"}, {"instruction": "// NewEditOptions returns an initialized EditOptions instance", "input": "go language", "output": "func NewEditOptions(editMode EditMode, ioStreams genericclioptions.IOStreams) *EditOptions {\n\treturn &EditOptions{\n\t\tRecordFlags: genericclioptions.NewRecordFlags(),\n\n\t\tEditMode: editMode,\n\n\t\tPrintFlags: genericclioptions.NewPrintFlags(\"edited\").WithTypeSetter(scheme.Scheme),\n\n\t\teditPrinterOptions: &editPrinterOptions{\n\t\t\t// create new editor-specific PrintFlags, with all\n\t\t\t// output flags disabled, except json / yaml\n\t\t\tprintFlags: (&genericclioptions.PrintFlags{\n\t\t\t\tJSONYamlPrintFlags: genericclioptions.NewJSONYamlPrintFlags(),\n\t\t\t}).WithDefaultOutput(\"yaml\"),\n\t\t\text:       \".yaml\",\n\t\t\taddHeader: true,\n\t\t},\n\n\t\tWindowsLineEndings: goruntime.GOOS == \"windows\",\n\n\t\tRecorder: genericclioptions.NoopRecorder{},\n\n\t\tIOStreams: ioStreams,\n\t}\n}"}, {"instruction": "//TODO: need to finish the method to get the rules when using webhook mode", "input": "go language", "output": "func (w *WebhookAuthorizer) RulesFor(user user.Info, namespace string) ([]authorizer.ResourceRuleInfo, []authorizer.NonResourceRuleInfo, bool, error) {\n\tvar (\n\t\tresourceRules    []authorizer.ResourceRuleInfo\n\t\tnonResourceRules []authorizer.NonResourceRuleInfo\n\t)\n\tincomplete := true\n\treturn resourceRules, nonResourceRules, incomplete, fmt.Errorf(\"webhook authorizer does not support user rule resolution\")\n}"}, {"instruction": "// Dial establishes the gRPC communication with the picked up plugin socket. https://godoc.org/google.golang.org/grpc#Dial", "input": "go language", "output": "func dial(unixSocketPath string, timeout time.Duration) (registerapi.RegistrationClient, *grpc.ClientConn, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), timeout)\n\tdefer cancel()\n\n\tc, err := grpc.DialContext(ctx, unixSocketPath, grpc.WithInsecure(), grpc.WithBlock(),\n\t\tgrpc.WithDialer(func(addr string, timeout time.Duration) (net.Conn, error) {\n\t\t\treturn net.DialTimeout(\"unix\", addr, timeout)\n\t\t}),\n\t)\n\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to dial socket %s, err: %v\", unixSocketPath, err)\n\t}\n\n\treturn registerapi.NewRegistrationClient(c), c, nil\n}"}, {"instruction": "// Read returns a full YAML document.", "input": "go language", "output": "func (r *YAMLReader) Read() ([]byte, error) {\n\tvar buffer bytes.Buffer\n\tfor {\n\t\tline, err := r.reader.Read()\n\t\tif err != nil && err != io.EOF {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tsep := len([]byte(separator))\n\t\tif i := bytes.Index(line, []byte(separator)); i == 0 {\n\t\t\t// We have a potential document terminator\n\t\t\ti += sep\n\t\t\tafter := line[i:]\n\t\t\tif len(strings.TrimRightFunc(string(after), unicode.IsSpace)) == 0 {\n\t\t\t\tif buffer.Len() != 0 {\n\t\t\t\t\treturn buffer.Bytes(), nil\n\t\t\t\t}\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif err == io.EOF {\n\t\t\tif buffer.Len() != 0 {\n\t\t\t\t// If we're at EOF, we have a final, non-terminated line. Return it.\n\t\t\t\treturn buffer.Bytes(), nil\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tbuffer.Write(line)\n\t}\n}"}, {"instruction": "// Delete the eligible dead container instances in a pod. Depending on the configuration, the latest dead containers may be kept around.", "input": "go language", "output": "func (kl *Kubelet) cleanUpContainersInPod(podID types.UID, exitedContainerID string) {\n\tif podStatus, err := kl.podCache.Get(podID); err == nil {\n\t\tremoveAll := false\n\t\tif syncedPod, ok := kl.podManager.GetPodByUID(podID); ok {\n\t\t\t// generate the api status using the cached runtime status to get up-to-date ContainerStatuses\n\t\t\tapiPodStatus := kl.generateAPIPodStatus(syncedPod, podStatus)\n\t\t\t// When an evicted or deleted pod has already synced, all containers can be removed.\n\t\t\tremoveAll = eviction.PodIsEvicted(syncedPod.Status) || (syncedPod.DeletionTimestamp != nil && notRunning(apiPodStatus.ContainerStatuses))\n\t\t}\n\t\tkl.containerDeletor.deleteContainersInPod(exitedContainerID, podStatus, removeAll)\n\t}\n}"}, {"instruction": "// GetPvtDataAndBlockByNum provides a mock function with given fields: seqNum", "input": "go language", "output": "func (_m *Committer) GetPvtDataAndBlockByNum(seqNum uint64) (*ledger.BlockAndPvtData, error) {\n\tret := _m.Called(seqNum)\n\n\tvar r0 *ledger.BlockAndPvtData\n\tif rf, ok := ret.Get(0).(func(uint64) *ledger.BlockAndPvtData); ok {\n\t\tr0 = rf(seqNum)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*ledger.BlockAndPvtData)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(uint64) error); ok {\n\t\tr1 = rf(seqNum)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// checkArgs makes sure all the arguments' types are known and can be handled.\n// integer types are converted to int64 and uint64, time.Time is converted to types.Time.\n// time.Duration is converted to types.Duration, other known types are leaved as it is.", "input": "go language", "output": "func checkArgs(args ...interface{}) error {\n\tfor i, v := range args {\n\t\tswitch x := v.(type) {\n\t\tcase bool:\n\t\t\tif x {\n\t\t\t\targs[i] = int64(1)\n\t\t\t} else {\n\t\t\t\targs[i] = int64(0)\n\t\t\t}\n\t\tcase int8:\n\t\t\targs[i] = int64(x)\n\t\tcase int16:\n\t\t\targs[i] = int64(x)\n\t\tcase int32:\n\t\t\targs[i] = int64(x)\n\t\tcase int:\n\t\t\targs[i] = int64(x)\n\t\tcase uint8:\n\t\t\targs[i] = uint64(x)\n\t\tcase uint16:\n\t\t\targs[i] = uint64(x)\n\t\tcase uint32:\n\t\t\targs[i] = uint64(x)\n\t\tcase uint:\n\t\t\targs[i] = uint64(x)\n\t\tcase int64:\n\t\tcase uint64:\n\t\tcase float32:\n\t\tcase float64:\n\t\tcase string:\n\t\tcase []byte:\n\t\tcase time.Duration:\n\t\t\targs[i] = types.Duration{Duration: x}\n\t\tcase time.Time:\n\t\t\targs[i] = types.Time{Time: types.FromGoTime(x), Type: mysql.TypeDatetime}\n\t\tcase nil:\n\t\tdefault:\n\t\t\treturn errors.Errorf(\"cannot use arg[%d] (type %T):unsupported type\", i, v)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// DeleteRelease uninstalls a named release and returns the response.", "input": "go language", "output": "func (h *Client) DeleteRelease(rlsName string, opts ...DeleteOption) (*rls.UninstallReleaseResponse, error) {\n\t// apply the uninstall options\n\treqOpts := h.opts\n\tfor _, opt := range opts {\n\t\topt(&reqOpts)\n\t}\n\n\tif reqOpts.dryRun {\n\t\t// In the dry run case, just see if the release exists\n\t\tr, err := h.ReleaseContent(rlsName)\n\t\tif err != nil {\n\t\t\treturn &rls.UninstallReleaseResponse{}, err\n\t\t}\n\t\treturn &rls.UninstallReleaseResponse{Release: r.Release}, nil\n\t}\n\n\treq := &reqOpts.uninstallReq\n\treq.Name = rlsName\n\treq.DisableHooks = reqOpts.disableHooks\n\tctx := NewContext()\n\n\tif reqOpts.before != nil {\n\t\tif err := reqOpts.before(ctx, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn h.delete(ctx, req)\n}"}, {"instruction": "// References returns a slice of references to the given ID. The slice\n// will be nil if there are no references to this ID.", "input": "go language", "output": "func (store *store) References(id digest.Digest) []reference.Named {\n\tstore.mu.RLock()\n\tdefer store.mu.RUnlock()\n\n\t// Convert the internal map to an array for two reasons:\n\t// 1) We must not return a mutable\n\t// 2) It would be ugly to expose the extraneous map keys to callers.\n\n\tvar references []reference.Named\n\tfor _, ref := range store.referencesByIDCache[id] {\n\t\treferences = append(references, ref)\n\t}\n\n\tsort.Sort(lexicalRefs(references))\n\n\treturn references\n}"}, {"instruction": "// PatchNodeTaints patches node's taints.", "input": "go language", "output": "func PatchNodeTaints(c clientset.Interface, nodeName string, oldNode *v1.Node, newNode *v1.Node) error {\n\toldData, err := json.Marshal(oldNode)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal old node %#v for node %q: %v\", oldNode, nodeName, err)\n\t}\n\n\tnewTaints := newNode.Spec.Taints\n\tnewNodeClone := oldNode.DeepCopy()\n\tnewNodeClone.Spec.Taints = newTaints\n\tnewData, err := json.Marshal(newNodeClone)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal new node %#v for node %q: %v\", newNodeClone, nodeName, err)\n\t}\n\n\tpatchBytes, err := strategicpatch.CreateTwoWayMergePatch(oldData, newData, v1.Node{})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create patch for node %q: %v\", nodeName, err)\n\t}\n\n\t_, err = c.CoreV1().Nodes().Patch(nodeName, types.StrategicMergePatchType, patchBytes)\n\treturn err\n}"}, {"instruction": "// RequestTransfer creates a TokenTransaction of type transfer request\n//func (t *Transactor) RequestTransfer(inTokens []*token.InputId, tokensToTransfer []*token.RecipientTransferShare) (*token.TokenTransaction, error) {", "input": "go language", "output": "func (t *Transactor) RequestTransfer(request *token.TransferRequest) (*token.TokenTransaction, error) {\n\tvar outputs []*token.PlainOutput\n\n\tinputs, tokenType, _, err := t.getInputsFromTokenIds(request.GetTokenIds())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ttt := range request.GetShares() {\n\t\toutputs = append(outputs, &token.PlainOutput{\n\t\t\tOwner:    ttt.Recipient,\n\t\t\tType:     tokenType,\n\t\t\tQuantity: ttt.Quantity,\n\t\t})\n\t}\n\n\t// prepare transfer request\n\ttransaction := &token.TokenTransaction{\n\t\tAction: &token.TokenTransaction_PlainAction{\n\t\t\tPlainAction: &token.PlainTokenAction{\n\t\t\t\tData: &token.PlainTokenAction_PlainTransfer{\n\t\t\t\t\tPlainTransfer: &token.PlainTransfer{\n\t\t\t\t\t\tInputs:  inputs,\n\t\t\t\t\t\tOutputs: outputs,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\treturn transaction, nil\n}"}, {"instruction": "// UnmarshalClusterStatus takes raw ConfigMap.Data and converts it to a ClusterStatus object", "input": "go language", "output": "func UnmarshalClusterStatus(data map[string]string) (*kubeadmapi.ClusterStatus, error) {\n\tclusterStatusData, ok := data[constants.ClusterStatusConfigMapKey]\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"unexpected error when reading kubeadm-config ConfigMap: %s key value pair missing\", constants.ClusterStatusConfigMapKey)\n\t}\n\tclusterStatus := &kubeadmapi.ClusterStatus{}\n\tif err := runtime.DecodeInto(kubeadmscheme.Codecs.UniversalDecoder(), []byte(clusterStatusData), clusterStatus); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn clusterStatus, nil\n}"}, {"instruction": "// Update updates internal state of what has been downloaded into the temporary\n// files by the remote device for this specific folder.", "input": "go language", "output": "func (t *deviceDownloadState) Update(folder string, updates []protocol.FileDownloadProgressUpdate) {\n\tif t == nil {\n\t\treturn\n\t}\n\tt.mut.RLock()\n\tf, ok := t.folders[folder]\n\tt.mut.RUnlock()\n\n\tif !ok {\n\t\tf = &deviceFolderDownloadState{\n\t\t\tmut:   sync.NewRWMutex(),\n\t\t\tfiles: make(map[string]deviceFolderFileDownloadState),\n\t\t}\n\t\tt.mut.Lock()\n\t\tt.folders[folder] = f\n\t\tt.mut.Unlock()\n\t}\n\n\tf.Update(updates)\n}"}, {"instruction": "// EnsureLoadBalancer is a test-spy implementation of LoadBalancer.EnsureLoadBalancer.\n// It adds an entry \"create\" into the internal method call record.", "input": "go language", "output": "func (f *FakeCloud) EnsureLoadBalancer(ctx context.Context, clusterName string, service *v1.Service, nodes []*v1.Node) (*v1.LoadBalancerStatus, error) {\n\tf.addCall(\"create\")\n\tif f.Balancers == nil {\n\t\tf.Balancers = make(map[string]FakeBalancer)\n\t}\n\n\tname := f.GetLoadBalancerName(ctx, clusterName, service)\n\tspec := service.Spec\n\n\tzone, err := f.GetZone(context.TODO())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tregion := zone.Region\n\n\tf.Balancers[name] = FakeBalancer{name, region, spec.LoadBalancerIP, spec.Ports, nodes}\n\n\tstatus := &v1.LoadBalancerStatus{}\n\tstatus.Ingress = []v1.LoadBalancerIngress{{IP: f.ExternalIP.String()}}\n\n\treturn status, f.Err\n}"}, {"instruction": "// FilteredBy filters by the given predicate. Empty APIResourceLists are dropped.", "input": "go language", "output": "func FilteredBy(pred ResourcePredicate, rls []*metav1.APIResourceList) []*metav1.APIResourceList {\n\tresult := []*metav1.APIResourceList{}\n\tfor _, rl := range rls {\n\t\tfiltered := *rl\n\t\tfiltered.APIResources = nil\n\t\tfor i := range rl.APIResources {\n\t\t\tif pred.Match(rl.GroupVersion, &rl.APIResources[i]) {\n\t\t\t\tfiltered.APIResources = append(filtered.APIResources, rl.APIResources[i])\n\t\t\t}\n\t\t}\n\t\tif filtered.APIResources != nil {\n\t\t\tresult = append(result, &filtered)\n\t\t}\n\t}\n\treturn result\n}"}, {"instruction": "// MountVolume mounts a Portworx Volume on the specified mountPath", "input": "go language", "output": "func (util *portworxVolumeUtil) MountVolume(m *portworxVolumeMounter, mountPath string) error {\n\tdriver, err := util.getLocalPortworxDriver(m.plugin.host)\n\tif err != nil || driver == nil {\n\t\tklog.Errorf(\"Failed to get portworx driver. Err: %v\", err)\n\t\treturn err\n\t}\n\n\terr = driver.Mount(m.volName, mountPath)\n\tif err != nil {\n\t\tklog.Errorf(\"Error mounting Portworx Volume (%v) on Path (%v): %v\", m.volName, mountPath, err)\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// Tasks provides a mock function with given fields: application", "input": "go language", "output": "func (_m *Marathon) Tasks(application string) (*marathon.Tasks, error) {\n\tret := _m.Called(application)\n\n\tvar r0 *marathon.Tasks\n\tif rf, ok := ret.Get(0).(func(string) *marathon.Tasks); ok {\n\t\tr0 = rf(application)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*marathon.Tasks)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(string) error); ok {\n\t\tr1 = rf(application)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// UpdateAttachment notifies the attacher about the attachment config.", "input": "go language", "output": "func (daemon *Daemon) UpdateAttachment(networkName, networkID, containerID string, config *network.NetworkingConfig) error {\n\tif daemon.clusterProvider == nil {\n\t\treturn fmt.Errorf(\"cluster provider is not initialized\")\n\t}\n\n\tif err := daemon.clusterProvider.UpdateAttachment(networkName, containerID, config); err != nil {\n\t\treturn daemon.clusterProvider.UpdateAttachment(networkID, containerID, config)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// WaitInspectWithArgs waits for the specified expression to be equals to the specified expected string in the given time.\n// Deprecated: use cli.WaitCmd instead", "input": "go language", "output": "func WaitInspectWithArgs(dockerBinary, name, expr, expected string, timeout time.Duration, arg ...string) error {\n\tafter := time.After(timeout)\n\n\targs := append(arg, \"inspect\", \"-f\", expr, name)\n\tfor {\n\t\tresult := icmd.RunCommand(dockerBinary, args...)\n\t\tif result.Error != nil {\n\t\t\tif !strings.Contains(strings.ToLower(result.Stderr()), \"no such\") {\n\t\t\t\treturn errors.Errorf(\"error executing docker inspect: %v\\n%s\",\n\t\t\t\t\tresult.Stderr(), result.Stdout())\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-after:\n\t\t\t\treturn result.Error\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tout := strings.TrimSpace(result.Stdout())\n\t\tif out == expected {\n\t\t\tbreak\n\t\t}\n\n\t\tselect {\n\t\tcase <-after:\n\t\t\treturn errors.Errorf(\"condition \\\"%q == %q\\\" not true in time (%v)\", out, expected, timeout)\n\t\tdefault:\n\t\t}\n\n\t\ttime.Sleep(100 * time.Millisecond)\n\t}\n\treturn nil\n}"}, {"instruction": "// lanNodeJoin is used to handle join events on the LAN pool.", "input": "go language", "output": "func (s *Server) lanNodeJoin(me serf.MemberEvent) {\n\tfor _, m := range me.Members {\n\t\tok, serverMeta := metadata.IsConsulServer(m)\n\t\tif !ok || serverMeta.Segment != \"\" {\n\t\t\tcontinue\n\t\t}\n\t\ts.logger.Printf(\"[INFO] consul: Adding LAN server %s\", serverMeta)\n\n\t\t// Update server lookup\n\t\ts.serverLookup.AddServer(serverMeta)\n\n\t\t// If we're still expecting to bootstrap, may need to handle this.\n\t\tif s.config.BootstrapExpect != 0 {\n\t\t\ts.maybeBootstrap()\n\t\t}\n\n\t\t// Kick the join flooders.\n\t\ts.FloodNotify()\n\t}\n}"}, {"instruction": "// UnmarshalJSON decodes the byte slice whether it's a string or an array of\n// strings. This method is needed to implement json.Unmarshaler.", "input": "go language", "output": "func (e *StrSlice) UnmarshalJSON(b []byte) error {\n\tif len(b) == 0 {\n\t\t// With no input, we preserve the existing value by returning nil and\n\t\t// leaving the target alone. This allows defining default values for\n\t\t// the type.\n\t\treturn nil\n\t}\n\n\tp := make([]string, 0, 1)\n\tif err := json.Unmarshal(b, &p); err != nil {\n\t\tvar s string\n\t\tif err := json.Unmarshal(b, &s); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tp = append(p, s)\n\t}\n\n\t*e = p\n\treturn nil\n}"}, {"instruction": "// Helper function for the binding generators.\n// It reads the unmatched characters after the inner type-match,\n//  (since the inner type is a prefix of the total type declaration),\n//  looks for valid arrays (possibly a dynamic one) wrapping the inner type,\n//  and returns the sizes of these arrays.\n//\n// Returned array sizes are in the same order as solidity signatures; inner array size first.\n// Array sizes may also be \"\", indicating a dynamic array.", "input": "go language", "output": "func wrapArray(stringKind string, innerLen int, innerMapping string) (string, []string) {\n\tremainder := stringKind[innerLen:]\n\t//find all the sizes\n\tmatches := regexp.MustCompile(`\\[(\\d*)\\]`).FindAllStringSubmatch(remainder, -1)\n\tparts := make([]string, 0, len(matches))\n\tfor _, match := range matches {\n\t\t//get group 1 from the regex match\n\t\tparts = append(parts, match[1])\n\t}\n\treturn innerMapping, parts\n}"}, {"instruction": "// HasSupport verifies if the given gvk supports DryRun. An error is\n// returned if it doesn't.", "input": "go language", "output": "func (v *DryRunVerifier) HasSupport(gvk schema.GroupVersionKind) error {\n\toapi, err := v.OpenAPIGetter.OpenAPISchema()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to download openapi: %v\", err)\n\t}\n\tsupports, err := openapi.SupportsDryRun(oapi, gvk)\n\tif err != nil {\n\t\t// We assume that we couldn't find the type, then check for namespace:\n\t\tsupports, _ = openapi.SupportsDryRun(oapi, schema.GroupVersionKind{Group: \"\", Version: \"v1\", Kind: \"Namespace\"})\n\t\t// If namespace supports dryRun, then we will support dryRun for CRDs only.\n\t\tif supports {\n\t\t\tsupports, err = v.Finder.HasCRD(gvk.GroupKind())\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"failed to check CRD: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\tif !supports {\n\t\treturn fmt.Errorf(\"%v doesn't support dry-run\", gvk)\n\t}\n\treturn nil\n}"}, {"instruction": "// handleFromEnvFileSource adds the specified env file source information\n// into the provided secret", "input": "go language", "output": "func handleFromEnvFileSource(secret *v1.Secret, envFileSource string) error {\n\tinfo, err := os.Stat(envFileSource)\n\tif err != nil {\n\t\tswitch err := err.(type) {\n\t\tcase *os.PathError:\n\t\t\treturn fmt.Errorf(\"error reading %s: %v\", envFileSource, err.Err)\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"error reading %s: %v\", envFileSource, err)\n\t\t}\n\t}\n\tif info.IsDir() {\n\t\treturn fmt.Errorf(\"env secret file cannot be a directory\")\n\t}\n\n\treturn addFromEnvFile(envFileSource, func(key, value string) error {\n\t\treturn addKeyFromLiteralToSecret(secret, key, []byte(value))\n\t})\n}"}, {"instruction": "// updateStats bumps the various state sync progress counters and displays a log\n// message for the user to see.", "input": "go language", "output": "func (s *stateSync) updateStats(written, duplicate, unexpected int, duration time.Duration) {\n\ts.d.syncStatsLock.Lock()\n\tdefer s.d.syncStatsLock.Unlock()\n\n\ts.d.syncStatsState.pending = uint64(s.sched.Pending())\n\ts.d.syncStatsState.processed += uint64(written)\n\ts.d.syncStatsState.duplicate += uint64(duplicate)\n\ts.d.syncStatsState.unexpected += uint64(unexpected)\n\n\tif written > 0 || duplicate > 0 || unexpected > 0 {\n\t\tlog.Info(\"Imported new state entries\", \"count\", written, \"elapsed\", common.PrettyDuration(duration), \"processed\", s.d.syncStatsState.processed, \"pending\", s.d.syncStatsState.pending, \"retry\", len(s.tasks), \"duplicate\", s.d.syncStatsState.duplicate, \"unexpected\", s.d.syncStatsState.unexpected)\n\t}\n\tif written > 0 {\n\t\trawdb.WriteFastTrieProgress(s.d.stateDB, s.d.syncStatsState.processed)\n\t}\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of PersistentVolumeClaims that match those selectors.", "input": "go language", "output": "func (c *FakePersistentVolumeClaims) List(opts v1.ListOptions) (result *corev1.PersistentVolumeClaimList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(persistentvolumeclaimsResource, persistentvolumeclaimsKind, c.ns, opts), &corev1.PersistentVolumeClaimList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &corev1.PersistentVolumeClaimList{ListMeta: obj.(*corev1.PersistentVolumeClaimList).ListMeta}\n\tfor _, item := range obj.(*corev1.PersistentVolumeClaimList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// updateAllocatedDevices gets a list of active pods and then frees any Devices that are bound to\n// terminated pods. Returns error on failure.", "input": "go language", "output": "func (m *ManagerImpl) updateAllocatedDevices(activePods []*v1.Pod) {\n\tif !m.sourcesReady.AllReady() {\n\t\treturn\n\t}\n\tm.mutex.Lock()\n\tdefer m.mutex.Unlock()\n\tactivePodUids := sets.NewString()\n\tfor _, pod := range activePods {\n\t\tactivePodUids.Insert(string(pod.UID))\n\t}\n\tallocatedPodUids := m.podDevices.pods()\n\tpodsToBeRemoved := allocatedPodUids.Difference(activePodUids)\n\tif len(podsToBeRemoved) <= 0 {\n\t\treturn\n\t}\n\tklog.V(3).Infof(\"pods to be removed: %v\", podsToBeRemoved.List())\n\tm.podDevices.delete(podsToBeRemoved.List())\n\t// Regenerated allocatedDevices after we update pod allocation information.\n\tm.allocatedDevices = m.podDevices.devices()\n}"}, {"instruction": "// parseRuncVersion parses the output of `runc --version` and extracts the\n// \"version\" and \"git commit\" from the output.\n//\n// Output example from `runc --version`:\n//\n//   runc version 1.0.0-rc5+dev\n//   commit: 69663f0bd4b60df09991c08812a60108003fa340\n//   spec: 1.0.0", "input": "go language", "output": "func parseRuncVersion(v string) (version string, commit string, err error) {\n\tlines := strings.Split(strings.TrimSpace(v), \"\\n\")\n\tfor _, line := range lines {\n\t\tif strings.HasPrefix(line, \"runc version\") {\n\t\t\tversion = strings.TrimSpace(strings.TrimPrefix(line, \"runc version\"))\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(line, \"commit:\") {\n\t\t\tcommit = strings.TrimSpace(strings.TrimPrefix(line, \"commit:\"))\n\t\t\tcontinue\n\t\t}\n\t}\n\tif version == \"\" && commit == \"\" {\n\t\terr = errors.Errorf(\"unknown output format: %s\", v)\n\t}\n\treturn version, commit, err\n}"}, {"instruction": "/*\n\tWhen splitting, data is given as a SectionReader, and the key is a hashSize long byte slice (Key), the root hash of the entire content will fill this once processing finishes.\n\tNew chunks to store are store using the putter which the caller provides.\n*/", "input": "go language", "output": "func TreeSplit(ctx context.Context, data io.Reader, size int64, putter Putter) (k Address, wait func(context.Context) error, err error) {\n\ttsp := &TreeSplitterParams{\n\t\tSplitterParams: SplitterParams{\n\t\t\tChunkerParams: ChunkerParams{\n\t\t\t\tchunkSize: chunk.DefaultSize,\n\t\t\t\thashSize:  putter.RefSize(),\n\t\t\t},\n\t\t\treader: data,\n\t\t\tputter: putter,\n\t\t},\n\t\tsize: size,\n\t}\n\treturn NewTreeSplitter(tsp).Split(ctx)\n}"}, {"instruction": "// normalizePortPortion attempts to normalize the \"port portion\" of a hostname,\n// which begins with the first colon in the hostname and should be followed\n// by a string of decimal digits.\n//\n// If the port portion is valid, a normalized version of it is returned along\n// with a nil error.\n//\n// If the port portion is invalid, the input string is returned verbatim along\n// with a non-nil error.\n//\n// An empty string is a valid port portion representing the absense of a port.\n// If non-empty, the first character must be a colon.", "input": "go language", "output": "func normalizePortPortion(s string) (string, error) {\n\tif s == \"\" {\n\t\treturn s, nil\n\t}\n\n\tif s[0] != ':' {\n\t\t// should never happen, since caller tends to guarantee the presence\n\t\t// of a colon due to how it's extracted from the string.\n\t\treturn s, errors.New(\"port portion is missing its initial colon\")\n\t}\n\n\tnumStr := s[1:]\n\tnum, err := strconv.Atoi(numStr)\n\tif err != nil {\n\t\treturn s, errors.New(\"port portion contains non-digit characters\")\n\t}\n\tif num == 443 {\n\t\treturn \"\", nil // \":443\" is the default\n\t}\n\tif num > 65535 {\n\t\treturn s, errors.New(\"port number is greater than 65535\")\n\t}\n\treturn fmt.Sprintf(\":%d\", num), nil\n}"}, {"instruction": "// gvkWithDefaults returns group kind and version defaulting from provided default", "input": "go language", "output": "func gvkWithDefaults(actual, defaultGVK schema.GroupVersionKind) schema.GroupVersionKind {\n\tif len(actual.Kind) == 0 {\n\t\tactual.Kind = defaultGVK.Kind\n\t}\n\tif len(actual.Version) == 0 && len(actual.Group) == 0 {\n\t\tactual.Group = defaultGVK.Group\n\t\tactual.Version = defaultGVK.Version\n\t}\n\tif len(actual.Version) == 0 && actual.Group == defaultGVK.Group {\n\t\tactual.Version = defaultGVK.Version\n\t}\n\treturn actual\n}"}, {"instruction": "// Detach the given device from the given host.", "input": "go language", "output": "func (detacher *photonPersistentDiskDetacher) Detach(volumeName string, nodeName types.NodeName) error {\n\n\thostName := string(nodeName)\n\tpdID := volumeName\n\tattached, err := detacher.photonDisks.DiskIsAttached(context.TODO(), pdID, nodeName)\n\tif err != nil {\n\t\t// Log error and continue with detach\n\t\tklog.Errorf(\n\t\t\t\"Error checking if persistent disk (%q) is already attached to current node (%q). Will continue and try detach anyway. err=%v\",\n\t\t\tpdID, hostName, err)\n\t}\n\n\tif err == nil && !attached {\n\t\t// Volume is already detached from node.\n\t\tklog.V(4).Infof(\"detach operation was successful. persistent disk %q is already detached from node %q.\", pdID, hostName)\n\t\treturn nil\n\t}\n\n\tif err := detacher.photonDisks.DetachDisk(context.TODO(), pdID, nodeName); err != nil {\n\t\tklog.Errorf(\"Error detaching volume %q: %v\", pdID, err)\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// removeTicket removes a ticket from the ticket store", "input": "go language", "output": "func (s *ticketStore) removeTicketRef(ref ticketRef) {\n\tlog.Trace(\"Removing discovery ticket reference\", \"node\", ref.t.node.ID, \"serial\", ref.t.serial)\n\n\t// Make nextRegisterableTicket return the next available ticket.\n\ts.nextTicketCached = nil\n\n\ttopic := ref.topic()\n\ttickets := s.tickets[topic]\n\n\tif tickets == nil {\n\t\tlog.Trace(\"Removing tickets from unknown topic\", \"topic\", topic)\n\t\treturn\n\t}\n\tbucket := timeBucket(ref.t.regTime[ref.idx] / mclock.AbsTime(ticketTimeBucketLen))\n\tlist := tickets.buckets[bucket]\n\tidx := -1\n\tfor i, bt := range list {\n\t\tif bt.t == ref.t {\n\t\t\tidx = i\n\t\t\tbreak\n\t\t}\n\t}\n\tif idx == -1 {\n\t\tpanic(nil)\n\t}\n\tlist = append(list[:idx], list[idx+1:]...)\n\tif len(list) != 0 {\n\t\ttickets.buckets[bucket] = list\n\t} else {\n\t\tdelete(tickets.buckets, bucket)\n\t}\n\tref.t.refCnt--\n\tif ref.t.refCnt == 0 {\n\t\tdelete(s.nodes, ref.t.node)\n\t\tdelete(s.nodeLastReq, ref.t.node)\n\t}\n}"}, {"instruction": "// Shutdown stops all nodes in the network and closes the quit channel", "input": "go language", "output": "func (net *Network) Shutdown() {\n\tfor _, node := range net.Nodes {\n\t\tlog.Debug(\"Stopping node\", \"id\", node.ID())\n\t\tif err := node.Stop(); err != nil {\n\t\t\tlog.Warn(\"Can't stop node\", \"id\", node.ID(), \"err\", err)\n\t\t}\n\t\t// If the node has the close method, call it.\n\t\tif closer, ok := node.Node.(io.Closer); ok {\n\t\t\tif err := closer.Close(); err != nil {\n\t\t\t\tlog.Warn(\"Can't close node\", \"id\", node.ID(), \"err\", err)\n\t\t\t}\n\t\t}\n\t}\n\tclose(net.quitc)\n}"}, {"instruction": "// vcConnect connects to vCenter with existing credentials\n// If credentials are invalid:\n// \t\t1. It will fetch credentials from credentialManager\n//      2. Update the credentials\n//\t\t3. Connects again to vCenter with fetched credentials", "input": "go language", "output": "func (nm *NodeManager) vcConnect(ctx context.Context, vsphereInstance *VSphereInstance) error {\n\terr := vsphereInstance.conn.Connect(ctx)\n\tif err == nil {\n\t\treturn nil\n\t}\n\n\tcredentialManager := nm.CredentialManager()\n\tif !vclib.IsInvalidCredentialsError(err) || credentialManager == nil {\n\t\tklog.Errorf(\"Cannot connect to vCenter with err: %v\", err)\n\t\treturn err\n\t}\n\n\tklog.V(4).Infof(\"Invalid credentials. Cannot connect to server %q. Fetching credentials from secrets.\", vsphereInstance.conn.Hostname)\n\n\t// Get latest credentials from SecretCredentialManager\n\tcredentials, err := credentialManager.GetCredential(vsphereInstance.conn.Hostname)\n\tif err != nil {\n\t\tklog.Errorf(\"Failed to get credentials from Secret Credential Manager with err: %v\", err)\n\t\treturn err\n\t}\n\tvsphereInstance.conn.UpdateCredentials(credentials.User, credentials.Password)\n\treturn vsphereInstance.conn.Connect(ctx)\n}"}, {"instruction": "// getStatefulSetsForPod returns a list of StatefulSets that potentially match\n// a given pod.", "input": "go language", "output": "func (ssc *StatefulSetController) getStatefulSetsForPod(pod *v1.Pod) []*apps.StatefulSet {\n\tsets, err := ssc.setLister.GetPodStatefulSets(pod)\n\tif err != nil {\n\t\treturn nil\n\t}\n\t// More than one set is selecting the same Pod\n\tif len(sets) > 1 {\n\t\t// ControllerRef will ensure we don't do anything crazy, but more than one\n\t\t// item in this list nevertheless constitutes user error.\n\t\tutilruntime.HandleError(\n\t\t\tfmt.Errorf(\n\t\t\t\t\"user error: more than one StatefulSet is selecting pods with labels: %+v\",\n\t\t\t\tpod.Labels))\n\t}\n\treturn sets\n}"}, {"instruction": "// modifyHostOptionsForSandbox applies NetworkMode/UTSMode to sandbox's dockercontainer.HostConfig.", "input": "go language", "output": "func modifyHostOptionsForSandbox(nsOpts *runtimeapi.NamespaceOption, network *knetwork.PluginManager, hc *dockercontainer.HostConfig) {\n\tif nsOpts.GetIpc() == runtimeapi.NamespaceMode_NODE {\n\t\thc.IpcMode = namespaceModeHost\n\t}\n\tif nsOpts.GetNetwork() == runtimeapi.NamespaceMode_NODE {\n\t\thc.NetworkMode = namespaceModeHost\n\t\treturn\n\t}\n\n\tif network == nil {\n\t\thc.NetworkMode = \"default\"\n\t\treturn\n\t}\n\n\tswitch network.PluginName() {\n\tcase \"cni\":\n\t\tfallthrough\n\tcase \"kubenet\":\n\t\thc.NetworkMode = \"none\"\n\tdefault:\n\t\thc.NetworkMode = \"default\"\n\t}\n}"}, {"instruction": "// UnmarshalText implements encoding.TextUnmarshaler", "input": "go language", "output": "func (b *Big) UnmarshalText(input []byte) error {\n\traw, err := checkNumberText(input)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(raw) > 64 {\n\t\treturn ErrBig256Range\n\t}\n\twords := make([]big.Word, len(raw)/bigWordNibbles+1)\n\tend := len(raw)\n\tfor i := range words {\n\t\tstart := end - bigWordNibbles\n\t\tif start < 0 {\n\t\t\tstart = 0\n\t\t}\n\t\tfor ri := start; ri < end; ri++ {\n\t\t\tnib := decodeNibble(raw[ri])\n\t\t\tif nib == badNibble {\n\t\t\t\treturn ErrSyntax\n\t\t\t}\n\t\t\twords[i] *= 16\n\t\t\twords[i] += big.Word(nib)\n\t\t}\n\t\tend = start\n\t}\n\tvar dec big.Int\n\tdec.SetBits(words)\n\t*b = (Big)(dec)\n\treturn nil\n}"}, {"instruction": "// DecodeToNode Converts the labels to a node.\n// labels -> nodes", "input": "go language", "output": "func DecodeToNode(labels map[string]string, filters ...string) (*Node, error) {\n\tvar sortedKeys []string\n\tfor key := range labels {\n\t\tif len(filters) == 0 {\n\t\t\tsortedKeys = append(sortedKeys, key)\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, filter := range filters {\n\t\t\tif len(key) >= len(filter) && strings.EqualFold(key[:len(filter)], filter) {\n\t\t\t\tsortedKeys = append(sortedKeys, key)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n\tsort.Strings(sortedKeys)\n\n\tlabelRoot := \"traefik\"\n\n\tvar node *Node\n\tfor i, key := range sortedKeys {\n\t\tsplit := strings.Split(key, \".\")\n\n\t\tif split[0] != labelRoot {\n\t\t\t// TODO (@ldez): error or continue\n\t\t\treturn nil, fmt.Errorf(\"invalid label root %s\", split[0])\n\t\t}\n\n\t\tlabelRoot = split[0]\n\n\t\tif i == 0 {\n\t\t\tnode = &Node{}\n\t\t}\n\t\tdecodeToNode(node, split, labels[key])\n\t}\n\n\treturn node, nil\n}"}, {"instruction": "// GetAllDDLJobsInQueue gets all DDL Jobs in the current queue.\n// The length of jobListKeys can only be 1 or 0.\n// If its length is 1, we need to replace m.jobListKey with jobListKeys[0].\n// Otherwise, we use m.jobListKey directly.", "input": "go language", "output": "func (m *Meta) GetAllDDLJobsInQueue(jobListKeys ...JobListKeyType) ([]*model.Job, error) {\n\tlistKey := m.jobListKey\n\tif len(jobListKeys) != 0 {\n\t\tlistKey = jobListKeys[0]\n\t}\n\n\tvalues, err := m.txn.LGetAll(listKey)\n\tif err != nil || values == nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\n\tjobs := make([]*model.Job, 0, len(values))\n\tfor _, val := range values {\n\t\tjob := &model.Job{}\n\t\terr = job.Decode(val)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tjobs = append(jobs, job)\n\t}\n\n\treturn jobs, nil\n}"}, {"instruction": "// isPrivileged will return true a pod has any privileged containers", "input": "go language", "output": "func isPrivileged(pod *corev1.Pod) bool {\n\tfor _, c := range pod.Spec.InitContainers {\n\t\tif c.SecurityContext == nil || c.SecurityContext.Privileged == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif *c.SecurityContext.Privileged {\n\t\t\treturn true\n\t\t}\n\t}\n\tfor _, c := range pod.Spec.Containers {\n\t\tif c.SecurityContext == nil || c.SecurityContext.Privileged == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif *c.SecurityContext.Privileged {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}"}, {"instruction": "// GetChaincodeData gets the ChaincodeData", "input": "go language", "output": "func (ccpack *SignedCDSPackage) GetChaincodeData() *ChaincodeData {\n\t//this has to be after creating a package and initializing it\n\t//If those steps fail, GetChaincodeData() should never be called\n\tif ccpack.depSpec == nil || ccpack.datab == nil || ccpack.id == nil {\n\t\tpanic(\"GetChaincodeData called on uninitialized package\")\n\t}\n\n\tvar instPolicy []byte\n\tif ccpack.sDepSpec != nil {\n\t\tinstPolicy = ccpack.sDepSpec.InstantiationPolicy\n\t}\n\n\treturn &ChaincodeData{\n\t\tName:                ccpack.depSpec.ChaincodeSpec.ChaincodeId.Name,\n\t\tVersion:             ccpack.depSpec.ChaincodeSpec.ChaincodeId.Version,\n\t\tData:                ccpack.datab,\n\t\tId:                  ccpack.id,\n\t\tInstantiationPolicy: instPolicy,\n\t}\n}"}, {"instruction": "// newDependencyUpdateCmd creates a new dependency update command.", "input": "go language", "output": "func newDependencyUpdateCmd(out io.Writer) *cobra.Command {\n\tduc := &dependencyUpdateCmd{out: out}\n\n\tcmd := &cobra.Command{\n\t\tUse:     \"update [flags] CHART\",\n\t\tAliases: []string{\"up\"},\n\t\tShort:   \"update charts/ based on the contents of requirements.yaml\",\n\t\tLong:    dependencyUpDesc,\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tcp := \".\"\n\t\t\tif len(args) > 0 {\n\t\t\t\tcp = args[0]\n\t\t\t}\n\n\t\t\tvar err error\n\t\t\tduc.chartpath, err = filepath.Abs(cp)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tduc.helmhome = settings.Home\n\n\t\t\treturn duc.run()\n\t\t},\n\t}\n\n\tf := cmd.Flags()\n\tf.BoolVar(&duc.verify, \"verify\", false, \"verify the packages against signatures\")\n\tf.StringVar(&duc.keyring, \"keyring\", defaultKeyring(), \"keyring containing public keys\")\n\tf.BoolVar(&duc.skipRefresh, \"skip-refresh\", false, \"do not refresh the local repository cache\")\n\n\treturn cmd\n}"}, {"instruction": "// WaitForPodToDisappear blocks until it timeouts or gets a \"NotFound\" response from the API Server when getting the Static Pod in question", "input": "go language", "output": "func (w *KubeWaiter) WaitForPodToDisappear(podName string) error {\n\treturn wait.PollImmediate(constants.APICallRetryInterval, w.timeout, func() (bool, error) {\n\t\t_, err := w.client.CoreV1().Pods(metav1.NamespaceSystem).Get(podName, metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\tfmt.Printf(\"[apiclient] The old Pod %q is now removed (which is desired)\\n\", podName)\n\t\t\treturn true, nil\n\t\t}\n\t\treturn false, nil\n\t})\n}"}, {"instruction": "// watchTillerUntilReady waits for the tiller pod to become available. This is useful in situations where we\n// want to wait before we call New().\n//\n// Returns true if it exists. If the timeout was reached and it could not find the pod, it returns false.", "input": "go language", "output": "func watchTillerUntilReady(namespace string, client kubernetes.Interface, timeout int64, newImage string) bool {\n\tdeadlinePollingChan := time.NewTimer(time.Duration(timeout) * time.Second).C\n\tcheckTillerPodTicker := time.NewTicker(500 * time.Millisecond)\n\tdoneChan := make(chan bool)\n\n\tdefer checkTillerPodTicker.Stop()\n\n\tgo func() {\n\t\tfor range checkTillerPodTicker.C {\n\t\t\timage, err := portforwarder.GetTillerPodImage(client.CoreV1(), namespace)\n\t\t\tif err == nil && image == newImage {\n\t\t\t\tdoneChan <- true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}()\n\n\tfor {\n\t\tselect {\n\t\tcase <-deadlinePollingChan:\n\t\t\treturn false\n\t\tcase <-doneChan:\n\t\t\treturn true\n\t\t}\n\t}\n}"}, {"instruction": "// Run is the long-running method that handles state syncing. It should be run\n// in it's own goroutine and will continue until a fatal error is hit or Close\n// is called. Run will return an error if it is called more than once, or called\n// after Close.", "input": "go language", "output": "func (m *Manager) Run() error {\n\tm.mu.Lock()\n\talreadyStarted := m.started\n\tm.started = true\n\tstateCh := m.stateCh\n\tm.mu.Unlock()\n\n\t// Protect against multiple Run calls.\n\tif alreadyStarted {\n\t\treturn ErrStarted\n\t}\n\n\t// Protect against being run after Close.\n\tif stateCh == nil {\n\t\treturn ErrStopped\n\t}\n\n\t// Register for notifications about state changes\n\tm.State.Notify(stateCh)\n\tdefer m.State.StopNotify(stateCh)\n\n\tfor {\n\t\tm.syncState()\n\n\t\t// Wait for a state change\n\t\t_, ok := <-stateCh\n\t\tif !ok {\n\t\t\t// Stopped\n\t\t\treturn nil\n\t\t}\n\t}\n}"}, {"instruction": "// parseCARoot returns a filled-in structs.CARoot from a raw PEM value.", "input": "go language", "output": "func parseCARoot(pemValue, provider, clusterID string) (*structs.CARoot, error) {\n\tid, err := connect.CalculateCertFingerprint(pemValue)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error parsing root fingerprint: %v\", err)\n\t}\n\trootCert, err := connect.ParseCert(pemValue)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error parsing root cert: %v\", err)\n\t}\n\treturn &structs.CARoot{\n\t\tID:                  id,\n\t\tName:                fmt.Sprintf(\"%s CA Root Cert\", strings.Title(provider)),\n\t\tSerialNumber:        rootCert.SerialNumber.Uint64(),\n\t\tSigningKeyID:        connect.HexString(rootCert.AuthorityKeyId),\n\t\tExternalTrustDomain: clusterID,\n\t\tNotBefore:           rootCert.NotBefore,\n\t\tNotAfter:            rootCert.NotAfter,\n\t\tRootCert:            pemValue,\n\t\tActive:              true,\n\t}, nil\n}"}, {"instruction": "// NamespaceToSelectableFields returns a field set that represents the object", "input": "go language", "output": "func NamespaceToSelectableFields(namespace *api.Namespace) fields.Set {\n\tobjectMetaFieldsSet := generic.ObjectMetaFieldsSet(&namespace.ObjectMeta, false)\n\tspecificFieldsSet := fields.Set{\n\t\t\"status.phase\": string(namespace.Status.Phase),\n\t\t// This is a bug, but we need to support it for backward compatibility.\n\t\t\"name\": namespace.Name,\n\t}\n\treturn generic.MergeFieldsSets(objectMetaFieldsSet, specificFieldsSet)\n}"}, {"instruction": "// NewVolumeBinder sets up the volume binding library and binding queue", "input": "go language", "output": "func NewVolumeBinder(\n\tclient clientset.Interface,\n\tnodeInformer coreinformers.NodeInformer,\n\tpvcInformer coreinformers.PersistentVolumeClaimInformer,\n\tpvInformer coreinformers.PersistentVolumeInformer,\n\tstorageClassInformer storageinformers.StorageClassInformer,\n\tbindTimeout time.Duration) *VolumeBinder {\n\n\treturn &VolumeBinder{\n\t\tBinder: persistentvolume.NewVolumeBinder(client, nodeInformer, pvcInformer, pvInformer, storageClassInformer, bindTimeout),\n\t}\n}"}, {"instruction": "// GraphNodeProviderConsumer", "input": "go language", "output": "func (n *NodeAbstractResource) ProvidedBy() (addrs.AbsProviderConfig, bool) {\n\t// If we have a config we prefer that above all else\n\tif n.Config != nil {\n\t\trelAddr := n.Config.ProviderConfigAddr()\n\t\treturn relAddr.Absolute(n.Path()), false\n\t}\n\n\t// Use our type and containing module path to guess a provider configuration address\n\treturn n.Addr.Resource.DefaultProviderConfig().Absolute(n.Addr.Module), false\n}"}, {"instruction": "// resolveReceipts returns the list of receipts for this block, fetching them\n// if necessary.", "input": "go language", "output": "func (b *Block) resolveReceipts(ctx context.Context) ([]*types.Receipt, error) {\n\tif b.receipts == nil {\n\t\thash := b.hash\n\t\tif hash == (common.Hash{}) {\n\t\t\theader, err := b.resolveHeader(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\thash = header.Hash()\n\t\t}\n\n\t\treceipts, err := b.backend.GetReceipts(ctx, hash)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tb.receipts = []*types.Receipt(receipts)\n\t}\n\treturn b.receipts, nil\n}"}, {"instruction": "// createPriceOracle sets up a matrix which can be queried to get\n// the price for a message via the Price method", "input": "go language", "output": "func (r *Registry) createPriceOracle() {\n\tsp := &StreamerPrices{\n\t\tregistry: r,\n\t}\n\tsp.priceMatrix = map[reflect.Type]*protocols.Price{\n\t\treflect.TypeOf(ChunkDeliveryMsgRetrieval{}): {\n\t\t\tValue:   sp.getChunkDeliveryMsgRetrievalPrice(), // arbitrary price for now\n\t\t\tPerByte: true,\n\t\t\tPayer:   protocols.Receiver,\n\t\t},\n\t\treflect.TypeOf(RetrieveRequestMsg{}): {\n\t\t\tValue:   sp.getRetrieveRequestMsgPrice(), // arbitrary price for now\n\t\t\tPerByte: false,\n\t\t\tPayer:   protocols.Sender,\n\t\t},\n\t}\n\tr.prices = sp\n}"}, {"instruction": "// Unlock released the lock. It is an error to call this\n// if the lock is not currently held.", "input": "go language", "output": "func (l *Lock) Unlock() error {\n\t// Hold the lock as we try to release\n\tl.l.Lock()\n\tdefer l.l.Unlock()\n\n\t// Ensure the lock is actually held\n\tif !l.isHeld {\n\t\treturn ErrLockNotHeld\n\t}\n\n\t// Set that we no longer own the lock\n\tl.isHeld = false\n\n\t// Stop the session renew\n\tif l.sessionRenew != nil {\n\t\tdefer func() {\n\t\t\tclose(l.sessionRenew)\n\t\t\tl.sessionRenew = nil\n\t\t}()\n\t}\n\n\t// Get the lock entry, and clear the lock session\n\tlockEnt := l.lockEntry(l.lockSession)\n\tl.lockSession = \"\"\n\n\t// Release the lock explicitly\n\tkv := l.c.KV()\n\t_, _, err := kv.Release(lockEnt, nil)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to release lock: %v\", err)\n\t}\n\treturn nil\n}"}, {"instruction": "// evalRecursive visits the given value recursively and pushes all of them to result", "input": "go language", "output": "func (j *JSONPath) evalRecursive(input []reflect.Value, node *RecursiveNode) ([]reflect.Value, error) {\n\tresult := []reflect.Value{}\n\tfor _, value := range input {\n\t\tresults := []reflect.Value{}\n\t\tvalue, isNil := template.Indirect(value)\n\t\tif isNil {\n\t\t\tcontinue\n\t\t}\n\n\t\tkind := value.Kind()\n\t\tif kind == reflect.Struct {\n\t\t\tfor i := 0; i < value.NumField(); i++ {\n\t\t\t\tresults = append(results, value.Field(i))\n\t\t\t}\n\t\t} else if kind == reflect.Map {\n\t\t\tfor _, key := range value.MapKeys() {\n\t\t\t\tresults = append(results, value.MapIndex(key))\n\t\t\t}\n\t\t} else if kind == reflect.Array || kind == reflect.Slice || kind == reflect.String {\n\t\t\tfor i := 0; i < value.Len(); i++ {\n\t\t\t\tresults = append(results, value.Index(i))\n\t\t\t}\n\t\t}\n\t\tif len(results) != 0 {\n\t\t\tresult = append(result, value)\n\t\t\toutput, err := j.evalRecursive(results, node)\n\t\t\tif err != nil {\n\t\t\t\treturn result, err\n\t\t\t}\n\t\t\tresult = append(result, output...)\n\t\t}\n\t}\n\treturn result, nil\n}"}, {"instruction": "// grantGlobalPriv manipulates mysql.user table.", "input": "go language", "output": "func (e *GrantExec) grantGlobalPriv(priv *ast.PrivElem, user *ast.UserSpec) error {\n\tif priv.Priv == 0 {\n\t\treturn nil\n\t}\n\tasgns, err := composeGlobalPrivUpdate(priv.Priv, \"Y\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tsql := fmt.Sprintf(`UPDATE %s.%s SET %s WHERE User='%s' AND Host='%s'`, mysql.SystemDB, mysql.UserTable, asgns, user.User.Username, user.User.Hostname)\n\t_, _, err = e.ctx.(sqlexec.RestrictedSQLExecutor).ExecRestrictedSQL(e.ctx, sql)\n\treturn err\n}"}, {"instruction": "// New returns a new instance of the os-namespaced template functions.", "input": "go language", "output": "func New(deps *deps.Deps) *Namespace {\n\n\t// Since Hugo 0.38 we can have multiple content dirs. This can make it hard to\n\t// reason about where the file is placed relative to the project root.\n\t// To make the {{ readFile .Filename }} variant just work, we create a composite\n\t// filesystem that first checks the work dir fs and then the content fs.\n\tvar rfs afero.Fs\n\tif deps.Fs != nil {\n\t\trfs = deps.Fs.WorkingDir\n\t\tif deps.PathSpec != nil && deps.PathSpec.BaseFs != nil {\n\t\t\trfs = afero.NewReadOnlyFs(afero.NewCopyOnWriteFs(deps.PathSpec.BaseFs.Content.Fs, deps.Fs.WorkingDir))\n\t\t}\n\t}\n\n\treturn &Namespace{\n\t\treadFileFs: rfs,\n\t\tdeps:       deps,\n\t}\n}"}, {"instruction": "// filterMembers redacts members that the token doesn't have access to.", "input": "go language", "output": "func (a *Agent) filterMembers(token string, members *[]serf.Member) error {\n\t// Resolve the token and bail if ACLs aren't enabled.\n\trule, err := a.resolveToken(token)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif rule == nil {\n\t\treturn nil\n\t}\n\n\t// Filter out members based on the node policy.\n\tm := *members\n\tfor i := 0; i < len(m); i++ {\n\t\tnode := m[i].Name\n\t\tif rule.NodeRead(node) {\n\t\t\tcontinue\n\t\t}\n\t\ta.logger.Printf(\"[DEBUG] agent: dropping node %q from result due to ACLs\", node)\n\t\tm = append(m[:i], m[i+1:]...)\n\t\ti--\n\t}\n\t*members = m\n\treturn nil\n}"}, {"instruction": "// ensureLease creates the lease if it does not exist. Returns the lease and\n// a bool (true if this call created the lease), or any error that occurs.", "input": "go language", "output": "func (c *controller) ensureLease() (*coordv1beta1.Lease, bool, error) {\n\tlease, err := c.leaseClient.Get(c.holderIdentity, metav1.GetOptions{})\n\tif apierrors.IsNotFound(err) {\n\t\t// lease does not exist, create it\n\t\tlease, err := c.leaseClient.Create(c.newLease(nil))\n\t\tif err != nil {\n\t\t\treturn nil, false, err\n\t\t}\n\t\treturn lease, true, nil\n\t} else if err != nil {\n\t\t// unexpected error getting lease\n\t\treturn nil, false, err\n\t}\n\t// lease already existed\n\treturn lease, false, nil\n}"}, {"instruction": "// NewKubeletStartPhase creates a kubeadm workflow phase that start kubelet on a node.", "input": "go language", "output": "func NewKubeletStartPhase() workflow.Phase {\n\treturn workflow.Phase{\n\t\tName:  \"kubelet-start [api-server-endpoint]\",\n\t\tShort: \"Write kubelet settings, certificates and (re)start the kubelet\",\n\t\tLong:  \"Write a file with KubeletConfiguration and an environment file with node specific kubelet settings, and then (re)start kubelet.\",\n\t\tRun:   runKubeletStartJoinPhase,\n\t\tInheritFlags: []string{\n\t\t\toptions.CfgPath,\n\t\t\toptions.NodeCRISocket,\n\t\t\toptions.NodeName,\n\t\t\toptions.FileDiscovery,\n\t\t\toptions.TokenDiscovery,\n\t\t\toptions.TokenDiscoveryCAHash,\n\t\t\toptions.TokenDiscoverySkipCAHash,\n\t\t\toptions.TLSBootstrapToken,\n\t\t\toptions.TokenStr,\n\t\t},\n\t}\n}"}, {"instruction": "// RecommendedDefaultNodeLifecycleControllerConfiguration defaults a pointer to a\n// NodeLifecycleControllerConfiguration struct. This will set the recommended default\n// values, but they may be subject to change between API versions. This function\n// is intentionally not registered in the scheme as a \"normal\" `SetDefaults_Foo`\n// function to allow consumers of this type to set whatever defaults for their\n// embedded configs. Forcing consumers to use these defaults would be problematic\n// as defaulting in the scheme is done as part of the conversion, and there would\n// be no easy way to opt-out. Instead, if you want to use this defaulting method\n// run it in your wrapper struct of this type in its `SetDefaults_` method.", "input": "go language", "output": "func RecommendedDefaultNodeLifecycleControllerConfiguration(obj *kubectrlmgrconfigv1alpha1.NodeLifecycleControllerConfiguration) {\n\tzero := metav1.Duration{}\n\tif obj.PodEvictionTimeout == zero {\n\t\tobj.PodEvictionTimeout = metav1.Duration{Duration: 5 * time.Minute}\n\t}\n\tif obj.NodeMonitorGracePeriod == zero {\n\t\tobj.NodeMonitorGracePeriod = metav1.Duration{Duration: 40 * time.Second}\n\t}\n\tif obj.NodeStartupGracePeriod == zero {\n\t\tobj.NodeStartupGracePeriod = metav1.Duration{Duration: 60 * time.Second}\n\t}\n\tif obj.EnableTaintManager == nil {\n\t\tobj.EnableTaintManager = utilpointer.BoolPtr(true)\n\t}\n}"}, {"instruction": "// AddPreShutdownHook allows you to add a PreShutdownHook.", "input": "go language", "output": "func (s *GenericAPIServer) AddPreShutdownHook(name string, hook PreShutdownHookFunc) error {\n\tif len(name) == 0 {\n\t\treturn fmt.Errorf(\"missing name\")\n\t}\n\tif hook == nil {\n\t\treturn nil\n\t}\n\n\ts.preShutdownHookLock.Lock()\n\tdefer s.preShutdownHookLock.Unlock()\n\n\tif s.preShutdownHooksCalled {\n\t\treturn fmt.Errorf(\"unable to add %q because PreShutdownHooks have already been called\", name)\n\t}\n\tif _, exists := s.preShutdownHooks[name]; exists {\n\t\treturn fmt.Errorf(\"unable to add %q because it is already registered\", name)\n\t}\n\n\ts.preShutdownHooks[name] = preShutdownHookEntry{hook: hook}\n\n\treturn nil\n}"}, {"instruction": "// DeepCopy returns a new resource state that contains equivalent data to the\n// receiver but shares no backing memory in common.\n//\n// As with all methods on Resource, this method is not safe to use concurrently\n// with writing to any portion of the recieving data structure. It is the\n// caller's responsibility to ensure mutual exclusion for the duration of the\n// operation, but may then freely modify the receiver and the returned copy\n// independently once this method returns.", "input": "go language", "output": "func (rs *Resource) DeepCopy() *Resource {\n\tif rs == nil {\n\t\treturn nil\n\t}\n\n\tinstances := make(map[addrs.InstanceKey]*ResourceInstance, len(rs.Instances))\n\tfor k, i := range rs.Instances {\n\t\tinstances[k] = i.DeepCopy()\n\t}\n\n\treturn &Resource{\n\t\tAddr:           rs.Addr,\n\t\tEachMode:       rs.EachMode,\n\t\tInstances:      instances,\n\t\tProviderConfig: rs.ProviderConfig, // technically mutable, but immutable by convention\n\t}\n}"}, {"instruction": "// SetFormat updates how log records are formatted and encoded. Log entries\n// created after this method has completed will use the new format.\n//\n// An error is returned if the log format specification cannot be parsed.", "input": "go language", "output": "func (s *Logging) SetFormat(format string) error {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\tif format == \"\" {\n\t\tformat = defaultFormat\n\t}\n\n\tif format == \"json\" {\n\t\ts.encoding = JSON\n\t\treturn nil\n\t}\n\n\tif format == \"logfmt\" {\n\t\ts.encoding = LOGFMT\n\t\treturn nil\n\t}\n\n\tformatters, err := fabenc.ParseFormat(format)\n\tif err != nil {\n\t\treturn err\n\t}\n\ts.multiFormatter.SetFormatters(formatters)\n\ts.encoding = CONSOLE\n\n\treturn nil\n}"}, {"instruction": "// DropDisabledFields removes disabled fields from the pod security policy spec.\n// This should be called from PrepareForCreate/PrepareForUpdate for all resources containing a od security policy spec.", "input": "go language", "output": "func DropDisabledFields(pspSpec, oldPSPSpec *policy.PodSecurityPolicySpec) {\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.ProcMountType) && !allowedProcMountTypesInUse(oldPSPSpec) {\n\t\tpspSpec.AllowedProcMountTypes = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.RunAsGroup) && (oldPSPSpec == nil || oldPSPSpec.RunAsGroup == nil) {\n\t\tpspSpec.RunAsGroup = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.Sysctls) && !sysctlsInUse(oldPSPSpec) {\n\t\tpspSpec.AllowedUnsafeSysctls = nil\n\t\tpspSpec.ForbiddenSysctls = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.CSIInlineVolume) {\n\t\tpspSpec.AllowedCSIDrivers = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.RuntimeClass) &&\n\t\t(oldPSPSpec == nil || oldPSPSpec.RuntimeClass == nil) {\n\t\tpspSpec.RuntimeClass = nil\n\t}\n}"}, {"instruction": "// Validate validates all the required options.", "input": "go language", "output": "func (o *Options) Validate() []error {\n\tvar errs []error\n\n\tif err := validation.ValidateKubeSchedulerConfiguration(&o.ComponentConfig).ToAggregate(); err != nil {\n\t\terrs = append(errs, err.Errors()...)\n\t}\n\terrs = append(errs, o.SecureServing.Validate()...)\n\terrs = append(errs, o.CombinedInsecureServing.Validate()...)\n\terrs = append(errs, o.Authentication.Validate()...)\n\terrs = append(errs, o.Authorization.Validate()...)\n\terrs = append(errs, o.Deprecated.Validate()...)\n\n\treturn errs\n}"}, {"instruction": "// SetShhConfig applies shh-related command line flags to the config.", "input": "go language", "output": "func SetShhConfig(ctx *cli.Context, stack *node.Node, cfg *whisper.Config) {\n\tif ctx.GlobalIsSet(WhisperMaxMessageSizeFlag.Name) {\n\t\tcfg.MaxMessageSize = uint32(ctx.GlobalUint(WhisperMaxMessageSizeFlag.Name))\n\t}\n\tif ctx.GlobalIsSet(WhisperMinPOWFlag.Name) {\n\t\tcfg.MinimumAcceptedPOW = ctx.GlobalFloat64(WhisperMinPOWFlag.Name)\n\t}\n\tif ctx.GlobalIsSet(WhisperRestrictConnectionBetweenLightClientsFlag.Name) {\n\t\tcfg.RestrictConnectionBetweenLightClients = true\n\t}\n}"}, {"instruction": "// NewClientBackedDryRunGetterFromKubeconfig creates a new ClientBackedDryRunGetter instance from the given KubeConfig file", "input": "go language", "output": "func NewClientBackedDryRunGetterFromKubeconfig(file string) (*ClientBackedDryRunGetter, error) {\n\tconfig, err := clientcmd.LoadFromFile(file)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to load kubeconfig\")\n\t}\n\tclientConfig, err := clientcmd.NewDefaultClientConfig(*config, &clientcmd.ConfigOverrides{}).ClientConfig()\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to create API client configuration from kubeconfig\")\n\t}\n\treturn NewClientBackedDryRunGetter(clientConfig)\n}"}, {"instruction": "// AccumulateRewards credits the coinbase of the given block with the mining\n// reward. The total reward consists of the static block reward and rewards for\n// included uncles. The coinbase of each uncle block is also rewarded.", "input": "go language", "output": "func accumulateRewards(config *params.ChainConfig, state *state.StateDB, header *types.Header, uncles []*types.Header) {\n\t// Select the correct block reward based on chain progression\n\tblockReward := FrontierBlockReward\n\tif config.IsByzantium(header.Number) {\n\t\tblockReward = ByzantiumBlockReward\n\t}\n\tif config.IsConstantinople(header.Number) {\n\t\tblockReward = ConstantinopleBlockReward\n\t}\n\t// Accumulate the rewards for the miner and any included uncles\n\treward := new(big.Int).Set(blockReward)\n\tr := new(big.Int)\n\tfor _, uncle := range uncles {\n\t\tr.Add(uncle.Number, big8)\n\t\tr.Sub(r, header.Number)\n\t\tr.Mul(r, blockReward)\n\t\tr.Div(r, big8)\n\t\tstate.AddBalance(uncle.Coinbase, r)\n\n\t\tr.Div(blockReward, big32)\n\t\treward.Add(reward, r)\n\t}\n\tstate.AddBalance(header.Coinbase, reward)\n}"}, {"instruction": "// validatePathNoBacksteps makes sure the targetPath does not have any `..` path elements when split\n//\n// This assumes the OS of the apiserver and the nodes are the same. The same check should be done\n// on the node to ensure there are no backsteps.", "input": "go language", "output": "func validatePathNoBacksteps(targetPath string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tparts := strings.Split(filepath.ToSlash(targetPath), \"/\")\n\tfor _, item := range parts {\n\t\tif item == \"..\" {\n\t\t\tallErrs = append(allErrs, field.Invalid(fldPath, targetPath, \"must not contain '..'\"))\n\t\t\tbreak // even for `../../..`, one error is sufficient to make the point\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// increments priority of the given child and reorders if necessary.", "input": "go language", "output": "func (n *node) incrementChildPrio(pos int) int {\n\tn.children[pos].priority++\n\tprio := n.children[pos].priority\n\n\t// adjust position (move to front)\n\tnewPos := pos\n\tfor newPos > 0 && n.children[newPos-1].priority < prio {\n\t\t// swap node positions\n\t\tn.children[newPos-1], n.children[newPos] = n.children[newPos], n.children[newPos-1]\n\n\t\tnewPos--\n\t}\n\n\t// build new index char string\n\tif newPos != pos {\n\t\tn.indices = n.indices[:newPos] + // unchanged prefix, might be empty\n\t\t\tn.indices[pos:pos+1] + // the index char we move\n\t\t\tn.indices[newPos:pos] + n.indices[pos+1:] // rest without char at 'pos'\n\t}\n\n\treturn newPos\n}"}, {"instruction": "// This implementation is shared between Linux and NsEnter", "input": "go language", "output": "func safeOpenSubPath(mounter mount.Interface, subpath Subpath) (int, error) {\n\tif !mount.PathWithinBase(subpath.Path, subpath.VolumePath) {\n\t\treturn -1, fmt.Errorf(\"subpath %q not within volume path %q\", subpath.Path, subpath.VolumePath)\n\t}\n\tfd, err := doSafeOpen(subpath.Path, subpath.VolumePath)\n\tif err != nil {\n\t\treturn -1, fmt.Errorf(\"error opening subpath %v: %v\", subpath.Path, err)\n\t}\n\treturn fd, nil\n}"}, {"instruction": "// StructuredGenerate outputs a pod disruption budget object using the configured fields.", "input": "go language", "output": "func (s *PodDisruptionBudgetV1Generator) StructuredGenerate() (runtime.Object, error) {\n\tif len(s.MinAvailable) == 0 {\n\t\t// defaulting behavior seen in Kubernetes 1.6 and below.\n\t\ts.MinAvailable = \"1\"\n\t}\n\n\tif err := s.validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tselector, err := metav1.ParseToLabelSelector(s.Selector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tminAvailable := intstr.Parse(s.MinAvailable)\n\treturn &policy.PodDisruptionBudget{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: s.Name,\n\t\t},\n\t\tSpec: policy.PodDisruptionBudgetSpec{\n\t\t\tMinAvailable: &minAvailable,\n\t\t\tSelector:     selector,\n\t\t},\n\t}, nil\n}"}, {"instruction": "// killContainersWithSyncResult kills all pod's containers with sync results.", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) killContainersWithSyncResult(pod *v1.Pod, runningPod kubecontainer.Pod, gracePeriodOverride *int64) (syncResults []*kubecontainer.SyncResult) {\n\tcontainerResults := make(chan *kubecontainer.SyncResult, len(runningPod.Containers))\n\twg := sync.WaitGroup{}\n\n\twg.Add(len(runningPod.Containers))\n\tfor _, container := range runningPod.Containers {\n\t\tgo func(container *kubecontainer.Container) {\n\t\t\tdefer utilruntime.HandleCrash()\n\t\t\tdefer wg.Done()\n\n\t\t\tkillContainerResult := kubecontainer.NewSyncResult(kubecontainer.KillContainer, container.Name)\n\t\t\tif err := m.killContainer(pod, container.ID, container.Name, \"\", gracePeriodOverride); err != nil {\n\t\t\t\tkillContainerResult.Fail(kubecontainer.ErrKillContainer, err.Error())\n\t\t\t}\n\t\t\tcontainerResults <- killContainerResult\n\t\t}(container)\n\t}\n\twg.Wait()\n\tclose(containerResults)\n\n\tfor containerResult := range containerResults {\n\t\tsyncResults = append(syncResults, containerResult)\n\t}\n\treturn\n}"}, {"instruction": "// expandLocations replaces the variables in the locations map with actual\n// directory locations.", "input": "go language", "output": "func expandLocations() error {\n\tnewLocations := make(map[LocationEnum]string)\n\tfor key, dir := range locationTemplates {\n\t\tfor varName, value := range baseDirs {\n\t\t\tdir = strings.Replace(dir, \"${\"+string(varName)+\"}\", value, -1)\n\t\t}\n\t\tvar err error\n\t\tdir, err = fs.ExpandTilde(dir)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnewLocations[key] = filepath.Clean(dir)\n\t}\n\tlocations = newLocations\n\treturn nil\n}"}, {"instruction": "// WaitForCacheSync is a helper function that waits for cache sync for CSIDriverLister", "input": "go language", "output": "func (kvh *kubeletVolumeHost) WaitForCacheSync() error {\n\tif kvh.csiDriversSynced == nil {\n\t\tklog.Error(\"csiDriversSynced not found on KubeletVolumeHost\")\n\t\treturn fmt.Errorf(\"csiDriversSynced not found on KubeletVolumeHost\")\n\t}\n\n\tsynced := []cache.InformerSynced{kvh.csiDriversSynced}\n\tif !cache.WaitForCacheSync(wait.NeverStop, synced...) {\n\t\tklog.Warning(\"failed to wait for cache sync for CSIDriverLister\")\n\t\treturn fmt.Errorf(\"failed to wait for cache sync for CSIDriverLister\")\n\t}\n\n\treturn nil\n}"}, {"instruction": "// setNextValue sets the next value for the given datum. For types like float,\n// we do not set because it is not discrete and does not matter too much when estimating the scalar info.", "input": "go language", "output": "func setNextValue(d *types.Datum) {\n\tswitch d.Kind() {\n\tcase types.KindBytes, types.KindString:\n\t\td.SetBytes(kv.Key(d.GetBytes()).PrefixNext())\n\tcase types.KindInt64:\n\t\td.SetInt64(d.GetInt64() + 1)\n\tcase types.KindUint64:\n\t\td.SetUint64(d.GetUint64() + 1)\n\tcase types.KindMysqlDuration:\n\t\tduration := d.GetMysqlDuration()\n\t\tduration.Duration = duration.Duration + 1\n\t\td.SetMysqlDuration(duration)\n\tcase types.KindMysqlTime:\n\t\tt := d.GetMysqlTime()\n\t\tsc := &stmtctx.StatementContext{TimeZone: types.BoundTimezone}\n\t\tif _, err := t.Add(sc, types.Duration{Duration: 1, Fsp: 0}); err != nil {\n\t\t\tlog.Error(errors.ErrorStack(err))\n\t\t}\n\t\td.SetMysqlTime(t)\n\t}\n}"}, {"instruction": "// TLSConfig is used to generate a TLSClientConfig that's useful for talking to\n// Consul using TLS.", "input": "go language", "output": "func SetupTLSConfig(tlsConfig *TLSConfig) (*tls.Config, error) {\n\ttlsClientConfig := &tls.Config{\n\t\tInsecureSkipVerify: tlsConfig.InsecureSkipVerify,\n\t}\n\n\tif tlsConfig.Address != \"\" {\n\t\tserver := tlsConfig.Address\n\t\thasPort := strings.LastIndex(server, \":\") > strings.LastIndex(server, \"]\")\n\t\tif hasPort {\n\t\t\tvar err error\n\t\t\tserver, _, err = net.SplitHostPort(server)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\ttlsClientConfig.ServerName = server\n\t}\n\n\tif tlsConfig.CertFile != \"\" && tlsConfig.KeyFile != \"\" {\n\t\ttlsCert, err := tls.LoadX509KeyPair(tlsConfig.CertFile, tlsConfig.KeyFile)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ttlsClientConfig.Certificates = []tls.Certificate{tlsCert}\n\t}\n\n\tif tlsConfig.CAFile != \"\" || tlsConfig.CAPath != \"\" {\n\t\trootConfig := &rootcerts.Config{\n\t\t\tCAFile: tlsConfig.CAFile,\n\t\t\tCAPath: tlsConfig.CAPath,\n\t\t}\n\t\tif err := rootcerts.ConfigureTLS(tlsClientConfig, rootConfig); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn tlsClientConfig, nil\n}"}, {"instruction": "// String implements fmt.Stringer and sanitizes sensitive fields of\n// TLSClientConfig to prevent accidental leaking via logs.", "input": "go language", "output": "func (c TLSClientConfig) String() string {\n\tcc := sanitizedTLSClientConfig{\n\t\tInsecure:   c.Insecure,\n\t\tServerName: c.ServerName,\n\t\tCertFile:   c.CertFile,\n\t\tKeyFile:    c.KeyFile,\n\t\tCAFile:     c.CAFile,\n\t\tCertData:   c.CertData,\n\t\tKeyData:    c.KeyData,\n\t\tCAData:     c.CAData,\n\t}\n\t// Explicitly mark non-empty credential fields as redacted.\n\tif len(cc.CertData) != 0 {\n\t\tcc.CertData = []byte(\"--- TRUNCATED ---\")\n\t}\n\tif len(cc.KeyData) != 0 {\n\t\tcc.KeyData = []byte(\"--- REDACTED ---\")\n\t}\n\treturn fmt.Sprintf(\"%#v\", cc)\n}"}, {"instruction": "// ViewHistory returns a list of the revision history of a statefulset\n// TODO: this should be a describer\n// TODO: needs to implement detailed revision view", "input": "go language", "output": "func (h *StatefulSetHistoryViewer) ViewHistory(namespace, name string, revision int64) (string, error) {\n\t_, history, err := statefulSetHistory(h.c.AppsV1(), namespace, name)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(history) <= 0 {\n\t\treturn \"No rollout history found.\", nil\n\t}\n\trevisions := make([]int64, len(history))\n\tfor _, revision := range history {\n\t\trevisions = append(revisions, revision.Revision)\n\t}\n\tsliceutil.SortInts64(revisions)\n\n\treturn tabbedString(func(out io.Writer) error {\n\t\tfmt.Fprintf(out, \"REVISION\\n\")\n\t\tfor _, r := range revisions {\n\t\t\tfmt.Fprintf(out, \"%d\\n\", r)\n\t\t}\n\t\treturn nil\n\t})\n}"}, {"instruction": "// AdoptControllerRevision sends a patch to take control of the ControllerRevision. It returns the error if\n// the patching fails.", "input": "go language", "output": "func (m *ControllerRevisionControllerRefManager) AdoptControllerRevision(history *apps.ControllerRevision) error {\n\tif err := m.CanAdopt(); err != nil {\n\t\treturn fmt.Errorf(\"can't adopt ControllerRevision %v/%v (%v): %v\", history.Namespace, history.Name, history.UID, err)\n\t}\n\t// Note that ValidateOwnerReferences() will reject this patch if another\n\t// OwnerReference exists with controller=true.\n\taddControllerPatch := fmt.Sprintf(\n\t\t`{\"metadata\":{\"ownerReferences\":[{\"apiVersion\":\"%s\",\"kind\":\"%s\",\"name\":\"%s\",\"uid\":\"%s\",\"controller\":true,\"blockOwnerDeletion\":true}],\"uid\":\"%s\"}}`,\n\t\tm.controllerKind.GroupVersion(), m.controllerKind.Kind,\n\t\tm.Controller.GetName(), m.Controller.GetUID(), history.UID)\n\treturn m.crControl.PatchControllerRevision(history.Namespace, history.Name, []byte(addControllerPatch))\n}"}, {"instruction": "// GetContainerLogs get container logs directly from docker daemon.", "input": "go language", "output": "func (d *dockerService) GetContainerLogs(_ context.Context, pod *v1.Pod, containerID kubecontainer.ContainerID, logOptions *v1.PodLogOptions, stdout, stderr io.Writer) error {\n\tcontainer, err := d.client.InspectContainer(containerID.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar since int64\n\tif logOptions.SinceSeconds != nil {\n\t\tt := metav1.Now().Add(-time.Duration(*logOptions.SinceSeconds) * time.Second)\n\t\tsince = t.Unix()\n\t}\n\tif logOptions.SinceTime != nil {\n\t\tsince = logOptions.SinceTime.Unix()\n\t}\n\topts := dockertypes.ContainerLogsOptions{\n\t\tShowStdout: true,\n\t\tShowStderr: true,\n\t\tSince:      strconv.FormatInt(since, 10),\n\t\tTimestamps: logOptions.Timestamps,\n\t\tFollow:     logOptions.Follow,\n\t}\n\tif logOptions.TailLines != nil {\n\t\topts.Tail = strconv.FormatInt(*logOptions.TailLines, 10)\n\t}\n\n\tsopts := libdocker.StreamOptions{\n\t\tOutputStream: stdout,\n\t\tErrorStream:  stderr,\n\t\tRawTerminal:  container.Config.Tty,\n\t}\n\treturn d.client.Logs(containerID.ID, opts, sopts)\n}"}, {"instruction": "// Run will not return until stopCh is closed. workers determines how many\n// endpoints will be handled in parallel.", "input": "go language", "output": "func (e *EndpointController) Run(workers int, stopCh <-chan struct{}) {\n\tdefer utilruntime.HandleCrash()\n\tdefer e.queue.ShutDown()\n\n\tklog.Infof(\"Starting endpoint controller\")\n\tdefer klog.Infof(\"Shutting down endpoint controller\")\n\n\tif !controller.WaitForCacheSync(\"endpoint\", stopCh, e.podsSynced, e.servicesSynced, e.endpointsSynced) {\n\t\treturn\n\t}\n\n\tfor i := 0; i < workers; i++ {\n\t\tgo wait.Until(e.worker, e.workerLoopPeriod, stopCh)\n\t}\n\n\tgo func() {\n\t\tdefer utilruntime.HandleCrash()\n\t\te.checkLeftoverEndpoints()\n\t}()\n\n\t<-stopCh\n}"}, {"instruction": "// SetSecurityPolicyForAlphaGlobalBackendService sets the given\n// SecurityPolicyReference for the BackendService identified by the given name.", "input": "go language", "output": "func (g *Cloud) SetSecurityPolicyForAlphaGlobalBackendService(backendServiceName string, securityPolicyReference *computealpha.SecurityPolicyReference) error {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\tmc := newBackendServiceMetricContextWithVersion(\"set_security_policy\", \"\", computeAlphaVersion)\n\treturn mc.Observe(g.c.AlphaBackendServices().SetSecurityPolicy(ctx, meta.GlobalKey(backendServiceName), securityPolicyReference))\n}"}, {"instruction": "// GetGlobalSysVar implements GlobalVarAccessor.GetGlobalSysVar interface.", "input": "go language", "output": "func (s *session) GetGlobalSysVar(name string) (string, error) {\n\tif s.Value(sessionctx.Initing) != nil {\n\t\t// When running bootstrap or upgrade, we should not access global storage.\n\t\treturn \"\", nil\n\t}\n\tsql := fmt.Sprintf(`SELECT VARIABLE_VALUE FROM %s.%s WHERE VARIABLE_NAME=\"%s\";`,\n\t\tmysql.SystemDB, mysql.GlobalVariablesTable, name)\n\tsysVar, err := s.getExecRet(s, sql)\n\tif err != nil {\n\t\tif executor.ErrResultIsEmpty.Equal(err) {\n\t\t\tif sv, ok := variable.SysVars[name]; ok {\n\t\t\t\treturn sv.Value, nil\n\t\t\t}\n\t\t\treturn \"\", variable.UnknownSystemVar.GenWithStackByArgs(name)\n\t\t}\n\t\treturn \"\", err\n\t}\n\treturn sysVar, nil\n}"}, {"instruction": "// GEt /v1/connect/ca/configuration", "input": "go language", "output": "func (s *HTTPServer) ConnectCAConfigurationGet(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\t// Method is tested in ConnectCAConfiguration\n\tvar args structs.DCSpecificRequest\n\tif done := s.parse(resp, req, &args.Datacenter, &args.QueryOptions); done {\n\t\treturn nil, nil\n\t}\n\n\tvar reply structs.CAConfiguration\n\terr := s.agent.RPC(\"ConnectCA.ConfigurationGet\", &args, &reply)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfixupConfig(&reply)\n\treturn reply, nil\n}"}, {"instruction": "// Validate checks validation of GenericOptions.", "input": "go language", "output": "func (o *GenericControllerManagerConfigurationOptions) Validate(allControllers []string, disabledByDefaultControllers []string) []error {\n\tif o == nil {\n\t\treturn nil\n\t}\n\n\terrs := []error{}\n\terrs = append(errs, o.Debugging.Validate()...)\n\n\tallControllersSet := sets.NewString(allControllers...)\n\tfor _, controller := range o.Controllers {\n\t\tif controller == \"*\" {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(controller, \"-\") {\n\t\t\tcontroller = controller[1:]\n\t\t}\n\t\tif !allControllersSet.Has(controller) {\n\t\t\terrs = append(errs, fmt.Errorf(\"%q is not in the list of known controllers\", controller))\n\t\t}\n\t}\n\n\treturn errs\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *IndexLookUpExecutor) Open(ctx context.Context) error {\n\tvar err error\n\tif e.corColInAccess {\n\t\te.ranges, err = rebuildIndexRanges(e.ctx, e.idxPlans[0].(*plannercore.PhysicalIndexScan), e.idxCols, e.colLens)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\te.kvRanges, err = distsql.IndexRangesToKVRanges(e.ctx.GetSessionVars().StmtCtx, getPhysicalTableID(e.table), e.index.ID, e.ranges, e.feedback)\n\tif err != nil {\n\t\te.feedback.Invalidate()\n\t\treturn err\n\t}\n\terr = e.open(ctx)\n\tif err != nil {\n\t\te.feedback.Invalidate()\n\t}\n\treturn err\n}"}, {"instruction": "// Check checks schema validity, returns true if use schemaVer and related tables at txnTS is legal.", "input": "go language", "output": "func (s *schemaValidator) Check(txnTS uint64, schemaVer int64, relatedTableIDs []int64) checkResult {\n\ts.mux.RLock()\n\tdefer s.mux.RUnlock()\n\tif !s.isStarted {\n\t\tlogutil.Logger(context.Background()).Info(\"the schema validator stopped before checking\")\n\t\treturn ResultUnknown\n\t}\n\tif s.lease == 0 {\n\t\treturn ResultSucc\n\t}\n\n\t// Schema changed, result decided by whether related tables change.\n\tif schemaVer < s.latestSchemaVer {\n\t\t// The DDL relatedTableIDs is empty.\n\t\tif len(relatedTableIDs) == 0 {\n\t\t\tlogutil.Logger(context.Background()).Info(\"the related table ID is empty\", zap.Int64(\"schemaVer\", schemaVer),\n\t\t\t\tzap.Int64(\"latestSchemaVer\", s.latestSchemaVer))\n\t\t\treturn ResultFail\n\t\t}\n\n\t\tif s.isRelatedTablesChanged(schemaVer, relatedTableIDs) {\n\t\t\treturn ResultFail\n\t\t}\n\t\treturn ResultSucc\n\t}\n\n\t// Schema unchanged, maybe success or the schema validator is unavailable.\n\tt := oracle.GetTimeFromTS(txnTS)\n\tif t.After(s.latestSchemaExpire) {\n\t\treturn ResultUnknown\n\t}\n\treturn ResultSucc\n}"}, {"instruction": "// getPodSandboxID gets the sandbox id by podUID and returns ([]sandboxID, error).\n// Param state could be nil in order to get all sandboxes belonging to same pod.", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) getSandboxIDByPodUID(podUID kubetypes.UID, state *runtimeapi.PodSandboxState) ([]string, error) {\n\tfilter := &runtimeapi.PodSandboxFilter{\n\t\tLabelSelector: map[string]string{types.KubernetesPodUIDLabel: string(podUID)},\n\t}\n\tif state != nil {\n\t\tfilter.State = &runtimeapi.PodSandboxStateValue{\n\t\t\tState: *state,\n\t\t}\n\t}\n\tsandboxes, err := m.runtimeService.ListPodSandbox(filter)\n\tif err != nil {\n\t\tklog.Errorf(\"ListPodSandbox with pod UID %q failed: %v\", podUID, err)\n\t\treturn nil, err\n\t}\n\n\tif len(sandboxes) == 0 {\n\t\treturn nil, nil\n\t}\n\n\t// Sort with newest first.\n\tsandboxIDs := make([]string, len(sandboxes))\n\tsort.Sort(podSandboxByCreated(sandboxes))\n\tfor i, s := range sandboxes {\n\t\tsandboxIDs[i] = s.Id\n\t}\n\n\treturn sandboxIDs, nil\n}"}, {"instruction": "// formatVirtualKey converts a virtual key (e.g., up arrow) into the appropriate ANSI string.", "input": "go language", "output": "func formatVirtualKey(key uint16, controlState uint32, escapeSequence []byte) string {\n\tshift, alt, control := getControlKeys(controlState)\n\tmodifier := getControlKeysModifier(shift, alt, control)\n\n\tif format, ok := arrowKeyMapPrefix[key]; ok {\n\t\treturn fmt.Sprintf(format, escapeSequence, modifier)\n\t}\n\n\tif format, ok := keyMapPrefix[key]; ok {\n\t\treturn fmt.Sprintf(format, modifier)\n\t}\n\n\treturn \"\"\n}"}, {"instruction": "// populateResourceListV1 takes strings of form <resourceName1>=<value1>,<resourceName1>=<value2>\n// and returns ResourceList.", "input": "go language", "output": "func populateResourceListV1(spec string) (v1.ResourceList, error) {\n\t// empty input gets a nil response to preserve generator test expected behaviors\n\tif spec == \"\" {\n\t\treturn nil, nil\n\t}\n\n\tresult := v1.ResourceList{}\n\tresourceStatements := strings.Split(spec, \",\")\n\tfor _, resourceStatement := range resourceStatements {\n\t\tparts := strings.Split(resourceStatement, \"=\")\n\t\tif len(parts) != 2 {\n\t\t\treturn nil, fmt.Errorf(\"Invalid argument syntax %v, expected <resource>=<value>\", resourceStatement)\n\t\t}\n\t\tresourceName := v1.ResourceName(parts[0])\n\t\tresourceQuantity, err := resource.ParseQuantity(parts[1])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresult[resourceName] = resourceQuantity\n\t}\n\treturn result, nil\n}"}, {"instruction": "// CheckpointList returns the checkpoints of the given container in the docker host", "input": "go language", "output": "func (cli *Client) CheckpointList(ctx context.Context, container string, options types.CheckpointListOptions) ([]types.Checkpoint, error) {\n\tvar checkpoints []types.Checkpoint\n\n\tquery := url.Values{}\n\tif options.CheckpointDir != \"\" {\n\t\tquery.Set(\"dir\", options.CheckpointDir)\n\t}\n\n\tresp, err := cli.get(ctx, \"/containers/\"+container+\"/checkpoints\", query, nil)\n\tdefer ensureReaderClosed(resp)\n\tif err != nil {\n\t\treturn checkpoints, wrapResponseError(err, resp, \"container\", container)\n\t}\n\n\terr = json.NewDecoder(resp.body).Decode(&checkpoints)\n\treturn checkpoints, err\n}"}, {"instruction": "// loadBufferedEvents iterates over the cached events in the buffer\n// and returns those that were emitted between two specific dates.\n// It uses `time.Unix(seconds, nanoseconds)` to generate valid dates with those arguments.\n// It filters those buffered messages with a topic function if it's not nil, otherwise it adds all messages.", "input": "go language", "output": "func (e *Events) loadBufferedEvents(since, until time.Time, topic func(interface{}) bool) []eventtypes.Message {\n\tvar buffered []eventtypes.Message\n\tif since.IsZero() && until.IsZero() {\n\t\treturn buffered\n\t}\n\n\tvar sinceNanoUnix int64\n\tif !since.IsZero() {\n\t\tsinceNanoUnix = since.UnixNano()\n\t}\n\n\tvar untilNanoUnix int64\n\tif !until.IsZero() {\n\t\tuntilNanoUnix = until.UnixNano()\n\t}\n\n\tfor i := len(e.events) - 1; i >= 0; i-- {\n\t\tev := e.events[i]\n\n\t\tif ev.TimeNano < sinceNanoUnix {\n\t\t\tbreak\n\t\t}\n\n\t\tif untilNanoUnix > 0 && ev.TimeNano > untilNanoUnix {\n\t\t\tcontinue\n\t\t}\n\n\t\tif topic == nil || topic(ev) {\n\t\t\tbuffered = append([]eventtypes.Message{ev}, buffered...)\n\t\t}\n\t}\n\treturn buffered\n}"}, {"instruction": "// importPreimages imports preimage data from the specified file.", "input": "go language", "output": "func importPreimages(ctx *cli.Context) error {\n\tif len(ctx.Args()) < 1 {\n\t\tutils.Fatalf(\"This command requires an argument.\")\n\t}\n\tstack := makeFullNode(ctx)\n\tdefer stack.Close()\n\n\tdb := utils.MakeChainDatabase(ctx, stack)\n\tstart := time.Now()\n\n\tif err := utils.ImportPreimages(db, ctx.Args().First()); err != nil {\n\t\tutils.Fatalf(\"Import error: %v\\n\", err)\n\t}\n\tfmt.Printf(\"Import done in %v\\n\", time.Since(start))\n\treturn nil\n}"}, {"instruction": "// newPuller returns a Puller interface that will pull from either a v1 or v2\n// registry. The endpoint argument contains a Version field that determines\n// whether a v1 or v2 puller will be created. The other parameters are passed\n// through to the underlying puller implementation for use during the actual\n// pull operation.", "input": "go language", "output": "func newPuller(endpoint registry.APIEndpoint, repoInfo *registry.RepositoryInfo, imagePullConfig *ImagePullConfig) (Puller, error) {\n\tswitch endpoint.Version {\n\tcase registry.APIVersion2:\n\t\treturn &v2Puller{\n\t\t\tV2MetadataService: metadata.NewV2MetadataService(imagePullConfig.MetadataStore),\n\t\t\tendpoint:          endpoint,\n\t\t\tconfig:            imagePullConfig,\n\t\t\trepoInfo:          repoInfo,\n\t\t}, nil\n\tcase registry.APIVersion1:\n\t\treturn &v1Puller{\n\t\t\tv1IDService: metadata.NewV1IDService(imagePullConfig.MetadataStore),\n\t\t\tendpoint:    endpoint,\n\t\t\tconfig:      imagePullConfig,\n\t\t\trepoInfo:    repoInfo,\n\t\t}, nil\n\t}\n\treturn nil, fmt.Errorf(\"unknown version %d for registry %s\", endpoint.Version, endpoint.URL)\n}"}, {"instruction": "// UnusedFilename finds a filename that isn't already used by a file in\n// the receiving sources and returns it.\n//\n// The given \"proposed\" name is returned verbatim if it isn't already used.\n// Otherwise, the function will try appending incrementing integers to the\n// proposed name until an unused name is found. Callers should propose names\n// that they do not expect to already be in use so that numeric suffixes are\n// only used in rare cases.\n//\n// The proposed name must end in either \".tf\" or \".tf.json\" because a\n// ModuleSources only has visibility into such files. This function will\n// panic if given a file whose name does not end with one of these\n// extensions.\n//\n// A ModuleSources only works on one directory at a time, so the proposed\n// name must not contain any directory separator characters.", "input": "go language", "output": "func (ms ModuleSources) UnusedFilename(proposed string) string {\n\text := fileExt(proposed)\n\tif ext == \"\" {\n\t\tpanic(fmt.Errorf(\"method UnusedFilename used with invalid proposal %q\", proposed))\n\t}\n\n\tif _, exists := ms[proposed]; !exists {\n\t\treturn proposed\n\t}\n\n\tbase := proposed[:len(proposed)-len(ext)]\n\tfor i := 1; ; i++ {\n\t\ttry := fmt.Sprintf(\"%s-%d%s\", base, i, ext)\n\t\tif _, exists := ms[try]; !exists {\n\t\t\treturn try\n\t\t}\n\t}\n}"}, {"instruction": "// Matches matches path against all the patterns. Matches is not safe to be\n// called concurrently", "input": "go language", "output": "func (pm *PatternMatcher) Matches(file string) (bool, error) {\n\tmatched := false\n\tfile = filepath.FromSlash(file)\n\tparentPath := filepath.Dir(file)\n\tparentPathDirs := strings.Split(parentPath, string(os.PathSeparator))\n\n\tfor _, pattern := range pm.patterns {\n\t\tnegative := false\n\n\t\tif pattern.exclusion {\n\t\t\tnegative = true\n\t\t}\n\n\t\tmatch, err := pattern.match(file)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif !match && parentPath != \".\" {\n\t\t\t// Check to see if the pattern matches one of our parent dirs.\n\t\t\tif len(pattern.dirs) <= len(parentPathDirs) {\n\t\t\t\tmatch, _ = pattern.match(strings.Join(parentPathDirs[:len(pattern.dirs)], string(os.PathSeparator)))\n\t\t\t}\n\t\t}\n\n\t\tif match {\n\t\t\tmatched = !negative\n\t\t}\n\t}\n\n\tif matched {\n\t\tlogrus.Debugf(\"Skipping excluded path: %s\", file)\n\t}\n\n\treturn matched, nil\n}"}, {"instruction": "// checkWhereMap handles the where-matching logic when the seqv value is a Map.", "input": "go language", "output": "func (ns *Namespace) checkWhereMap(seqv, kv, mv reflect.Value, path []string, op string) (interface{}, error) {\n\trv := reflect.MakeMap(seqv.Type())\n\tkeys := seqv.MapKeys()\n\tfor _, k := range keys {\n\t\telemv := seqv.MapIndex(k)\n\t\tswitch elemv.Kind() {\n\t\tcase reflect.Array, reflect.Slice:\n\t\t\tr, err := ns.checkWhereArray(elemv, kv, mv, path, op)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tswitch rr := reflect.ValueOf(r); rr.Kind() {\n\t\t\tcase reflect.Slice:\n\t\t\t\tif rr.Len() > 0 {\n\t\t\t\t\trv.SetMapIndex(k, elemv)\n\t\t\t\t}\n\t\t\t}\n\t\tcase reflect.Interface:\n\t\t\telemvv, isNil := indirect(elemv)\n\t\t\tif isNil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tswitch elemvv.Kind() {\n\t\t\tcase reflect.Array, reflect.Slice:\n\t\t\t\tr, err := ns.checkWhereArray(elemvv, kv, mv, path, op)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\tswitch rr := reflect.ValueOf(r); rr.Kind() {\n\t\t\t\tcase reflect.Slice:\n\t\t\t\t\tif rr.Len() > 0 {\n\t\t\t\t\t\trv.SetMapIndex(k, elemv)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn rv.Interface(), nil\n}"}, {"instruction": "// splitSlicesAndValues moves all slice values defined in c to 'slices'\n// and all other values to 'values'.", "input": "go language", "output": "func (b *Builder) splitSlicesAndValues(c Config) (slices, values Config) {\n\tv, t := reflect.ValueOf(c), reflect.TypeOf(c)\n\trs, rv := reflect.New(t), reflect.New(t)\n\n\tfor i := 0; i < t.NumField(); i++ {\n\t\tf := t.Field(i)\n\t\tif f.Type.Kind() == reflect.Slice {\n\t\t\trs.Elem().Field(i).Set(v.Field(i))\n\t\t} else {\n\t\t\trv.Elem().Field(i).Set(v.Field(i))\n\t\t}\n\t}\n\treturn rs.Elem().Interface().(Config), rv.Elem().Interface().(Config)\n}"}, {"instruction": "// FetchBodies sends a block body retrieval request to the remote peer.", "input": "go language", "output": "func (p *peerConnection) FetchBodies(request *fetchRequest) error {\n\t// Sanity check the protocol version\n\tif p.version < 62 {\n\t\tpanic(fmt.Sprintf(\"body fetch [eth/62+] requested on eth/%d\", p.version))\n\t}\n\t// Short circuit if the peer is already fetching\n\tif !atomic.CompareAndSwapInt32(&p.blockIdle, 0, 1) {\n\t\treturn errAlreadyFetching\n\t}\n\tp.blockStarted = time.Now()\n\n\t// Convert the header set to a retrievable slice\n\thashes := make([]common.Hash, 0, len(request.Headers))\n\tfor _, header := range request.Headers {\n\t\thashes = append(hashes, header.Hash())\n\t}\n\tgo p.peer.RequestBodies(hashes)\n\n\treturn nil\n}"}, {"instruction": "// ServeHTTP handles table related requests, such as table's region information, disk usage.", "input": "go language", "output": "func (h tableHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\t// parse params\n\tparams := mux.Vars(req)\n\tdbName := params[pDBName]\n\ttableName := params[pTableName]\n\tschema, err := h.schema()\n\tif err != nil {\n\t\twriteError(w, err)\n\t\treturn\n\t}\n\t// get table's schema.\n\ttableVal, err := schema.TableByName(model.NewCIStr(dbName), model.NewCIStr(tableName))\n\tif err != nil {\n\t\twriteError(w, err)\n\t\treturn\n\t}\n\n\tswitch h.op {\n\tcase opTableRegions:\n\t\th.handleRegionRequest(schema, tableVal, w, req)\n\tcase opTableDiskUsage:\n\t\th.handleDiskUsageRequest(schema, tableVal, w, req)\n\tcase opTableScatter:\n\t\th.handleScatterTableRequest(schema, tableVal, w, req)\n\tcase opStopTableScatter:\n\t\th.handleStopScatterTableRequest(schema, tableVal, w, req)\n\tdefault:\n\t\twriteError(w, errors.New(\"method not found\"))\n\t}\n}"}, {"instruction": "// Verify verifies a signed GossipMessage with a given Verifier.\n// Returns nil on success, error on failure.", "input": "go language", "output": "func (m *SignedGossipMessage) Verify(peerIdentity []byte, verify Verifier) error {\n\tif m.Envelope == nil {\n\t\treturn errors.New(\"Missing envelope\")\n\t}\n\tif len(m.Envelope.Payload) == 0 {\n\t\treturn errors.New(\"Empty payload\")\n\t}\n\tif len(m.Envelope.Signature) == 0 {\n\t\treturn errors.New(\"Empty signature\")\n\t}\n\tpayloadSigVerificationErr := verify(peerIdentity, m.Envelope.Signature, m.Envelope.Payload)\n\tif payloadSigVerificationErr != nil {\n\t\treturn payloadSigVerificationErr\n\t}\n\tif m.Envelope.SecretEnvelope != nil {\n\t\tpayload := m.Envelope.SecretEnvelope.Payload\n\t\tsig := m.Envelope.SecretEnvelope.Signature\n\t\tif len(payload) == 0 {\n\t\t\treturn errors.New(\"Empty payload\")\n\t\t}\n\t\tif len(sig) == 0 {\n\t\t\treturn errors.New(\"Empty signature\")\n\t\t}\n\t\treturn verify(peerIdentity, sig, payload)\n\t}\n\treturn nil\n}"}, {"instruction": "// numericContextResultType returns types.EvalType for numeric function's parameters.\n// the returned types.EvalType should be one of: types.ETInt, types.ETDecimal, types.ETReal", "input": "go language", "output": "func numericContextResultType(ft *types.FieldType) types.EvalType {\n\tif types.IsTypeTemporal(ft.Tp) {\n\t\tif ft.Decimal > 0 {\n\t\t\treturn types.ETDecimal\n\t\t}\n\t\treturn types.ETInt\n\t}\n\tif types.IsBinaryStr(ft) {\n\t\treturn types.ETInt\n\t}\n\tevalTp4Ft := types.ETReal\n\tif !ft.Hybrid() {\n\t\tevalTp4Ft = ft.EvalType()\n\t\tif evalTp4Ft != types.ETDecimal && evalTp4Ft != types.ETInt {\n\t\t\tevalTp4Ft = types.ETReal\n\t\t}\n\t}\n\treturn evalTp4Ft\n}"}, {"instruction": "// OnDigest notifies the engine that a digest has arrived", "input": "go language", "output": "func (engine *PullEngine) OnDigest(digest []string, nonce uint64, context interface{}) {\n\tif !engine.isAcceptingDigests() || !engine.outgoingNONCES.Exists(nonce) {\n\t\treturn\n\t}\n\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\tfor _, n := range digest {\n\t\tif engine.state.Exists(n) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif _, exists := engine.item2owners[n]; !exists {\n\t\t\tengine.item2owners[n] = make([]string, 0)\n\t\t}\n\n\t\tengine.item2owners[n] = append(engine.item2owners[n], engine.nonces2peers[nonce])\n\t}\n}"}, {"instruction": "// IsSame checks if one HealthCheck is the same as another, without looking\n// at the Raft information (that's why we didn't call it IsEqual). This is\n// useful for seeing if an update would be idempotent for all the functional\n// parts of the structure.", "input": "go language", "output": "func (c *HealthCheck) IsSame(other *HealthCheck) bool {\n\tif c.Node != other.Node ||\n\t\tc.CheckID != other.CheckID ||\n\t\tc.Name != other.Name ||\n\t\tc.Status != other.Status ||\n\t\tc.Notes != other.Notes ||\n\t\tc.Output != other.Output ||\n\t\tc.ServiceID != other.ServiceID ||\n\t\tc.ServiceName != other.ServiceName ||\n\t\t!reflect.DeepEqual(c.ServiceTags, other.ServiceTags) ||\n\t\t!reflect.DeepEqual(c.Definition, other.Definition) {\n\t\treturn false\n\t}\n\n\treturn true\n}"}, {"instruction": "// SupportsAttributes ignores all calls that do not deal with pod resources or storage requests (PVCs).\n// Also ignores any call that has a subresource defined.", "input": "go language", "output": "func (d *DefaultLimitRangerActions) SupportsAttributes(a admission.Attributes) bool {\n\tif a.GetSubresource() != \"\" {\n\t\treturn false\n\t}\n\n\t// Since containers and initContainers cannot currently be added, removed, or updated, it is unnecessary\n\t// to mutate and validate limitrange on pod updates. Trying to mutate containers or initContainers on a pod\n\t// update request will always fail pod validation because those fields are immutable once the object is created.\n\tif a.GetKind().GroupKind() == api.Kind(\"Pod\") && a.GetOperation() == admission.Update {\n\t\treturn false\n\t}\n\n\treturn a.GetKind().GroupKind() == api.Kind(\"Pod\") || a.GetKind().GroupKind() == api.Kind(\"PersistentVolumeClaim\")\n}"}, {"instruction": "// PersistWithConfig provides a mock function with given fields: txid, blockHeight, privateSimulationResultsWithConfig", "input": "go language", "output": "func (_m *Store) PersistWithConfig(txid string, blockHeight uint64, privateSimulationResultsWithConfig *protostransientstore.TxPvtReadWriteSetWithConfigInfo) error {\n\tret := _m.Called(txid, blockHeight, privateSimulationResultsWithConfig)\n\n\tvar r0 error\n\tif rf, ok := ret.Get(0).(func(string, uint64, *protostransientstore.TxPvtReadWriteSetWithConfigInfo) error); ok {\n\t\tr0 = rf(txid, blockHeight, privateSimulationResultsWithConfig)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}"}, {"instruction": "// StartRecordingToSink starts sending events received from the specified eventBroadcaster to the given sink.\n// The return value can be ignored or used to stop recording, if desired.\n// TODO: make me an object with parameterizable queue length and retry interval", "input": "go language", "output": "func (eventBroadcaster *eventBroadcasterImpl) StartRecordingToSink(sink EventSink) watch.Interface {\n\t// The default math/rand package functions aren't thread safe, so create a\n\t// new Rand object for each StartRecording call.\n\trandGen := rand.New(rand.NewSource(time.Now().UnixNano()))\n\teventCorrelator := NewEventCorrelatorWithOptions(eventBroadcaster.options)\n\treturn eventBroadcaster.StartEventWatcher(\n\t\tfunc(event *v1.Event) {\n\t\t\trecordToSink(sink, event, eventCorrelator, randGen, eventBroadcaster.sleepDuration)\n\t\t})\n}"}, {"instruction": "// Load loads a directory of charts as if it were a repository.\n//\n// It requires the presence of an index.yaml file in the directory.", "input": "go language", "output": "func (r *ChartRepository) Load() error {\n\tdirInfo, err := os.Stat(r.Config.Name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !dirInfo.IsDir() {\n\t\treturn fmt.Errorf(\"%q is not a directory\", r.Config.Name)\n\t}\n\n\t// FIXME: Why are we recursively walking directories?\n\t// FIXME: Why are we not reading the repositories.yaml to figure out\n\t// what repos to use?\n\tfilepath.Walk(r.Config.Name, func(path string, f os.FileInfo, err error) error {\n\t\tif !f.IsDir() {\n\t\t\tif strings.Contains(f.Name(), \"-index.yaml\") {\n\t\t\t\ti, err := LoadIndexFile(path)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tr.IndexFile = i\n\t\t\t} else if strings.HasSuffix(f.Name(), \".tgz\") {\n\t\t\t\tr.ChartPaths = append(r.ChartPaths, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn nil\n}"}, {"instruction": "// deleteFromIndices removes the object from each of the managed indexes\n// it is intended to be called from a function that already has a lock on the cache", "input": "go language", "output": "func (c *threadSafeMap) deleteFromIndices(obj interface{}, key string) {\n\tfor name, indexFunc := range c.indexers {\n\t\tindexValues, err := indexFunc(obj)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Errorf(\"unable to calculate an index entry for key %q on index %q: %v\", key, name, err))\n\t\t}\n\n\t\tindex := c.indices[name]\n\t\tif index == nil {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, indexValue := range indexValues {\n\t\t\tset := index[indexValue]\n\t\t\tif set != nil {\n\t\t\t\tset.Delete(key)\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// rewriteHTML scans the HTML for tags with url-valued attributes, and updates\n// those values with the urlRewriter function. The updated HTML is output to the\n// writer.", "input": "go language", "output": "func rewriteHTML(reader io.Reader, writer io.Writer, urlRewriter func(string) string) error {\n\t// Note: This assumes the content is UTF-8.\n\ttokenizer := html.NewTokenizer(reader)\n\n\tvar err error\n\tfor err == nil {\n\t\ttokenType := tokenizer.Next()\n\t\tswitch tokenType {\n\t\tcase html.ErrorToken:\n\t\t\terr = tokenizer.Err()\n\t\tcase html.StartTagToken, html.SelfClosingTagToken:\n\t\t\ttoken := tokenizer.Token()\n\t\t\tif urlAttrs, ok := atomsToAttrs[token.DataAtom]; ok {\n\t\t\t\tfor i, attr := range token.Attr {\n\t\t\t\t\tif urlAttrs.Has(attr.Key) {\n\t\t\t\t\t\ttoken.Attr[i].Val = urlRewriter(attr.Val)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t_, err = writer.Write([]byte(token.String()))\n\t\tdefault:\n\t\t\t_, err = writer.Write(tokenizer.Raw())\n\t\t}\n\t}\n\tif err != io.EOF {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// ServerResourcesForGroupVersion returns the supported resources for a group\n// and version.", "input": "go language", "output": "func (c *FakeDiscovery) ServerResourcesForGroupVersion(groupVersion string) (*metav1.APIResourceList, error) {\n\taction := testing.ActionImpl{\n\t\tVerb:     \"get\",\n\t\tResource: schema.GroupVersionResource{Resource: \"resource\"},\n\t}\n\tc.Invokes(action, nil)\n\tfor _, resourceList := range c.Resources {\n\t\tif resourceList.GroupVersion == groupVersion {\n\t\t\treturn resourceList, nil\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"GroupVersion %q not found\", groupVersion)\n}"}, {"instruction": "// newTimestampDir creates a new timestamp directory", "input": "go language", "output": "func (w *AtomicWriter) newTimestampDir() (string, error) {\n\ttsDir, err := ioutil.TempDir(w.targetDir, time.Now().UTC().Format(\"..2006_01_02_15_04_05.\"))\n\tif err != nil {\n\t\tklog.Errorf(\"%s: unable to create new temp directory: %v\", w.logContext, err)\n\t\treturn \"\", err\n\t}\n\n\t// 0755 permissions are needed to allow 'group' and 'other' to recurse the\n\t// directory tree.  do a chmod here to ensure that permissions are set correctly\n\t// regardless of the process' umask.\n\terr = os.Chmod(tsDir, 0755)\n\tif err != nil {\n\t\tklog.Errorf(\"%s: unable to set mode on new temp directory: %v\", w.logContext, err)\n\t\treturn \"\", err\n\t}\n\n\treturn tsDir, nil\n}"}, {"instruction": "// mergeDNSOptions merges DNS options. If duplicated, entries given by PodDNSConfigOption will\n// overwrite the existing ones.", "input": "go language", "output": "func mergeDNSOptions(existingDNSConfigOptions []string, dnsConfigOptions []v1.PodDNSConfigOption) []string {\n\toptionsMap := make(map[string]string)\n\tfor _, op := range existingDNSConfigOptions {\n\t\tif index := strings.Index(op, \":\"); index != -1 {\n\t\t\toptionsMap[op[:index]] = op[index+1:]\n\t\t} else {\n\t\t\toptionsMap[op] = \"\"\n\t\t}\n\t}\n\tfor _, op := range dnsConfigOptions {\n\t\tif op.Value != nil {\n\t\t\toptionsMap[op.Name] = *op.Value\n\t\t} else {\n\t\t\toptionsMap[op.Name] = \"\"\n\t\t}\n\t}\n\t// Reconvert DNS options into a string array.\n\toptions := []string{}\n\tfor opName, opValue := range optionsMap {\n\t\top := opName\n\t\tif opValue != \"\" {\n\t\t\top = op + \":\" + opValue\n\t\t}\n\t\toptions = append(options, op)\n\t}\n\treturn options\n}"}, {"instruction": "// updateSchemaVersion increments the schema version by 1 and sets SchemaDiff.", "input": "go language", "output": "func updateSchemaVersion(t *meta.Meta, job *model.Job) (int64, error) {\n\tschemaVersion, err := t.GenSchemaVersion()\n\tif err != nil {\n\t\treturn 0, errors.Trace(err)\n\t}\n\tdiff := &model.SchemaDiff{\n\t\tVersion:  schemaVersion,\n\t\tType:     job.Type,\n\t\tSchemaID: job.SchemaID,\n\t}\n\tif job.Type == model.ActionTruncateTable {\n\t\t// Truncate table has two table ID, should be handled differently.\n\t\terr = job.DecodeArgs(&diff.TableID)\n\t\tif err != nil {\n\t\t\treturn 0, errors.Trace(err)\n\t\t}\n\t\tdiff.OldTableID = job.TableID\n\t} else if job.Type == model.ActionRenameTable {\n\t\terr = job.DecodeArgs(&diff.OldSchemaID)\n\t\tif err != nil {\n\t\t\treturn 0, errors.Trace(err)\n\t\t}\n\t\tdiff.TableID = job.TableID\n\t} else {\n\t\tdiff.TableID = job.TableID\n\t}\n\terr = t.SetSchemaDiff(diff)\n\treturn schemaVersion, errors.Trace(err)\n}"}, {"instruction": "// Login is used to exchange auth method credentials for a newly-minted Consul Token.", "input": "go language", "output": "func (a *ACL) Login(auth *ACLLoginParams, q *WriteOptions) (*ACLToken, *WriteMeta, error) {\n\tr := a.c.newRequest(\"POST\", \"/v1/acl/login\")\n\tr.setWriteOptions(q)\n\tr.obj = auth\n\n\trtt, resp, err := requireOK(a.c.doRequest(r))\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\twm := &WriteMeta{RequestTime: rtt}\n\tvar out ACLToken\n\tif err := decodeBody(resp, &out); err != nil {\n\t\treturn nil, nil, err\n\t}\n\treturn &out, wm, nil\n}"}, {"instruction": "// Commit implements the function in the interface `Store`", "input": "go language", "output": "func (s *store) Commit() error {\n\tif !s.batchPending {\n\t\treturn &ErrIllegalCall{\"No pending batch to commit\"}\n\t}\n\tcommittingBlockNum := s.nextBlockNum()\n\tlogger.Debugf(\"Committing private data for block [%d]\", committingBlockNum)\n\tbatch := leveldbhelper.NewUpdateBatch()\n\tbatch.Delete(pendingCommitKey)\n\tbatch.Put(lastCommittedBlkkey, encodeLastCommittedBlockVal(committingBlockNum))\n\tif err := s.db.WriteBatch(batch, true); err != nil {\n\t\treturn err\n\t}\n\ts.batchPending = false\n\ts.isEmpty = false\n\ts.lastCommittedBlock = committingBlockNum\n\tlogger.Debugf(\"Committed private data for block [%d]\", committingBlockNum)\n\ts.performPurgeIfScheduled(committingBlockNum)\n\treturn nil\n}"}, {"instruction": "// Register registers a plugin", "input": "go language", "output": "func Register(plugins *admission.Plugins) {\n\tplugins.Register(PluginName, func(config io.Reader) (admission.Interface, error) {\n\t\t// the pods/status endpoint is ignored by this plugin since old kubelets\n\t\t// corrupt them.  the pod status strategy ensures status updates cannot mutate\n\t\t// ownerRef.\n\t\twhiteList := []whiteListItem{\n\t\t\t{\n\t\t\t\tgroupResource: schema.GroupResource{Resource: \"pods\"},\n\t\t\t\tsubresource:   \"status\",\n\t\t\t},\n\t\t}\n\t\treturn &gcPermissionsEnforcement{\n\t\t\tHandler:   admission.NewHandler(admission.Create, admission.Update),\n\t\t\twhiteList: whiteList,\n\t\t}, nil\n\t})\n}"}, {"instruction": "// getSessionVarsWaitTimeout get session variable wait_timeout", "input": "go language", "output": "func (cc *clientConn) getSessionVarsWaitTimeout(ctx context.Context) uint64 {\n\tvalStr, exists := cc.ctx.GetSessionVars().GetSystemVar(variable.WaitTimeout)\n\tif !exists {\n\t\treturn variable.DefWaitTimeout\n\t}\n\twaitTimeout, err := strconv.ParseUint(valStr, 10, 64)\n\tif err != nil {\n\t\tlogutil.Logger(ctx).Warn(\"get sysval wait_timeout error, use default value\", zap.Error(err))\n\t\t// if get waitTimeout error, use default value\n\t\treturn variable.DefWaitTimeout\n\t}\n\treturn waitTimeout\n}"}, {"instruction": "// ComputeV2MetadataHMACKey returns a key for the given \"authConfig\" that can be used to hash v2 metadata\n// entries.", "input": "go language", "output": "func ComputeV2MetadataHMACKey(authConfig *types.AuthConfig) ([]byte, error) {\n\tif authConfig == nil {\n\t\treturn nil, nil\n\t}\n\tkey := authConfigKeyInput{\n\t\tUsername:      authConfig.Username,\n\t\tPassword:      authConfig.Password,\n\t\tAuth:          authConfig.Auth,\n\t\tIdentityToken: authConfig.IdentityToken,\n\t\tRegistryToken: authConfig.RegistryToken,\n\t}\n\tbuf, err := json.Marshal(&key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn []byte(digest.FromBytes(buf)), nil\n}"}, {"instruction": "// ValidateContainerStateTransition test to if any illegal container state transitions are being attempted", "input": "go language", "output": "func ValidateContainerStateTransition(newStatuses, oldStatuses []core.ContainerStatus, fldpath *field.Path, restartPolicy core.RestartPolicy) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\t// If we should always restart, containers are allowed to leave the terminated state\n\tif restartPolicy == core.RestartPolicyAlways {\n\t\treturn allErrs\n\t}\n\tfor i, oldStatus := range oldStatuses {\n\t\t// Skip any container that is not terminated\n\t\tif oldStatus.State.Terminated == nil {\n\t\t\tcontinue\n\t\t}\n\t\t// Skip any container that failed but is allowed to restart\n\t\tif oldStatus.State.Terminated.ExitCode != 0 && restartPolicy == core.RestartPolicyOnFailure {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, newStatus := range newStatuses {\n\t\t\tif oldStatus.Name == newStatus.Name && newStatus.State.Terminated == nil {\n\t\t\t\tallErrs = append(allErrs, field.Forbidden(fldpath.Index(i).Child(\"state\"), \"may not be transitioned to non-terminated state\"))\n\t\t\t}\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// dial establishes the gRPC communication with the registered device plugin. https://godoc.org/google.golang.org/grpc#Dial", "input": "go language", "output": "func dial(unixSocketPath string) (pluginapi.DevicePluginClient, *grpc.ClientConn, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\n\tc, err := grpc.DialContext(ctx, unixSocketPath, grpc.WithInsecure(), grpc.WithBlock(),\n\t\tgrpc.WithDialer(func(addr string, timeout time.Duration) (net.Conn, error) {\n\t\t\treturn net.DialTimeout(\"unix\", addr, timeout)\n\t\t}),\n\t)\n\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(errFailedToDialDevicePlugin+\" %v\", err)\n\t}\n\n\treturn pluginapi.NewDevicePluginClient(c), c, nil\n}"}, {"instruction": "// GetSubresourcesForVersion returns the subresources for given version or nil.", "input": "go language", "output": "func GetSubresourcesForVersion(crd *CustomResourceDefinition, version string) (*CustomResourceSubresources, error) {\n\tif !HasPerVersionSubresources(crd.Spec.Versions) {\n\t\treturn crd.Spec.Subresources, nil\n\t}\n\tif crd.Spec.Subresources != nil {\n\t\treturn nil, fmt.Errorf(\"malformed CustomResourceDefinition %s version %s: top-level and per-version subresources must be mutual exclusive\", crd.Name, version)\n\t}\n\tfor _, v := range crd.Spec.Versions {\n\t\tif version == v.Name {\n\t\t\treturn v.Subresources, nil\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"version %s not found in CustomResourceDefinition: %v\", version, crd.Name)\n}"}, {"instruction": "// NodeService is used to retrieve a specific service associated with the given\n// node.", "input": "go language", "output": "func (s *Store) NodeService(nodeName string, serviceID string) (uint64, *structs.NodeService, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, \"services\")\n\n\t// Query the service\n\tservice, err := s.getNodeServiceTxn(tx, nodeName, serviceID)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed querying service for node %q: %s\", nodeName, err)\n\t}\n\n\treturn idx, service, nil\n}"}, {"instruction": "// Heap returns a pprof heap dump", "input": "go language", "output": "func (d *Debug) Heap() ([]byte, error) {\n\tr := d.c.newRequest(\"GET\", \"/debug/pprof/heap\")\n\t_, resp, err := d.c.doRequest(r)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error making request: %s\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// We return a raw response because we're just passing through a response\n\t// from the pprof handlers\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error decoding body: %s\", err)\n\t}\n\n\treturn body, nil\n}"}, {"instruction": "// SwarmUpdate updates the swarm.", "input": "go language", "output": "func (cli *Client) SwarmUpdate(ctx context.Context, version swarm.Version, swarm swarm.Spec, flags swarm.UpdateFlags) error {\n\tquery := url.Values{}\n\tquery.Set(\"version\", strconv.FormatUint(version.Index, 10))\n\tquery.Set(\"rotateWorkerToken\", fmt.Sprintf(\"%v\", flags.RotateWorkerToken))\n\tquery.Set(\"rotateManagerToken\", fmt.Sprintf(\"%v\", flags.RotateManagerToken))\n\tquery.Set(\"rotateManagerUnlockKey\", fmt.Sprintf(\"%v\", flags.RotateManagerUnlockKey))\n\tresp, err := cli.post(ctx, \"/swarm/update\", query, swarm, nil)\n\tensureReaderClosed(resp)\n\treturn err\n}"}, {"instruction": "// The LB needs to be configured with instance addresses on the same\n// subnet as the LB (aka opts.SubnetID).  Currently we're just\n// guessing that the node's InternalIP is the right address.\n// In case no InternalIP can be found, ExternalIP is tried.\n// If neither InternalIP nor ExternalIP can be found an error is\n// returned.", "input": "go language", "output": "func nodeAddressForLB(node *v1.Node) (string, error) {\n\taddrs := node.Status.Addresses\n\tif len(addrs) == 0 {\n\t\treturn \"\", ErrNoAddressFound\n\t}\n\n\tallowedAddrTypes := []v1.NodeAddressType{v1.NodeInternalIP, v1.NodeExternalIP}\n\n\tfor _, allowedAddrType := range allowedAddrTypes {\n\t\tfor _, addr := range addrs {\n\t\t\tif addr.Type == allowedAddrType {\n\t\t\t\treturn addr.Address, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn \"\", ErrNoAddressFound\n}"}, {"instruction": "// ClientIP implements a best effort algorithm to return the real client IP, it parses\n// X-Real-IP and X-Forwarded-For in order to work properly with reverse-proxies such us: nginx or haproxy.\n// Use X-Forwarded-For before X-Real-Ip as nginx uses X-Real-Ip with the proxy's IP.", "input": "go language", "output": "func (c *Context) ClientIP() string {\n\tif c.engine.ForwardedByClientIP {\n\t\tclientIP := c.requestHeader(\"X-Forwarded-For\")\n\t\tclientIP = strings.TrimSpace(strings.Split(clientIP, \",\")[0])\n\t\tif clientIP == \"\" {\n\t\t\tclientIP = strings.TrimSpace(c.requestHeader(\"X-Real-Ip\"))\n\t\t}\n\t\tif clientIP != \"\" {\n\t\t\treturn clientIP\n\t\t}\n\t}\n\n\tif c.engine.AppEngine {\n\t\tif addr := c.requestHeader(\"X-Appengine-Remote-Addr\"); addr != \"\" {\n\t\t\treturn addr\n\t\t}\n\t}\n\n\tif ip, _, err := net.SplitHostPort(strings.TrimSpace(c.Request.RemoteAddr)); err == nil {\n\t\treturn ip\n\t}\n\n\treturn \"\"\n}"}, {"instruction": "// GetSortedMapValues returns a sorted map previously filled with SetInMap.", "input": "go language", "output": "func (c *Scratch) GetSortedMapValues(key string) interface{} {\n\tc.mu.RLock()\n\n\tif c.values[key] == nil {\n\t\tc.mu.RUnlock()\n\t\treturn nil\n\t}\n\n\tunsortedMap := c.values[key].(map[string]interface{})\n\tc.mu.RUnlock()\n\tvar keys []string\n\tfor mapKey := range unsortedMap {\n\t\tkeys = append(keys, mapKey)\n\t}\n\n\tsort.Strings(keys)\n\n\tsortedArray := make([]interface{}, len(unsortedMap))\n\tfor i, mapKey := range keys {\n\t\tsortedArray[i] = unsortedMap[mapKey]\n\t}\n\n\treturn sortedArray\n}"}, {"instruction": "// expandOptionalAddrs expands the go-sockaddr template in s and returns the\n// result as a list of strings. If s does not contain a go-sockaddr template,\n// the result list will contain the input string as a single element with no\n// error set. In contrast to expandAddrs, expandOptionalAddrs does not validate\n// if the result contains valid addresses and returns a list of strings.\n// However, if the expansion of the go-sockaddr template fails an error is set.", "input": "go language", "output": "func (b *Builder) expandOptionalAddrs(name string, s *string) []string {\n\tif s == nil || *s == \"\" {\n\t\treturn nil\n\t}\n\n\tx, err := template.Parse(*s)\n\tif err != nil {\n\t\tb.err = multierror.Append(b.err, fmt.Errorf(\"%s: error parsing %q: %s\", name, *s, err))\n\t\treturn nil\n\t}\n\n\tif x != *s {\n\t\t// A template has been expanded, split the results from go-sockaddr\n\t\treturn strings.Fields(x)\n\t} else {\n\t\t// No template has been expanded, pass through the input\n\t\treturn []string{*s}\n\t}\n}"}, {"instruction": "// ValidateSignatureValues verifies whether the signature values are valid with\n// the given chain rules. The v value is assumed to be either 0 or 1.", "input": "go language", "output": "func ValidateSignatureValues(v byte, r, s *big.Int, homestead bool) bool {\n\tif r.Cmp(common.Big1) < 0 || s.Cmp(common.Big1) < 0 {\n\t\treturn false\n\t}\n\t// reject upper range of s values (ECDSA malleability)\n\t// see discussion in secp256k1/libsecp256k1/include/secp256k1.h\n\tif homestead && s.Cmp(secp256k1halfN) > 0 {\n\t\treturn false\n\t}\n\t// Frontier: allow s to be in full N range\n\treturn r.Cmp(secp256k1N) < 0 && s.Cmp(secp256k1N) < 0 && (v == 0 || v == 1)\n}"}, {"instruction": "// Decode unmarshals the raw representation of the instance object being\n// changed. Pass the implied type of the corresponding resource type schema\n// for correct operation.", "input": "go language", "output": "func (rcs *ResourceInstanceChangeSrc) Decode(ty cty.Type) (*ResourceInstanceChange, error) {\n\tchange, err := rcs.ChangeSrc.Decode(ty)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &ResourceInstanceChange{\n\t\tAddr:            rcs.Addr,\n\t\tDeposedKey:      rcs.DeposedKey,\n\t\tProviderAddr:    rcs.ProviderAddr,\n\t\tChange:          *change,\n\t\tRequiredReplace: rcs.RequiredReplace,\n\t\tPrivate:         rcs.Private,\n\t}, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *GenericControllerManagerConfiguration) DeepCopyInto(out *GenericControllerManagerConfiguration) {\n\t*out = *in\n\tout.MinResyncPeriod = in.MinResyncPeriod\n\tout.ClientConnection = in.ClientConnection\n\tout.ControllerStartInterval = in.ControllerStartInterval\n\tin.LeaderElection.DeepCopyInto(&out.LeaderElection)\n\tif in.Controllers != nil {\n\t\tin, out := &in.Controllers, &out.Controllers\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tout.Debugging = in.Debugging\n\treturn\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of DaemonSets that match those selectors.", "input": "go language", "output": "func (c *FakeDaemonSets) List(opts v1.ListOptions) (result *v1beta2.DaemonSetList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(daemonsetsResource, daemonsetsKind, c.ns, opts), &v1beta2.DaemonSetList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta2.DaemonSetList{ListMeta: obj.(*v1beta2.DaemonSetList).ListMeta}\n\tfor _, item := range obj.(*v1beta2.DaemonSetList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// RunCompletion checks given arguments and executes command", "input": "go language", "output": "func RunCompletion(out io.Writer, boilerPlate string, cmd *cobra.Command, args []string) error {\n\tif length := len(args); length == 0 {\n\t\treturn errors.New(\"shell not specified\")\n\t} else if length > 1 {\n\t\treturn errors.New(\"too many arguments. expected only the shell type\")\n\t}\n\trun, found := completionShells[args[0]]\n\tif !found {\n\t\treturn errors.Errorf(\"unsupported shell type %q\", args[0])\n\t}\n\n\tif len(boilerPlate) == 0 {\n\t\tboilerPlate = defaultBoilerPlate\n\t}\n\tif _, err := out.Write([]byte(boilerPlate)); err != nil {\n\t\treturn err\n\t}\n\treturn run(out, cmd.Parent())\n}"}, {"instruction": "// neighbourhoodRadiusForPot returns the neighbourhood radius of the kademlia\n// neighbourhood radius encloses the nearest neighbour set with size >= neighbourhoodSize\n// i.e., neighbourhood radius is the deepest PO such that all bins not shallower altogether\n// contain at least neighbourhoodSize connected peers\n// if there is altogether less than neighbourhoodSize peers connected, it returns 0\n// caller must hold the lock", "input": "go language", "output": "func neighbourhoodRadiusForPot(p *pot.Pot, neighbourhoodSize int, pivotAddr []byte) (depth int) {\n\tif p.Size() <= neighbourhoodSize {\n\t\treturn 0\n\t}\n\t// total number of peers in iteration\n\tvar size int\n\tf := func(v pot.Val, i int) bool {\n\t\t// po == 256 means that addr is the pivot address(self)\n\t\tif i == 256 {\n\t\t\treturn true\n\t\t}\n\t\tsize++\n\n\t\t// this means we have all nn-peers.\n\t\t// depth is by default set to the bin of the farthest nn-peer\n\t\tif size == neighbourhoodSize {\n\t\t\tdepth = i\n\t\t\treturn false\n\t\t}\n\n\t\treturn true\n\t}\n\tp.EachNeighbour(pivotAddr, Pof, f)\n\treturn depth\n}"}, {"instruction": "// IgnoreFile returns whether a given file should be ignored.", "input": "go language", "output": "func (s *SourceSpec) IgnoreFile(filename string) bool {\n\tif filename == \"\" {\n\t\tif _, ok := s.SourceFs.(*afero.OsFs); ok {\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n\n\tbase := filepath.Base(filename)\n\n\tif len(base) > 0 {\n\t\tfirst := base[0]\n\t\tlast := base[len(base)-1]\n\t\tif first == '.' ||\n\t\t\tfirst == '#' ||\n\t\t\tlast == '~' {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif len(s.ignoreFilesRe) == 0 {\n\t\treturn false\n\t}\n\n\tfor _, re := range s.ignoreFilesRe {\n\t\tif re.MatchString(filename) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *RevokeExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\tif e.done {\n\t\treturn nil\n\t}\n\te.done = true\n\n\t// Revoke for each user.\n\tfor _, user := range e.Users {\n\t\t// Check if user exists.\n\t\texists, err := userExists(e.ctx, user.User.Username, user.User.Hostname)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !exists {\n\t\t\treturn errors.Errorf(\"Unknown user: %s\", user.User)\n\t\t}\n\n\t\terr = e.revokeOneUser(user.User.Username, user.User.Hostname)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tdomain.GetDomain(e.ctx).NotifyUpdatePrivilege(e.ctx)\n\treturn nil\n}"}, {"instruction": "// getAllReplicaSetsAndSyncRevision returns all the replica sets for the provided deployment (new and all old), with new RS's and deployment's revision updated.\n//\n// rsList should come from getReplicaSetsForDeployment(d).\n//\n// 1. Get all old RSes this deployment targets, and calculate the max revision number among them (maxOldV).\n// 2. Get new RS this deployment targets (whose pod template matches deployment's), and update new RS's revision number to (maxOldV + 1),\n//    only if its revision number is smaller than (maxOldV + 1). If this step failed, we'll update it in the next deployment sync loop.\n// 3. Copy new RS's revision number to deployment (update deployment's revision). If this step failed, we'll update it in the next deployment sync loop.\n//\n// Note that currently the deployment controller is using caches to avoid querying the server for reads.\n// This may lead to stale reads of replica sets, thus incorrect deployment status.", "input": "go language", "output": "func (dc *DeploymentController) getAllReplicaSetsAndSyncRevision(d *apps.Deployment, rsList []*apps.ReplicaSet, createIfNotExisted bool) (*apps.ReplicaSet, []*apps.ReplicaSet, error) {\n\t_, allOldRSs := deploymentutil.FindOldReplicaSets(d, rsList)\n\n\t// Get new replica set with the updated revision number\n\tnewRS, err := dc.getNewReplicaSet(d, rsList, allOldRSs, createIfNotExisted)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn newRS, allOldRSs, nil\n}"}, {"instruction": "// incGCSizeInBatch changes gcSize field value\n// by change which can be negative. This function\n// must be called under batchMu lock.", "input": "go language", "output": "func (db *DB) incGCSizeInBatch(batch *leveldb.Batch, change int64) (err error) {\n\tif change == 0 {\n\t\treturn nil\n\t}\n\tgcSize, err := db.gcSize.Get()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar new uint64\n\tif change > 0 {\n\t\tnew = gcSize + uint64(change)\n\t} else {\n\t\t// 'change' is an int64 and is negative\n\t\t// a conversion is needed with correct sign\n\t\tc := uint64(-change)\n\t\tif c > gcSize {\n\t\t\t// protect uint64 undeflow\n\t\t\treturn nil\n\t\t}\n\t\tnew = gcSize - c\n\t}\n\tdb.gcSize.PutInBatch(batch, new)\n\n\t// trigger garbage collection if we reached the capacity\n\tif new >= db.capacity {\n\t\tdb.triggerGarbageCollection()\n\t}\n\treturn nil\n}"}, {"instruction": "// hasCorrectIssuer returns true if tokenData is a valid JWT in compact\n// serialization format and the \"iss\" claim matches the iss field of this token\n// authenticator, and otherwise returns false.\n//\n// Note: go-jose currently does not allow access to unverified JWS payloads.\n// See https://github.com/square/go-jose/issues/169", "input": "go language", "output": "func (j *jwtTokenAuthenticator) hasCorrectIssuer(tokenData string) bool {\n\tparts := strings.Split(tokenData, \".\")\n\tif len(parts) != 3 {\n\t\treturn false\n\t}\n\tpayload, err := base64.RawURLEncoding.DecodeString(parts[1])\n\tif err != nil {\n\t\treturn false\n\t}\n\tclaims := struct {\n\t\t// WARNING: this JWT is not verified. Do not trust these claims.\n\t\tIssuer string `json:\"iss\"`\n\t}{}\n\tif err := json.Unmarshal(payload, &claims); err != nil {\n\t\treturn false\n\t}\n\tif claims.Issuer != j.iss {\n\t\treturn false\n\t}\n\treturn true\n\n}"}, {"instruction": "// Stream opens a protocol streamer to the server and streams until a client closes\n// the connection or the server disconnects.", "input": "go language", "output": "func (e *streamExecutor) Stream(options StreamOptions) error {\n\treq, err := http.NewRequest(e.method, e.url.String(), nil)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error creating request: %v\", err)\n\t}\n\n\tconn, protocol, err := spdy.Negotiate(\n\t\te.upgrader,\n\t\t&http.Client{Transport: e.transport},\n\t\treq,\n\t\te.protocols...,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer conn.Close()\n\n\tvar streamer streamProtocolHandler\n\n\tswitch protocol {\n\tcase remotecommand.StreamProtocolV4Name:\n\t\tstreamer = newStreamProtocolV4(options)\n\tcase remotecommand.StreamProtocolV3Name:\n\t\tstreamer = newStreamProtocolV3(options)\n\tcase remotecommand.StreamProtocolV2Name:\n\t\tstreamer = newStreamProtocolV2(options)\n\tcase \"\":\n\t\tklog.V(4).Infof(\"The server did not negotiate a streaming protocol version. Falling back to %s\", remotecommand.StreamProtocolV1Name)\n\t\tfallthrough\n\tcase remotecommand.StreamProtocolV1Name:\n\t\tstreamer = newStreamProtocolV1(options)\n\t}\n\n\treturn streamer.stream(conn)\n}"}, {"instruction": "// Admit makes an admission decision based on the request attributes", "input": "go language", "output": "func (a *AlwaysPullImages) Admit(attributes admission.Attributes, o admission.ObjectInterfaces) (err error) {\n\t// Ignore all calls to subresources or resources other than pods.\n\tif shouldIgnore(attributes) {\n\t\treturn nil\n\t}\n\tpod, ok := attributes.GetObject().(*api.Pod)\n\tif !ok {\n\t\treturn apierrors.NewBadRequest(\"Resource was marked with kind Pod but was unable to be converted\")\n\t}\n\n\tfor i := range pod.Spec.InitContainers {\n\t\tpod.Spec.InitContainers[i].ImagePullPolicy = api.PullAlways\n\t}\n\n\tfor i := range pod.Spec.Containers {\n\t\tpod.Spec.Containers[i].ImagePullPolicy = api.PullAlways\n\t}\n\n\treturn nil\n}"}, {"instruction": "// ValidateNetworking validates networking configuration", "input": "go language", "output": "func ValidateNetworking(c *kubeadm.Networking, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tallErrs = append(allErrs, apivalidation.ValidateDNS1123Subdomain(c.DNSDomain, field.NewPath(\"dnsDomain\"))...)\n\tallErrs = append(allErrs, ValidateIPNetFromString(c.ServiceSubnet, constants.MinimumAddressesInServiceSubnet, field.NewPath(\"serviceSubnet\"))...)\n\tif len(c.PodSubnet) != 0 {\n\t\tallErrs = append(allErrs, ValidateIPNetFromString(c.PodSubnet, constants.MinimumAddressesInServiceSubnet, field.NewPath(\"podSubnet\"))...)\n\t}\n\treturn allErrs\n}"}, {"instruction": "// doCleanupMountPoint unmounts the given path and\n// deletes the remaining directory if successful.\n// if extensiveMountPointCheck is true\n// IsNotMountPoint will be called instead of IsLikelyNotMountPoint.\n// IsNotMountPoint is more expensive but properly handles bind mounts within the same fs.\n// if corruptedMnt is true, it means that the mountPath is a corrupted mountpoint, and the mount point check\n// will be skipped", "input": "go language", "output": "func doCleanupMountPoint(mountPath string, mounter Interface, extensiveMountPointCheck bool, corruptedMnt bool) error {\n\tif !corruptedMnt {\n\t\tvar notMnt bool\n\t\tvar err error\n\t\tif extensiveMountPointCheck {\n\t\t\tnotMnt, err = IsNotMountPoint(mounter, mountPath)\n\t\t} else {\n\t\t\tnotMnt, err = mounter.IsLikelyNotMountPoint(mountPath)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif notMnt {\n\t\t\tklog.Warningf(\"Warning: %q is not a mountpoint, deleting\", mountPath)\n\t\t\treturn os.Remove(mountPath)\n\t\t}\n\t}\n\n\t// Unmount the mount path\n\tklog.V(4).Infof(\"%q is a mountpoint, unmounting\", mountPath)\n\tif err := mounter.Unmount(mountPath); err != nil {\n\t\treturn err\n\t}\n\n\tnotMnt, mntErr := mounter.IsLikelyNotMountPoint(mountPath)\n\tif mntErr != nil {\n\t\treturn mntErr\n\t}\n\tif notMnt {\n\t\tklog.V(4).Infof(\"%q is unmounted, deleting the directory\", mountPath)\n\t\treturn os.Remove(mountPath)\n\t}\n\treturn fmt.Errorf(\"Failed to unmount path %v\", mountPath)\n}"}, {"instruction": "// This function sets limiters according to corresponding DeviceConfiguration", "input": "go language", "output": "func (lim *limiter) setLimitsLocked(device config.DeviceConfiguration) bool {\n\treadLimiter := lim.getReadLimiterLocked(device.DeviceID)\n\twriteLimiter := lim.getWriteLimiterLocked(device.DeviceID)\n\n\t// limiters for this device are created so we can store previous rates for logging\n\tpreviousReadLimit := readLimiter.Limit()\n\tpreviousWriteLimit := writeLimiter.Limit()\n\tcurrentReadLimit := rate.Limit(device.MaxRecvKbps) * 1024\n\tcurrentWriteLimit := rate.Limit(device.MaxSendKbps) * 1024\n\tif device.MaxSendKbps <= 0 {\n\t\tcurrentWriteLimit = rate.Inf\n\t}\n\tif device.MaxRecvKbps <= 0 {\n\t\tcurrentReadLimit = rate.Inf\n\t}\n\t// Nothing about this device has changed. Start processing next device\n\tif previousWriteLimit == currentWriteLimit && previousReadLimit == currentReadLimit {\n\t\treturn false\n\t}\n\n\treadLimiter.SetLimit(currentReadLimit)\n\twriteLimiter.SetLimit(currentWriteLimit)\n\n\treturn true\n}"}, {"instruction": "// RemoveMember notifies an etcd cluster to remove an existing member", "input": "go language", "output": "func (c *Client) RemoveMember(id uint64) ([]Member, error) {\n\tcli, err := clientv3.New(clientv3.Config{\n\t\tEndpoints:   c.Endpoints,\n\t\tDialTimeout: 30 * time.Second,\n\t\tTLS:         c.TLS,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer cli.Close()\n\n\t// Remove an existing member from the cluster\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tresp, err := cli.MemberRemove(ctx, id)\n\tcancel()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Returns the updated list of etcd members\n\tret := []Member{}\n\tfor _, m := range resp.Members {\n\t\tret = append(ret, Member{Name: m.Name, PeerURL: m.PeerURLs[0]})\n\t}\n\n\treturn ret, nil\n}"}, {"instruction": "// Sender returns the address derived from the signature (V, R, S) using secp256k1\n// elliptic curve and an error if it failed deriving or upon an incorrect\n// signature.\n//\n// Sender may cache the address, allowing it to be used regardless of\n// signing method. The cache is invalidated if the cached signer does\n// not match the signer used in the current call.", "input": "go language", "output": "func Sender(signer Signer, tx *Transaction) (common.Address, error) {\n\tif sc := tx.from.Load(); sc != nil {\n\t\tsigCache := sc.(sigCache)\n\t\t// If the signer used to derive from in a previous\n\t\t// call is not the same as used current, invalidate\n\t\t// the cache.\n\t\tif sigCache.signer.Equal(signer) {\n\t\t\treturn sigCache.from, nil\n\t\t}\n\t}\n\n\taddr, err := signer.Sender(tx)\n\tif err != nil {\n\t\treturn common.Address{}, err\n\t}\n\ttx.from.Store(sigCache{signer: signer, from: addr})\n\treturn addr, nil\n}"}, {"instruction": "// processTTL checks whether a given Job's TTL has expired, and add it to the queue after the TTL is expected to expire\n// if the TTL will expire later.", "input": "go language", "output": "func (tc *Controller) processTTL(job *batch.Job) (expired bool, err error) {\n\t// We don't care about the Jobs that are going to be deleted, or the ones that don't need clean up.\n\tif job.DeletionTimestamp != nil || !needsCleanup(job) {\n\t\treturn false, nil\n\t}\n\n\tnow := tc.clock.Now()\n\tt, err := timeLeft(job, &now)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t// TTL has expired\n\tif *t <= 0 {\n\t\treturn true, nil\n\t}\n\n\ttc.enqueueAfter(job, *t)\n\treturn false, nil\n}"}, {"instruction": "// NewV1Endpoint parses the given address to return a registry endpoint.", "input": "go language", "output": "func NewV1Endpoint(index *registrytypes.IndexInfo, userAgent string, metaHeaders http.Header) (*V1Endpoint, error) {\n\ttlsConfig, err := newTLSConfig(index.Name, index.Secure)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tendpoint, err := newV1EndpointFromStr(GetAuthConfigKey(index), tlsConfig, userAgent, metaHeaders)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := validateEndpoint(endpoint); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn endpoint, nil\n}"}, {"instruction": "// makeProtocols creates protocol descriptors for the given LES versions.", "input": "go language", "output": "func (c *lesCommons) makeProtocols(versions []uint) []p2p.Protocol {\n\tprotos := make([]p2p.Protocol, len(versions))\n\tfor i, version := range versions {\n\t\tversion := version\n\t\tprotos[i] = p2p.Protocol{\n\t\t\tName:     \"les\",\n\t\t\tVersion:  version,\n\t\t\tLength:   ProtocolLengths[version],\n\t\t\tNodeInfo: c.nodeInfo,\n\t\t\tRun: func(p *p2p.Peer, rw p2p.MsgReadWriter) error {\n\t\t\t\treturn c.protocolManager.runPeer(version, p, rw)\n\t\t\t},\n\t\t\tPeerInfo: func(id enode.ID) interface{} {\n\t\t\t\tif p := c.protocolManager.peers.Peer(fmt.Sprintf(\"%x\", id.Bytes())); p != nil {\n\t\t\t\t\treturn p.Info()\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t},\n\t\t}\n\t}\n\treturn protos\n}"}, {"instruction": "// compareHost compares two host string using some special rules, return value 1, 0, -1 means > = <.\n// TODO: Check how MySQL do it exactly, instead of guess its rules.", "input": "go language", "output": "func compareHost(x, y string) int {\n\t// The more-specific, the smaller it is.\n\t// The pattern '%' means \u201cany host\u201d and is least specific.\n\tif y == `%` {\n\t\tif x == `%` {\n\t\t\treturn 0\n\t\t}\n\t\treturn -1\n\t}\n\n\t// The empty string '' also means \u201cany host\u201d but sorts after '%'.\n\tif y == \"\" {\n\t\tif x == \"\" {\n\t\t\treturn 0\n\t\t}\n\t\treturn -1\n\t}\n\n\t// One of them end with `%`.\n\txEnd := strings.HasSuffix(x, `%`)\n\tyEnd := strings.HasSuffix(y, `%`)\n\tif xEnd || yEnd {\n\t\tswitch {\n\t\tcase !xEnd && yEnd:\n\t\t\treturn -1\n\t\tcase xEnd && !yEnd:\n\t\t\treturn 1\n\t\tcase xEnd && yEnd:\n\t\t\t// 192.168.199.% smaller than 192.168.%\n\t\t\t// A not very accurate comparison, compare them by length.\n\t\t\tif len(x) > len(y) {\n\t\t\t\treturn -1\n\t\t\t}\n\t\t}\n\t\treturn 0\n\t}\n\n\t// For other case, the order is nondeterministic.\n\tswitch x < y {\n\tcase true:\n\t\treturn -1\n\tcase false:\n\t\treturn 1\n\t}\n\treturn 0\n}"}, {"instruction": "// newLightFetcher creates a new light fetcher", "input": "go language", "output": "func newLightFetcher(pm *ProtocolManager) *lightFetcher {\n\tf := &lightFetcher{\n\t\tpm:             pm,\n\t\tchain:          pm.blockchain.(*light.LightChain),\n\t\todr:            pm.odr,\n\t\tpeers:          make(map[*peer]*fetcherPeerInfo),\n\t\tdeliverChn:     make(chan fetchResponse, 100),\n\t\trequested:      make(map[uint64]fetchRequest),\n\t\ttimeoutChn:     make(chan uint64),\n\t\trequestChn:     make(chan bool, 100),\n\t\tsyncDone:       make(chan *peer),\n\t\tmaxConfirmedTd: big.NewInt(0),\n\t}\n\tpm.peers.notify(f)\n\n\tf.pm.wg.Add(1)\n\tgo f.syncLoop()\n\treturn f\n}"}, {"instruction": "// newManager returns an implementation of cgroups.Manager", "input": "go language", "output": "func (l *libcontainerAdapter) newManager(cgroups *libcontainerconfigs.Cgroup, paths map[string]string) (libcontainercgroups.Manager, error) {\n\tswitch l.cgroupManagerType {\n\tcase libcontainerCgroupfs:\n\t\treturn &cgroupfs.Manager{\n\t\t\tCgroups: cgroups,\n\t\t\tPaths:   paths,\n\t\t}, nil\n\tcase libcontainerSystemd:\n\t\t// this means you asked systemd to manage cgroups, but systemd was not on the host, so all you can do is panic...\n\t\tif !cgroupsystemd.UseSystemd() {\n\t\t\tpanic(\"systemd cgroup manager not available\")\n\t\t}\n\t\treturn &cgroupsystemd.Manager{\n\t\t\tCgroups: cgroups,\n\t\t\tPaths:   paths,\n\t\t}, nil\n\t}\n\treturn nil, fmt.Errorf(\"invalid cgroup manager configuration\")\n}"}, {"instruction": "// WriteError translates a CRI streaming error into an appropriate HTTP response.", "input": "go language", "output": "func WriteError(err error, w http.ResponseWriter) error {\n\tvar status int\n\tswitch grpc.Code(err) {\n\tcase codes.NotFound:\n\t\tstatus = http.StatusNotFound\n\tcase codes.ResourceExhausted:\n\t\t// We only expect to hit this if there is a DoS, so we just wait the full TTL.\n\t\t// If this is ever hit in steady-state operations, consider increasing the maxInFlight requests,\n\t\t// or plumbing through the time to next expiration.\n\t\tw.Header().Set(\"Retry-After\", strconv.Itoa(int(cacheTTL.Seconds())))\n\t\tstatus = http.StatusTooManyRequests\n\tdefault:\n\t\tstatus = http.StatusInternalServerError\n\t}\n\tw.WriteHeader(status)\n\t_, writeErr := w.Write([]byte(err.Error()))\n\treturn writeErr\n}"}, {"instruction": "// Unpack performs the operation hexdata -> Go format", "input": "go language", "output": "func (arguments Arguments) Unpack(v interface{}, data []byte) error {\n\t// make sure the passed value is arguments pointer\n\tif reflect.Ptr != reflect.ValueOf(v).Kind() {\n\t\treturn fmt.Errorf(\"abi: Unpack(non-pointer %T)\", v)\n\t}\n\tmarshalledValues, err := arguments.UnpackValues(data)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif arguments.isTuple() {\n\t\treturn arguments.unpackTuple(v, marshalledValues)\n\t}\n\treturn arguments.unpackAtomic(v, marshalledValues[0])\n}"}, {"instruction": "// resolveInputIPAddr tries to resolve the IP address from the string passed as input\n// - tries to match the string as an interface name, if so returns the IP address associated with it\n// - on failure of previous step tries to parse the string as an IP address itself\n//\t if succeeds returns the IP address", "input": "go language", "output": "func resolveInputIPAddr(input string, isUnspecifiedValid bool) (net.IP, error) {\n\t// Try to see if it is an interface name\n\tinterfaceAddr, err := resolveInterfaceAddr(input)\n\tif err == nil {\n\t\treturn interfaceAddr, nil\n\t}\n\t// String matched interface but there is a potential ambiguity to be resolved\n\tif err != errNoSuchInterface {\n\t\treturn nil, err\n\t}\n\n\t// String is not an interface check if it is a valid IP\n\tif ip := net.ParseIP(input); ip != nil && (isUnspecifiedValid || !ip.IsUnspecified()) {\n\t\treturn ip, nil\n\t}\n\n\t// Not valid IP found\n\treturn nil, errBadNetworkIdentifier\n}"}, {"instruction": "// AuthZResponse authorized and manipulates the response from docker daemon using authZ plugins", "input": "go language", "output": "func (ctx *Ctx) AuthZResponse(rm ResponseModifier, r *http.Request) error {\n\tctx.authReq.ResponseStatusCode = rm.StatusCode()\n\tctx.authReq.ResponseHeaders = headers(rm.Header())\n\n\tif sendBody(ctx.requestURI, rm.Header()) {\n\t\tctx.authReq.ResponseBody = rm.RawBody()\n\t}\n\n\tfor _, plugin := range ctx.plugins {\n\t\tlogrus.Debugf(\"AuthZ response using plugin %s\", plugin.Name())\n\n\t\tauthRes, err := plugin.AuthZResponse(ctx.authReq)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"plugin %s failed with error: %s\", plugin.Name(), err)\n\t\t}\n\n\t\tif !authRes.Allow {\n\t\t\treturn newAuthorizationError(plugin.Name(), authRes.Msg)\n\t\t}\n\t}\n\n\trm.FlushAll()\n\n\treturn nil\n}"}, {"instruction": "// Init initializes information.", "input": "go language", "output": "func Init() {\n\tdriver := tikv.Driver{}\n\tvar err error\n\tstore, err = driver.Open(fmt.Sprintf(\"tikv://%s?cluster=1\", *pdAddr))\n\tterror.MustNil(err)\n\n\tprometheus.MustRegister(txnCounter)\n\tprometheus.MustRegister(txnRolledbackCounter)\n\tprometheus.MustRegister(txnDurations)\n\thttp.Handle(\"/metrics\", prometheus.Handler())\n\n\tgo func() {\n\t\terr1 := http.ListenAndServe(\":9191\", nil)\n\t\tterror.Log(errors.Trace(err1))\n\t}()\n}"}, {"instruction": "// NewPathSpecWithBaseBaseFsProvided creats a new PathSpec from the given filesystems and language.\n// If an existing BaseFs is provided, parts of that is reused.", "input": "go language", "output": "func NewPathSpecWithBaseBaseFsProvided(fs *hugofs.Fs, cfg config.Provider, baseBaseFs *filesystems.BaseFs) (*PathSpec, error) {\n\n\tp, err := paths.New(fs, cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar options []func(*filesystems.BaseFs) error\n\tif baseBaseFs != nil {\n\t\toptions = []func(*filesystems.BaseFs) error{\n\t\t\tfilesystems.WithBaseFs(baseBaseFs),\n\t\t}\n\t}\n\tbfs, err := filesystems.NewBase(p, options...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tps := &PathSpec{\n\t\tPaths:           p,\n\t\tBaseFs:          bfs,\n\t\tFs:              fs,\n\t\tCfg:             cfg,\n\t\tProcessingStats: NewProcessingStats(p.Lang()),\n\t}\n\n\tbasePath := ps.BaseURL.Path()\n\tif basePath != \"\" && basePath != \"/\" {\n\t\tps.BasePath = basePath\n\t}\n\n\treturn ps, nil\n}"}, {"instruction": "// GetMountPoints gives a platform specific transformation to types.MountPoint. Callers must hold a Container lock.", "input": "go language", "output": "func (container *Container) GetMountPoints() []types.MountPoint {\n\tmountPoints := make([]types.MountPoint, 0, len(container.MountPoints))\n\tfor _, m := range container.MountPoints {\n\t\tmountPoints = append(mountPoints, types.MountPoint{\n\t\t\tType:        m.Type,\n\t\t\tName:        m.Name,\n\t\t\tSource:      m.Path(),\n\t\t\tDestination: m.Destination,\n\t\t\tDriver:      m.Driver,\n\t\t\tMode:        m.Mode,\n\t\t\tRW:          m.RW,\n\t\t\tPropagation: m.Propagation,\n\t\t})\n\t}\n\treturn mountPoints\n}"}, {"instruction": "// update executes periodic operations on the peer, including message transmission\n// and expiration.", "input": "go language", "output": "func (peer *Peer) update() {\n\t// Start the tickers for the updates\n\texpire := time.NewTicker(expirationCycle)\n\ttransmit := time.NewTicker(transmissionCycle)\n\n\t// Loop and transmit until termination is requested\n\tfor {\n\t\tselect {\n\t\tcase <-expire.C:\n\t\t\tpeer.expire()\n\n\t\tcase <-transmit.C:\n\t\t\tif err := peer.broadcast(); err != nil {\n\t\t\t\tlog.Trace(\"broadcast failed\", \"reason\", err, \"peer\", peer.ID())\n\t\t\t\treturn\n\t\t\t}\n\n\t\tcase <-peer.quit:\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// setStatus recreates the status of the given HPA, updating the current and\n// desired replicas, as well as the metric statuses", "input": "go language", "output": "func (a *HorizontalController) setStatus(hpa *autoscalingv2.HorizontalPodAutoscaler, currentReplicas, desiredReplicas int32, metricStatuses []autoscalingv2.MetricStatus, rescale bool) {\n\thpa.Status = autoscalingv2.HorizontalPodAutoscalerStatus{\n\t\tCurrentReplicas: currentReplicas,\n\t\tDesiredReplicas: desiredReplicas,\n\t\tLastScaleTime:   hpa.Status.LastScaleTime,\n\t\tCurrentMetrics:  metricStatuses,\n\t\tConditions:      hpa.Status.Conditions,\n\t}\n\n\tif rescale {\n\t\tnow := metav1.NewTime(time.Now())\n\t\thpa.Status.LastScaleTime = &now\n\t}\n}"}, {"instruction": "// NewCommandStartWardleServer provides a CLI handler for 'start master' command\n// with a default WardleServerOptions.", "input": "go language", "output": "func NewCommandStartWardleServer(defaults *WardleServerOptions, stopCh <-chan struct{}) *cobra.Command {\n\to := *defaults\n\tcmd := &cobra.Command{\n\t\tShort: \"Launch a wardle API server\",\n\t\tLong:  \"Launch a wardle API server\",\n\t\tRunE: func(c *cobra.Command, args []string) error {\n\t\t\tif err := o.Complete(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := o.Validate(args); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := o.RunWardleServer(stopCh); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tflags := cmd.Flags()\n\to.RecommendedOptions.AddFlags(flags)\n\tutilfeature.DefaultMutableFeatureGate.AddFlag(flags)\n\n\treturn cmd\n}"}, {"instruction": "// Returns a set of targeted nodes. A targeted node is either addressed\n// directly, address indirectly via its container, or it's a dependency of a\n// targeted node. Destroy mode keeps dependents instead of dependencies.", "input": "go language", "output": "func (t *TargetsTransformer) selectTargetedNodes(g *Graph, addrs []addrs.Targetable) (*dag.Set, error) {\n\ttargetedNodes := new(dag.Set)\n\n\tvertices := g.Vertices()\n\n\tfor _, v := range vertices {\n\t\tif t.nodeIsTarget(v, addrs) {\n\t\t\ttargetedNodes.Add(v)\n\n\t\t\t// We inform nodes that ask about the list of targets - helps for nodes\n\t\t\t// that need to dynamically expand. Note that this only occurs for nodes\n\t\t\t// that are already directly targeted.\n\t\t\tif tn, ok := v.(GraphNodeTargetable); ok {\n\t\t\t\ttn.SetTargets(addrs)\n\t\t\t}\n\n\t\t\tvar deps *dag.Set\n\t\t\tvar err error\n\t\t\tif t.Destroy {\n\t\t\t\tdeps, err = g.Descendents(v)\n\t\t\t} else {\n\t\t\t\tdeps, err = g.Ancestors(v)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tfor _, d := range deps.List() {\n\t\t\t\ttargetedNodes.Add(d)\n\t\t\t}\n\t\t}\n\t}\n\treturn t.addDependencies(targetedNodes, g)\n}"}, {"instruction": "// Connect returns a handler for the pod exec proxy", "input": "go language", "output": "func (r *ExecREST) Connect(ctx context.Context, name string, opts runtime.Object, responder rest.Responder) (http.Handler, error) {\n\texecOpts, ok := opts.(*api.PodExecOptions)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"invalid options object: %#v\", opts)\n\t}\n\tlocation, transport, err := pod.ExecLocation(r.Store, r.KubeletConn, ctx, name, execOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newThrottledUpgradeAwareProxyHandler(location, transport, false, true, true, responder), nil\n}"}, {"instruction": "// ConfirmUsable looks a particular context and determines if that particular part of the config is useable.  There might still be errors in the config,\n// but no errors in the sections requested or referenced.  It does not return early so that it can find as many errors as possible.", "input": "go language", "output": "func ConfirmUsable(config clientcmdapi.Config, passedContextName string) error {\n\tvalidationErrors := make([]error, 0)\n\n\tif clientcmdapi.IsConfigEmpty(&config) {\n\t\treturn newErrConfigurationInvalid([]error{ErrEmptyConfig})\n\t}\n\n\tvar contextName string\n\tif len(passedContextName) != 0 {\n\t\tcontextName = passedContextName\n\t} else {\n\t\tcontextName = config.CurrentContext\n\t}\n\n\tif len(contextName) == 0 {\n\t\treturn ErrNoContext\n\t}\n\n\tcontext, exists := config.Contexts[contextName]\n\tif !exists {\n\t\tvalidationErrors = append(validationErrors, &errContextNotFound{contextName})\n\t}\n\n\tif exists {\n\t\tvalidationErrors = append(validationErrors, validateContext(contextName, *context, config)...)\n\t\tvalidationErrors = append(validationErrors, validateAuthInfo(context.AuthInfo, *config.AuthInfos[context.AuthInfo])...)\n\t\tvalidationErrors = append(validationErrors, validateClusterInfo(context.Cluster, *config.Clusters[context.Cluster])...)\n\t}\n\n\treturn newErrConfigurationInvalid(validationErrors)\n}"}, {"instruction": "// Get the volume and node object from actual state of world\n// This is an internal function and caller should acquire and release the lock\n//\n// Note that this returns disconnected objects, so if you change the volume object you must set it back with\n// `asw.attachedVolumes[volumeName]=volumeObj`.\n//\n// If you change the node object you must use `volumeObj.nodesAttachedTo[nodeName] = nodeObj`\n// This is correct, because if volumeObj is empty this function returns an error, and nodesAttachedTo\n// map is a reference type, and thus mutating the copy changes the original map.", "input": "go language", "output": "func (asw *actualStateOfWorld) getNodeAndVolume(\n\tvolumeName v1.UniqueVolumeName, nodeName types.NodeName) (attachedVolume, nodeAttachedTo, error) {\n\n\tvolumeObj, volumeExists := asw.attachedVolumes[volumeName]\n\tif volumeExists {\n\t\tnodeObj, nodeExists := volumeObj.nodesAttachedTo[nodeName]\n\t\tif nodeExists {\n\t\t\treturn volumeObj, nodeObj, nil\n\t\t}\n\t}\n\n\treturn attachedVolume{}, nodeAttachedTo{}, fmt.Errorf(\"volume %v is no longer attached to the node %q\",\n\t\tvolumeName,\n\t\tnodeName)\n}"}, {"instruction": "// IntrinsicGas computes the 'intrinsic gas' for a message with the given data.", "input": "go language", "output": "func IntrinsicGas(data []byte, contractCreation, homestead bool) (uint64, error) {\n\t// Set the starting gas for the raw transaction\n\tvar gas uint64\n\tif contractCreation && homestead {\n\t\tgas = params.TxGasContractCreation\n\t} else {\n\t\tgas = params.TxGas\n\t}\n\t// Bump the required gas by the amount of transactional data\n\tif len(data) > 0 {\n\t\t// Zero and non-zero bytes are priced differently\n\t\tvar nz uint64\n\t\tfor _, byt := range data {\n\t\t\tif byt != 0 {\n\t\t\t\tnz++\n\t\t\t}\n\t\t}\n\t\t// Make sure we don't exceed uint64 for all data combinations\n\t\tif (math.MaxUint64-gas)/params.TxDataNonZeroGas < nz {\n\t\t\treturn 0, vm.ErrOutOfGas\n\t\t}\n\t\tgas += nz * params.TxDataNonZeroGas\n\n\t\tz := uint64(len(data)) - nz\n\t\tif (math.MaxUint64-gas)/params.TxDataZeroGas < z {\n\t\t\treturn 0, vm.ErrOutOfGas\n\t\t}\n\t\tgas += z * params.TxDataZeroGas\n\t}\n\treturn gas, nil\n}"}, {"instruction": "// GetExec gets the URL the exec will be served from, or nil if the Kubelet will serve it.", "input": "go language", "output": "func (kl *Kubelet) GetExec(podFullName string, podUID types.UID, containerName string, cmd []string, streamOpts remotecommandserver.Options) (*url.URL, error) {\n\tcontainer, err := kl.findContainer(podFullName, podUID, containerName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif container == nil {\n\t\treturn nil, fmt.Errorf(\"container not found (%q)\", containerName)\n\t}\n\treturn kl.streamingRuntime.GetExec(container.ID, cmd, streamOpts.Stdin, streamOpts.Stdout, streamOpts.Stderr, streamOpts.TTY)\n}"}, {"instruction": "// getContext returns the clientcmdapi.Context, or an error if a required context is not found.", "input": "go language", "output": "func (config *DirectClientConfig) getContext() (clientcmdapi.Context, error) {\n\tcontexts := config.config.Contexts\n\tcontextName, required := config.getContextName()\n\n\tmergedContext := clientcmdapi.NewContext()\n\tif configContext, exists := contexts[contextName]; exists {\n\t\tmergo.MergeWithOverwrite(mergedContext, configContext)\n\t} else if required {\n\t\treturn clientcmdapi.Context{}, fmt.Errorf(\"context %q does not exist\", contextName)\n\t}\n\tmergo.MergeWithOverwrite(mergedContext, config.overrides.Context)\n\n\treturn *mergedContext, nil\n}"}, {"instruction": "// handleCall processes method calls.", "input": "go language", "output": "func (h *handler) handleCall(cp *callProc, msg *jsonrpcMessage) *jsonrpcMessage {\n\tif msg.isSubscribe() {\n\t\treturn h.handleSubscribe(cp, msg)\n\t}\n\tvar callb *callback\n\tif msg.isUnsubscribe() {\n\t\tcallb = h.unsubscribeCb\n\t} else {\n\t\tcallb = h.reg.callback(msg.Method)\n\t}\n\tif callb == nil {\n\t\treturn msg.errorResponse(&methodNotFoundError{method: msg.Method})\n\t}\n\targs, err := parsePositionalArguments(msg.Params, callb.argTypes)\n\tif err != nil {\n\t\treturn msg.errorResponse(&invalidParamsError{err.Error()})\n\t}\n\n\treturn h.runMethod(cp.ctx, msg, callb, args)\n}"}, {"instruction": "// UnlockAccount will unlock the account associated with the given address with\n// the given password for duration seconds. If duration is nil it will use a\n// default of 300 seconds. It returns an indication if the account was unlocked.", "input": "go language", "output": "func (s *PrivateAccountAPI) UnlockAccount(ctx context.Context, addr common.Address, password string, duration *uint64) (bool, error) {\n\t// When the API is exposed by external RPC(http, ws etc), unless the user\n\t// explicitly specifies to allow the insecure account unlocking, otherwise\n\t// it is disabled.\n\tif s.b.ExtRPCEnabled() && !s.b.AccountManager().Config().InsecureUnlockAllowed {\n\t\treturn false, errors.New(\"account unlock with HTTP access is forbidden\")\n\t}\n\n\tconst max = uint64(time.Duration(math.MaxInt64) / time.Second)\n\tvar d time.Duration\n\tif duration == nil {\n\t\td = 300 * time.Second\n\t} else if *duration > max {\n\t\treturn false, errors.New(\"unlock duration too large\")\n\t} else {\n\t\td = time.Duration(*duration) * time.Second\n\t}\n\terr := fetchKeystore(s.am).TimedUnlock(accounts.Account{Address: addr}, password, d)\n\tif err != nil {\n\t\tlog.Warn(\"Failed account unlock attempt\", \"address\", addr, \"err\", err)\n\t}\n\treturn err == nil, err\n}"}, {"instruction": "// ServerKeepaliveOptions returns gRPC keepalive options for server.  If\n// opts is nil, the default keepalive options are returned", "input": "go language", "output": "func ServerKeepaliveOptions(ka *KeepaliveOptions) []grpc.ServerOption {\n\t// use default keepalive options if nil\n\tif ka == nil {\n\t\tka = DefaultKeepaliveOptions\n\t}\n\tvar serverOpts []grpc.ServerOption\n\tkap := keepalive.ServerParameters{\n\t\tTime:    ka.ServerInterval,\n\t\tTimeout: ka.ServerTimeout,\n\t}\n\tserverOpts = append(serverOpts, grpc.KeepaliveParams(kap))\n\tkep := keepalive.EnforcementPolicy{\n\t\tMinTime: ka.ServerMinInterval,\n\t\t// allow keepalive w/o rpc\n\t\tPermitWithoutStream: true,\n\t}\n\tserverOpts = append(serverOpts, grpc.KeepaliveEnforcementPolicy(kep))\n\treturn serverOpts\n}"}, {"instruction": "// VerifyByChannel checks that signature is a valid signature of message\n// under a peer's verification key, but also in the context of a specific channel.\n// If the verification succeeded, Verify returns nil meaning no error occurred.\n// If peerIdentity is nil, then the verification fails.", "input": "go language", "output": "func (s *MSPMessageCryptoService) VerifyByChannel(chainID common.ChainID, peerIdentity api.PeerIdentityType, signature, message []byte) error {\n\t// Validate arguments\n\tif len(peerIdentity) == 0 {\n\t\treturn errors.New(\"Invalid Peer Identity. It must be different from nil.\")\n\t}\n\n\t// Get the policy manager for channel chainID\n\tcpm, flag := s.channelPolicyManagerGetter.Manager(string(chainID))\n\tif cpm == nil {\n\t\treturn fmt.Errorf(\"Could not acquire policy manager for channel %s\", string(chainID))\n\t}\n\tmcsLogger.Debugf(\"Got policy manager for channel [%s] with flag [%t]\", string(chainID), flag)\n\n\t// Get channel reader policy\n\tpolicy, flag := cpm.GetPolicy(policies.ChannelApplicationReaders)\n\tmcsLogger.Debugf(\"Got reader policy for channel [%s] with flag [%t]\", string(chainID), flag)\n\n\treturn policy.Evaluate(\n\t\t[]*pcommon.SignedData{{\n\t\t\tData:      message,\n\t\t\tIdentity:  []byte(peerIdentity),\n\t\t\tSignature: signature,\n\t\t}},\n\t)\n}"}, {"instruction": "// compare two variables of the same type, i.e. non complex one, such as TypeList or TypeMap", "input": "go language", "output": "func compareSimpleVariables(a, b ast.Variable) (bool, error) {\n\tif a.Type != b.Type {\n\t\treturn false, fmt.Errorf(\n\t\t\t\"won't compare items of different types %s and %s\",\n\t\t\ta.Type.Printable(), b.Type.Printable())\n\t}\n\tswitch a.Type {\n\tcase ast.TypeString:\n\t\treturn a.Value.(string) == b.Value.(string), nil\n\tdefault:\n\t\treturn false, fmt.Errorf(\n\t\t\t\"can't compare items of type %s\",\n\t\t\ta.Type.Printable())\n\t}\n}"}, {"instruction": "// New creates a function that can be used\n// to inject a script tag for the livereload JavaScript in a HTML document.", "input": "go language", "output": "func New(port int) transform.Transformer {\n\treturn func(ft transform.FromTo) error {\n\t\tb := ft.From().Bytes()\n\t\tendBodyTag := \"</body>\"\n\t\tmatch := []byte(endBodyTag)\n\t\treplaceTemplate := `<script data-no-instant>document.write('<script src=\"/livereload.js?port=%d&mindelay=10\"></' + 'script>')</script>%s`\n\t\treplace := []byte(fmt.Sprintf(replaceTemplate, port, endBodyTag))\n\n\t\tnewcontent := bytes.Replace(b, match, replace, 1)\n\t\tif len(newcontent) == len(b) {\n\t\t\tendBodyTag = \"</BODY>\"\n\t\t\treplace := []byte(fmt.Sprintf(replaceTemplate, port, endBodyTag))\n\t\t\tmatch := []byte(endBodyTag)\n\t\t\tnewcontent = bytes.Replace(b, match, replace, 1)\n\t\t}\n\n\t\tif _, err := ft.To().Write(newcontent); err != nil {\n\t\t\thelpers.DistinctWarnLog.Println(\"Failed to inject LiveReload script:\", err)\n\t\t}\n\t\treturn nil\n\t}\n}"}, {"instruction": "// FillNilSlices sets default value on slices that are still nil.", "input": "go language", "output": "func FillNilSlices(data interface{}) error {\n\ts := reflect.ValueOf(data).Elem()\n\tt := s.Type()\n\n\tfor i := 0; i < s.NumField(); i++ {\n\t\tf := s.Field(i)\n\t\ttag := t.Field(i).Tag\n\n\t\tv := tag.Get(\"default\")\n\t\tif len(v) > 0 {\n\t\t\tswitch f.Interface().(type) {\n\t\t\tcase []string:\n\t\t\t\tif f.IsNil() {\n\t\t\t\t\t// Treat the default as a comma separated slice\n\t\t\t\t\tvs := strings.Split(v, \",\")\n\t\t\t\t\tfor i := range vs {\n\t\t\t\t\t\tvs[i] = strings.TrimSpace(vs[i])\n\t\t\t\t\t}\n\n\t\t\t\t\trv := reflect.MakeSlice(reflect.TypeOf([]string{}), len(vs), len(vs))\n\t\t\t\t\tfor i, v := range vs {\n\t\t\t\t\t\trv.Index(i).SetString(v)\n\t\t\t\t\t}\n\t\t\t\t\tf.Set(rv)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// printPodsMultilineWithIndent prints multiple pods with a user-defined alignment.", "input": "go language", "output": "func printPodsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, pods []corev1.Pod) {\n\tw.Write(LEVEL_0, \"%s%s:%s\", initialIndent, title, innerIndent)\n\n\tif pods == nil || len(pods) == 0 {\n\t\tw.WriteLine(\"<none>\")\n\t\treturn\n\t}\n\n\t// to print pods in the sorted order\n\tsort.Slice(pods, func(i, j int) bool {\n\t\tcmpKey := func(pod corev1.Pod) string {\n\t\t\treturn pod.Name\n\t\t}\n\t\treturn cmpKey(pods[i]) < cmpKey(pods[j])\n\t})\n\n\tfor i, pod := range pods {\n\t\tif i != 0 {\n\t\t\tw.Write(LEVEL_0, \"%s\", initialIndent)\n\t\t\tw.Write(LEVEL_0, \"%s\", innerIndent)\n\t\t}\n\t\tw.Write(LEVEL_0, \"%s\\n\", pod.Name)\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *LimitedResource) DeepCopyInto(out *LimitedResource) {\n\t*out = *in\n\tif in.MatchContains != nil {\n\t\tin, out := &in.MatchContains, &out.MatchContains\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.MatchScopes != nil {\n\t\tin, out := &in.MatchScopes, &out.MatchScopes\n\t\t*out = make([]v1.ScopedResourceSelectorRequirement, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// SetRestarting sets the container state to \"restarting\" without locking.\n// It also sets the container PID to 0.", "input": "go language", "output": "func (s *State) SetRestarting(exitStatus *ExitStatus) {\n\t// we should consider the container running when it is restarting because of\n\t// all the checks in docker around rm/stop/etc\n\ts.Running = true\n\ts.Restarting = true\n\ts.Paused = false\n\ts.Pid = 0\n\ts.FinishedAt = time.Now().UTC()\n\ts.ExitCodeValue = exitStatus.ExitCode\n\ts.OOMKilled = exitStatus.OOMKilled\n\tclose(s.waitStop) // fire waiters for stop\n\ts.waitStop = make(chan struct{})\n}"}, {"instruction": "// Consensus passes the given ConsensusRequest message to the raft.Node instance.", "input": "go language", "output": "func (s *RPC) SendConsensus(destination uint64, msg *orderer.ConsensusRequest) error {\n\tif s.Logger.IsEnabledFor(zapcore.DebugLevel) {\n\t\tdefer s.consensusSent(time.Now(), destination, msg)\n\t}\n\n\tstream, err := s.getOrCreateStream(destination, ConsensusOperation)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq := &orderer.StepRequest{\n\t\tPayload: &orderer.StepRequest_ConsensusRequest{\n\t\t\tConsensusRequest: msg,\n\t\t},\n\t}\n\n\ts.consensusLock.Lock()\n\tdefer s.consensusLock.Unlock()\n\n\terr = stream.Send(req)\n\tif err != nil {\n\t\ts.unMapStream(destination, ConsensusOperation)\n\t}\n\n\treturn err\n}"}, {"instruction": "// RenderResult renders the explain result as specified format.", "input": "go language", "output": "func (e *Explain) RenderResult() error {\n\tif e.StmtPlan == nil {\n\t\treturn nil\n\t}\n\tswitch strings.ToLower(e.Format) {\n\tcase ast.ExplainFormatROW:\n\t\te.explainedPlans = map[int]bool{}\n\t\te.explainPlanInRowFormat(e.StmtPlan.(PhysicalPlan), \"root\", \"\", true)\n\tcase ast.ExplainFormatDOT:\n\t\te.prepareDotInfo(e.StmtPlan.(PhysicalPlan))\n\tdefault:\n\t\treturn errors.Errorf(\"explain format '%s' is not supported now\", e.Format)\n\t}\n\treturn nil\n}"}, {"instruction": "// ACLTokenListExpires lists tokens that are expired as of the provided time.\n// The returned set will be no larger than the max value provided.", "input": "go language", "output": "func (s *Store) ACLTokenListExpired(local bool, asOf time.Time, max int) (structs.ACLTokens, <-chan struct{}, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\titer, err := tx.Get(\"acl-tokens\", s.expiresIndexName(local))\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed acl token listing: %v\", err)\n\t}\n\n\tvar (\n\t\ttokens structs.ACLTokens\n\t\ti      int\n\t)\n\tfor raw := iter.Next(); raw != nil; raw = iter.Next() {\n\t\ttoken := raw.(*structs.ACLToken)\n\t\tif token.ExpirationTime != nil && !token.ExpirationTime.Before(asOf) {\n\t\t\treturn tokens, nil, nil\n\t\t}\n\n\t\ttokens = append(tokens, token)\n\t\ti += 1\n\t\tif i >= max {\n\t\t\treturn tokens, nil, nil\n\t\t}\n\t}\n\n\treturn tokens, iter.WatchCh(), nil\n}"}, {"instruction": "// MarshalJSON marshals type Criteria to a json string", "input": "go language", "output": "func (c Criteria) MarshalJSON() ([]byte, error) {\n\ttype Criteria struct {\n\t\tSymKeyID     string        `json:\"symKeyID\"`\n\t\tPrivateKeyID string        `json:\"privateKeyID\"`\n\t\tSig          hexutil.Bytes `json:\"sig\"`\n\t\tMinPow       float64       `json:\"minPow\"`\n\t\tTopics       []TopicType   `json:\"topics\"`\n\t\tAllowP2P     bool          `json:\"allowP2P\"`\n\t}\n\tvar enc Criteria\n\tenc.SymKeyID = c.SymKeyID\n\tenc.PrivateKeyID = c.PrivateKeyID\n\tenc.Sig = c.Sig\n\tenc.MinPow = c.MinPow\n\tenc.Topics = c.Topics\n\tenc.AllowP2P = c.AllowP2P\n\treturn json.Marshal(&enc)\n}"}, {"instruction": "// LoadMirrors loads mirrors to config, after removing duplicates.\n// Returns an error if mirrors contains an invalid mirror.", "input": "go language", "output": "func (config *serviceConfig) LoadMirrors(mirrors []string) error {\n\tmMap := map[string]struct{}{}\n\tunique := []string{}\n\n\tfor _, mirror := range mirrors {\n\t\tm, err := ValidateMirror(mirror)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, exist := mMap[m]; !exist {\n\t\t\tmMap[m] = struct{}{}\n\t\t\tunique = append(unique, m)\n\t\t}\n\t}\n\n\tconfig.Mirrors = unique\n\n\t// Configure public registry since mirrors may have changed.\n\tconfig.IndexConfigs[IndexName] = &registrytypes.IndexInfo{\n\t\tName:     IndexName,\n\t\tMirrors:  config.Mirrors,\n\t\tSecure:   true,\n\t\tOfficial: true,\n\t}\n\n\treturn nil\n}"}, {"instruction": "// eachListChunk fetches runtimeObject list chunks using this ListPager and invokes fn on each list\n// chunk. If fn returns an error, processing stops and that error is returned. If fn does not return\n// an error, any error encountered while retrieving the list from the server is returned. If the\n// context cancels or times out, the context error is returned. Since the list is retrieved in\n// paginated chunks, an \"Expired\" error (metav1.StatusReasonExpired) may be returned if the\n// pagination list requests exceed the expiration limit of the apiserver being called.", "input": "go language", "output": "func (p *ListPager) eachListChunk(ctx context.Context, options metav1.ListOptions, fn func(obj runtime.Object) error) error {\n\tif options.Limit == 0 {\n\t\toptions.Limit = p.PageSize\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tobj, err := p.PageFn(ctx, options)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm, err := meta.ListAccessor(obj)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"returned object must be a list: %v\", err)\n\t\t}\n\t\tif err := fn(obj); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// if we have no more items, return.\n\t\tif len(m.GetContinue()) == 0 {\n\t\t\treturn nil\n\t\t}\n\t\t// set the next loop up\n\t\toptions.Continue = m.GetContinue()\n\t}\n}"}, {"instruction": "// Start is used to start an HTTP check.\n// The check runs until stop is called", "input": "go language", "output": "func (c *CheckHTTP) Start() {\n\tc.stopLock.Lock()\n\tdefer c.stopLock.Unlock()\n\n\tif c.httpClient == nil {\n\t\t// Create the transport. We disable HTTP Keep-Alive's to prevent\n\t\t// failing checks due to the keepalive interval.\n\t\ttrans := cleanhttp.DefaultTransport()\n\t\ttrans.DisableKeepAlives = true\n\n\t\t// Take on the supplied TLS client config.\n\t\ttrans.TLSClientConfig = c.TLSClientConfig\n\n\t\t// Create the HTTP client.\n\t\tc.httpClient = &http.Client{\n\t\t\tTimeout:   10 * time.Second,\n\t\t\tTransport: trans,\n\t\t}\n\n\t\t// For long (>10s) interval checks the http timeout is 10s, otherwise the\n\t\t// timeout is the interval. This means that a check *should* return\n\t\t// before the next check begins.\n\t\tif c.Timeout > 0 && c.Timeout < c.Interval {\n\t\t\tc.httpClient.Timeout = c.Timeout\n\t\t} else if c.Interval < 10*time.Second {\n\t\t\tc.httpClient.Timeout = c.Interval\n\t\t}\n\t}\n\n\tc.stop = false\n\tc.stopCh = make(chan struct{})\n\tgo c.run()\n}"}, {"instruction": "// pullScannerRoutine aggregates paths to be scanned after pulling. The scan is\n// scheduled once when scanChan is closed (scanning can not happen during pulling).", "input": "go language", "output": "func (f *sendReceiveFolder) pullScannerRoutine(scanChan <-chan string) {\n\ttoBeScanned := make(map[string]struct{})\n\n\tfor path := range scanChan {\n\t\ttoBeScanned[path] = struct{}{}\n\t}\n\n\tif len(toBeScanned) != 0 {\n\t\tscanList := make([]string, 0, len(toBeScanned))\n\t\tfor path := range toBeScanned {\n\t\t\tl.Debugln(f, \"scheduling scan after pulling for\", path)\n\t\t\tscanList = append(scanList, path)\n\t\t}\n\t\tf.Scan(scanList)\n\t}\n}"}, {"instruction": "// CanUpgradeKubelets returns whether an upgrade of any kubelet in the cluster is possible", "input": "go language", "output": "func (u *Upgrade) CanUpgradeKubelets() bool {\n\t// If there are multiple different versions now, an upgrade is possible (even if only for a subset of the nodes)\n\tif len(u.Before.KubeletVersions) > 1 {\n\t\treturn true\n\t}\n\t// Don't report something available for upgrade if we don't know the current state\n\tif len(u.Before.KubeletVersions) == 0 {\n\t\treturn false\n\t}\n\n\t// if the same version number existed both before and after, we don't have to upgrade it\n\t_, sameVersionFound := u.Before.KubeletVersions[u.After.KubeVersion]\n\treturn !sameVersionFound\n}"}, {"instruction": "// Implements p2p.MsgWriter", "input": "go language", "output": "func (prw *PssReadWriter) WriteMsg(msg p2p.Msg) error {\n\tlog.Trace(\"pssrw writemsg\", \"msg\", msg)\n\tif prw.closed {\n\t\treturn fmt.Errorf(\"connection closed\")\n\t}\n\trlpdata := make([]byte, msg.Size)\n\tmsg.Payload.Read(rlpdata)\n\tpmsg, err := rlp.EncodeToBytes(ProtocolMsg{\n\t\tCode:    msg.Code,\n\t\tSize:    msg.Size,\n\t\tPayload: rlpdata,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn prw.sendFunc(prw.key, *prw.topic, pmsg)\n}"}, {"instruction": "// applyLayerHandler parses a diff in the standard layer format from `layer`, and\n// applies it to the directory `dest`. Returns the size in bytes of the\n// contents of the layer.", "input": "go language", "output": "func applyLayerHandler(dest string, layer io.Reader, options *archive.TarOptions, decompress bool) (size int64, err error) {\n\tdest = filepath.Clean(dest)\n\n\t// Ensure it is a Windows-style volume path\n\tdest = longpath.AddPrefix(dest)\n\n\tif decompress {\n\t\tdecompressed, err := archive.DecompressStream(layer)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\tdefer decompressed.Close()\n\n\t\tlayer = decompressed\n\t}\n\n\ttmpDir, err := ioutil.TempDir(os.Getenv(\"temp\"), \"temp-docker-extract\")\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"ApplyLayer failed to create temp-docker-extract under %s. %s\", dest, err)\n\t}\n\n\ts, err := archive.UnpackLayer(dest, layer, nil)\n\tos.RemoveAll(tmpDir)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"ApplyLayer %s failed UnpackLayer to %s: %s\", layer, dest, err)\n\t}\n\n\treturn s, nil\n}"}, {"instruction": "// Snapshots creates snapshots of the services by calling the\n// simulation_snapshot RPC method", "input": "go language", "output": "func (sn *SimNode) Snapshots() (map[string][]byte, error) {\n\tsn.lock.RLock()\n\tservices := make(map[string]node.Service, len(sn.running))\n\tfor name, service := range sn.running {\n\t\tservices[name] = service\n\t}\n\tsn.lock.RUnlock()\n\tif len(services) == 0 {\n\t\treturn nil, errors.New(\"no running services\")\n\t}\n\tsnapshots := make(map[string][]byte)\n\tfor name, service := range services {\n\t\tif s, ok := service.(interface {\n\t\t\tSnapshot() ([]byte, error)\n\t\t}); ok {\n\t\t\tsnap, err := s.Snapshot()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tsnapshots[name] = snap\n\t\t}\n\t}\n\treturn snapshots, nil\n}"}, {"instruction": "// ValidateAvoidPodsInNodeAnnotations tests that the serialized AvoidPods in Node.Annotations has valid data", "input": "go language", "output": "func ValidateAvoidPodsInNodeAnnotations(annotations map[string]string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\tv1Avoids, err := v1helper.GetAvoidPodsFromNodeAnnotations(annotations)\n\tif err != nil {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath.Child(\"AvoidPods\"), core.PreferAvoidPodsAnnotationKey, err.Error()))\n\t\treturn allErrs\n\t}\n\tvar avoids core.AvoidPods\n\tif err := corev1.Convert_v1_AvoidPods_To_core_AvoidPods(&v1Avoids, &avoids, nil); err != nil {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath.Child(\"AvoidPods\"), core.PreferAvoidPodsAnnotationKey, err.Error()))\n\t\treturn allErrs\n\t}\n\n\tif len(avoids.PreferAvoidPods) != 0 {\n\t\tfor i, pa := range avoids.PreferAvoidPods {\n\t\t\tidxPath := fldPath.Child(core.PreferAvoidPodsAnnotationKey).Index(i)\n\t\t\tallErrs = append(allErrs, validatePreferAvoidPodsEntry(pa, idxPath)...)\n\t\t}\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// GetPath returns the path to the user specific mount of a Quobyte volume\n// Returns a path in the format ../user#group@volume", "input": "go language", "output": "func (quobyteVolume *quobyte) GetPath() string {\n\tuser := quobyteVolume.user\n\tif len(user) == 0 {\n\t\tuser = \"root\"\n\t}\n\n\tgroup := quobyteVolume.group\n\tif len(group) == 0 {\n\t\tgroup = \"nfsnobody\"\n\t}\n\n\t// Quobyte has only one mount in the PluginDir where all Volumes are mounted\n\t// The Quobyte client does a fixed-user mapping\n\tpluginDir := quobyteVolume.plugin.host.GetPluginDir(utilstrings.EscapeQualifiedName(quobytePluginName))\n\treturn filepath.Join(pluginDir, fmt.Sprintf(\"%s#%s@%s\", user, group, quobyteVolume.volume))\n}"}, {"instruction": "// ticketsInWindow returns the tickets of a given topic in the registration window.", "input": "go language", "output": "func (s *ticketStore) ticketsInWindow(topic Topic) []ticketRef {\n\t// Sanity check that the topic still exists before operating on it\n\tif s.tickets[topic] == nil {\n\t\tlog.Warn(\"Listing non-existing discovery tickets\", \"topic\", topic)\n\t\treturn nil\n\t}\n\t// Gather all the tickers in the next time window\n\tvar tickets []ticketRef\n\n\tbuckets := s.tickets[topic].buckets\n\tfor idx := timeBucket(0); idx < timeWindow; idx++ {\n\t\ttickets = append(tickets, buckets[s.lastBucketFetched+idx]...)\n\t}\n\tlog.Trace(\"Retrieved discovery registration tickets\", \"topic\", topic, \"from\", s.lastBucketFetched, \"tickets\", len(tickets))\n\treturn tickets\n}"}, {"instruction": "// ToProtoModels builds the proto formatted models from OpenAPI spec", "input": "go language", "output": "func ToProtoModels(openAPISpec *spec.Swagger) (proto.Models, error) {\n\tspecBytes, err := json.MarshalIndent(openAPISpec, \" \", \" \")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar info yaml.MapSlice\n\terr = yaml.Unmarshal(specBytes, &info)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdoc, err := openapi_v2.NewDocument(info, compiler.NewContext(\"$root\", nil))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmodels, err := proto.NewOpenAPIData(doc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn models, nil\n}"}, {"instruction": "// Implementation of EC2.Instances", "input": "go language", "output": "func (s *awsSdkEC2) DescribeInstances(request *ec2.DescribeInstancesInput) ([]*ec2.Instance, error) {\n\t// Instances are paged\n\tresults := []*ec2.Instance{}\n\tvar nextToken *string\n\trequestTime := time.Now()\n\tfor {\n\t\tresponse, err := s.ec2.DescribeInstances(request)\n\t\tif err != nil {\n\t\t\trecordAWSMetric(\"describe_instance\", 0, err)\n\t\t\treturn nil, fmt.Errorf(\"error listing AWS instances: %q\", err)\n\t\t}\n\n\t\tfor _, reservation := range response.Reservations {\n\t\t\tresults = append(results, reservation.Instances...)\n\t\t}\n\n\t\tnextToken = response.NextToken\n\t\tif aws.StringValue(nextToken) == \"\" {\n\t\t\tbreak\n\t\t}\n\t\trequest.NextToken = nextToken\n\t}\n\ttimeTaken := time.Since(requestTime).Seconds()\n\trecordAWSMetric(\"describe_instance\", timeTaken, nil)\n\treturn results, nil\n}"}, {"instruction": "// StartSaveSpan stores the span specified in the passed context for later retrieval\n// The span object but be context value on the key StoreLabelId.\n// It will be stored under the the following string key context.Value(StoreLabelId)|.|context.Value(StoreLabelMeta)", "input": "go language", "output": "func StartSaveSpan(ctx context.Context) context.Context {\n\tif !Enabled {\n\t\treturn ctx\n\t}\n\ttraceId := ctx.Value(StoreLabelId)\n\n\tif traceId != nil {\n\t\ttraceStr := traceId.(string)\n\t\tvar sp opentracing.Span\n\t\tctx, sp = spancontext.StartSpan(\n\t\t\tctx,\n\t\t\ttraceStr,\n\t\t)\n\t\ttraceMeta := ctx.Value(StoreLabelMeta)\n\t\tif traceMeta != nil {\n\t\t\ttraceStr = traceStr + \".\" + traceMeta.(string)\n\t\t}\n\t\tstore.spans.Store(traceStr, sp)\n\t}\n\treturn ctx\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of MutatingWebhookConfigurations that match those selectors.", "input": "go language", "output": "func (c *FakeMutatingWebhookConfigurations) List(opts v1.ListOptions) (result *v1beta1.MutatingWebhookConfigurationList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootListAction(mutatingwebhookconfigurationsResource, mutatingwebhookconfigurationsKind, opts), &v1beta1.MutatingWebhookConfigurationList{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta1.MutatingWebhookConfigurationList{ListMeta: obj.(*v1beta1.MutatingWebhookConfigurationList).ListMeta}\n\tfor _, item := range obj.(*v1beta1.MutatingWebhookConfigurationList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// setupMounts configures the mount points for a container by appending each\n// of the configured mounts on the container to the OCI mount structure\n// which will ultimately be passed into the oci runtime during container creation.\n// It also ensures each of the mounts are lexicographically sorted.\n// BUGBUG TODO Windows containerd. This would be much better if it returned\n// an array of runtime spec mounts, not container mounts. Then no need to\n// do multiple transitions.", "input": "go language", "output": "func (daemon *Daemon) setupMounts(c *container.Container) ([]container.Mount, error) {\n\tvar mnts []container.Mount\n\tfor _, mount := range c.MountPoints { // type is volumemounts.MountPoint\n\t\tif err := daemon.lazyInitializeVolume(c.ID, mount); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ts, err := mount.Setup(c.MountLabel, idtools.Identity{}, nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tmnts = append(mnts, container.Mount{\n\t\t\tSource:      s,\n\t\t\tDestination: mount.Destination,\n\t\t\tWritable:    mount.RW,\n\t\t})\n\t}\n\n\tsort.Sort(mounts(mnts))\n\treturn mnts, nil\n}"}, {"instruction": "// resolveControllerRef returns the controller referenced by a ControllerRef,\n// or nil if the ControllerRef could not be resolved to a matching controller\n// of the correct Kind.", "input": "go language", "output": "func (rsc *ReplicaSetController) resolveControllerRef(namespace string, controllerRef *metav1.OwnerReference) *apps.ReplicaSet {\n\t// We can't look up by UID, so look up by Name and then verify UID.\n\t// Don't even try to look up by Name if it's the wrong Kind.\n\tif controllerRef.Kind != rsc.Kind {\n\t\treturn nil\n\t}\n\trs, err := rsc.rsLister.ReplicaSets(namespace).Get(controllerRef.Name)\n\tif err != nil {\n\t\treturn nil\n\t}\n\tif rs.UID != controllerRef.UID {\n\t\t// The controller we found with this Name is not the same one that the\n\t\t// ControllerRef points to.\n\t\treturn nil\n\t}\n\treturn rs\n}"}, {"instruction": "// Init creates a driver with the given home and the set of options.", "input": "go language", "output": "func Init(home string, options []string, uidMaps, gidMaps []idtools.IDMap) (graphdriver.Driver, error) {\n\tdeviceSet, err := NewDeviceSet(home, true, options, uidMaps, gidMaps)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Driver{\n\t\tDeviceSet: deviceSet,\n\t\thome:      home,\n\t\tuidMaps:   uidMaps,\n\t\tgidMaps:   gidMaps,\n\t\tctr:       graphdriver.NewRefCounter(graphdriver.NewDefaultChecker()),\n\t\tlocker:    locker.New(),\n\t}\n\n\treturn graphdriver.NewNaiveDiffDriver(d, uidMaps, gidMaps), nil\n}"}, {"instruction": "// Patch applies the patch and returns the patched persistentVolumeClaim.", "input": "go language", "output": "func (c *FakePersistentVolumeClaims) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *corev1.PersistentVolumeClaim, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewPatchSubresourceAction(persistentvolumeclaimsResource, c.ns, name, pt, data, subresources...), &corev1.PersistentVolumeClaim{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*corev1.PersistentVolumeClaim), err\n}"}, {"instruction": "// Clone is used to return a new token cloned from an existing one\n//\n// Deprecated: Use TokenClone instead.", "input": "go language", "output": "func (a *ACL) Clone(id string, q *WriteOptions) (string, *WriteMeta, error) {\n\tr := a.c.newRequest(\"PUT\", \"/v1/acl/clone/\"+id)\n\tr.setWriteOptions(q)\n\trtt, resp, err := requireOK(a.c.doRequest(r))\n\tif err != nil {\n\t\treturn \"\", nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\twm := &WriteMeta{RequestTime: rtt}\n\tvar out struct{ ID string }\n\tif err := decodeBody(resp, &out); err != nil {\n\t\treturn \"\", nil, err\n\t}\n\treturn out.ID, wm, nil\n}"}, {"instruction": "// NewDeleteCommandFlags provides default flags and values for use with the \"delete\" command", "input": "go language", "output": "func NewDeleteCommandFlags(usage string) *DeleteFlags {\n\tcascade := true\n\tgracePeriod := -1\n\n\t// setup command defaults\n\tall := false\n\tallNamespaces := false\n\tforce := false\n\tignoreNotFound := false\n\tnow := false\n\toutput := \"\"\n\tlabelSelector := \"\"\n\tfieldSelector := \"\"\n\ttimeout := time.Duration(0)\n\twait := true\n\n\tfilenames := []string{}\n\trecursive := false\n\tkustomize := \"\"\n\n\treturn &DeleteFlags{\n\t\t// Not using helpers.go since it provides function to add '-k' for FileNameOptions, but not FileNameFlags\n\t\tFileNameFlags: &genericclioptions.FileNameFlags{Usage: usage, Filenames: &filenames, Kustomize: &kustomize, Recursive: &recursive},\n\t\tLabelSelector: &labelSelector,\n\t\tFieldSelector: &fieldSelector,\n\n\t\tCascade:     &cascade,\n\t\tGracePeriod: &gracePeriod,\n\n\t\tAll:            &all,\n\t\tAllNamespaces:  &allNamespaces,\n\t\tForce:          &force,\n\t\tIgnoreNotFound: &ignoreNotFound,\n\t\tNow:            &now,\n\t\tTimeout:        &timeout,\n\t\tWait:           &wait,\n\t\tOutput:         &output,\n\t}\n}"}, {"instruction": "// AnonymousClientConfig returns a copy of the given config with all user credentials (cert/key, bearer token, and username/password) and custom transports (WrapTransport, Transport) removed", "input": "go language", "output": "func AnonymousClientConfig(config *Config) *Config {\n\t// copy only known safe fields\n\treturn &Config{\n\t\tHost:          config.Host,\n\t\tAPIPath:       config.APIPath,\n\t\tContentConfig: config.ContentConfig,\n\t\tTLSClientConfig: TLSClientConfig{\n\t\t\tInsecure:   config.Insecure,\n\t\t\tServerName: config.ServerName,\n\t\t\tCAFile:     config.TLSClientConfig.CAFile,\n\t\t\tCAData:     config.TLSClientConfig.CAData,\n\t\t},\n\t\tRateLimiter: config.RateLimiter,\n\t\tUserAgent:   config.UserAgent,\n\t\tQPS:         config.QPS,\n\t\tBurst:       config.Burst,\n\t\tTimeout:     config.Timeout,\n\t\tDial:        config.Dial,\n\t}\n}"}, {"instruction": "// marshalPlanModules iterates over a list of modules to recursively describe\n// the full module tree.", "input": "go language", "output": "func marshalPlanModules(\n\tchanges *plans.Changes,\n\tschemas *terraform.Schemas,\n\tchildModules []addrs.ModuleInstance,\n\tmoduleMap map[string][]addrs.ModuleInstance,\n\tmoduleResourceMap map[string][]addrs.AbsResourceInstance,\n) ([]module, error) {\n\n\tvar ret []module\n\n\tfor _, child := range childModules {\n\t\tmoduleResources := moduleResourceMap[child.String()]\n\t\t// cm for child module, naming things is hard.\n\t\tvar cm module\n\t\t// don't populate the address for the root module\n\t\tif child.String() != \"\" {\n\t\t\tcm.Address = child.String()\n\t\t}\n\t\trs, err := marshalPlanResources(changes, moduleResources, schemas)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcm.Resources = rs\n\n\t\tif len(moduleMap[child.String()]) > 0 {\n\t\t\tmoreChildModules, err := marshalPlanModules(changes, schemas, moduleMap[child.String()], moduleMap, moduleResourceMap)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tcm.ChildModules = moreChildModules\n\t\t}\n\n\t\tret = append(ret, cm)\n\t}\n\n\treturn ret, nil\n}"}, {"instruction": "// SetUnstructuredContent obeys the conventions of List and keeps Items and the items\n// array in sync. If items is not an array of objects in the incoming map, then any\n// mismatched item will be removed.", "input": "go language", "output": "func (obj *UnstructuredList) SetUnstructuredContent(content map[string]interface{}) {\n\tobj.Object = content\n\tif content == nil {\n\t\tobj.Items = nil\n\t\treturn\n\t}\n\titems, ok := obj.Object[\"items\"].([]interface{})\n\tif !ok || items == nil {\n\t\titems = []interface{}{}\n\t}\n\tunstructuredItems := make([]Unstructured, 0, len(items))\n\tnewItems := make([]interface{}, 0, len(items))\n\tfor _, item := range items {\n\t\to, ok := item.(map[string]interface{})\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tunstructuredItems = append(unstructuredItems, Unstructured{Object: o})\n\t\tnewItems = append(newItems, o)\n\t}\n\tobj.Items = unstructuredItems\n\tobj.Object[\"items\"] = newItems\n}"}, {"instruction": "// deposit deposits amount to the chequebook account.\n// The caller must hold lock.", "input": "go language", "output": "func (cb *Chequebook) deposit(amount *big.Int) (string, error) {\n\t// since the amount is variable here, we do not use sessions\n\tdepositTransactor := bind.NewKeyedTransactor(cb.prvKey)\n\tdepositTransactor.Value = amount\n\tchbookRaw := &contract.ChequebookRaw{Contract: cb.contract}\n\ttx, err := chbookRaw.Transfer(depositTransactor)\n\tif err != nil {\n\t\tcb.log.Warn(\"Failed to fund chequebook\", \"amount\", amount, \"balance\", cb.balance, \"target\", cb.buffer, \"err\", err)\n\t\treturn \"\", err\n\t}\n\t// assume that transaction is actually successful, we add the amount to balance right away\n\tcb.balance.Add(cb.balance, amount)\n\tcb.log.Trace(\"Deposited funds to chequebook\", \"amount\", amount, \"balance\", cb.balance, \"target\", cb.buffer)\n\treturn tx.Hash().Hex(), nil\n}"}, {"instruction": "// createCompositeKey and its related functions and consts copied from core/chaincode/shim/chaincode.go", "input": "go language", "output": "func createCompositeKey(objectType string, attributes []string) (string, error) {\n\tif err := validateCompositeKeyAttribute(objectType); err != nil {\n\t\treturn \"\", err\n\t}\n\tck := compositeKeyNamespace + objectType + string(minUnicodeRuneValue)\n\tfor _, att := range attributes {\n\t\tif err := validateCompositeKeyAttribute(att); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tck += att + string(minUnicodeRuneValue)\n\t}\n\treturn ck, nil\n}"}, {"instruction": "// InsertTxn adds a new tombstone.", "input": "go language", "output": "func (g *Graveyard) InsertTxn(tx *memdb.Txn, key string, idx uint64) error {\n\t// Insert the tombstone.\n\tstone := &Tombstone{Key: key, Index: idx}\n\tif err := tx.Insert(\"tombstones\", stone); err != nil {\n\t\treturn fmt.Errorf(\"failed inserting tombstone: %s\", err)\n\t}\n\n\tif err := tx.Insert(\"index\", &IndexEntry{\"tombstones\", idx}); err != nil {\n\t\treturn fmt.Errorf(\"failed updating index: %s\", err)\n\t}\n\n\t// If GC is configured, then we hint that this index requires reaping.\n\tif g.gc != nil {\n\t\ttx.Defer(func() { g.gc.Hint(idx) })\n\t}\n\treturn nil\n}"}, {"instruction": "// Syncing returns false in case the node is currently not syncing with the network. It can be up to date or has not\n// yet received the latest block headers from its pears. In case it is synchronizing:\n// - startingBlock: block number this node started to synchronise from\n// - currentBlock:  block number this node is currently importing\n// - highestBlock:  block number of the highest block header this node has received from peers\n// - pulledStates:  number of state entries processed until now\n// - knownStates:   number of known state entries that still need to be pulled", "input": "go language", "output": "func (s *PublicEthereumAPI) Syncing() (interface{}, error) {\n\tprogress := s.b.Downloader().Progress()\n\n\t// Return not syncing if the synchronisation already completed\n\tif progress.CurrentBlock >= progress.HighestBlock {\n\t\treturn false, nil\n\t}\n\t// Otherwise gather the block sync stats\n\treturn map[string]interface{}{\n\t\t\"startingBlock\": hexutil.Uint64(progress.StartingBlock),\n\t\t\"currentBlock\":  hexutil.Uint64(progress.CurrentBlock),\n\t\t\"highestBlock\":  hexutil.Uint64(progress.HighestBlock),\n\t\t\"pulledStates\":  hexutil.Uint64(progress.PulledStates),\n\t\t\"knownStates\":   hexutil.Uint64(progress.KnownStates),\n\t}, nil\n}"}, {"instruction": "// evalDecimal evals ABS(value).\n// See https://dev.mysql.com/doc/refman/5.7/en/mathematical-functions.html#function_abs", "input": "go language", "output": "func (b *builtinAbsDecSig) evalDecimal(row chunk.Row) (*types.MyDecimal, bool, error) {\n\tval, isNull, err := b.args[0].EvalDecimal(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn nil, isNull, err\n\t}\n\tto := new(types.MyDecimal)\n\tif !val.IsNegative() {\n\t\t*to = *val\n\t} else {\n\t\tif err = types.DecimalSub(new(types.MyDecimal), val, to); err != nil {\n\t\t\treturn nil, true, err\n\t\t}\n\t}\n\treturn to, false, nil\n}"}, {"instruction": "// DeleteVolume uses the cloud entrypoint to delete specified volume", "input": "go language", "output": "func (util *DiskUtil) DeleteVolume(cd *cinderVolumeDeleter) error {\n\tcloud, err := cd.plugin.getCloudProvider()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err = cloud.DeleteVolume(cd.pdName); err != nil {\n\t\t// OpenStack cloud provider returns volume.tryAgainError when necessary,\n\t\t// no handling needed here.\n\t\tklog.V(2).Infof(\"Error deleting cinder volume %s: %v\", cd.pdName, err)\n\t\treturn err\n\t}\n\tklog.V(2).Infof(\"Successfully deleted cinder volume %s\", cd.pdName)\n\treturn nil\n}"}, {"instruction": "// NewRemoteRuntimeService creates a new internalapi.RuntimeService.", "input": "go language", "output": "func NewRemoteRuntimeService(endpoint string, connectionTimeout time.Duration) (internalapi.RuntimeService, error) {\n\tklog.V(3).Infof(\"Connecting to runtime service %s\", endpoint)\n\taddr, dailer, err := util.GetAddressAndDialer(endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), connectionTimeout)\n\tdefer cancel()\n\n\tconn, err := grpc.DialContext(ctx, addr, grpc.WithInsecure(), grpc.WithDialer(dailer), grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxMsgSize)))\n\tif err != nil {\n\t\tklog.Errorf(\"Connect remote runtime %s failed: %v\", addr, err)\n\t\treturn nil, err\n\t}\n\n\treturn &RemoteRuntimeService{\n\t\ttimeout:       connectionTimeout,\n\t\truntimeClient: runtimeapi.NewRuntimeServiceClient(conn),\n\t\tlogReduction:  logreduction.NewLogReduction(identicalErrorDelay),\n\t}, nil\n}"}, {"instruction": "// GetVersion returns the etcd version of the cluster.\n// An error is returned if the version of all endpoints do not match", "input": "go language", "output": "func (c *Client) GetVersion() (string, error) {\n\tvar clusterVersion string\n\n\tversions, err := c.GetClusterVersions()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tfor _, v := range versions {\n\t\tif clusterVersion != \"\" && clusterVersion != v {\n\t\t\treturn \"\", errors.Errorf(\"etcd cluster contains endpoints with mismatched versions: %v\", versions)\n\t\t}\n\t\tclusterVersion = v\n\t}\n\tif clusterVersion == \"\" {\n\t\treturn \"\", errors.New(\"could not determine cluster etcd version\")\n\t}\n\treturn clusterVersion, nil\n}"}, {"instruction": "// ObjectValueID takes a value that is assumed to be an object representation\n// of some resource instance object and attempts to heuristically find an\n// attribute of it that is likely to be a unique identifier in the remote\n// system that it belongs to which will be useful to the user.\n//\n// If such an attribute is found, its name and string value intended for\n// display are returned. Both returned strings are empty if no such attribute\n// exists, in which case the caller should assume that the resource instance\n// address within the Terraform configuration is the best available identifier.\n//\n// This is only a best-effort sort of thing, relying on naming conventions in\n// our resource type schemas. The result is not guaranteed to be unique, but\n// should generally be suitable for display to an end-user anyway.\n//\n// This function will panic if the given value is not of an object type.", "input": "go language", "output": "func ObjectValueID(obj cty.Value) (k, v string) {\n\tif obj.IsNull() || !obj.IsKnown() {\n\t\treturn \"\", \"\"\n\t}\n\n\tatys := obj.Type().AttributeTypes()\n\n\tswitch {\n\n\tcase atys[\"id\"] == cty.String:\n\t\tv := obj.GetAttr(\"id\")\n\t\tif v.IsKnown() && !v.IsNull() {\n\t\t\treturn \"id\", v.AsString()\n\t\t}\n\n\tcase atys[\"name\"] == cty.String:\n\t\t// \"name\" isn't always globally unique, but if there isn't also an\n\t\t// \"id\" then it _often_ is, in practice.\n\t\tv := obj.GetAttr(\"name\")\n\t\tif v.IsKnown() && !v.IsNull() {\n\t\t\treturn \"name\", v.AsString()\n\t\t}\n\t}\n\n\treturn \"\", \"\"\n}"}, {"instruction": "// UpdateAPIServiceSpec updates the api service's OpenAPI spec. It is thread safe.", "input": "go language", "output": "func (s *specAggregator) UpdateAPIServiceSpec(apiServiceName string, spec *spec.Swagger, etag string) error {\n\ts.rwMutex.Lock()\n\tdefer s.rwMutex.Unlock()\n\n\tspecInfo, existingService := s.openAPISpecs[apiServiceName]\n\tif !existingService {\n\t\treturn fmt.Errorf(\"APIService %q does not exists\", apiServiceName)\n\t}\n\n\t// For APIServices (non-local) specs, only merge their /apis/ prefixed endpoint as it is the only paths\n\t// proxy handler delegates.\n\tif specInfo.apiService.Spec.Service != nil {\n\t\tspec = aggregator.FilterSpecByPathsWithoutSideEffects(spec, []string{\"/apis/\"})\n\t}\n\n\treturn s.tryUpdatingServiceSpecs(&openAPISpecInfo{\n\t\tapiService: specInfo.apiService,\n\t\tspec:       spec,\n\t\thandler:    specInfo.handler,\n\t\tetag:       etag,\n\t})\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *KubeProxyConntrackConfiguration) DeepCopyInto(out *KubeProxyConntrackConfiguration) {\n\t*out = *in\n\tif in.Max != nil {\n\t\tin, out := &in.Max, &out.Max\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.MaxPerCore != nil {\n\t\tin, out := &in.MaxPerCore, &out.MaxPerCore\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.Min != nil {\n\t\tin, out := &in.Min, &out.Min\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.TCPEstablishedTimeout != nil {\n\t\tin, out := &in.TCPEstablishedTimeout, &out.TCPEstablishedTimeout\n\t\t*out = new(v1.Duration)\n\t\t**out = **in\n\t}\n\tif in.TCPCloseWaitTimeout != nil {\n\t\tin, out := &in.TCPCloseWaitTimeout, &out.TCPCloseWaitTimeout\n\t\t*out = new(v1.Duration)\n\t\t**out = **in\n\t}\n\treturn\n}"}, {"instruction": "// NewIdentityMapper method, all we need is a reference to a MessageCryptoService", "input": "go language", "output": "func NewIdentityMapper(mcs api.MessageCryptoService, selfIdentity api.PeerIdentityType, onPurge purgeTrigger, sa api.SecurityAdvisor) Mapper {\n\tselfPKIID := mcs.GetPKIidOfCert(selfIdentity)\n\tidMapper := &identityMapperImpl{\n\t\tonPurge:    onPurge,\n\t\tmcs:        mcs,\n\t\tpkiID2Cert: make(map[string]*storedIdentity),\n\t\tstopChan:   make(chan struct{}),\n\t\tselfPKIID:  string(selfPKIID),\n\t\tsa:         sa,\n\t}\n\tif err := idMapper.Put(selfPKIID, selfIdentity); err != nil {\n\t\tpanic(errors.Wrap(err, \"Failed putting our own identity into the identity mapper\"))\n\t}\n\tgo idMapper.periodicalPurgeUnusedIdentities()\n\treturn idMapper\n}"}, {"instruction": "// AddFlags registers flags for a cli", "input": "go language", "output": "func (flags *WaitFlags) AddFlags(cmd *cobra.Command) {\n\tflags.PrintFlags.AddFlags(cmd)\n\tflags.ResourceBuilderFlags.AddFlags(cmd.Flags())\n\n\tcmd.Flags().DurationVar(&flags.Timeout, \"timeout\", flags.Timeout, \"The length of time to wait before giving up.  Zero means check once and don't wait, negative means wait for a week.\")\n\tcmd.Flags().StringVar(&flags.ForCondition, \"for\", flags.ForCondition, \"The condition to wait on: [delete|condition=condition-name].\")\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *VolumeAttachmentStatus) DeepCopyInto(out *VolumeAttachmentStatus) {\n\t*out = *in\n\tif in.AttachmentMetadata != nil {\n\t\tin, out := &in.AttachmentMetadata, &out.AttachmentMetadata\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.AttachError != nil {\n\t\tin, out := &in.AttachError, &out.AttachError\n\t\t*out = new(VolumeError)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.DetachError != nil {\n\t\tin, out := &in.DetachError, &out.DetachError\n\t\t*out = new(VolumeError)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\treturn\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *IndexReaderExecutor) Open(ctx context.Context) error {\n\tvar err error\n\tif e.corColInAccess {\n\t\te.ranges, err = rebuildIndexRanges(e.ctx, e.plans[0].(*plannercore.PhysicalIndexScan), e.idxCols, e.colLens)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tkvRanges, err := distsql.IndexRangesToKVRanges(e.ctx.GetSessionVars().StmtCtx, e.physicalTableID, e.index.ID, e.ranges, e.feedback)\n\tif err != nil {\n\t\te.feedback.Invalidate()\n\t\treturn err\n\t}\n\treturn e.open(ctx, kvRanges)\n}"}, {"instruction": "// MakeFileFunc constructs a function that takes a file path and returns the\n// contents of that file, either directly as a string (where valid UTF-8 is\n// required) or as a string containing base64 bytes.", "input": "go language", "output": "func MakeFileFunc(baseDir string, encBase64 bool) function.Function {\n\treturn function.New(&function.Spec{\n\t\tParams: []function.Parameter{\n\t\t\t{\n\t\t\t\tName: \"path\",\n\t\t\t\tType: cty.String,\n\t\t\t},\n\t\t},\n\t\tType: function.StaticReturnType(cty.String),\n\t\tImpl: func(args []cty.Value, retType cty.Type) (cty.Value, error) {\n\t\t\tpath := args[0].AsString()\n\t\t\tsrc, err := readFileBytes(baseDir, path)\n\t\t\tif err != nil {\n\t\t\t\treturn cty.UnknownVal(cty.String), err\n\t\t\t}\n\n\t\t\tswitch {\n\t\t\tcase encBase64:\n\t\t\t\tenc := base64.StdEncoding.EncodeToString(src)\n\t\t\t\treturn cty.StringVal(enc), nil\n\t\t\tdefault:\n\t\t\t\tif !utf8.Valid(src) {\n\t\t\t\t\treturn cty.UnknownVal(cty.String), fmt.Errorf(\"contents of %s are not valid UTF-8; use the filebase64 function to obtain the Base64 encoded contents or the other file functions (e.g. filemd5, filesha256) to obtain file hashing results instead\", path)\n\t\t\t\t}\n\t\t\t\treturn cty.StringVal(string(src)), nil\n\t\t\t}\n\t\t},\n\t})\n}"}, {"instruction": "// splitNodeItemKey returns the components of a key created by nodeItemKey.", "input": "go language", "output": "func splitNodeItemKey(key []byte) (id ID, ip net.IP, field string) {\n\tid, key = splitNodeKey(key)\n\t// Skip discover root.\n\tif string(key) == dbDiscoverRoot {\n\t\treturn id, nil, \"\"\n\t}\n\tkey = key[len(dbDiscoverRoot)+1:]\n\t// Split out the IP.\n\tip = net.IP(key[:16])\n\tif ip4 := ip.To4(); ip4 != nil {\n\t\tip = ip4\n\t}\n\tkey = key[16+1:]\n\t// Field is the remainder of key.\n\tfield = string(key)\n\treturn id, ip, field\n}"}, {"instruction": "// PatchNodeStatus patches node status.", "input": "go language", "output": "func PatchNodeStatus(c v1core.CoreV1Interface, nodeName types.NodeName, oldNode *v1.Node, newNode *v1.Node) (*v1.Node, []byte, error) {\n\tpatchBytes, err := preparePatchBytesforNodeStatus(nodeName, oldNode, newNode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tupdatedNode, err := c.Nodes().Patch(string(nodeName), types.StrategicMergePatchType, patchBytes, \"status\")\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to patch status %q for node %q: %v\", patchBytes, nodeName, err)\n\t}\n\treturn updatedNode, patchBytes, nil\n}"}, {"instruction": "// RemoveString returns a newly created []string that contains all items from slice that\n// are not equal to s and modifier(s) in case modifier func is provided.", "input": "go language", "output": "func RemoveString(slice []string, s string, modifier func(s string) string) []string {\n\tnewSlice := make([]string, 0)\n\tfor _, item := range slice {\n\t\tif item == s {\n\t\t\tcontinue\n\t\t}\n\t\tif modifier != nil && modifier(item) == s {\n\t\t\tcontinue\n\t\t}\n\t\tnewSlice = append(newSlice, item)\n\t}\n\tif len(newSlice) == 0 {\n\t\t// Sanitize for unit tests so we don't need to distinguish empty array\n\t\t// and nil.\n\t\tnewSlice = nil\n\t}\n\treturn newSlice\n}"}, {"instruction": "// priorityClassPermittedInNamespace returns true if we allow the given priority class name in the\n// given namespace. It currently checks that system priorities are created only in the system namespace.", "input": "go language", "output": "func priorityClassPermittedInNamespace(priorityClassName string, namespace string) bool {\n\t// Only allow system priorities in the system namespace. This is to prevent abuse or incorrect\n\t// usage of these priorities. Pods created at these priorities could preempt system critical\n\t// components.\n\tfor _, spc := range scheduling.SystemPriorityClasses() {\n\t\tif spc.Name == priorityClassName && namespace != metav1.NamespaceSystem {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}"}, {"instruction": "// RunAPIVersions does the work", "input": "go language", "output": "func (o *APIVersionsOptions) RunAPIVersions() error {\n\t// Always request fresh data from the server\n\to.discoveryClient.Invalidate()\n\n\tgroupList, err := o.discoveryClient.ServerGroups()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"couldn't get available api versions from server: %v\", err)\n\t}\n\tapiVersions := metav1.ExtractGroupVersions(groupList)\n\tsort.Strings(apiVersions)\n\tfor _, v := range apiVersions {\n\t\tfmt.Fprintln(o.Out, v)\n\t}\n\treturn nil\n}"}, {"instruction": "// Pack the given method name to conform the ABI. Method call's data\n// will consist of method_id, args0, arg1, ... argN. Method id consists\n// of 4 bytes and arguments are all 32 bytes.\n// Method ids are created from the first 4 bytes of the hash of the\n// methods string signature. (signature = baz(uint32,string32))", "input": "go language", "output": "func (abi ABI) Pack(name string, args ...interface{}) ([]byte, error) {\n\t// Fetch the ABI of the requested method\n\tif name == \"\" {\n\t\t// constructor\n\t\targuments, err := abi.Constructor.Inputs.Pack(args...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn arguments, nil\n\t}\n\tmethod, exist := abi.Methods[name]\n\tif !exist {\n\t\treturn nil, fmt.Errorf(\"method '%s' not found\", name)\n\t}\n\targuments, err := method.Inputs.Pack(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Pack up the method ID too if not a constructor and return\n\treturn append(method.Id(), arguments...), nil\n}"}, {"instruction": "// HandleChain creates/returns a reference to a consensus.Chain object for the\n// given set of support resources. Implements the consensus.Consenter\n// interface. Called by consensus.newChainSupport(), which is itself called by\n// multichannel.NewManagerImpl() when ranging over the ledgerFactory's\n// existingChains.", "input": "go language", "output": "func (consenter *consenterImpl) HandleChain(support consensus.ConsenterSupport, metadata *cb.Metadata) (consensus.Chain, error) {\n\tlastOffsetPersisted, lastOriginalOffsetProcessed, lastResubmittedConfigOffset := getOffsets(metadata.Value, support.ChainID())\n\tch, err := newChain(consenter, support, lastOffsetPersisted, lastOriginalOffsetProcessed, lastResubmittedConfigOffset)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tconsenter.healthChecker.RegisterChecker(ch.channel.String(), ch)\n\treturn ch, nil\n}"}, {"instruction": "// check if message is in the cache", "input": "go language", "output": "func (p *Pss) checkFwdCache(msg *PssMsg) bool {\n\tp.fwdCacheMu.Lock()\n\tdefer p.fwdCacheMu.Unlock()\n\n\tdigest := p.digest(msg)\n\tentry, ok := p.fwdCache[digest]\n\tif ok {\n\t\tif entry.expiresAt.After(time.Now()) {\n\t\t\tlog.Trace(\"unexpired cache\", \"digest\", fmt.Sprintf(\"%x\", digest))\n\t\t\tmetrics.GetOrRegisterCounter(\"pss.checkfwdcache.unexpired\", nil).Inc(1)\n\t\t\treturn true\n\t\t}\n\t\tmetrics.GetOrRegisterCounter(\"pss.checkfwdcache.expired\", nil).Inc(1)\n\t}\n\treturn false\n}"}, {"instruction": "// ReceivedReply adjusts estimated buffer value according to the value included in\n// the latest request reply.", "input": "go language", "output": "func (node *ServerNode) ReceivedReply(reqID, bv uint64) {\n\tnode.lock.Lock()\n\tdefer node.lock.Unlock()\n\n\tnow := node.clock.Now()\n\tnode.recalcBLE(now)\n\tif bv > node.params.BufLimit {\n\t\tbv = node.params.BufLimit\n\t}\n\tsc, ok := node.pending[reqID]\n\tif !ok {\n\t\treturn\n\t}\n\tdelete(node.pending, reqID)\n\tcc := node.sumCost - sc\n\tnewEstimate := uint64(0)\n\tif bv > cc {\n\t\tnewEstimate = bv - cc\n\t}\n\tif newEstimate > node.bufEstimate {\n\t\t// Note: we never reduce the buffer estimate based on the reported value because\n\t\t// this can only happen because of the delayed delivery of the latest reply.\n\t\t// The lowest estimate based on the previous reply can still be considered valid.\n\t\tnode.bufEstimate = newEstimate\n\t}\n\n\tnode.bufRecharge = node.bufEstimate < node.params.BufLimit\n\tnode.lastTime = now\n\tif node.log != nil {\n\t\tnode.log.add(now, fmt.Sprintf(\"received  reqID=%d  bufEst=%d  reportedBv=%d  sumCost=%d  oldSumCost=%d\", reqID, node.bufEstimate, bv, node.sumCost, sc))\n\t}\n}"}, {"instruction": "// resolve retrieves the hostname a service is running on either by returning the\n// actual server name and port, or preferably an nginx virtual host if available.", "input": "go language", "output": "func resolve(client *sshClient, network string, service string, port int) (string, error) {\n\t// Inspect the service to get various configurations from it\n\tinfos, err := inspectContainer(client, fmt.Sprintf(\"%s_%s_1\", network, service))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif !infos.running {\n\t\treturn \"\", ErrServiceOffline\n\t}\n\t// Container online, extract any environmental variables\n\tif vhost := infos.envvars[\"VIRTUAL_HOST\"]; vhost != \"\" {\n\t\treturn vhost, nil\n\t}\n\treturn fmt.Sprintf(\"%s:%d\", client.server, port), nil\n}"}, {"instruction": "// make push instruction function", "input": "go language", "output": "func makePush(size uint64, pushByteSize int) executionFunc {\n\treturn func(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {\n\t\tcodeLen := len(contract.Code)\n\n\t\tstartMin := codeLen\n\t\tif int(*pc+1) < startMin {\n\t\t\tstartMin = int(*pc + 1)\n\t\t}\n\n\t\tendMin := codeLen\n\t\tif startMin+pushByteSize < endMin {\n\t\t\tendMin = startMin + pushByteSize\n\t\t}\n\n\t\tinteger := interpreter.intPool.get()\n\t\tstack.push(integer.SetBytes(common.RightPadBytes(contract.Code[startMin:endMin], pushByteSize)))\n\n\t\t*pc += size\n\t\treturn nil, nil\n\t}\n}"}, {"instruction": "// saves state to a file, caller is responsible for locking", "input": "go language", "output": "func (sf *stateFile) storeState() {\n\tvar content []byte\n\tvar err error\n\n\tdata := stateFileData{\n\t\tPolicyName:    sf.policyName,\n\t\tDefaultCPUSet: sf.cache.GetDefaultCPUSet().String(),\n\t\tEntries:       map[string]string{},\n\t}\n\n\tfor containerID, cset := range sf.cache.GetCPUAssignments() {\n\t\tdata.Entries[containerID] = cset.String()\n\t}\n\n\tif content, err = json.Marshal(data); err != nil {\n\t\tpanic(\"[cpumanager] state file: could not serialize state to json\")\n\t}\n\n\tif err = ioutil.WriteFile(sf.stateFilePath, content, 0644); err != nil {\n\t\tpanic(\"[cpumanager] state file not written\")\n\t}\n\treturn\n}"}, {"instruction": "// getOrInitialize either grabs the configmaps current value or defines the value\n// and sets the configmap. This is for the case of the user calling GetClusterID()\n// before the watch has begun.", "input": "go language", "output": "func (ci *ClusterID) getOrInitialize() error {\n\tif ci.store == nil {\n\t\treturn errors.New(\"Cloud.ClusterID is not ready. Call Initialize() before using\")\n\t}\n\n\tif ci.clusterID != nil {\n\t\treturn nil\n\t}\n\n\texists, err := ci.getConfigMap()\n\tif err != nil {\n\t\treturn err\n\t} else if exists {\n\t\treturn nil\n\t}\n\n\t// The configmap does not exist - let's try creating one.\n\tnewID, err := makeUID()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tklog.V(4).Infof(\"Creating clusteriD: %v\", newID)\n\tcfg := &v1.ConfigMap{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      UIDConfigMapName,\n\t\t\tNamespace: UIDNamespace,\n\t\t},\n\t}\n\tcfg.Data = map[string]string{\n\t\tUIDCluster:  newID,\n\t\tUIDProvider: newID,\n\t}\n\n\tif _, err := ci.client.CoreV1().ConfigMaps(UIDNamespace).Create(cfg); err != nil {\n\t\tklog.Errorf(\"GCE cloud provider failed to create %v config map to store cluster id: %v\", ci.cfgMapKey, err)\n\t\treturn err\n\t}\n\n\tklog.V(2).Infof(\"Created a config map containing clusteriD: %v\", newID)\n\tci.update(cfg)\n\treturn nil\n}"}, {"instruction": "// CreateOrUpdateRouteTable invokes az.RouteTablesClient.CreateOrUpdate with exponential backoff retry", "input": "go language", "output": "func (az *Cloud) CreateOrUpdateRouteTable(routeTable network.RouteTable) error {\n\tif az.Config.shouldOmitCloudProviderBackoff() {\n\t\tctx, cancel := getContextWithCancel()\n\t\tdefer cancel()\n\n\t\tresp, err := az.RouteTablesClient.CreateOrUpdate(ctx, az.RouteTableResourceGroup, az.RouteTableName, routeTable)\n\t\treturn az.processHTTPResponse(nil, \"\", resp, err)\n\t}\n\n\treturn az.createOrUpdateRouteTableWithRetry(routeTable)\n}"}, {"instruction": "// TableHandlesToKVRanges converts sorted handle to kv ranges.\n// For continuous handles, we should merge them to a single key range.", "input": "go language", "output": "func TableHandlesToKVRanges(tid int64, handles []int64) []kv.KeyRange {\n\tkrs := make([]kv.KeyRange, 0, len(handles))\n\ti := 0\n\tfor i < len(handles) {\n\t\tj := i + 1\n\t\tfor ; j < len(handles) && handles[j-1] != math.MaxInt64; j++ {\n\t\t\tif handles[j] != handles[j-1]+1 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tlow := codec.EncodeInt(nil, handles[i])\n\t\thigh := codec.EncodeInt(nil, handles[j-1])\n\t\thigh = []byte(kv.Key(high).PrefixNext())\n\t\tstartKey := tablecodec.EncodeRowKey(tid, low)\n\t\tendKey := tablecodec.EncodeRowKey(tid, high)\n\t\tkrs = append(krs, kv.KeyRange{StartKey: startKey, EndKey: endKey})\n\t\ti = j\n\t}\n\treturn krs\n}"}, {"instruction": "// SetServerRootCAs sets the list of authorities used to verify server\n// certificates based on a list of PEM-encoded X509 certificate authorities", "input": "go language", "output": "func (client *GRPCClient) SetServerRootCAs(serverRoots [][]byte) error {\n\n\t// NOTE: if no serverRoots are specified, the current cert pool will be\n\t// replaced with an empty one\n\tcertPool := x509.NewCertPool()\n\tfor _, root := range serverRoots {\n\t\terr := AddPemToCertPool(root, certPool)\n\t\tif err != nil {\n\t\t\treturn errors.WithMessage(err, \"error adding root certificate\")\n\t\t}\n\t}\n\tclient.tlsConfig.RootCAs = certPool\n\treturn nil\n}"}, {"instruction": "// create is a helper function to create a mock apply that uses the configured\n// working directory to find the logfile.", "input": "go language", "output": "func (m *mockApplies) create(cvID, workspaceID string) (*tfe.Apply, error) {\n\tc, ok := m.client.ConfigurationVersions.configVersions[cvID]\n\tif !ok {\n\t\treturn nil, tfe.ErrResourceNotFound\n\t}\n\tif c.Speculative {\n\t\t// Speculative means its plan-only so we don't create a Apply.\n\t\treturn nil, nil\n\t}\n\n\tid := generateID(\"apply-\")\n\turl := fmt.Sprintf(\"https://app.terraform.io/_archivist/%s\", id)\n\n\ta := &tfe.Apply{\n\t\tID:         id,\n\t\tLogReadURL: url,\n\t\tStatus:     tfe.ApplyPending,\n\t}\n\n\tw, ok := m.client.Workspaces.workspaceIDs[workspaceID]\n\tif !ok {\n\t\treturn nil, tfe.ErrResourceNotFound\n\t}\n\n\tif w.AutoApply {\n\t\ta.Status = tfe.ApplyRunning\n\t}\n\n\tm.logs[url] = filepath.Join(\n\t\tm.client.ConfigurationVersions.uploadPaths[cvID],\n\t\tw.WorkingDirectory,\n\t\t\"apply.log\",\n\t)\n\tm.applies[a.ID] = a\n\n\treturn a, nil\n}"}, {"instruction": "// providerRequiresNetworkingConfiguration returns whether the cloud provider\n// requires special networking configuration.", "input": "go language", "output": "func (kl *Kubelet) providerRequiresNetworkingConfiguration() bool {\n\t// TODO: We should have a mechanism to say whether native cloud provider\n\t// is used or whether we are using overlay networking. We should return\n\t// true for cloud providers if they implement Routes() interface and\n\t// we are not using overlay networking.\n\tif kl.cloud == nil || kl.cloud.ProviderName() != \"gce\" {\n\t\treturn false\n\t}\n\t_, supported := kl.cloud.Routes()\n\treturn supported\n}"}, {"instruction": "// extractToDeleteItems takes a list and\n// returns 2 lists: one contains items that should be kept and the other contains items to be deleted.", "input": "go language", "output": "func extractToDeleteItems(l []interface{}) ([]interface{}, []interface{}, error) {\n\tvar nonDelete, toDelete []interface{}\n\tfor _, v := range l {\n\t\tm, ok := v.(map[string]interface{})\n\t\tif !ok {\n\t\t\treturn nil, nil, mergepatch.ErrBadArgType(m, v)\n\t\t}\n\n\t\tdirective, foundDirective := m[directiveMarker]\n\t\tif foundDirective && directive == deleteDirective {\n\t\t\ttoDelete = append(toDelete, v)\n\t\t} else {\n\t\t\tnonDelete = append(nonDelete, v)\n\t\t}\n\t}\n\treturn nonDelete, toDelete, nil\n}"}, {"instruction": "// WARNING: If you're adding any return calls or defer any more work from this\n// function you have to make sure to update nodesInProcessing properly with the\n// disposition of the node when the work is done.", "input": "go language", "output": "func (r *rangeAllocator) AllocateOrOccupyCIDR(node *v1.Node) error {\n\tif node == nil {\n\t\treturn nil\n\t}\n\tif !r.insertNodeToProcessing(node.Name) {\n\t\tklog.V(2).Infof(\"Node %v is already in a process of CIDR assignment.\", node.Name)\n\t\treturn nil\n\t}\n\tif node.Spec.PodCIDR != \"\" {\n\t\treturn r.occupyCIDR(node)\n\t}\n\tpodCIDR, err := r.cidrs.AllocateNext()\n\tif err != nil {\n\t\tr.removeNodeFromProcessing(node.Name)\n\t\tnodeutil.RecordNodeStatusChange(r.recorder, node, \"CIDRNotAvailable\")\n\t\treturn fmt.Errorf(\"failed to allocate cidr: %v\", err)\n\t}\n\n\tklog.V(4).Infof(\"Putting node %s with CIDR %s into the work queue\", node.Name, podCIDR)\n\tr.nodeCIDRUpdateChannel <- nodeAndCIDR{\n\t\tnodeName: node.Name,\n\t\tcidr:     podCIDR,\n\t}\n\treturn nil\n}"}, {"instruction": "// serveChunkExplorer starts an http server in background with chunk explorer handler\n// using the provided global store. Server is started if the returned shutdown function\n// is not nil.", "input": "go language", "output": "func serveChunkExplorer(ctx *cli.Context, globalStore mock.GlobalStorer) (shutdown func(), err error) {\n\tif !ctx.IsSet(\"explorer-address\") {\n\t\treturn nil, nil\n\t}\n\n\tcorsOrigins := ctx.StringSlice(\"explorer-cors-origin\")\n\tserver := &http.Server{\n\t\tHandler:      explorer.NewHandler(globalStore, corsOrigins),\n\t\tIdleTimeout:  30 * time.Minute,\n\t\tReadTimeout:  2 * time.Minute,\n\t\tWriteTimeout: 2 * time.Minute,\n\t}\n\tlistener, err := net.Listen(\"tcp\", ctx.String(\"explorer-address\"))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"explorer: %v\", err)\n\t}\n\tlog.Info(\"chunk explorer http\", \"address\", listener.Addr().String(), \"origins\", corsOrigins)\n\n\tgo func() {\n\t\tif err := server.Serve(listener); err != nil {\n\t\t\tlog.Error(\"chunk explorer\", \"err\", err)\n\t\t}\n\t}()\n\n\treturn func() {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tdefer cancel()\n\t\tif err := server.Shutdown(ctx); err != nil {\n\t\t\tlog.Error(\"chunk explorer: shutdown\", \"err\", err)\n\t\t}\n\t}, nil\n}"}, {"instruction": "// update keeps track of the downloader events. Please be aware that this is a one shot type of update loop.\n// It's entered once and as soon as `Done` or `Failed` has been broadcasted the events are unregistered and\n// the loop is exited. This to prevent a major security vuln where external parties can DOS you with blocks\n// and halt your mining operation for as long as the DOS continues.", "input": "go language", "output": "func (self *Miner) update() {\n\tevents := self.mux.Subscribe(downloader.StartEvent{}, downloader.DoneEvent{}, downloader.FailedEvent{})\n\tdefer events.Unsubscribe()\n\n\tfor {\n\t\tselect {\n\t\tcase ev := <-events.Chan():\n\t\t\tif ev == nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tswitch ev.Data.(type) {\n\t\t\tcase downloader.StartEvent:\n\t\t\t\tatomic.StoreInt32(&self.canStart, 0)\n\t\t\t\tif self.Mining() {\n\t\t\t\t\tself.Stop()\n\t\t\t\t\tatomic.StoreInt32(&self.shouldStart, 1)\n\t\t\t\t\tlog.Info(\"Mining aborted due to sync\")\n\t\t\t\t}\n\t\t\tcase downloader.DoneEvent, downloader.FailedEvent:\n\t\t\t\tshouldStart := atomic.LoadInt32(&self.shouldStart) == 1\n\n\t\t\t\tatomic.StoreInt32(&self.canStart, 1)\n\t\t\t\tatomic.StoreInt32(&self.shouldStart, 0)\n\t\t\t\tif shouldStart {\n\t\t\t\t\tself.Start(self.coinbase)\n\t\t\t\t}\n\t\t\t\t// stop immediately and ignore all further pending events\n\t\t\t\treturn\n\t\t\t}\n\t\tcase <-self.exitCh:\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// AcceptRequest returns whether a new request can be accepted and the missing\n// buffer amount if it was rejected due to a buffer underrun. If accepted, maxCost\n// is deducted from the flow control buffer.", "input": "go language", "output": "func (node *ClientNode) AcceptRequest(reqID, index, maxCost uint64) (accepted bool, bufShort uint64, priority int64) {\n\tnode.lock.Lock()\n\tdefer node.lock.Unlock()\n\n\tnow := node.cm.clock.Now()\n\tnode.update(now)\n\tif maxCost > node.bufValue {\n\t\tif node.log != nil {\n\t\t\tnode.log.add(now, fmt.Sprintf(\"rejected  reqID=%d  bv=%d  maxCost=%d\", reqID, node.bufValue, maxCost))\n\t\t\tnode.log.dump(now)\n\t\t}\n\t\treturn false, maxCost - node.bufValue, 0\n\t}\n\tnode.bufValue -= maxCost\n\tnode.sumCost += maxCost\n\tif node.log != nil {\n\t\tnode.log.add(now, fmt.Sprintf(\"accepted  reqID=%d  bv=%d  maxCost=%d  sumCost=%d\", reqID, node.bufValue, maxCost, node.sumCost))\n\t}\n\tnode.accepted[index] = node.sumCost\n\treturn true, 0, node.cm.accepted(node, maxCost, now)\n}"}, {"instruction": "// HugePageLimits converts the API representation to a map\n// from huge page size (in bytes) to huge page limit (in bytes).", "input": "go language", "output": "func HugePageLimits(resourceList v1.ResourceList) map[int64]int64 {\n\thugePageLimits := map[int64]int64{}\n\tfor k, v := range resourceList {\n\t\tif v1helper.IsHugePageResourceName(k) {\n\t\t\tpageSize, _ := v1helper.HugePageSizeFromResourceName(k)\n\t\t\tif value, exists := hugePageLimits[pageSize.Value()]; exists {\n\t\t\t\thugePageLimits[pageSize.Value()] = value + v.Value()\n\t\t\t} else {\n\t\t\t\thugePageLimits[pageSize.Value()] = v.Value()\n\t\t\t}\n\t\t}\n\t}\n\treturn hugePageLimits\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of StorageClasses that match those selectors.", "input": "go language", "output": "func (c *FakeStorageClasses) List(opts v1.ListOptions) (result *v1beta1.StorageClassList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootListAction(storageclassesResource, storageclassesKind, opts), &v1beta1.StorageClassList{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta1.StorageClassList{ListMeta: obj.(*v1beta1.StorageClassList).ListMeta}\n\tfor _, item := range obj.(*v1beta1.StorageClassList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// Read keeps a cursor so cannot be called simulateously, see ReadAt", "input": "go language", "output": "func (r *LazyChunkReader) Read(b []byte) (read int, err error) {\n\tlog.Trace(\"lazychunkreader.read\", \"key\", r.addr)\n\tmetrics.GetOrRegisterCounter(\"lazychunkreader.read\", nil).Inc(1)\n\n\tread, err = r.ReadAt(b, r.off)\n\tif err != nil && err != io.EOF {\n\t\tlog.Trace(\"lazychunkreader.readat\", \"read\", read, \"err\", err)\n\t\tmetrics.GetOrRegisterCounter(\"lazychunkreader.read.err\", nil).Inc(1)\n\t}\n\n\tmetrics.GetOrRegisterCounter(\"lazychunkreader.read.bytes\", nil).Inc(int64(read))\n\n\tr.off += int64(read)\n\treturn read, err\n}"}, {"instruction": "// waitForMembershipStabilization waits for membership view to stabilize\n// or until a time limit expires, or until a peer declares itself as a leader", "input": "go language", "output": "func (le *leaderElectionSvcImpl) waitForMembershipStabilization(timeLimit time.Duration) {\n\tle.logger.Debug(le.id, \": Entering\")\n\tdefer le.logger.Debug(le.id, \": Exiting, peers found\", len(le.adapter.Peers()))\n\tendTime := time.Now().Add(timeLimit)\n\tviewSize := len(le.adapter.Peers())\n\tfor !le.shouldStop() {\n\t\ttime.Sleep(le.config.MembershipSampleInterval)\n\t\tnewSize := len(le.adapter.Peers())\n\t\tif newSize == viewSize || time.Now().After(endTime) || le.isLeaderExists() {\n\t\t\treturn\n\t\t}\n\t\tviewSize = newSize\n\t}\n}"}, {"instruction": "// Get the remote state.", "input": "go language", "output": "func (r *remoteClient) Get() (*remote.Payload, error) {\n\tctx := context.Background()\n\n\tsv, err := r.client.StateVersions.Current(ctx, r.workspace.ID)\n\tif err != nil {\n\t\tif err == tfe.ErrResourceNotFound {\n\t\t\t// If no state exists, then return nil.\n\t\t\treturn nil, nil\n\t\t}\n\t\treturn nil, fmt.Errorf(\"Error retrieving state: %v\", err)\n\t}\n\n\tstate, err := r.client.StateVersions.Download(ctx, sv.DownloadURL)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error downloading state: %v\", err)\n\t}\n\n\t// If the state is empty, then return nil.\n\tif len(state) == 0 {\n\t\treturn nil, nil\n\t}\n\n\t// Get the MD5 checksum of the state.\n\tsum := md5.Sum(state)\n\n\treturn &remote.Payload{\n\t\tData: state,\n\t\tMD5:  sum[:],\n\t}, nil\n}"}, {"instruction": "// exceedMemoryRequests compares whether or not pods' memory usage exceeds their requests", "input": "go language", "output": "func exceedMemoryRequests(stats statsFunc) cmpFunc {\n\treturn func(p1, p2 *v1.Pod) int {\n\t\tp1Stats, p1Found := stats(p1)\n\t\tp2Stats, p2Found := stats(p2)\n\t\tif !p1Found || !p2Found {\n\t\t\t// prioritize evicting the pod for which no stats were found\n\t\t\treturn cmpBool(!p1Found, !p2Found)\n\t\t}\n\n\t\tp1Memory := memoryUsage(p1Stats.Memory)\n\t\tp2Memory := memoryUsage(p2Stats.Memory)\n\t\tp1ExceedsRequests := p1Memory.Cmp(podRequest(p1, v1.ResourceMemory)) == 1\n\t\tp2ExceedsRequests := p2Memory.Cmp(podRequest(p2, v1.ResourceMemory)) == 1\n\t\t// prioritize evicting the pod which exceeds its requests\n\t\treturn cmpBool(p1ExceedsRequests, p2ExceedsRequests)\n\t}\n}"}, {"instruction": "// Round returns the nearest integer, rounding half away from zero.\n//\n// Special cases are:\n//\tRound(\u00b10) = \u00b10\n//\tRound(\u00b1Inf) = \u00b1Inf\n//\tRound(NaN) = NaN", "input": "go language", "output": "func _round(x float64) float64 {\n\t// Round is a faster implementation of:\n\t//\n\t// func Round(x float64) float64 {\n\t//   t := Trunc(x)\n\t//   if Abs(x-t) >= 0.5 {\n\t//     return t + Copysign(1, x)\n\t//   }\n\t//   return t\n\t// }\n\tconst (\n\t\tsignMask = 1 << 63\n\t\tfracMask = 1<<shift - 1\n\t\thalf     = 1 << (shift - 1)\n\t\tone      = bias << shift\n\t)\n\n\tbits := math.Float64bits(x)\n\te := uint(bits>>shift) & mask\n\tif e < bias {\n\t\t// Round abs(x) < 1 including denormals.\n\t\tbits &= signMask // +-0\n\t\tif e == bias-1 {\n\t\t\tbits |= one // +-1\n\t\t}\n\t} else if e < bias+shift {\n\t\t// Round any abs(x) >= 1 containing a fractional component [0,1).\n\t\t//\n\t\t// Numbers with larger exponents are returned unchanged since they\n\t\t// must be either an integer, infinity, or NaN.\n\t\te -= bias\n\t\tbits += half >> e\n\t\tbits &^= fracMask >> e\n\t}\n\treturn math.Float64frombits(bits)\n}"}, {"instruction": "// preparedQueryCreate makes a new prepared query.", "input": "go language", "output": "func (s *HTTPServer) preparedQueryCreate(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\targs := structs.PreparedQueryRequest{\n\t\tOp: structs.PreparedQueryCreate,\n\t}\n\ts.parseDC(req, &args.Datacenter)\n\ts.parseToken(req, &args.Token)\n\tif err := decodeBody(req, &args.Query, nil); err != nil {\n\t\tresp.WriteHeader(http.StatusBadRequest)\n\t\tfmt.Fprintf(resp, \"Request decode failed: %v\", err)\n\t\treturn nil, nil\n\t}\n\n\tvar reply string\n\tif err := s.agent.RPC(\"PreparedQuery.Apply\", &args, &reply); err != nil {\n\t\treturn nil, err\n\t}\n\treturn preparedQueryCreateResponse{reply}, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ImageReviewSpec) DeepCopyInto(out *ImageReviewSpec) {\n\t*out = *in\n\tif in.Containers != nil {\n\t\tin, out := &in.Containers, &out.Containers\n\t\t*out = make([]ImageReviewContainerSpec, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.Annotations != nil {\n\t\tin, out := &in.Annotations, &out.Annotations\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// NewSelectorSpreadPriority creates a SelectorSpread.", "input": "go language", "output": "func NewSelectorSpreadPriority(\n\tserviceLister algorithm.ServiceLister,\n\tcontrollerLister algorithm.ControllerLister,\n\treplicaSetLister algorithm.ReplicaSetLister,\n\tstatefulSetLister algorithm.StatefulSetLister) (PriorityMapFunction, PriorityReduceFunction) {\n\tselectorSpread := &SelectorSpread{\n\t\tserviceLister:     serviceLister,\n\t\tcontrollerLister:  controllerLister,\n\t\treplicaSetLister:  replicaSetLister,\n\t\tstatefulSetLister: statefulSetLister,\n\t}\n\treturn selectorSpread.CalculateSpreadPriorityMap, selectorSpread.CalculateSpreadPriorityReduce\n}"}, {"instruction": "// Get performs an HTTP GET and returns the bytes and/or an error. Any non-200\n// return code is returned as an error.", "input": "go language", "output": "func (p *Process) Get(path string) ([]byte, error) {\n\tclient := &http.Client{\n\t\tTimeout: 30 * time.Second,\n\t\tTransport: &http.Transport{\n\t\t\tDial:              dialer.Dial,\n\t\t\tProxy:             http.ProxyFromEnvironment,\n\t\t\tDisableKeepAlives: true,\n\t\t},\n\t}\n\n\turl := fmt.Sprintf(\"http://%s%s\", p.addr, path)\n\treq, err := http.NewRequest(\"GET\", url, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq.Header.Add(\"X-API-Key\", APIKey)\n\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn p.readResponse(resp)\n}"}, {"instruction": "// prepareTempDir prepares and returns the default directory to use\n// for temporary files.\n// If it doesn't exist, it is created. If it exists, its content is removed.", "input": "go language", "output": "func prepareTempDir(rootDir string, rootIdentity idtools.Identity) (string, error) {\n\tvar tmpDir string\n\tif tmpDir = os.Getenv(\"DOCKER_TMPDIR\"); tmpDir == \"\" {\n\t\ttmpDir = filepath.Join(rootDir, \"tmp\")\n\t\tnewName := tmpDir + \"-old\"\n\t\tif err := os.Rename(tmpDir, newName); err == nil {\n\t\t\tgo func() {\n\t\t\t\tif err := os.RemoveAll(newName); err != nil {\n\t\t\t\t\tlogrus.Warnf(\"failed to delete old tmp directory: %s\", newName)\n\t\t\t\t}\n\t\t\t}()\n\t\t} else if !os.IsNotExist(err) {\n\t\t\tlogrus.Warnf(\"failed to rename %s for background deletion: %s. Deleting synchronously\", tmpDir, err)\n\t\t\tif err := os.RemoveAll(tmpDir); err != nil {\n\t\t\t\tlogrus.Warnf(\"failed to delete old tmp directory: %s\", tmpDir)\n\t\t\t}\n\t\t}\n\t}\n\t// We don't remove the content of tmpdir if it's not the default,\n\t// it may hold things that do not belong to us.\n\treturn tmpDir, idtools.MkdirAllAndChown(tmpDir, 0700, rootIdentity)\n}"}, {"instruction": "// GetQuota - get the quota limits of a directory that was configured with SetQuota", "input": "go language", "output": "func (q *Control) GetQuota(targetPath string, quota *Quota) error {\n\n\tprojectID, ok := q.quotas[targetPath]\n\tif !ok {\n\t\treturn errors.Errorf(\"quota not found for path: %s\", targetPath)\n\t}\n\n\t//\n\t// get the quota limit for the container's project id\n\t//\n\tvar d C.fs_disk_quota_t\n\n\tvar cs = C.CString(q.backingFsBlockDev)\n\tdefer C.free(unsafe.Pointer(cs))\n\n\t_, _, errno := unix.Syscall6(unix.SYS_QUOTACTL, C.Q_XGETPQUOTA,\n\t\tuintptr(unsafe.Pointer(cs)), uintptr(C.__u32(projectID)),\n\t\tuintptr(unsafe.Pointer(&d)), 0, 0)\n\tif errno != 0 {\n\t\treturn errors.Wrapf(errno, \"Failed to get quota limit for projid %d on %s\",\n\t\t\tprojectID, q.backingFsBlockDev)\n\t}\n\tquota.Size = uint64(d.d_blk_hardlimit) * 512\n\n\treturn nil\n}"}, {"instruction": "// CountStmtNode records the number of statements with the same type.", "input": "go language", "output": "func CountStmtNode(stmtNode ast.StmtNode, inRestrictedSQL bool) {\n\tif inRestrictedSQL {\n\t\treturn\n\t}\n\n\ttypeLabel := GetStmtLabel(stmtNode)\n\tswitch typeLabel {\n\tcase \"Use\":\n\t\tstmtNodeCounterUse.Inc()\n\tcase \"Show\":\n\t\tstmtNodeCounterShow.Inc()\n\tcase \"Begin\":\n\t\tstmtNodeCounterBegin.Inc()\n\tcase \"Commit\":\n\t\tstmtNodeCounterCommit.Inc()\n\tcase \"Rollback\":\n\t\tstmtNodeCounterRollback.Inc()\n\tcase \"Insert\":\n\t\tstmtNodeCounterInsert.Inc()\n\tcase \"Replace\":\n\t\tstmtNodeCounterReplace.Inc()\n\tcase \"Delete\":\n\t\tstmtNodeCounterDelete.Inc()\n\tcase \"Update\":\n\t\tstmtNodeCounterUpdate.Inc()\n\tcase \"Select\":\n\t\tstmtNodeCounterSelect.Inc()\n\tdefault:\n\t\tmetrics.StmtNodeCounter.WithLabelValues(typeLabel).Inc()\n\t}\n\n\tif !config.GetGlobalConfig().Status.RecordQPSbyDB {\n\t\treturn\n\t}\n\n\tdbLabels := getStmtDbLabel(stmtNode)\n\tfor dbLabel := range dbLabels {\n\t\tmetrics.DbStmtNodeCounter.WithLabelValues(dbLabel, typeLabel).Inc()\n\t}\n}"}, {"instruction": "// Get retrieves the object from the Namespace and Name fields", "input": "go language", "output": "func (i *Info) Get() (err error) {\n\tobj, err := NewHelper(i.Client, i.Mapping).Get(i.Namespace, i.Name, i.Export)\n\tif err != nil {\n\t\tif errors.IsNotFound(err) && len(i.Namespace) > 0 && i.Namespace != metav1.NamespaceDefault && i.Namespace != metav1.NamespaceAll {\n\t\t\terr2 := i.Client.Get().AbsPath(\"api\", \"v1\", \"namespaces\", i.Namespace).Do().Error()\n\t\t\tif err2 != nil && errors.IsNotFound(err2) {\n\t\t\t\treturn err2\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\ti.Object = obj\n\ti.ResourceVersion, _ = metadataAccessor.ResourceVersion(obj)\n\treturn nil\n}"}, {"instruction": "// DecodeObjectManagedFields extracts and converts the objects ManagedFields into a fieldpath.ManagedFields.", "input": "go language", "output": "func DecodeObjectManagedFields(from runtime.Object) (fieldpath.ManagedFields, error) {\n\tif from == nil {\n\t\treturn make(map[string]*fieldpath.VersionedSet), nil\n\t}\n\taccessor, err := meta.Accessor(from)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"couldn't get accessor: %v\", err))\n\t}\n\n\tmanaged, err := decodeManagedFields(accessor.GetManagedFields())\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to convert managed fields from API: %v\", err)\n\t}\n\treturn managed, err\n}"}, {"instruction": "// handleResponse processes method call responses.", "input": "go language", "output": "func (h *handler) handleResponse(msg *jsonrpcMessage) {\n\top := h.respWait[string(msg.ID)]\n\tif op == nil {\n\t\th.log.Debug(\"Unsolicited RPC response\", \"reqid\", idForLog{msg.ID})\n\t\treturn\n\t}\n\tdelete(h.respWait, string(msg.ID))\n\t// For normal responses, just forward the reply to Call/BatchCall.\n\tif op.sub == nil {\n\t\top.resp <- msg\n\t\treturn\n\t}\n\t// For subscription responses, start the subscription if the server\n\t// indicates success. EthSubscribe gets unblocked in either case through\n\t// the op.resp channel.\n\tdefer close(op.resp)\n\tif msg.Error != nil {\n\t\top.err = msg.Error\n\t\treturn\n\t}\n\tif op.err = json.Unmarshal(msg.Result, &op.sub.subid); op.err == nil {\n\t\tgo op.sub.start()\n\t\th.clientSubs[op.sub.subid] = op.sub\n\t}\n}"}, {"instruction": "// GetByKey is never guaranteed to return back the value set in Mutation.  It could be paged out, it could\n// be older than another copy, the backingCache may be more recent or, you might have written twice into the same key.\n// You get a value that was valid at some snapshot of time and will always return the newer of backingCache and mutationCache.", "input": "go language", "output": "func (c *mutationCache) GetByKey(key string) (interface{}, bool, error) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tobj, exists, err := c.backingCache.GetByKey(key)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tif !exists {\n\t\tif !c.includeAdds {\n\t\t\t// we can't distinguish between, \"didn't observe create\" and \"was deleted after create\", so\n\t\t\t// if the key is missing, we always return it as missing\n\t\t\treturn nil, false, nil\n\t\t}\n\t\tobj, exists = c.mutationCache.Get(key)\n\t\tif !exists {\n\t\t\treturn nil, false, nil\n\t\t}\n\t}\n\tobjRuntime, ok := obj.(runtime.Object)\n\tif !ok {\n\t\treturn obj, true, nil\n\t}\n\treturn c.newerObject(key, objRuntime), true, nil\n}"}, {"instruction": "// query callback representing the query of a chaincode", "input": "go language", "output": "func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n\tvar A string // Entities\n\tvar err error\n\n\tif len(args) != 1 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting name of the person to query\")\n\t}\n\n\tA = args[0]\n\n\t// Get the state from the ledger\n\tAvalbytes, err := stub.GetState(A)\n\tif err != nil {\n\t\tjsonResp := \"{\\\"Error\\\":\\\"Failed to get state for \" + A + \"\\\"}\"\n\t\treturn shim.Error(jsonResp)\n\t}\n\n\tif Avalbytes == nil {\n\t\tjsonResp := \"{\\\"Error\\\":\\\"Nil amount for \" + A + \"\\\"}\"\n\t\treturn shim.Error(jsonResp)\n\t}\n\n\tjsonResp := \"{\\\"Name\\\":\\\"\" + A + \"\\\",\\\"Amount\\\":\\\"\" + string(Avalbytes) + \"\\\"}\"\n\tfmt.Printf(\"Query Response:%s\\n\", jsonResp)\n\treturn shim.Success(Avalbytes)\n}"}, {"instruction": "// RemoveNode removes the overall information about the node.", "input": "go language", "output": "func (n *NodeInfo) RemoveNode(node *v1.Node) error {\n\t// We don't remove NodeInfo for because there can still be some pods on this node -\n\t// this is because notifications about pods are delivered in a different watch,\n\t// and thus can potentially be observed later, even though they happened before\n\t// node removal. This is handled correctly in cache.go file.\n\tn.node = nil\n\tn.allocatableResource = &Resource{}\n\tn.taints, n.taintsErr = nil, nil\n\tn.memoryPressureCondition = v1.ConditionUnknown\n\tn.diskPressureCondition = v1.ConditionUnknown\n\tn.pidPressureCondition = v1.ConditionUnknown\n\tn.imageStates = make(map[string]*ImageStateSummary)\n\tn.generation = nextGeneration()\n\treturn nil\n}"}, {"instruction": "// InstanceKeyLess returns true if the first given instance key i should sort\n// before the second key j, and false otherwise.", "input": "go language", "output": "func InstanceKeyLess(i, j InstanceKey) bool {\n\tiTy := instanceKeyType(i)\n\tjTy := instanceKeyType(j)\n\n\tswitch {\n\tcase i == j:\n\t\treturn false\n\tcase i == NoKey:\n\t\treturn true\n\tcase j == NoKey:\n\t\treturn false\n\tcase iTy != jTy:\n\t\t// The ordering here is arbitrary except that we want NoKeyType\n\t\t// to sort before the others, so we'll just use the enum values\n\t\t// of InstanceKeyType here (where NoKey is zero, sorting before\n\t\t// any other).\n\t\treturn uint32(iTy) < uint32(jTy)\n\tcase iTy == IntKeyType:\n\t\treturn int(i.(IntKey)) < int(j.(IntKey))\n\tcase iTy == StringKeyType:\n\t\treturn string(i.(StringKey)) < string(j.(StringKey))\n\tdefault:\n\t\t// Shouldn't be possible to get down here in practice, since the\n\t\t// above is exhaustive.\n\t\treturn false\n\t}\n}"}, {"instruction": "// GetLoadBalancer returns whether the specified load balancer exists, and\n// if so, what its status is.", "input": "go language", "output": "func (az *Cloud) GetLoadBalancer(ctx context.Context, clusterName string, service *v1.Service) (status *v1.LoadBalancerStatus, exists bool, err error) {\n\t_, status, exists, err = az.getServiceLoadBalancer(service, clusterName, nil, false)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tif !exists {\n\t\tserviceName := getServiceName(service)\n\t\tklog.V(5).Infof(\"getloadbalancer (cluster:%s) (service:%s) - doesn't exist\", clusterName, serviceName)\n\t\treturn nil, false, nil\n\t}\n\treturn status, true, nil\n}"}, {"instruction": "// expireNodes iterates over the database and deletes all nodes that have not\n// been seen (i.e. received a pong from) for some allotted time.", "input": "go language", "output": "func (db *nodeDB) expireNodes() error {\n\tthreshold := time.Now().Add(-nodeDBNodeExpiration)\n\n\t// Find discovered nodes that are older than the allowance\n\tit := db.lvl.NewIterator(nil, nil)\n\tdefer it.Release()\n\n\tfor it.Next() {\n\t\t// Skip the item if not a discovery node\n\t\tid, field := splitKey(it.Key())\n\t\tif field != nodeDBDiscoverRoot {\n\t\t\tcontinue\n\t\t}\n\t\t// Skip the node if not expired yet (and not self)\n\t\tif !bytes.Equal(id[:], db.self[:]) {\n\t\t\tif seen := db.lastPong(id); seen.After(threshold) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// Otherwise delete all associated information\n\t\tdb.deleteNode(id)\n\t}\n\treturn nil\n}"}, {"instruction": "// ShardRowID shards the implicit row ID by adding shard value to the row ID's first few bits.", "input": "go language", "output": "func (d *ddl) ShardRowID(ctx sessionctx.Context, tableIdent ast.Ident, uVal uint64) error {\n\tschema, t, err := d.getSchemaAndTableByIdent(ctx, tableIdent)\n\tif err != nil {\n\t\treturn errors.Trace(err)\n\t}\n\tok, _ := hasAutoIncrementColumn(t.Meta())\n\tif ok && uVal != 0 {\n\t\treturn errUnsupportedShardRowIDBits\n\t}\n\tif uVal == t.Meta().ShardRowIDBits {\n\t\t// Nothing need to do.\n\t\treturn nil\n\t}\n\terr = verifyNoOverflowShardBits(d.sessPool, t, uVal)\n\tif err != nil {\n\t\treturn err\n\t}\n\tjob := &model.Job{\n\t\tType:       model.ActionShardRowID,\n\t\tSchemaID:   schema.ID,\n\t\tTableID:    t.Meta().ID,\n\t\tBinlogInfo: &model.HistoryInfo{},\n\t\tArgs:       []interface{}{uVal},\n\t}\n\terr = d.doDDLJob(ctx, job)\n\terr = d.callHookOnChanged(err)\n\treturn errors.Trace(err)\n}"}, {"instruction": "// Admit checks Pods and admits or rejects them. It also resolves the priority of pods based on their PriorityClass.\n// Note that pod validation mechanism prevents update of a pod priority.", "input": "go language", "output": "func (p *priorityPlugin) Admit(a admission.Attributes, o admission.ObjectInterfaces) error {\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.PodPriority) {\n\t\treturn nil\n\t}\n\n\toperation := a.GetOperation()\n\t// Ignore all calls to subresources\n\tif len(a.GetSubresource()) != 0 {\n\t\treturn nil\n\t}\n\n\tswitch a.GetResource().GroupResource() {\n\tcase podResource:\n\t\tif operation == admission.Create || operation == admission.Update {\n\t\t\treturn p.admitPod(a)\n\t\t}\n\t\treturn nil\n\n\tdefault:\n\t\treturn nil\n\t}\n}"}, {"instruction": "// NewHTTPCodeRanges creates HTTPCodeRanges from a given []string.\n// Break out the http status code ranges into a low int and high int\n// for ease of use at runtime", "input": "go language", "output": "func NewHTTPCodeRanges(strBlocks []string) (HTTPCodeRanges, error) {\n\tvar blocks HTTPCodeRanges\n\tfor _, block := range strBlocks {\n\t\tcodes := strings.Split(block, \"-\")\n\t\t// if only a single HTTP code was configured, assume the best and create the correct configuration on the user's behalf\n\t\tif len(codes) == 1 {\n\t\t\tcodes = append(codes, codes[0])\n\t\t}\n\t\tlowCode, err := strconv.Atoi(codes[0])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\thighCode, err := strconv.Atoi(codes[1])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tblocks = append(blocks, [2]int{lowCode, highCode})\n\t}\n\treturn blocks, nil\n}"}, {"instruction": "// New creates rate limiter middleware.", "input": "go language", "output": "func New(ctx context.Context, next http.Handler, config config.RateLimit, name string) (http.Handler, error) {\n\tmiddlewares.GetLogger(ctx, name, typeName).Debug(\"Creating middleware\")\n\n\textractFunc, err := utils.NewExtractor(config.ExtractorFunc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trateSet := ratelimit.NewRateSet()\n\tfor _, rate := range config.RateSet {\n\t\tif err = rateSet.Add(time.Duration(rate.Period), rate.Average, rate.Burst); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\trl, err := ratelimit.New(next, extractFunc, rateSet)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &rateLimiter{handler: rl, name: name}, nil\n}"}, {"instruction": "// Commit writes the block and state of a genesis specification to the database.\n// The block is committed as the canonical head block.", "input": "go language", "output": "func (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) {\n\tblock := g.ToBlock(db)\n\tif block.Number().Sign() != 0 {\n\t\treturn nil, fmt.Errorf(\"can't commit genesis block with number > 0\")\n\t}\n\trawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty)\n\trawdb.WriteBlock(db, block)\n\trawdb.WriteReceipts(db, block.Hash(), block.NumberU64(), nil)\n\trawdb.WriteCanonicalHash(db, block.Hash(), block.NumberU64())\n\trawdb.WriteHeadBlockHash(db, block.Hash())\n\trawdb.WriteHeadHeaderHash(db, block.Hash())\n\n\tconfig := g.Config\n\tif config == nil {\n\t\tconfig = params.AllEthashProtocolChanges\n\t}\n\trawdb.WriteChainConfig(db, block.Hash(), config)\n\treturn block, nil\n}"}, {"instruction": "// saveToDb saves pool status to the database storage\n// (automatically called during shutdown)", "input": "go language", "output": "func (f *freeClientPool) saveToDb() {\n\tnow := f.clock.Now()\n\tstorage := freeClientPoolStorage{\n\t\tLogOffset: uint64(f.logOffset(now)),\n\t\tList:      make([]*freeClientPoolEntry, len(f.addressMap)),\n\t}\n\ti := 0\n\tfor _, e := range f.addressMap {\n\t\tif e.connected {\n\t\t\tf.calcLogUsage(e, now)\n\t\t}\n\t\tstorage.List[i] = e\n\t\ti++\n\t}\n\tenc, err := rlp.EncodeToBytes(storage)\n\tif err != nil {\n\t\tlog.Error(\"Failed to encode client list\", \"err\", err)\n\t} else {\n\t\tf.db.Put([]byte(\"freeClientPool\"), enc)\n\t}\n}"}, {"instruction": "// NewPSTMTPlanCacheKey creates a new pstmtPlanCacheKey object.", "input": "go language", "output": "func NewPSTMTPlanCacheKey(sessionVars *variable.SessionVars, pstmtID uint32, schemaVersion int64) kvcache.Key {\n\ttimezoneOffset := 0\n\tif sessionVars.TimeZone != nil {\n\t\t_, timezoneOffset = time.Now().In(sessionVars.TimeZone).Zone()\n\t}\n\treturn &pstmtPlanCacheKey{\n\t\tdatabase:       sessionVars.CurrentDB,\n\t\tconnID:         sessionVars.ConnectionID,\n\t\tpstmtID:        pstmtID,\n\t\tsnapshot:       sessionVars.SnapshotTS,\n\t\tschemaVersion:  schemaVersion,\n\t\tsqlMode:        sessionVars.SQLMode,\n\t\ttimezoneOffset: timezoneOffset,\n\t}\n}"}, {"instruction": "// Validate container resource name\n// Refer to docs/design/resources.md for more details.", "input": "go language", "output": "func validateContainerResourceName(value string, fldPath *field.Path) field.ErrorList {\n\tallErrs := validateResourceName(value, fldPath)\n\n\tif len(strings.Split(value, \"/\")) == 1 {\n\t\tif !helper.IsStandardContainerResourceName(value) {\n\t\t\treturn append(allErrs, field.Invalid(fldPath, value, \"must be a standard resource for containers\"))\n\t\t}\n\t} else if !helper.IsNativeResource(core.ResourceName(value)) {\n\t\tif !helper.IsExtendedResourceName(core.ResourceName(value)) {\n\t\t\treturn append(allErrs, field.Invalid(fldPath, value, \"doesn't follow extended resource name standard\"))\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// hashimotoLight aggregates data from the full dataset (using only a small\n// in-memory cache) in order to produce our final value for a particular header\n// hash and nonce.", "input": "go language", "output": "func hashimotoLight(size uint64, cache []uint32, hash []byte, nonce uint64) ([]byte, []byte) {\n\tkeccak512 := makeHasher(sha3.NewLegacyKeccak512())\n\n\tlookup := func(index uint32) []uint32 {\n\t\trawData := generateDatasetItem(cache, index, keccak512)\n\n\t\tdata := make([]uint32, len(rawData)/4)\n\t\tfor i := 0; i < len(data); i++ {\n\t\t\tdata[i] = binary.LittleEndian.Uint32(rawData[i*4:])\n\t\t}\n\t\treturn data\n\t}\n\treturn hashimoto(hash, nonce, size, lookup)\n}"}, {"instruction": "// evalDuration evals a builtinTimeTimeTimeDiffSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_timediff", "input": "go language", "output": "func (b *builtinTimeTimeTimeDiffSig) evalDuration(row chunk.Row) (d types.Duration, isNull bool, err error) {\n\tlhs, isNull, err := b.args[0].EvalTime(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn d, isNull, err\n\t}\n\n\trhs, isNull, err := b.args[1].EvalTime(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn d, isNull, err\n\t}\n\n\tsc := b.ctx.GetSessionVars().StmtCtx\n\td, isNull, err = calculateTimeDiff(sc, lhs, rhs)\n\treturn d, isNull, err\n}"}, {"instruction": "// convertFakeContainer converts the fake container to real container", "input": "go language", "output": "func convertFakeContainer(f *FakeContainer) *dockertypes.ContainerJSON {\n\tif f.Config == nil {\n\t\tf.Config = &dockercontainer.Config{}\n\t}\n\tif f.HostConfig == nil {\n\t\tf.HostConfig = &dockercontainer.HostConfig{}\n\t}\n\treturn &dockertypes.ContainerJSON{\n\t\tContainerJSONBase: &dockertypes.ContainerJSONBase{\n\t\t\tID:    f.ID,\n\t\t\tName:  f.Name,\n\t\t\tImage: f.Config.Image,\n\t\t\tState: &dockertypes.ContainerState{\n\t\t\t\tRunning:    f.Running,\n\t\t\t\tExitCode:   f.ExitCode,\n\t\t\t\tPid:        f.Pid,\n\t\t\t\tStartedAt:  dockerTimestampToString(f.StartedAt),\n\t\t\t\tFinishedAt: dockerTimestampToString(f.FinishedAt),\n\t\t\t},\n\t\t\tCreated:    dockerTimestampToString(f.CreatedAt),\n\t\t\tHostConfig: f.HostConfig,\n\t\t},\n\t\tConfig:          f.Config,\n\t\tNetworkSettings: &dockertypes.NetworkSettings{},\n\t}\n}"}, {"instruction": "// MetadataFromContext extracts Metadata from a given context.Context", "input": "go language", "output": "func MetadataFromContext(ctx context.Context) Metadata {\n\tm := Metadata{\"NA\", \"NA\", \"NA\", \"\", \"\"} // batman\n\n\tif v := ctx.Value(\"remote\"); v != nil {\n\t\tm.Remote = v.(string)\n\t}\n\tif v := ctx.Value(\"scheme\"); v != nil {\n\t\tm.Scheme = v.(string)\n\t}\n\tif v := ctx.Value(\"local\"); v != nil {\n\t\tm.Local = v.(string)\n\t}\n\tif v := ctx.Value(\"Origin\"); v != nil {\n\t\tm.Origin = v.(string)\n\t}\n\tif v := ctx.Value(\"User-Agent\"); v != nil {\n\t\tm.UserAgent = v.(string)\n\t}\n\treturn m\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *ShowDDLJobQueriesExec) Open(ctx context.Context) error {\n\tif err := e.baseExecutor.Open(ctx); err != nil {\n\t\treturn err\n\t}\n\ttxn, err := e.ctx.Txn(true)\n\tif err != nil {\n\t\treturn err\n\t}\n\tjobs, err := admin.GetDDLJobs(txn)\n\tif err != nil {\n\t\treturn err\n\t}\n\thistoryJobs, err := admin.GetHistoryDDLJobs(txn, admin.DefNumHistoryJobs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te.jobs = append(e.jobs, jobs...)\n\te.jobs = append(e.jobs, historyJobs...)\n\n\treturn nil\n}"}, {"instruction": "// SetupWorkingDirectory sets up the container's working directory as set in container.Config.WorkingDir", "input": "go language", "output": "func (container *Container) SetupWorkingDirectory(rootIdentity idtools.Identity) error {\n\t// TODO @jhowardmsft, @gupta-ak LCOW Support. This will need revisiting.\n\t// We will need to do remote filesystem operations here.\n\tif container.OS != runtime.GOOS {\n\t\treturn nil\n\t}\n\n\tif container.Config.WorkingDir == \"\" {\n\t\treturn nil\n\t}\n\n\tcontainer.Config.WorkingDir = filepath.Clean(container.Config.WorkingDir)\n\tpth, err := container.GetResourcePath(container.Config.WorkingDir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := idtools.MkdirAllAndChownNew(pth, 0755, rootIdentity); err != nil {\n\t\tpthInfo, err2 := os.Stat(pth)\n\t\tif err2 == nil && pthInfo != nil && !pthInfo.IsDir() {\n\t\t\treturn errors.Errorf(\"Cannot mkdir: %s is not a directory\", container.Config.WorkingDir)\n\t\t}\n\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// Log is intended to be called once at the end of your request handler, via defer", "input": "go language", "output": "func (rl *respLogger) Log() {\n\tlatency := time.Since(rl.startTime)\n\tif klog.V(3) {\n\t\tif !rl.hijacked {\n\t\t\tklog.InfoDepth(1, fmt.Sprintf(\"%s %s: (%v) %v%v%v [%s %s]\", rl.req.Method, rl.req.RequestURI, latency, rl.status, rl.statusStack, rl.addedInfo, rl.req.UserAgent(), rl.req.RemoteAddr))\n\t\t} else {\n\t\t\tklog.InfoDepth(1, fmt.Sprintf(\"%s %s: (%v) hijacked [%s %s]\", rl.req.Method, rl.req.RequestURI, latency, rl.req.UserAgent(), rl.req.RemoteAddr))\n\t\t}\n\t}\n}"}, {"instruction": "// Next moves the iterator to the next node, returning whether there are any\n// further nodes. In case of an internal error this method returns false and\n// sets the Error field to the encountered failure. If `descend` is false,\n// skips iterating over any subnodes of the current node.", "input": "go language", "output": "func (it *nodeIterator) Next(descend bool) bool {\n\tif it.err == errIteratorEnd {\n\t\treturn false\n\t}\n\tif seek, ok := it.err.(seekError); ok {\n\t\tif it.err = it.seek(seek.key); it.err != nil {\n\t\t\treturn false\n\t\t}\n\t}\n\t// Otherwise step forward with the iterator and report any errors.\n\tstate, parentIndex, path, err := it.peek(descend)\n\tit.err = err\n\tif it.err != nil {\n\t\treturn false\n\t}\n\tit.push(state, parentIndex, path)\n\treturn true\n}"}, {"instruction": "// Equal compares two diffs for exact equality.\n//\n// This is different from the Same comparison that is supported which\n// checks for operation equality taking into account computed values. Equal\n// instead checks for exact equality.", "input": "go language", "output": "func (d *Diff) Equal(d2 *Diff) bool {\n\t// If one is nil, they must both be nil\n\tif d == nil || d2 == nil {\n\t\treturn d == d2\n\t}\n\n\t// Sort the modules\n\tsort.Sort(moduleDiffSort(d.Modules))\n\tsort.Sort(moduleDiffSort(d2.Modules))\n\n\t// Copy since we have to modify the module destroy flag to false so\n\t// we don't compare that. TODO: delete this when we get rid of the\n\t// destroy flag on modules.\n\tdCopy := d.DeepCopy()\n\td2Copy := d2.DeepCopy()\n\tfor _, m := range dCopy.Modules {\n\t\tm.Destroy = false\n\t}\n\tfor _, m := range d2Copy.Modules {\n\t\tm.Destroy = false\n\t}\n\n\t// Use DeepEqual\n\treturn reflect.DeepEqual(dCopy, d2Copy)\n}"}, {"instruction": "// RegisterDefaults adds defaulters functions to the given scheme.\n// Public to allow building arbitrary schemes.\n// All generated defaulters are covering - they call all nested defaulters.", "input": "go language", "output": "func RegisterDefaults(scheme *runtime.Scheme) error {\n\tscheme.AddTypeDefaultingFunc(&v1beta1.MutatingWebhookConfiguration{}, func(obj interface{}) {\n\t\tSetObjectDefaults_MutatingWebhookConfiguration(obj.(*v1beta1.MutatingWebhookConfiguration))\n\t})\n\tscheme.AddTypeDefaultingFunc(&v1beta1.MutatingWebhookConfigurationList{}, func(obj interface{}) {\n\t\tSetObjectDefaults_MutatingWebhookConfigurationList(obj.(*v1beta1.MutatingWebhookConfigurationList))\n\t})\n\tscheme.AddTypeDefaultingFunc(&v1beta1.ValidatingWebhookConfiguration{}, func(obj interface{}) {\n\t\tSetObjectDefaults_ValidatingWebhookConfiguration(obj.(*v1beta1.ValidatingWebhookConfiguration))\n\t})\n\tscheme.AddTypeDefaultingFunc(&v1beta1.ValidatingWebhookConfigurationList{}, func(obj interface{}) {\n\t\tSetObjectDefaults_ValidatingWebhookConfigurationList(obj.(*v1beta1.ValidatingWebhookConfigurationList))\n\t})\n\treturn nil\n}"}, {"instruction": "// NewController constructs a new Controller object and returns it. The dynamicConfigDir\n// path must be absolute. transform applies an arbitrary transformation to config after loading, and before validation.\n// This can be used, for example, to include config from flags before the controller's validation step.\n// If transform returns an error, loadConfig will fail, and an InternalError will be reported.\n// Be wary if using this function as an extension point, in most cases the controller should\n// probably just be natively extended to do what you need. Injecting flag precedence transformations\n// is something of an exception because the caller of this controller (cmd/) is aware of flags, but this\n// controller's tree (pkg/) is not.", "input": "go language", "output": "func NewController(dynamicConfigDir string, transform TransformFunc) *Controller {\n\treturn &Controller{\n\t\ttransform: transform,\n\t\t// channels must have capacity at least 1, since we signal with non-blocking writes\n\t\tpendingConfigSource: make(chan bool, 1),\n\t\tconfigStatus:        status.NewNodeConfigStatus(),\n\t\tcheckpointStore:     store.NewFsStore(utilfs.DefaultFs{}, filepath.Join(dynamicConfigDir, storeDir)),\n\t}\n}"}, {"instruction": "// Stop stops the node by first sending SIGTERM and then SIGKILL if the node\n// doesn't stop within 5s", "input": "go language", "output": "func (n *ExecNode) Stop() error {\n\tif n.Cmd == nil {\n\t\treturn nil\n\t}\n\tdefer func() {\n\t\tn.Cmd = nil\n\t}()\n\n\tif n.client != nil {\n\t\tn.client.Close()\n\t\tn.client = nil\n\t\tn.wsAddr = \"\"\n\t\tn.Info = nil\n\t}\n\n\tif err := n.Cmd.Process.Signal(syscall.SIGTERM); err != nil {\n\t\treturn n.Cmd.Process.Kill()\n\t}\n\twaitErr := make(chan error)\n\tgo func() {\n\t\twaitErr <- n.Cmd.Wait()\n\t}()\n\tselect {\n\tcase err := <-waitErr:\n\t\treturn err\n\tcase <-time.After(5 * time.Second):\n\t\treturn n.Cmd.Process.Kill()\n\t}\n}"}, {"instruction": "// Kill implements the SessionManager interface.", "input": "go language", "output": "func (s *Server) Kill(connectionID uint64, query bool) {\n\ts.rwlock.Lock()\n\tdefer s.rwlock.Unlock()\n\tlogutil.Logger(context.Background()).Info(\"kill\", zap.Uint64(\"connID\", connectionID), zap.Bool(\"query\", query))\n\tmetrics.ServerEventCounter.WithLabelValues(metrics.EventKill).Inc()\n\n\tconn, ok := s.clients[uint32(connectionID)]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif !query {\n\t\t// Mark the client connection status as WaitShutdown, when the goroutine detect\n\t\t// this, it will end the dispatch loop and exit.\n\t\tatomic.StoreInt32(&conn.status, connStatusWaitShutdown)\n\t}\n\tkillConn(conn)\n}"}, {"instruction": "// ===== Example: Ad hoc rich query ========================================================\n// queryMarbles uses a query string to perform a query for marbles.\n// Query string matching state database syntax is passed in and executed as is.\n// Supports ad hoc queries that can be defined at runtime by the client.\n// If this is not desired, follow the queryMarblesForOwner example for parameterized queries.\n// Only available on state databases that support rich query (e.g. CouchDB)\n// =========================================================================================", "input": "go language", "output": "func (t *SimpleChaincode) queryMarbles(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n\n\t//   0\n\t// \"queryString\"\n\tif len(args) < 1 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 1\")\n\t}\n\n\tqueryString := args[0]\n\n\tqueryResults, err := getQueryResultForQueryString(stub, queryString)\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\treturn shim.Success(queryResults)\n}"}, {"instruction": "// ExpectDeletions records expectations for the given deleteKeys, against the given controller.", "input": "go language", "output": "func (u *UIDTrackingControllerExpectations) ExpectDeletions(rcKey string, deletedKeys []string) error {\n\tu.uidStoreLock.Lock()\n\tdefer u.uidStoreLock.Unlock()\n\n\tif existing := u.GetUIDs(rcKey); existing != nil && existing.Len() != 0 {\n\t\tklog.Errorf(\"Clobbering existing delete keys: %+v\", existing)\n\t}\n\texpectedUIDs := sets.NewString()\n\tfor _, k := range deletedKeys {\n\t\texpectedUIDs.Insert(k)\n\t}\n\tklog.V(4).Infof(\"Controller %v waiting on deletions for: %+v\", rcKey, deletedKeys)\n\tif err := u.uidStore.Add(&UIDSet{expectedUIDs, rcKey}); err != nil {\n\t\treturn err\n\t}\n\treturn u.ControllerExpectationsInterface.ExpectDeletions(rcKey, expectedUIDs.Len())\n}"}, {"instruction": "// Get returns a read-only copy of the system capabilities.", "input": "go language", "output": "func Get() Capabilities {\n\tcapInstance.lock.Lock()\n\tdefer capInstance.lock.Unlock()\n\t// This check prevents clobbering of capabilities that might've been set via SetForTests\n\tif capInstance.capabilities == nil {\n\t\tInitialize(Capabilities{\n\t\t\tAllowPrivileged: false,\n\t\t\tPrivilegedSources: PrivilegedSources{\n\t\t\t\tHostNetworkSources: []string{},\n\t\t\t\tHostPIDSources:     []string{},\n\t\t\t\tHostIPCSources:     []string{},\n\t\t\t},\n\t\t})\n\t}\n\treturn *capInstance.capabilities\n}"}, {"instruction": "// NewDefaultOptions builds a \"normal\" set of options.  You wouldn't normally expose this, but hyperkube isn't cobra compatible", "input": "go language", "output": "func NewDefaultOptions(out, err io.Writer) *AggregatorOptions {\n\to := &AggregatorOptions{\n\t\tRecommendedOptions: genericoptions.NewRecommendedOptions(\n\t\t\tdefaultEtcdPathPrefix,\n\t\t\taggregatorscheme.Codecs.LegacyCodec(v1beta1.SchemeGroupVersion),\n\t\t\tgenericoptions.NewProcessInfo(\"kube-aggregator\", \"kube-system\"),\n\t\t),\n\t\tAPIEnablement: genericoptions.NewAPIEnablementOptions(),\n\n\t\tStdOut: out,\n\t\tStdErr: err,\n\t}\n\n\treturn o\n}"}, {"instruction": "// ForResource gives generic access to a shared informer of the matching type\n// TODO extend this to unknown resources with a client pool", "input": "go language", "output": "func (f *sharedInformerFactory) ForResource(resource schema.GroupVersionResource) (GenericInformer, error) {\n\tswitch resource {\n\t// Group=apiregistration.k8s.io, Version=internalVersion\n\tcase apiregistration.SchemeGroupVersion.WithResource(\"apiservices\"):\n\t\treturn &genericInformer{resource: resource.GroupResource(), informer: f.Apiregistration().InternalVersion().APIServices().Informer()}, nil\n\n\t}\n\n\treturn nil, fmt.Errorf(\"no informer found for %v\", resource)\n}"}, {"instruction": "// AddImagesCommonConfigFlags adds the flags that configure kubeadm (and affect the images kubeadm will use)", "input": "go language", "output": "func AddImagesCommonConfigFlags(flagSet *flag.FlagSet, cfg *kubeadmapiv1beta2.InitConfiguration, cfgPath *string, featureGatesString *string) {\n\toptions.AddKubernetesVersionFlag(flagSet, &cfg.ClusterConfiguration.KubernetesVersion)\n\toptions.AddFeatureGatesStringFlag(flagSet, featureGatesString)\n\toptions.AddImageMetaFlags(flagSet, &cfg.ImageRepository)\n\tflagSet.StringVar(cfgPath, \"config\", *cfgPath, \"Path to kubeadm config file.\")\n}"}, {"instruction": "// MarshalInitConfigurationToBytes marshals the internal InitConfiguration object to bytes. It writes the embedded\n// ClusterConfiguration object with ComponentConfigs out as separate YAML documents", "input": "go language", "output": "func MarshalInitConfigurationToBytes(cfg *kubeadmapi.InitConfiguration, gv schema.GroupVersion) ([]byte, error) {\n\tinitbytes, err := kubeadmutil.MarshalToYamlForCodecs(cfg, gv, kubeadmscheme.Codecs)\n\tif err != nil {\n\t\treturn []byte{}, err\n\t}\n\tallFiles := [][]byte{initbytes}\n\n\t// Exception: If the specified groupversion is targeting the internal type, don't print embedded ClusterConfiguration contents\n\t// This is mostly used for unit testing. In a real scenario the internal version of the API is never marshalled as-is.\n\tif gv.Version != runtime.APIVersionInternal {\n\t\tclusterbytes, err := MarshalClusterConfigurationToBytes(&cfg.ClusterConfiguration, gv)\n\t\tif err != nil {\n\t\t\treturn []byte{}, err\n\t\t}\n\t\tallFiles = append(allFiles, clusterbytes)\n\t}\n\treturn bytes.Join(allFiles, []byte(kubeadmconstants.YAMLDocumentSeparator)), nil\n}"}, {"instruction": "// UpdateDashboardModel updates an existing model from command into model for update", "input": "go language", "output": "func (cmd *UpdateFolderCommand) UpdateDashboardModel(dashFolder *Dashboard, orgId int64, userId int64) {\n\tdashFolder.OrgId = orgId\n\tdashFolder.Title = strings.TrimSpace(cmd.Title)\n\tdashFolder.Data.Set(\"title\", dashFolder.Title)\n\n\tif cmd.Uid != \"\" {\n\t\tdashFolder.SetUid(cmd.Uid)\n\t}\n\n\tdashFolder.SetVersion(cmd.Version)\n\tdashFolder.IsFolder = true\n\n\tif userId == 0 {\n\t\tuserId = -1\n\t}\n\n\tdashFolder.UpdatedBy = userId\n\tdashFolder.UpdateSlug()\n}"}, {"instruction": "// UpdateLease resets the TTL on a master IP in storage", "input": "go language", "output": "func (s *storageLeases) UpdateLease(ip string) error {\n\tkey := path.Join(s.baseKey, ip)\n\treturn s.storage.GuaranteedUpdate(apirequest.NewDefaultContext(), key, &corev1.Endpoints{}, true, nil, func(input kruntime.Object, respMeta storage.ResponseMeta) (kruntime.Object, *uint64, error) {\n\t\t// just make sure we've got the right IP set, and then refresh the TTL\n\t\texisting := input.(*corev1.Endpoints)\n\t\texisting.Subsets = []corev1.EndpointSubset{\n\t\t\t{\n\t\t\t\tAddresses: []corev1.EndpointAddress{{IP: ip}},\n\t\t\t},\n\t\t}\n\n\t\t// leaseTime needs to be in seconds\n\t\tleaseTime := uint64(s.leaseTime / time.Second)\n\n\t\t// NB: GuaranteedUpdate does not perform the store operation unless\n\t\t// something changed between load and store (not including resource\n\t\t// version), meaning we can't refresh the TTL without actually\n\t\t// changing a field.\n\t\texisting.Generation++\n\n\t\tklog.V(6).Infof(\"Resetting TTL on master IP %q listed in storage to %v\", ip, leaseTime)\n\n\t\treturn existing, &leaseTime, nil\n\t})\n}"}, {"instruction": "// localEvent is called when we receive an event on the local Serf", "input": "go language", "output": "func (c *Client) localEvent(event serf.UserEvent) {\n\t// Handle only consul events\n\tif !strings.HasPrefix(event.Name, \"consul:\") {\n\t\treturn\n\t}\n\n\tswitch name := event.Name; {\n\tcase name == newLeaderEvent:\n\t\tc.logger.Printf(\"[INFO] consul: New leader elected: %s\", event.Payload)\n\n\t\t// Trigger the callback\n\t\tif c.config.ServerUp != nil {\n\t\t\tc.config.ServerUp()\n\t\t}\n\tcase isUserEvent(name):\n\t\tevent.Name = rawUserEventName(name)\n\t\tc.logger.Printf(\"[DEBUG] consul: user event: %s\", event.Name)\n\n\t\t// Trigger the callback\n\t\tif c.config.UserEventHandler != nil {\n\t\t\tc.config.UserEventHandler(event)\n\t\t}\n\tdefault:\n\t\tif !c.handleEnterpriseUserEvents(event) {\n\t\t\tc.logger.Printf(\"[WARN] consul: Unhandled local event: %v\", event)\n\t\t}\n\t}\n}"}, {"instruction": "// IsCorruptedMnt return true if err is about corrupted mount point", "input": "go language", "output": "func IsCorruptedMnt(err error) bool {\n\tif err == nil {\n\t\treturn false\n\t}\n\tvar underlyingError error\n\tswitch pe := err.(type) {\n\tcase nil:\n\t\treturn false\n\tcase *os.PathError:\n\t\tunderlyingError = pe.Err\n\tcase *os.LinkError:\n\t\tunderlyingError = pe.Err\n\tcase *os.SyscallError:\n\t\tunderlyingError = pe.Err\n\t}\n\n\treturn underlyingError == syscall.ENOTCONN || underlyingError == syscall.ESTALE || underlyingError == syscall.EIO || underlyingError == syscall.EACCES\n}"}, {"instruction": "// cleanupAssumedPods exists for making test deterministic by taking time as input argument.", "input": "go language", "output": "func (cache *schedulerCache) cleanupAssumedPods(now time.Time) {\n\tcache.mu.Lock()\n\tdefer cache.mu.Unlock()\n\n\t// The size of assumedPods should be small\n\tfor key := range cache.assumedPods {\n\t\tps, ok := cache.podStates[key]\n\t\tif !ok {\n\t\t\tpanic(\"Key found in assumed set but not in podStates. Potentially a logical error.\")\n\t\t}\n\t\tif !ps.bindingFinished {\n\t\t\tklog.V(3).Infof(\"Couldn't expire cache for pod %v/%v. Binding is still in progress.\",\n\t\t\t\tps.pod.Namespace, ps.pod.Name)\n\t\t\tcontinue\n\t\t}\n\t\tif now.After(*ps.deadline) {\n\t\t\tklog.Warningf(\"Pod %s/%s expired\", ps.pod.Namespace, ps.pod.Name)\n\t\t\tif err := cache.expirePod(key, ps); err != nil {\n\t\t\t\tklog.Errorf(\"ExpirePod failed for %s: %v\", key, err)\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// NewServer returns a new simulation API server", "input": "go language", "output": "func NewServer(network *Network) *Server {\n\ts := &Server{\n\t\trouter:  httprouter.New(),\n\t\tnetwork: network,\n\t}\n\n\ts.OPTIONS(\"/\", s.Options)\n\ts.GET(\"/\", s.GetNetwork)\n\ts.POST(\"/start\", s.StartNetwork)\n\ts.POST(\"/stop\", s.StopNetwork)\n\ts.POST(\"/mocker/start\", s.StartMocker)\n\ts.POST(\"/mocker/stop\", s.StopMocker)\n\ts.GET(\"/mocker\", s.GetMockers)\n\ts.POST(\"/reset\", s.ResetNetwork)\n\ts.GET(\"/events\", s.StreamNetworkEvents)\n\ts.GET(\"/snapshot\", s.CreateSnapshot)\n\ts.POST(\"/snapshot\", s.LoadSnapshot)\n\ts.POST(\"/nodes\", s.CreateNode)\n\ts.GET(\"/nodes\", s.GetNodes)\n\ts.GET(\"/nodes/:nodeid\", s.GetNode)\n\ts.POST(\"/nodes/:nodeid/start\", s.StartNode)\n\ts.POST(\"/nodes/:nodeid/stop\", s.StopNode)\n\ts.POST(\"/nodes/:nodeid/conn/:peerid\", s.ConnectNode)\n\ts.DELETE(\"/nodes/:nodeid/conn/:peerid\", s.DisconnectNode)\n\ts.GET(\"/nodes/:nodeid/rpc\", s.NodeRPC)\n\n\treturn s\n}"}, {"instruction": "// ToHashKey removes the leading and trailing zeros and generates a hash key.\n// Two Decimals dec0 and dec1 with different fraction will generate the same hash keys if dec0.Compare(dec1) == 0.", "input": "go language", "output": "func (d *MyDecimal) ToHashKey() ([]byte, error) {\n\t_, digitsInt := d.removeLeadingZeros()\n\t_, digitsFrac := d.removeTrailingZeros()\n\tprec := digitsInt + digitsFrac\n\tif prec == 0 { // zeroDecimal\n\t\tprec = 1\n\t}\n\tbuf, err := d.ToBin(prec, digitsFrac)\n\tif err == ErrTruncated {\n\t\t// This err is caused by shorter digitsFrac;\n\t\t// After removing the trailing zeros from a Decimal,\n\t\t// so digitsFrac may be less than the real digitsFrac of the Decimal,\n\t\t// thus ErrTruncated may be raised, we can ignore it here.\n\t\terr = nil\n\t}\n\treturn buf, err\n}"}, {"instruction": "// podMatchesScopeFunc is a function that knows how to evaluate if a pod matches a scope", "input": "go language", "output": "func podMatchesScopeFunc(selector corev1.ScopedResourceSelectorRequirement, object runtime.Object) (bool, error) {\n\tpod, err := toExternalPodOrError(object)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tswitch selector.ScopeName {\n\tcase corev1.ResourceQuotaScopeTerminating:\n\t\treturn isTerminating(pod), nil\n\tcase corev1.ResourceQuotaScopeNotTerminating:\n\t\treturn !isTerminating(pod), nil\n\tcase corev1.ResourceQuotaScopeBestEffort:\n\t\treturn isBestEffort(pod), nil\n\tcase corev1.ResourceQuotaScopeNotBestEffort:\n\t\treturn !isBestEffort(pod), nil\n\tcase corev1.ResourceQuotaScopePriorityClass:\n\t\treturn podMatchesSelector(pod, selector)\n\t}\n\treturn false, nil\n}"}, {"instruction": "// InWritableDir calls fn(path), while making sure that the directory\n// containing `path` is writable for the duration of the call.", "input": "go language", "output": "func InWritableDir(fn func(string) error, fs fs.Filesystem, path string) error {\n\tdir := filepath.Dir(path)\n\tinfo, err := fs.Stat(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !info.IsDir() {\n\t\treturn errors.New(\"Not a directory: \" + path)\n\t}\n\tif info.Mode()&0200 == 0 {\n\t\t// A non-writeable directory (for this user; we assume that's the\n\t\t// relevant part). Temporarily change the mode so we can delete the\n\t\t// file or directory inside it.\n\t\terr = fs.Chmod(dir, 0755)\n\t\tif err == nil {\n\t\t\tdefer func() {\n\t\t\t\terr = fs.Chmod(dir, info.Mode())\n\t\t\t\tif err != nil {\n\t\t\t\t\t// We managed to change the permission bits like a\n\t\t\t\t\t// millisecond ago, so it'd be bizarre if we couldn't\n\t\t\t\t\t// change it back.\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\treturn fn(path)\n}"}, {"instruction": "// createProvidersFromPolicies creates providers from the constraints supplied.", "input": "go language", "output": "func (c *PodSecurityPolicyPlugin) createProvidersFromPolicies(psps []*policyv1beta1.PodSecurityPolicy, namespace string) ([]psp.Provider, []error) {\n\tvar (\n\t\t// collected providers\n\t\tproviders []psp.Provider\n\t\t// collected errors to return\n\t\terrs []error\n\t)\n\n\tfor _, constraint := range psps {\n\t\tprovider, err := psp.NewSimpleProvider(constraint, namespace, c.strategyFactory)\n\t\tif err != nil {\n\t\t\terrs = append(errs, fmt.Errorf(\"error creating provider for PSP %s: %v\", constraint.Name, err))\n\t\t\tcontinue\n\t\t}\n\t\tproviders = append(providers, provider)\n\t}\n\treturn providers, errs\n}"}, {"instruction": "// IsConfigBlock validates whenever given block contains configuration\n// update transaction", "input": "go language", "output": "func IsConfigBlock(block *cb.Block) bool {\n\tenvelope, err := ExtractEnvelope(block, 0)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tpayload, err := GetPayload(envelope)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tif payload.Header == nil {\n\t\treturn false\n\t}\n\n\thdr, err := UnmarshalChannelHeader(payload.Header.ChannelHeader)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\treturn cb.HeaderType(hdr.Type) == cb.HeaderType_CONFIG || cb.HeaderType(hdr.Type) == cb.HeaderType_ORDERER_TRANSACTION\n}"}, {"instruction": "// targetEncodingForTransform returns the appropriate serializer for the input media type", "input": "go language", "output": "func targetEncodingForTransform(scope *RequestScope, mediaType negotiation.MediaTypeOptions, req *http.Request) (schema.GroupVersionKind, runtime.NegotiatedSerializer, bool) {\n\tswitch target := mediaType.Convert; {\n\tcase target == nil:\n\tcase target.Kind == \"PartialObjectMetadata\" && target.GroupVersion() == metav1beta1.SchemeGroupVersion,\n\t\ttarget.Kind == \"PartialObjectMetadataList\" && target.GroupVersion() == metav1beta1.SchemeGroupVersion,\n\t\ttarget.Kind == \"Table\" && target.GroupVersion() == metav1beta1.SchemeGroupVersion:\n\t\treturn *target, metainternalversion.Codecs, true\n\t}\n\treturn scope.Kind, scope.Serializer, false\n}"}, {"instruction": "// expire is the generic check that move expired tasks from a pending pool back\n// into a task pool, returning all entities caught with expired tasks.\n//\n// Note, this method expects the queue lock to be already held. The\n// reason the lock is not obtained in here is because the parameters already need\n// to access the queue, so they already need a lock anyway.", "input": "go language", "output": "func (q *queue) expire(timeout time.Duration, pendPool map[string]*fetchRequest, taskQueue *prque.Prque, timeoutMeter metrics.Meter) map[string]int {\n\t// Iterate over the expired requests and return each to the queue\n\texpiries := make(map[string]int)\n\tfor id, request := range pendPool {\n\t\tif time.Since(request.Time) > timeout {\n\t\t\t// Update the metrics with the timeout\n\t\t\ttimeoutMeter.Mark(1)\n\n\t\t\t// Return any non satisfied requests to the pool\n\t\t\tif request.From > 0 {\n\t\t\t\ttaskQueue.Push(request.From, -int64(request.From))\n\t\t\t}\n\t\t\tfor _, header := range request.Headers {\n\t\t\t\ttaskQueue.Push(header, -int64(header.Number.Uint64()))\n\t\t\t}\n\t\t\t// Add the peer to the expiry report along the number of failed requests\n\t\t\texpiries[id] = len(request.Headers)\n\n\t\t\t// Remove the expired requests from the pending pool directly\n\t\t\tdelete(pendPool, id)\n\t\t}\n\t}\n\treturn expiries\n}"}, {"instruction": "// RecommendedContextOverrideFlags is a convenience method to return recommended flag names prefixed with a string of your choosing", "input": "go language", "output": "func RecommendedContextOverrideFlags(prefix string) ContextOverrideFlags {\n\treturn ContextOverrideFlags{\n\t\tClusterName:  FlagInfo{prefix + FlagClusterName, \"\", \"\", \"The name of the kubeconfig cluster to use\"},\n\t\tAuthInfoName: FlagInfo{prefix + FlagAuthInfoName, \"\", \"\", \"The name of the kubeconfig user to use\"},\n\t\tNamespace:    FlagInfo{prefix + FlagNamespace, \"n\", \"\", \"If present, the namespace scope for this CLI request\"},\n\t}\n}"}, {"instruction": "// AllocAutoID implements table.Table AllocAutoID interface.", "input": "go language", "output": "func (t *tableCommon) AllocAutoID(ctx sessionctx.Context) (int64, error) {\n\trowID, err := t.Allocator(ctx).Alloc(t.tableID)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tif t.meta.ShardRowIDBits > 0 {\n\t\t// Use max record ShardRowIDBits to check overflow.\n\t\tif OverflowShardBits(rowID, t.meta.MaxShardRowIDBits) {\n\t\t\t// If overflow, the rowID may be duplicated. For examples,\n\t\t\t// t.meta.ShardRowIDBits = 4\n\t\t\t// rowID = 0010111111111111111111111111111111111111111111111111111111111111\n\t\t\t// shard = 01000000000000000000000000000000000000000000000000000000000000000\n\t\t\t// will be duplicated with:\n\t\t\t// rowID = 0100111111111111111111111111111111111111111111111111111111111111\n\t\t\t// shard = 0010000000000000000000000000000000000000000000000000000000000000\n\t\t\treturn 0, autoid.ErrAutoincReadFailed\n\t\t}\n\t\ttxnCtx := ctx.GetSessionVars().TxnCtx\n\t\tif txnCtx.Shard == nil {\n\t\t\tshard := t.calcShard(txnCtx.StartTS)\n\t\t\ttxnCtx.Shard = &shard\n\t\t}\n\t\trowID |= *txnCtx.Shard\n\t}\n\treturn rowID, nil\n}"}, {"instruction": "// BatchGet queries values with the keys.", "input": "go language", "output": "func (c *RawKVClient) BatchGet(keys [][]byte) ([][]byte, error) {\n\tstart := time.Now()\n\tdefer func() {\n\t\ttikvRawkvCmdHistogramWithBatchGet.Observe(time.Since(start).Seconds())\n\t}()\n\n\tbo := NewBackoffer(context.Background(), rawkvMaxBackoff)\n\tresp, err := c.sendBatchReq(bo, keys, tikvrpc.CmdRawBatchGet)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\n\tcmdResp := resp.RawBatchGet\n\tif cmdResp == nil {\n\t\treturn nil, errors.Trace(ErrBodyMissing)\n\t}\n\n\tkeyToValue := make(map[string][]byte, len(keys))\n\tfor _, pair := range cmdResp.Pairs {\n\t\tkeyToValue[string(pair.Key)] = pair.Value\n\t}\n\n\tvalues := make([][]byte, len(keys))\n\tfor i, key := range keys {\n\t\tvalues[i] = keyToValue[string(key)]\n\t}\n\treturn values, nil\n}"}, {"instruction": "// PendingPods returns all the pending pods in the queue. This function is\n// used for debugging purposes in the scheduler cache dumper and comparer.", "input": "go language", "output": "func (p *PriorityQueue) PendingPods() []*v1.Pod {\n\tp.lock.RLock()\n\tdefer p.lock.RUnlock()\n\tresult := []*v1.Pod{}\n\tfor _, pInfo := range p.activeQ.List() {\n\t\tresult = append(result, pInfo.(*podInfo).pod)\n\t}\n\tfor _, pInfo := range p.podBackoffQ.List() {\n\t\tresult = append(result, pInfo.(*podInfo).pod)\n\t}\n\tfor _, pInfo := range p.unschedulableQ.podInfoMap {\n\t\tresult = append(result, pInfo.pod)\n\t}\n\treturn result\n}"}, {"instruction": "// NewKubeConfigFilePhase creates a kubeadm workflow phase that creates a kubeconfig file.", "input": "go language", "output": "func NewKubeConfigFilePhase(kubeConfigFileName string) workflow.Phase {\n\treturn workflow.Phase{\n\t\tName:         kubeconfigFilePhaseProperties[kubeConfigFileName].name,\n\t\tShort:        kubeconfigFilePhaseProperties[kubeConfigFileName].short,\n\t\tLong:         fmt.Sprintf(kubeconfigFilePhaseProperties[kubeConfigFileName].long, kubeConfigFileName),\n\t\tRun:          runKubeConfigFile(kubeConfigFileName),\n\t\tInheritFlags: getKubeConfigPhaseFlags(kubeConfigFileName),\n\t}\n}"}, {"instruction": "// PrivateKeyToEncryptedPEM converts a private key to an encrypted PEM", "input": "go language", "output": "func PrivateKeyToEncryptedPEM(privateKey interface{}, pwd []byte) ([]byte, error) {\n\tif privateKey == nil {\n\t\treturn nil, errors.New(\"Invalid private key. It must be different from nil.\")\n\t}\n\n\tswitch k := privateKey.(type) {\n\tcase *ecdsa.PrivateKey:\n\t\tif k == nil {\n\t\t\treturn nil, errors.New(\"Invalid ecdsa private key. It must be different from nil.\")\n\t\t}\n\t\traw, err := x509.MarshalECPrivateKey(k)\n\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tblock, err := x509.EncryptPEMBlock(\n\t\t\trand.Reader,\n\t\t\t\"PRIVATE KEY\",\n\t\t\traw,\n\t\t\tpwd,\n\t\t\tx509.PEMCipherAES256)\n\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn pem.EncodeToMemory(block), nil\n\n\tdefault:\n\t\treturn nil, errors.New(\"Invalid key type. It must be *ecdsa.PrivateKey\")\n\t}\n}"}, {"instruction": "// Init callback representing the invocation of a chaincode\n// This chaincode will manage two accounts A and B and will transfer X units from A to B upon invoke", "input": "go language", "output": "func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response {\n\tvar err error\n\t_, args := stub.GetFunctionAndParameters()\n\tif len(args) != 4 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 4\")\n\t}\n\n\t// Initialize the chaincode\n\tA = args[0]\n\tAval, err = strconv.Atoi(args[1])\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for asset holding\")\n\t}\n\tB = args[2]\n\tBval, err = strconv.Atoi(args[3])\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for asset holding\")\n\t}\n\tfmt.Printf(\"Aval = %d, Bval = %d\\n\", Aval, Bval)\n\n\treturn shim.Success(nil)\n}"}, {"instruction": "// AddWork adds a work to the WorkerQueue which will be executed not earlier than `fireAt`.", "input": "go language", "output": "func (q *TimedWorkerQueue) AddWork(args *WorkArgs, createdAt time.Time, fireAt time.Time) {\n\tkey := args.KeyFromWorkArgs()\n\tklog.V(4).Infof(\"Adding TimedWorkerQueue item %v at %v to be fired at %v\", key, createdAt, fireAt)\n\n\tq.Lock()\n\tdefer q.Unlock()\n\tif _, exists := q.workers[key]; exists {\n\t\tklog.Warningf(\"Trying to add already existing work for %+v. Skipping.\", args)\n\t\treturn\n\t}\n\tworker := CreateWorker(args, createdAt, fireAt, q.getWrappedWorkerFunc(key))\n\tq.workers[key] = worker\n}"}, {"instruction": "// Reload reads the configuration in the host and reloads the daemon and server.", "input": "go language", "output": "func Reload(configFile string, flags *pflag.FlagSet, reload func(*Config)) error {\n\tlogrus.Infof(\"Got signal to reload configuration, reloading from: %s\", configFile)\n\tnewConfig, err := getConflictFreeConfiguration(configFile, flags)\n\tif err != nil {\n\t\tif flags.Changed(\"config-file\") || !os.IsNotExist(err) {\n\t\t\treturn errors.Wrapf(err, \"unable to configure the Docker daemon with file %s\", configFile)\n\t\t}\n\t\tnewConfig = New()\n\t}\n\n\tif err := Validate(newConfig); err != nil {\n\t\treturn errors.Wrap(err, \"file configuration validation failed\")\n\t}\n\n\t// Check if duplicate label-keys with different values are found\n\tnewLabels, err := GetConflictFreeLabels(newConfig.Labels)\n\tif err != nil {\n\t\treturn err\n\t}\n\tnewConfig.Labels = newLabels\n\n\treload(newConfig)\n\treturn nil\n}"}, {"instruction": "// createTxidRangeEndKey returns a endKey to do a range query on transient store using txid", "input": "go language", "output": "func createTxidRangeEndKey(txid string) []byte {\n\tvar endKey []byte\n\tendKey = append(endKey, prwsetPrefix)\n\tendKey = append(endKey, compositeKeySep)\n\tendKey = append(endKey, []byte(txid)...)\n\t// As txid is a fixed length string (i.e., 128 bits long UUID), 0xff can be used as a stopper.\n\t// Otherwise a super-string of a given txid would also fall under the end key of range query.\n\tendKey = append(endKey, byte(0xff))\n\treturn endKey\n}"}, {"instruction": "// CalculatePatch calls the mutation function on the provided info object, and generates a strategic merge patch for\n// the changes in the object. Encoder must be able to encode the info into the appropriate destination type.\n// This function returns whether the mutation function made any change in the original object.", "input": "go language", "output": "func CalculatePatch(patch *Patch, encoder runtime.Encoder, mutateFn PatchFn) bool {\n\tpatch.Before, patch.Err = runtime.Encode(encoder, patch.Info.Object)\n\tpatch.After, patch.Err = mutateFn(patch.Info.Object)\n\tif patch.Err != nil {\n\t\treturn true\n\t}\n\tif patch.After == nil {\n\t\treturn false\n\t}\n\n\tpatch.Patch, patch.Err = strategicpatch.CreateTwoWayMergePatch(patch.Before, patch.After, patch.Info.Object)\n\treturn true\n}"}, {"instruction": "// NewEvaluatorSuite creates an EvaluatorSuite to evaluate all the exprs.\n// avoidColumnEvaluator can be removed after column pool is supported.", "input": "go language", "output": "func NewEvaluatorSuite(exprs []Expression, avoidColumnEvaluator bool) *EvaluatorSuite {\n\te := &EvaluatorSuite{}\n\n\tfor i := 0; i < len(exprs); i++ {\n\t\tif col, isCol := exprs[i].(*Column); isCol && !avoidColumnEvaluator {\n\t\t\tif e.columnEvaluator == nil {\n\t\t\t\te.columnEvaluator = &columnEvaluator{inputIdxToOutputIdxes: make(map[int][]int)}\n\t\t\t}\n\t\t\tinputIdx, outputIdx := col.Index, i\n\t\t\te.columnEvaluator.inputIdxToOutputIdxes[inputIdx] = append(e.columnEvaluator.inputIdxToOutputIdxes[inputIdx], outputIdx)\n\t\t\tcontinue\n\t\t}\n\t\tif e.defaultEvaluator == nil {\n\t\t\te.defaultEvaluator = &defaultEvaluator{\n\t\t\t\toutputIdxes: make([]int, 0, len(exprs)),\n\t\t\t\texprs:       make([]Expression, 0, len(exprs)),\n\t\t\t}\n\t\t}\n\t\te.defaultEvaluator.exprs = append(e.defaultEvaluator.exprs, exprs[i])\n\t\te.defaultEvaluator.outputIdxes = append(e.defaultEvaluator.outputIdxes, i)\n\t}\n\n\tif e.defaultEvaluator != nil {\n\t\te.defaultEvaluator.vectorizable = Vectorizable(e.defaultEvaluator.exprs)\n\t}\n\treturn e\n}"}, {"instruction": "// StrategicMergeMapPatch applies a strategic merge patch. The original and patch documents\n// must be JSONMap. A patch can be created from an original and modified document by\n// calling CreateTwoWayMergeMapPatch.\n// Warning: the original and patch JSONMap objects are mutated by this function and should not be reused.", "input": "go language", "output": "func StrategicMergeMapPatch(original, patch JSONMap, dataStruct interface{}) (JSONMap, error) {\n\tschema, err := NewPatchMetaFromStruct(dataStruct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We need the go struct tags `patchMergeKey` and `patchStrategy` for fields that support a strategic merge patch.\n\t// For native resources, we can easily figure out these tags since we know the fields.\n\n\t// Because custom resources are decoded as Unstructured and because we're missing the metadata about how to handle\n\t// each field in a strategic merge patch, we can't find the go struct tags. Hence, we can't easily  do a strategic merge\n\t// for custom resources. So we should fail fast and return an error.\n\tif _, ok := dataStruct.(*unstructured.Unstructured); ok {\n\t\treturn nil, mergepatch.ErrUnsupportedStrategicMergePatchFormat\n\t}\n\n\treturn StrategicMergeMapPatchUsingLookupPatchMeta(original, patch, schema)\n}"}, {"instruction": "// GetMissingPvtDataInfoForMostRecentBlocks invokes the function on underlying pvtdata store", "input": "go language", "output": "func (s *Store) GetMissingPvtDataInfoForMostRecentBlocks(maxBlock int) (ledger.MissingPvtDataInfo, error) {\n\t// it is safe to not acquire a read lock on s.rwlock. Without a lock, the value of\n\t// lastCommittedBlock can change due to a new block commit. As a result, we may not\n\t// be able to fetch the missing data info of truly the most recent blocks. This\n\t// decision was made to ensure that the regular block commit rate is not affected.\n\treturn s.pvtdataStore.GetMissingPvtDataInfoForMostRecentBlocks(maxBlock)\n}"}, {"instruction": "// Prefetch processes the state changes according to the Ethereum rules by running\n// the transaction messages using the statedb, but any changes are discarded. The\n// only goal is to pre-cache transaction signatures and state trie nodes.", "input": "go language", "output": "func (p *statePrefetcher) Prefetch(block *types.Block, statedb *state.StateDB, cfg vm.Config, interrupt *uint32) {\n\tvar (\n\t\theader  = block.Header()\n\t\tgaspool = new(GasPool).AddGas(block.GasLimit())\n\t)\n\t// Iterate over and process the individual transactions\n\tfor i, tx := range block.Transactions() {\n\t\t// If block precaching was interrupted, abort\n\t\tif interrupt != nil && atomic.LoadUint32(interrupt) == 1 {\n\t\t\treturn\n\t\t}\n\t\t// Block precaching permitted to continue, execute the transaction\n\t\tstatedb.Prepare(tx.Hash(), block.Hash(), i)\n\t\tif err := precacheTransaction(p.config, p.bc, nil, gaspool, statedb, header, tx, cfg); err != nil {\n\t\t\treturn // Ugh, something went horribly wrong, bail out\n\t\t}\n\t}\n}"}, {"instruction": "// NewHub creates a new hardware wallet manager for smartcards.", "input": "go language", "output": "func NewHub(scheme string, datadir string) (*Hub, error) {\n\tcontext, err := pcsc.EstablishContext(pcsc.ScopeSystem)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\thub := &Hub{\n\t\tscheme:  scheme,\n\t\tcontext: context,\n\t\tdatadir: datadir,\n\t\twallets: make(map[string]*Wallet),\n\t\tquit:    make(chan chan error),\n\t}\n\tif err := hub.readPairings(); err != nil {\n\t\treturn nil, err\n\t}\n\thub.refreshWallets()\n\treturn hub, nil\n}"}, {"instruction": "// InterpretListError converts a generic error on a retrieval\n// operation into the appropriate API error.", "input": "go language", "output": "func InterpretListError(err error, qualifiedResource schema.GroupResource) error {\n\tswitch {\n\tcase storage.IsNotFound(err):\n\t\treturn errors.NewNotFound(qualifiedResource, \"\")\n\tcase storage.IsUnreachable(err):\n\t\treturn errors.NewServerTimeout(qualifiedResource, \"list\", 2) // TODO: make configurable or handled at a higher level\n\tcase storage.IsInternalError(err):\n\t\treturn errors.NewInternalError(err)\n\tdefault:\n\t\treturn err\n\t}\n}"}, {"instruction": "// validateParameters tests that keys are qualified names and that provisionerParameter are < 256kB.", "input": "go language", "output": "func validateParameters(params map[string]string, fldPath *field.Path) field.ErrorList {\n\tvar totalSize int64\n\tallErrs := field.ErrorList{}\n\n\tif len(params) > maxProvisionerParameterLen {\n\t\tallErrs = append(allErrs, field.TooLong(fldPath, \"Provisioner Parameters exceeded max allowed\", maxProvisionerParameterLen))\n\t\treturn allErrs\n\t}\n\n\tfor k, v := range params {\n\t\tif len(k) < 1 {\n\t\t\tallErrs = append(allErrs, field.Invalid(fldPath, k, \"field can not be empty.\"))\n\t\t}\n\t\ttotalSize += (int64)(len(k)) + (int64)(len(v))\n\t}\n\n\tif totalSize > maxProvisionerParameterSize {\n\t\tallErrs = append(allErrs, field.TooLong(fldPath, \"\", maxProvisionerParameterSize))\n\t}\n\treturn allErrs\n}"}, {"instruction": "// Copy data from a remote to a destination directory.", "input": "go language", "output": "func (cst *ClientSessionTransport) Copy(ctx context.Context, id fscache.RemoteIdentifier, dest string, cu filesync.CacheUpdater) error {\n\tcsi, ok := id.(*ClientSessionSourceIdentifier)\n\tif !ok {\n\t\treturn errors.New(\"invalid identifier for client session\")\n\t}\n\n\treturn filesync.FSSync(ctx, csi.caller, filesync.FSSendRequestOpt{\n\t\tIncludePatterns: csi.includePatterns,\n\t\tDestDir:         dest,\n\t\tCacheUpdater:    cu,\n\t})\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of ReplicaSets that match those selectors.", "input": "go language", "output": "func (c *FakeReplicaSets) List(opts v1.ListOptions) (result *v1beta2.ReplicaSetList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(replicasetsResource, replicasetsKind, c.ns, opts), &v1beta2.ReplicaSetList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta2.ReplicaSetList{ListMeta: obj.(*v1beta2.ReplicaSetList).ListMeta}\n\tfor _, item := range obj.(*v1beta2.ReplicaSetList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// adaptSharedNamespaceContainer replaces container name with its ID in hostConfig.\n// To be more precisely, it modifies `container:name` to `container:ID` of PidMode, IpcMode\n// and NetworkMode.\n//\n// When a container shares its namespace with another container, use ID can keep the namespace\n// sharing connection between the two containers even the another container is renamed.", "input": "go language", "output": "func adaptSharedNamespaceContainer(daemon containerGetter, hostConfig *containertypes.HostConfig) {\n\tcontainerPrefix := \"container:\"\n\tif hostConfig.PidMode.IsContainer() {\n\t\tpidContainer := hostConfig.PidMode.Container()\n\t\t// if there is any error returned here, we just ignore it and leave it to be\n\t\t// handled in the following logic\n\t\tif c, err := daemon.GetContainer(pidContainer); err == nil {\n\t\t\thostConfig.PidMode = containertypes.PidMode(containerPrefix + c.ID)\n\t\t}\n\t}\n\tif hostConfig.IpcMode.IsContainer() {\n\t\tipcContainer := hostConfig.IpcMode.Container()\n\t\tif c, err := daemon.GetContainer(ipcContainer); err == nil {\n\t\t\thostConfig.IpcMode = containertypes.IpcMode(containerPrefix + c.ID)\n\t\t}\n\t}\n\tif hostConfig.NetworkMode.IsContainer() {\n\t\tnetContainer := hostConfig.NetworkMode.ConnectedContainer()\n\t\tif c, err := daemon.GetContainer(netContainer); err == nil {\n\t\t\thostConfig.NetworkMode = containertypes.NetworkMode(containerPrefix + c.ID)\n\t\t}\n\t}\n}"}, {"instruction": "// WaitForCacheSync waits for all started informers' cache were synced.", "input": "go language", "output": "func (f *dynamicSharedInformerFactory) WaitForCacheSync(stopCh <-chan struct{}) map[schema.GroupVersionResource]bool {\n\tinformers := func() map[schema.GroupVersionResource]cache.SharedIndexInformer {\n\t\tf.lock.Lock()\n\t\tdefer f.lock.Unlock()\n\n\t\tinformers := map[schema.GroupVersionResource]cache.SharedIndexInformer{}\n\t\tfor informerType, informer := range f.informers {\n\t\t\tif f.startedInformers[informerType] {\n\t\t\t\tinformers[informerType] = informer.Informer()\n\t\t\t}\n\t\t}\n\t\treturn informers\n\t}()\n\n\tres := map[schema.GroupVersionResource]bool{}\n\tfor informType, informer := range informers {\n\t\tres[informType] = cache.WaitForCacheSync(stopCh, informer.HasSynced)\n\t}\n\treturn res\n}"}, {"instruction": "// extractJoinGroup extracts all the join nodes connected with continuous\n// InnerJoins to construct a join group. This join group is further used to\n// construct a new join order based on a reorder algorithm.\n//\n// For example: \"InnerJoin(InnerJoin(a, b), LeftJoin(c, d))\"\n// results in a join group {a, b, LeftJoin(c, d)}.", "input": "go language", "output": "func extractJoinGroup(p LogicalPlan) (group []LogicalPlan, eqEdges []*expression.ScalarFunction, otherConds []expression.Expression) {\n\tjoin, isJoin := p.(*LogicalJoin)\n\tif !isJoin || join.preferJoinType > uint(0) || join.JoinType != InnerJoin || join.StraightJoin {\n\t\treturn []LogicalPlan{p}, nil, nil\n\t}\n\n\tlhsGroup, lhsEqualConds, lhsOtherConds := extractJoinGroup(join.children[0])\n\trhsGroup, rhsEqualConds, rhsOtherConds := extractJoinGroup(join.children[1])\n\n\tgroup = append(group, lhsGroup...)\n\tgroup = append(group, rhsGroup...)\n\teqEdges = append(eqEdges, join.EqualConditions...)\n\teqEdges = append(eqEdges, lhsEqualConds...)\n\teqEdges = append(eqEdges, rhsEqualConds...)\n\totherConds = append(otherConds, join.OtherConditions...)\n\totherConds = append(otherConds, lhsOtherConds...)\n\totherConds = append(otherConds, rhsOtherConds...)\n\treturn group, eqEdges, otherConds\n}"}, {"instruction": "// CoordinateNode returns the LAN node in the given datacenter, along with\n// raw network coordinates.", "input": "go language", "output": "func (s *HTTPServer) CoordinateNode(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\tif s.checkCoordinateDisabled(resp, req) {\n\t\treturn nil, nil\n\t}\n\n\tnode := strings.TrimPrefix(req.URL.Path, \"/v1/coordinate/node/\")\n\targs := structs.NodeSpecificRequest{Node: node}\n\tif done := s.parse(resp, req, &args.Datacenter, &args.QueryOptions); done {\n\t\treturn nil, nil\n\t}\n\n\tvar out structs.IndexedCoordinates\n\tdefer setMeta(resp, &out.QueryMeta)\n\tif err := s.agent.RPC(\"Coordinate.Node\", &args, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\tresult := filterCoordinates(req, out.Coordinates)\n\tif len(result) == 0 {\n\t\tresp.WriteHeader(http.StatusNotFound)\n\t\treturn nil, nil\n\t}\n\n\treturn result, nil\n}"}, {"instruction": "// Into stores the result into obj, if possible. If obj is nil it is ignored.\n// If the returned object is of type Status and has .Status != StatusSuccess, the\n// additional information in Status will be used to enrich the error.", "input": "go language", "output": "func (r Result) Into(obj runtime.Object) error {\n\tif r.err != nil {\n\t\t// Check whether the result has a Status object in the body and prefer that.\n\t\treturn r.Error()\n\t}\n\tif r.decoder == nil {\n\t\treturn fmt.Errorf(\"serializer for %s doesn't exist\", r.contentType)\n\t}\n\tif len(r.body) == 0 {\n\t\treturn fmt.Errorf(\"0-length response with status code: %d and content type: %s\",\n\t\t\tr.statusCode, r.contentType)\n\t}\n\n\tout, _, err := r.decoder.Decode(r.body, nil, obj)\n\tif err != nil || out == obj {\n\t\treturn err\n\t}\n\t// if a different object is returned, see if it is Status and avoid double decoding\n\t// the object.\n\tswitch t := out.(type) {\n\tcase *metav1.Status:\n\t\t// any status besides StatusSuccess is considered an error.\n\t\tif t.Status != metav1.StatusSuccess {\n\t\t\treturn errors.FromObject(t)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// Create creates Kubernetes resources from an io.reader.\n//\n// Namespace will set the namespace.", "input": "go language", "output": "func (c *Client) Create(namespace string, reader io.Reader, timeout int64, shouldWait bool) error {\n\tclient, err := c.KubernetesClientSet()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := ensureNamespace(client, namespace); err != nil {\n\t\treturn err\n\t}\n\tc.Log(\"building resources from manifest\")\n\tinfos, buildErr := c.BuildUnstructured(namespace, reader)\n\tif buildErr != nil {\n\t\treturn buildErr\n\t}\n\tc.Log(\"creating %d resource(s)\", len(infos))\n\tif err := perform(infos, createResource); err != nil {\n\t\treturn err\n\t}\n\tif shouldWait {\n\t\treturn c.waitForResources(time.Duration(timeout)*time.Second, infos)\n\t}\n\treturn nil\n}"}, {"instruction": "// ObjectKinds returns all possible group,version,kind of the go object, true if the\n// object is considered unversioned, or an error if it's not a pointer or is unregistered.", "input": "go language", "output": "func (s *Scheme) ObjectKinds(obj Object) ([]schema.GroupVersionKind, bool, error) {\n\t// Unstructured objects are always considered to have their declared GVK\n\tif _, ok := obj.(Unstructured); ok {\n\t\t// we require that the GVK be populated in order to recognize the object\n\t\tgvk := obj.GetObjectKind().GroupVersionKind()\n\t\tif len(gvk.Kind) == 0 {\n\t\t\treturn nil, false, NewMissingKindErr(\"unstructured object has no kind\")\n\t\t}\n\t\tif len(gvk.Version) == 0 {\n\t\t\treturn nil, false, NewMissingVersionErr(\"unstructured object has no version\")\n\t\t}\n\t\treturn []schema.GroupVersionKind{gvk}, false, nil\n\t}\n\n\tv, err := conversion.EnforcePtr(obj)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tt := v.Type()\n\n\tgvks, ok := s.typeToGVK[t]\n\tif !ok {\n\t\treturn nil, false, NewNotRegisteredErrForType(s.schemeName, t)\n\t}\n\t_, unversionedType := s.unversionedTypes[t]\n\n\treturn gvks, unversionedType, nil\n}"}, {"instruction": "// Validate provides a mock function with given fields: block, namespace, txPosition, actionPosition, policy", "input": "go language", "output": "func (_m *TransactionValidator) Validate(block *common.Block, namespace string, txPosition int, actionPosition int, policy []byte) errors.TxValidationError {\n\tret := _m.Called(block, namespace, txPosition, actionPosition, policy)\n\n\tvar r0 errors.TxValidationError\n\tif rf, ok := ret.Get(0).(func(*common.Block, string, int, int, []byte) errors.TxValidationError); ok {\n\t\tr0 = rf(block, namespace, txPosition, actionPosition, policy)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(errors.TxValidationError)\n\t\t}\n\t}\n\n\treturn r0\n}"}, {"instruction": "// This is is just some helpers used to create some JSON used in the Hugo docs.", "input": "go language", "output": "func init() {\n\n\tdocsProvider := func() map[string]interface{} {\n\t\tdocs := make(map[string]interface{})\n\n\t\tvar chromaLexers []interface{}\n\n\t\tsort.Sort(lexers.Registry.Lexers)\n\n\t\tfor _, l := range lexers.Registry.Lexers {\n\n\t\t\tconfig := l.Config()\n\n\t\t\tvar filenames []string\n\t\t\tfilenames = append(filenames, config.Filenames...)\n\t\t\tfilenames = append(filenames, config.AliasFilenames...)\n\n\t\t\taliases := config.Aliases\n\n\t\t\tfor _, filename := range filenames {\n\t\t\t\talias := strings.TrimSpace(strings.TrimPrefix(filepath.Ext(filename), \".\"))\n\t\t\t\tif alias != \"\" {\n\t\t\t\t\taliases = append(aliases, alias)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tsort.Strings(aliases)\n\t\t\taliases = UniqueStrings(aliases)\n\n\t\t\tlexerEntry := struct {\n\t\t\t\tName    string\n\t\t\t\tAliases []string\n\t\t\t}{\n\t\t\t\tconfig.Name,\n\t\t\t\taliases,\n\t\t\t}\n\n\t\t\tchromaLexers = append(chromaLexers, lexerEntry)\n\n\t\t\tdocs[\"lexers\"] = chromaLexers\n\t\t}\n\t\treturn docs\n\n\t}\n\n\tdocshelper.AddDocProvider(\"chroma\", docsProvider)\n}"}, {"instruction": "// GetFilterMessages returns the messages that match the filter criteria and\n// are received between the last poll and now.", "input": "go language", "output": "func (api *PublicWhisperAPI) GetFilterMessages(id string) ([]*Message, error) {\n\tapi.mu.Lock()\n\tf := api.w.GetFilter(id)\n\tif f == nil {\n\t\tapi.mu.Unlock()\n\t\treturn nil, fmt.Errorf(\"filter not found\")\n\t}\n\tapi.lastUsed[id] = time.Now()\n\tapi.mu.Unlock()\n\n\treceivedMessages := f.Retrieve()\n\tmessages := make([]*Message, 0, len(receivedMessages))\n\tfor _, msg := range receivedMessages {\n\t\tmessages = append(messages, ToWhisperMessage(msg))\n\t}\n\n\treturn messages, nil\n}"}, {"instruction": "// PendingTransactions returns the transactions that are in the transaction pool\n// and have a from address that is one of the accounts this node manages.", "input": "go language", "output": "func (s *PublicTransactionPoolAPI) PendingTransactions() ([]*RPCTransaction, error) {\n\tpending, err := s.b.GetPoolTransactions()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\taccounts := make(map[common.Address]struct{})\n\tfor _, wallet := range s.b.AccountManager().Wallets() {\n\t\tfor _, account := range wallet.Accounts() {\n\t\t\taccounts[account.Address] = struct{}{}\n\t\t}\n\t}\n\ttransactions := make([]*RPCTransaction, 0, len(pending))\n\tfor _, tx := range pending {\n\t\tvar signer types.Signer = types.HomesteadSigner{}\n\t\tif tx.Protected() {\n\t\t\tsigner = types.NewEIP155Signer(tx.ChainId())\n\t\t}\n\t\tfrom, _ := types.Sender(signer, tx)\n\t\tif _, exists := accounts[from]; exists {\n\t\t\ttransactions = append(transactions, newRPCPendingTransaction(tx))\n\t\t}\n\t}\n\treturn transactions, nil\n}"}, {"instruction": "//send the metrics to the DB", "input": "go language", "output": "func (r *reporter) save() error {\n\t//create a LevelDB Batch\n\tbatch := leveldb.Batch{}\n\t//for each metric in the registry (which is independent)...\n\tr.reg.Each(func(name string, i interface{}) {\n\t\tmetric, ok := i.(metrics.Counter)\n\t\tif ok {\n\t\t\t//assuming every metric here to be a Counter (separate registry)\n\t\t\t//...create a snapshot...\n\t\t\tms := metric.Snapshot()\n\t\t\tbyteVal := make([]byte, 8)\n\t\t\tbinary.BigEndian.PutUint64(byteVal, uint64(ms.Count()))\n\t\t\t//...and save the value to the DB\n\t\t\tbatch.Put([]byte(name), byteVal)\n\t\t}\n\t})\n\treturn r.db.Write(&batch, nil)\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ExternalMetricValue) DeepCopyInto(out *ExternalMetricValue) {\n\t*out = *in\n\tout.TypeMeta = in.TypeMeta\n\tif in.MetricLabels != nil {\n\t\tin, out := &in.MetricLabels, &out.MetricLabels\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tin.Timestamp.DeepCopyInto(&out.Timestamp)\n\tif in.WindowSeconds != nil {\n\t\tin, out := &in.WindowSeconds, &out.WindowSeconds\n\t\t*out = new(int64)\n\t\t**out = **in\n\t}\n\tout.Value = in.Value.DeepCopy()\n\treturn\n}"}, {"instruction": "// RegisterConversions adds conversion functions to the given scheme.\n// Public to allow building arbitrary schemes.", "input": "go language", "output": "func RegisterConversions(s *runtime.Scheme) error {\n\tif err := s.AddGeneratedConversionFunc((*Configuration)(nil), (*podtolerationrestriction.Configuration)(nil), func(a, b interface{}, scope conversion.Scope) error {\n\t\treturn Convert_v1alpha1_Configuration_To_podtolerationrestriction_Configuration(a.(*Configuration), b.(*podtolerationrestriction.Configuration), scope)\n\t}); err != nil {\n\t\treturn err\n\t}\n\tif err := s.AddGeneratedConversionFunc((*podtolerationrestriction.Configuration)(nil), (*Configuration)(nil), func(a, b interface{}, scope conversion.Scope) error {\n\t\treturn Convert_podtolerationrestriction_Configuration_To_v1alpha1_Configuration(a.(*podtolerationrestriction.Configuration), b.(*Configuration), scope)\n\t}); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// NewWorker instantiates a local worker", "input": "go language", "output": "func NewWorker(opt Opt) (*Worker, error) {\n\tsm, err := source.NewManager()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcm := opt.CacheManager\n\tsm.Register(opt.ImageSource)\n\n\tgs, err := git.NewSource(git.Opt{\n\t\tCacheAccessor: cm,\n\t\tMetadataStore: opt.MetadataStore,\n\t})\n\tif err == nil {\n\t\tsm.Register(gs)\n\t} else {\n\t\tlogrus.Warnf(\"Could not register builder git source: %s\", err)\n\t}\n\n\ths, err := http.NewSource(http.Opt{\n\t\tCacheAccessor: cm,\n\t\tMetadataStore: opt.MetadataStore,\n\t\tTransport:     opt.Transport,\n\t})\n\tif err == nil {\n\t\tsm.Register(hs)\n\t} else {\n\t\tlogrus.Warnf(\"Could not register builder http source: %s\", err)\n\t}\n\n\tss, err := local.NewSource(local.Opt{\n\t\tCacheAccessor: cm,\n\t\tMetadataStore: opt.MetadataStore,\n\t})\n\tif err == nil {\n\t\tsm.Register(ss)\n\t} else {\n\t\tlogrus.Warnf(\"Could not register builder local source: %s\", err)\n\t}\n\n\treturn &Worker{\n\t\tOpt:           opt,\n\t\tSourceManager: sm,\n\t}, nil\n}"}, {"instruction": "// doEncHandshake runs the protocol handshake using authenticated\n// messages. the protocol handshake is the first authenticated message\n// and also verifies whether the encryption handshake 'worked' and the\n// remote side actually provided the right public key.", "input": "go language", "output": "func (t *rlpx) doEncHandshake(prv *ecdsa.PrivateKey, dial *ecdsa.PublicKey) (*ecdsa.PublicKey, error) {\n\tvar (\n\t\tsec secrets\n\t\terr error\n\t)\n\tif dial == nil {\n\t\tsec, err = receiverEncHandshake(t.fd, prv)\n\t} else {\n\t\tsec, err = initiatorEncHandshake(t.fd, prv, dial)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tt.wmu.Lock()\n\tt.rw = newRLPXFrameRW(t.fd, sec)\n\tt.wmu.Unlock()\n\treturn sec.Remote.ExportECDSA(), nil\n}"}, {"instruction": "// getKubeletContainers lists containers managed by kubelet.\n// The boolean parameter specifies whether returns all containers including\n// those already exited and dead containers (used for garbage collection).", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) getKubeletContainers(allContainers bool) ([]*runtimeapi.Container, error) {\n\tfilter := &runtimeapi.ContainerFilter{}\n\tif !allContainers {\n\t\tfilter.State = &runtimeapi.ContainerStateValue{\n\t\t\tState: runtimeapi.ContainerState_CONTAINER_RUNNING,\n\t\t}\n\t}\n\n\tcontainers, err := m.runtimeService.ListContainers(filter)\n\tif err != nil {\n\t\tklog.Errorf(\"getKubeletContainers failed: %v\", err)\n\t\treturn nil, err\n\t}\n\n\treturn containers, nil\n}"}, {"instruction": "// checkFolderDeviceStatusLocked first checks the folder and then whether the\n// given device is connected and shares this folder.\n// Need to hold (read) lock on both m.fmut and m.pmut when calling this.", "input": "go language", "output": "func (m *model) checkDeviceFolderConnectedLocked(device protocol.DeviceID, folder string) error {\n\tif err := m.checkFolderRunningLocked(folder); err != nil {\n\t\treturn err\n\t}\n\n\tif cfg, ok := m.cfg.Device(device); !ok {\n\t\treturn errDeviceUnknown\n\t} else if cfg.Paused {\n\t\treturn errDevicePaused\n\t}\n\n\tif _, ok := m.conn[device]; !ok {\n\t\treturn errors.New(\"device is not connected\")\n\t}\n\n\tif cfg, ok := m.cfg.Folder(folder); !ok || !cfg.SharedWith(device) {\n\t\treturn errors.New(\"folder is not shared with device\")\n\t}\n\treturn nil\n}"}, {"instruction": "// Query fetches all releases that match the provided map of labels.\n// An error is returned if the secret fails to retrieve the releases.", "input": "go language", "output": "func (secrets *Secrets) Query(labels map[string]string) ([]*rspb.Release, error) {\n\tls := kblabels.Set{}\n\tfor k, v := range labels {\n\t\tif errs := validation.IsValidLabelValue(v); len(errs) != 0 {\n\t\t\treturn nil, fmt.Errorf(\"invalid label value: %q: %s\", v, strings.Join(errs, \"; \"))\n\t\t}\n\t\tls[k] = v\n\t}\n\n\topts := metav1.ListOptions{LabelSelector: ls.AsSelector().String()}\n\n\tlist, err := secrets.impl.List(opts)\n\tif err != nil {\n\t\tsecrets.Log(\"query: failed to query with labels: %s\", err)\n\t\treturn nil, err\n\t}\n\n\tif len(list.Items) == 0 {\n\t\treturn nil, storageerrors.ErrReleaseNotFound(labels[\"NAME\"])\n\t}\n\n\tvar results []*rspb.Release\n\tfor _, item := range list.Items {\n\t\trls, err := decodeRelease(string(item.Data[\"release\"]))\n\t\tif err != nil {\n\t\t\tsecrets.Log(\"query: failed to decode release: %s\", err)\n\t\t\tcontinue\n\t\t}\n\t\tresults = append(results, rls)\n\t}\n\treturn results, nil\n}"}, {"instruction": "// This validate will make sure targetPath:\n// 1. is not abs path\n// 2. does not contain any '..' elements\n// 3. does not start with '..'", "input": "go language", "output": "func validateLocalNonReservedPath(targetPath string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tallErrs = append(allErrs, validateLocalDescendingPath(targetPath, fldPath)...)\n\t// Don't report this error if the check for .. elements already caught it.\n\tif strings.HasPrefix(targetPath, \"..\") && !strings.HasPrefix(targetPath, \"../\") {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, targetPath, \"must not start with '..'\"))\n\t}\n\treturn allErrs\n}"}, {"instruction": "// NewOperationGenerator is returns instance of operationGenerator", "input": "go language", "output": "func NewOperationGenerator(kubeClient clientset.Interface,\n\tvolumePluginMgr *volume.VolumePluginMgr,\n\trecorder record.EventRecorder,\n\tcheckNodeCapabilitiesBeforeMount bool,\n\tblkUtil volumepathhandler.BlockVolumePathHandler) OperationGenerator {\n\n\treturn &operationGenerator{\n\t\tkubeClient:                       kubeClient,\n\t\tvolumePluginMgr:                  volumePluginMgr,\n\t\trecorder:                         recorder,\n\t\tcheckNodeCapabilitiesBeforeMount: checkNodeCapabilitiesBeforeMount,\n\t\tblkUtil:                          blkUtil,\n\t}\n}"}, {"instruction": "// LookupUser uses traditional local system files lookup (from libcontainer/user) on a username,\n// followed by a call to `getent` for supporting host configured non-files passwd and group dbs", "input": "go language", "output": "func LookupUser(username string) (user.User, error) {\n\t// first try a local system files lookup using existing capabilities\n\tusr, err := user.LookupUser(username)\n\tif err == nil {\n\t\treturn usr, nil\n\t}\n\t// local files lookup failed; attempt to call `getent` to query configured passwd dbs\n\tusr, err = getentUser(fmt.Sprintf(\"%s %s\", \"passwd\", username))\n\tif err != nil {\n\t\treturn user.User{}, err\n\t}\n\treturn usr, nil\n}"}, {"instruction": "// Config return a cloud controller manager config objective", "input": "go language", "output": "func (o *CloudControllerManagerOptions) Config(allControllers, disabledByDefaultControllers []string) (*cloudcontrollerconfig.Config, error) {\n\tif err := o.Validate(allControllers, disabledByDefaultControllers); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := o.SecureServing.MaybeDefaultWithSelfSignedCerts(\"localhost\", nil, []net.IP{net.ParseIP(\"127.0.0.1\")}); err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating self-signed certificates: %v\", err)\n\t}\n\n\tc := &cloudcontrollerconfig.Config{}\n\tif err := o.ApplyTo(c, CloudControllerManagerUserAgent); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// monitorLock is a long running routine to monitor a semaphore ownership\n// It closes the stopCh if we lose our slot.", "input": "go language", "output": "func (s *Semaphore) monitorLock(session string, stopCh chan struct{}) {\n\tdefer close(stopCh)\n\tkv := s.c.KV()\n\topts := &QueryOptions{RequireConsistent: true}\nWAIT:\n\tretries := s.opts.MonitorRetries\nRETRY:\n\tpairs, meta, err := kv.List(s.opts.Prefix, opts)\n\tif err != nil {\n\t\t// If configured we can try to ride out a brief Consul unavailability\n\t\t// by doing retries. Note that we have to attempt the retry in a non-\n\t\t// blocking fashion so that we have a clean place to reset the retry\n\t\t// counter if service is restored.\n\t\tif retries > 0 && IsRetryableError(err) {\n\t\t\ttime.Sleep(s.opts.MonitorRetryTime)\n\t\t\tretries--\n\t\t\topts.WaitIndex = 0\n\t\t\tgoto RETRY\n\t\t}\n\t\treturn\n\t}\n\tlockPair := s.findLock(pairs)\n\tlock, err := s.decodeLock(lockPair)\n\tif err != nil {\n\t\treturn\n\t}\n\ts.pruneDeadHolders(lock, pairs)\n\tif _, ok := lock.Holders[session]; ok {\n\t\topts.WaitIndex = meta.LastIndex\n\t\tgoto WAIT\n\t}\n}"}, {"instruction": "// startTableWorker launchs some background goroutines which pick tasks from workCh and execute the task.", "input": "go language", "output": "func (e *IndexLookUpExecutor) startTableWorker(ctx context.Context, workCh <-chan *lookupTableTask) {\n\tlookupConcurrencyLimit := e.ctx.GetSessionVars().IndexLookupConcurrency\n\te.tblWorkerWg.Add(lookupConcurrencyLimit)\n\tfor i := 0; i < lookupConcurrencyLimit; i++ {\n\t\tworker := &tableWorker{\n\t\t\tidxLookup:      e,\n\t\t\tworkCh:         workCh,\n\t\t\tfinished:       e.finished,\n\t\t\tbuildTblReader: e.buildTableReader,\n\t\t\tkeepOrder:      e.keepOrder,\n\t\t\thandleIdx:      e.handleIdx,\n\t\t\tisCheckOp:      e.isCheckOp,\n\t\t\tmemTracker:     memory.NewTracker(tableWorkerLabel, -1),\n\t\t}\n\t\tworker.memTracker.AttachTo(e.memTracker)\n\t\tctx1, cancel := context.WithCancel(ctx)\n\t\tgo func() {\n\t\t\tworker.pickAndExecTask(ctx1)\n\t\t\tcancel()\n\t\t\te.tblWorkerWg.Done()\n\t\t}()\n\t}\n}"}, {"instruction": "// newResponseRecorder returns an initialized responseRecorder.", "input": "go language", "output": "func newResponseRecorder(rw http.ResponseWriter, logger logrus.FieldLogger) responseRecorder {\n\trecorder := &responseRecorderWithoutCloseNotify{\n\t\tHeaderMap:      make(http.Header),\n\t\tBody:           new(bytes.Buffer),\n\t\tCode:           http.StatusOK,\n\t\tresponseWriter: rw,\n\t\tlogger:         logger,\n\t}\n\tif _, ok := rw.(http.CloseNotifier); ok {\n\t\treturn &responseRecorderWithCloseNotify{recorder}\n\t}\n\treturn recorder\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ObjectMetricStatus) DeepCopyInto(out *ObjectMetricStatus) {\n\t*out = *in\n\tout.Target = in.Target\n\tout.CurrentValue = in.CurrentValue.DeepCopy()\n\tif in.Selector != nil {\n\t\tin, out := &in.Selector, &out.Selector\n\t\t*out = new(v1.LabelSelector)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.AverageValue != nil {\n\t\tin, out := &in.AverageValue, &out.AverageValue\n\t\tx := (*in).DeepCopy()\n\t\t*out = &x\n\t}\n\treturn\n}"}, {"instruction": "// Register injects a new peer into the working set, or returns an error if the\n// peer is already known.\n//\n// The method also sets the starting throughput values of the new peer to the\n// average of all existing peers, to give it a realistic chance of being used\n// for data retrievals.", "input": "go language", "output": "func (ps *peerSet) Register(p *peerConnection) error {\n\t// Retrieve the current median RTT as a sane default\n\tp.rtt = ps.medianRTT()\n\n\t// Register the new peer with some meaningful defaults\n\tps.lock.Lock()\n\tif _, ok := ps.peers[p.id]; ok {\n\t\tps.lock.Unlock()\n\t\treturn errAlreadyRegistered\n\t}\n\tif len(ps.peers) > 0 {\n\t\tp.headerThroughput, p.blockThroughput, p.receiptThroughput, p.stateThroughput = 0, 0, 0, 0\n\n\t\tfor _, peer := range ps.peers {\n\t\t\tpeer.lock.RLock()\n\t\t\tp.headerThroughput += peer.headerThroughput\n\t\t\tp.blockThroughput += peer.blockThroughput\n\t\t\tp.receiptThroughput += peer.receiptThroughput\n\t\t\tp.stateThroughput += peer.stateThroughput\n\t\t\tpeer.lock.RUnlock()\n\t\t}\n\t\tp.headerThroughput /= float64(len(ps.peers))\n\t\tp.blockThroughput /= float64(len(ps.peers))\n\t\tp.receiptThroughput /= float64(len(ps.peers))\n\t\tp.stateThroughput /= float64(len(ps.peers))\n\t}\n\tps.peers[p.id] = p\n\tps.lock.Unlock()\n\n\tps.newPeerFeed.Send(p)\n\treturn nil\n}"}, {"instruction": "// FilterABIChanged is a free log retrieval operation binding the contract event 0xaa121bbeef5f32f5961a2a28966e769023910fc9479059ee3495d4c1a696efe3.\n//\n// Solidity: event ABIChanged(node indexed bytes32, contentType indexed uint256)", "input": "go language", "output": "func (_PublicResolver *PublicResolverFilterer) FilterABIChanged(opts *bind.FilterOpts, node [][32]byte, contentType []*big.Int) (*PublicResolverABIChangedIterator, error) {\n\n\tvar nodeRule []interface{}\n\tfor _, nodeItem := range node {\n\t\tnodeRule = append(nodeRule, nodeItem)\n\t}\n\tvar contentTypeRule []interface{}\n\tfor _, contentTypeItem := range contentType {\n\t\tcontentTypeRule = append(contentTypeRule, contentTypeItem)\n\t}\n\n\tlogs, sub, err := _PublicResolver.contract.FilterLogs(opts, \"ABIChanged\", nodeRule, contentTypeRule)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &PublicResolverABIChangedIterator{contract: _PublicResolver.contract, event: \"ABIChanged\", logs: logs, sub: sub}, nil\n}"}, {"instruction": "// formatProgress formats the progress information for a specified action.", "input": "go language", "output": "func (sf *jsonProgressFormatter) formatProgress(id, action string, progress *jsonmessage.JSONProgress, aux interface{}) []byte {\n\tif progress == nil {\n\t\tprogress = &jsonmessage.JSONProgress{}\n\t}\n\tvar auxJSON *json.RawMessage\n\tif aux != nil {\n\t\tauxJSONBytes, err := json.Marshal(aux)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\tauxJSON = new(json.RawMessage)\n\t\t*auxJSON = auxJSONBytes\n\t}\n\tb, err := json.Marshal(&jsonmessage.JSONMessage{\n\t\tStatus:          action,\n\t\tProgressMessage: progress.String(),\n\t\tProgress:        progress,\n\t\tID:              id,\n\t\tAux:             auxJSON,\n\t})\n\tif err != nil {\n\t\treturn nil\n\t}\n\treturn appendNewline(b)\n}"}, {"instruction": "// NewNodeID returns a new unique ID for a node to be added to g. The returned ID does\n// not become a valid ID in g until it is added to g.", "input": "go language", "output": "func (g *UndirectedGraph) NewNodeID() int {\n\tif len(g.nodes) == 0 {\n\t\treturn 0\n\t}\n\tif len(g.nodes) == maxInt {\n\t\tpanic(fmt.Sprintf(\"simple: cannot allocate node: no slot\"))\n\t}\n\n\tvar id int\n\tif g.freeIDs.Len() != 0 && g.freeIDs.TakeMin(&id) {\n\t\treturn id\n\t}\n\tif id = g.usedIDs.Max(); id < maxInt {\n\t\treturn id + 1\n\t}\n\tfor id = 0; id < maxInt; id++ {\n\t\tif !g.usedIDs.Has(id) {\n\t\t\treturn id\n\t\t}\n\t}\n\tpanic(\"unreachable\")\n}"}, {"instruction": "// handleEvents is used to process incoming user events", "input": "go language", "output": "func (a *Agent) handleEvents() {\n\tfor {\n\t\tselect {\n\t\tcase e := <-a.eventCh:\n\t\t\t// Decode the event\n\t\t\tmsg := new(UserEvent)\n\t\t\tif err := decodeMsgPack(e.Payload, msg); err != nil {\n\t\t\t\ta.logger.Printf(\"[ERR] agent: Failed to decode event: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tmsg.LTime = uint64(e.LTime)\n\n\t\t\t// Skip if we don't pass filtering\n\t\t\tif !a.shouldProcessUserEvent(msg) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Ingest the event\n\t\t\ta.ingestUserEvent(msg)\n\n\t\tcase <-a.shutdownCh:\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// SignCertificate creates a signed certificate based on a built-in template\n// and saves it in baseDir/name", "input": "go language", "output": "func (ca *CA) SignCertificate(baseDir, name string, ous, sans []string, pub *ecdsa.PublicKey,\n\tku x509.KeyUsage, eku []x509.ExtKeyUsage) (*x509.Certificate, error) {\n\n\ttemplate := x509Template()\n\ttemplate.KeyUsage = ku\n\ttemplate.ExtKeyUsage = eku\n\n\t//set the organization for the subject\n\tsubject := subjectTemplateAdditional(ca.Country, ca.Province, ca.Locality, ca.OrganizationalUnit, ca.StreetAddress, ca.PostalCode)\n\tsubject.CommonName = name\n\n\tsubject.OrganizationalUnit = append(subject.OrganizationalUnit, ous...)\n\n\ttemplate.Subject = subject\n\tfor _, san := range sans {\n\t\t// try to parse as an IP address first\n\t\tip := net.ParseIP(san)\n\t\tif ip != nil {\n\t\t\ttemplate.IPAddresses = append(template.IPAddresses, ip)\n\t\t} else {\n\t\t\ttemplate.DNSNames = append(template.DNSNames, san)\n\t\t}\n\t}\n\n\tcert, err := genCertificateECDSA(baseDir, name, &template, ca.SignCert,\n\t\tpub, ca.Signer)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn cert, nil\n}"}, {"instruction": "// DeleteExpectations deletes the UID set and invokes DeleteExpectations on the\n// underlying ControllerExpectationsInterface.", "input": "go language", "output": "func (u *UIDTrackingControllerExpectations) DeleteExpectations(rcKey string) {\n\tu.uidStoreLock.Lock()\n\tdefer u.uidStoreLock.Unlock()\n\n\tu.ControllerExpectationsInterface.DeleteExpectations(rcKey)\n\tif uidExp, exists, err := u.uidStore.GetByKey(rcKey); err == nil && exists {\n\t\tif err := u.uidStore.Delete(uidExp); err != nil {\n\t\t\tklog.V(2).Infof(\"Error deleting uid expectations for controller %v: %v\", rcKey, err)\n\t\t}\n\t}\n}"}, {"instruction": "// NodeSelectorRequirementsAsSelector converts the []NodeSelectorRequirement core type into a struct that implements\n// labels.Selector.", "input": "go language", "output": "func NodeSelectorRequirementsAsSelector(nsm []core.NodeSelectorRequirement) (labels.Selector, error) {\n\tif len(nsm) == 0 {\n\t\treturn labels.Nothing(), nil\n\t}\n\tselector := labels.NewSelector()\n\tfor _, expr := range nsm {\n\t\tvar op selection.Operator\n\t\tswitch expr.Operator {\n\t\tcase core.NodeSelectorOpIn:\n\t\t\top = selection.In\n\t\tcase core.NodeSelectorOpNotIn:\n\t\t\top = selection.NotIn\n\t\tcase core.NodeSelectorOpExists:\n\t\t\top = selection.Exists\n\t\tcase core.NodeSelectorOpDoesNotExist:\n\t\t\top = selection.DoesNotExist\n\t\tcase core.NodeSelectorOpGt:\n\t\t\top = selection.GreaterThan\n\t\tcase core.NodeSelectorOpLt:\n\t\t\top = selection.LessThan\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"%q is not a valid node selector operator\", expr.Operator)\n\t\t}\n\t\tr, err := labels.NewRequirement(expr.Key, op, expr.Values)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tselector = selector.Add(*r)\n\t}\n\treturn selector, nil\n}"}, {"instruction": "// ResourceList returns a resource list of this resource.", "input": "go language", "output": "func (r *Resource) ResourceList() v1.ResourceList {\n\tresult := v1.ResourceList{\n\t\tv1.ResourceCPU:              *resource.NewMilliQuantity(r.MilliCPU, resource.DecimalSI),\n\t\tv1.ResourceMemory:           *resource.NewQuantity(r.Memory, resource.BinarySI),\n\t\tv1.ResourcePods:             *resource.NewQuantity(int64(r.AllowedPodNumber), resource.BinarySI),\n\t\tv1.ResourceEphemeralStorage: *resource.NewQuantity(r.EphemeralStorage, resource.BinarySI),\n\t}\n\tfor rName, rQuant := range r.ScalarResources {\n\t\tif v1helper.IsHugePageResourceName(rName) {\n\t\t\tresult[rName] = *resource.NewQuantity(rQuant, resource.BinarySI)\n\t\t} else {\n\t\t\tresult[rName] = *resource.NewQuantity(rQuant, resource.DecimalSI)\n\t\t}\n\t}\n\treturn result\n}"}, {"instruction": "// MakeDataDir retrieves the currently requested data directory, terminating\n// if none (or the empty string) is specified. If the node is starting a testnet,\n// the a subdirectory of the specified datadir will be used.", "input": "go language", "output": "func MakeDataDir(ctx *cli.Context) string {\n\tif path := ctx.GlobalString(DataDirFlag.Name); path != \"\" {\n\t\tif ctx.GlobalBool(TestnetFlag.Name) {\n\t\t\treturn filepath.Join(path, \"testnet\")\n\t\t}\n\t\tif ctx.GlobalBool(RinkebyFlag.Name) {\n\t\t\treturn filepath.Join(path, \"rinkeby\")\n\t\t}\n\t\tif ctx.GlobalBool(GoerliFlag.Name) {\n\t\t\treturn filepath.Join(path, \"goerli\")\n\t\t}\n\t\treturn path\n\t}\n\tFatalf(\"Cannot determine default data directory, please set manually (--datadir)\")\n\treturn \"\"\n}"}, {"instruction": "// Send sends the request, and receives a response", "input": "go language", "output": "func (stub *ClientStub) Send(server string, conf common.Config, req *discovery.Request) (ServiceResponse, error) {\n\tcomm, err := comm.NewClient(conf.TLSConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsigner, err := signer.NewSigner(conf.SignerConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttimeout, cancel := context.WithTimeout(context.Background(), defaultTimeout)\n\tdefer cancel()\n\n\tdisc := discovery.NewClient(comm.NewDialer(server), signer.Sign, 0)\n\n\tresp, err := disc.Send(timeout, req, &AuthInfo{\n\t\tClientIdentity:    signer.Creator,\n\t\tClientTlsCertHash: comm.TLSCertHash,\n\t})\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed connecting to %s: %v\", server, err)\n\t}\n\treturn &response{\n\t\tResponse: resp,\n\t}, nil\n}"}, {"instruction": "// DecrypterVerify exposes how to get state to the ledger after having received keys for\n// decrypting (AES 256 bit key) and verifying (X9.62/SECG curve over a 256 bit prime field) that has been provided to the chaincode through the\n// transient field", "input": "go language", "output": "func (t *EncCC) DecrypterVerify(stub shim.ChaincodeStubInterface, args []string, decKey, verKey []byte) pb.Response {\n\t// create the decrypter/verify entity - we give it an ID, the bccsp instance and the keys\n\tent, err := entities.NewAES256EncrypterECDSASignerEntity(\"ID\", t.bccspInst, decKey, verKey)\n\tif err != nil {\n\t\treturn shim.Error(fmt.Sprintf(\"entities.NewAES256DecrypterEntity failed, err %s\", err))\n\t}\n\n\tif len(args) != 1 {\n\t\treturn shim.Error(\"Expected 1 parameters to function DecrypterVerify\")\n\t}\n\tkey := args[0]\n\n\t// here we decrypt the state associated to key and verify it\n\tcleartextValue, err := getStateDecryptAndVerify(stub, ent, key)\n\tif err != nil {\n\t\treturn shim.Error(fmt.Sprintf(\"getStateDecryptAndVerify failed, err %+v\", err))\n\t}\n\n\t// here we return the decrypted and verified value as a result\n\treturn shim.Success(cleartextValue)\n}"}, {"instruction": "// WaitForObservedDeployment polls for deployment to be updated so that deployment.Status.ObservedGeneration >= desiredGeneration.\n// Returns error if polling timesout.", "input": "go language", "output": "func WaitForObservedDeployment(getDeploymentFunc func() (*apps.Deployment, error), desiredGeneration int64, interval, timeout time.Duration) error {\n\t// TODO: This should take clientset.Interface when all code is updated to use clientset. Keeping it this way allows the function to be used by callers who have client.Interface.\n\treturn wait.PollImmediate(interval, timeout, func() (bool, error) {\n\t\tdeployment, err := getDeploymentFunc()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn deployment.Status.ObservedGeneration >= desiredGeneration, nil\n\t})\n}"}, {"instruction": "// NewServer initializes and configures a kubelet.Server object to handle HTTP requests.", "input": "go language", "output": "func NewServer(\n\thost HostInterface,\n\tresourceAnalyzer stats.ResourceAnalyzer,\n\tauth AuthInterface,\n\tenableDebuggingHandlers,\n\tenableContentionProfiling,\n\tredirectContainerStreaming bool,\n\tcriHandler http.Handler) Server {\n\tserver := Server{\n\t\thost:                       host,\n\t\tresourceAnalyzer:           resourceAnalyzer,\n\t\tauth:                       auth,\n\t\trestfulCont:                &filteringContainer{Container: restful.NewContainer()},\n\t\tredirectContainerStreaming: redirectContainerStreaming,\n\t}\n\tif auth != nil {\n\t\tserver.InstallAuthFilter()\n\t}\n\tserver.InstallDefaultHandlers()\n\tif enableDebuggingHandlers {\n\t\tserver.InstallDebuggingHandlers(criHandler)\n\t\tif enableContentionProfiling {\n\t\t\tgoruntime.SetBlockProfileRate(1)\n\t\t}\n\t} else {\n\t\tserver.InstallDebuggingDisabledHandlers()\n\t}\n\treturn server\n}"}, {"instruction": "// nextRotationDeadline returns a value for the threshold at which the\n// current certificate should be rotated, 80%+/-10% of the expiration of the\n// certificate.", "input": "go language", "output": "func (m *manager) nextRotationDeadline() time.Time {\n\t// forceRotation is not protected by locks\n\tif m.forceRotation {\n\t\tm.forceRotation = false\n\t\treturn time.Now()\n\t}\n\n\tm.certAccessLock.RLock()\n\tdefer m.certAccessLock.RUnlock()\n\n\tif !m.certSatisfiesTemplateLocked() {\n\t\treturn time.Now()\n\t}\n\n\tnotAfter := m.cert.Leaf.NotAfter\n\ttotalDuration := float64(notAfter.Sub(m.cert.Leaf.NotBefore))\n\tdeadline := m.cert.Leaf.NotBefore.Add(jitteryDuration(totalDuration))\n\n\tklog.V(2).Infof(\"Certificate expiration is %v, rotation deadline is %v\", notAfter, deadline)\n\tif m.certificateExpiration != nil {\n\t\tm.certificateExpiration.Set(float64(notAfter.Unix()))\n\t}\n\treturn deadline\n}"}, {"instruction": "// GetNetworkDriverList returns the list of plugins drivers\n// registered for network.", "input": "go language", "output": "func (daemon *Daemon) GetNetworkDriverList() []string {\n\tif !daemon.NetworkControllerEnabled() {\n\t\treturn nil\n\t}\n\n\tpluginList := daemon.netController.BuiltinDrivers()\n\n\tmanagedPlugins := daemon.PluginStore.GetAllManagedPluginsByCap(driverapi.NetworkPluginEndpointType)\n\n\tfor _, plugin := range managedPlugins {\n\t\tpluginList = append(pluginList, plugin.Name())\n\t}\n\n\tpluginMap := make(map[string]bool)\n\tfor _, plugin := range pluginList {\n\t\tpluginMap[plugin] = true\n\t}\n\n\tnetworks := daemon.netController.Networks()\n\n\tfor _, network := range networks {\n\t\tif !pluginMap[network.Type()] {\n\t\t\tpluginList = append(pluginList, network.Type())\n\t\t\tpluginMap[network.Type()] = true\n\t\t}\n\t}\n\n\tsort.Strings(pluginList)\n\n\treturn pluginList\n}"}, {"instruction": "// ParseHost and set defaults for a Daemon host string.\n// defaultToTLS is preferred over defaultToUnixXDG.", "input": "go language", "output": "func ParseHost(defaultToTLS, defaultToUnixXDG bool, val string) (string, error) {\n\thost := strings.TrimSpace(val)\n\tif host == \"\" {\n\t\tif defaultToTLS {\n\t\t\thost = DefaultTLSHost\n\t\t} else if defaultToUnixXDG {\n\t\t\truntimeDir, err := homedir.GetRuntimeDir()\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\t\t\tsocket := filepath.Join(runtimeDir, \"docker.sock\")\n\t\t\thost = \"unix://\" + socket\n\t\t} else {\n\t\t\thost = DefaultHost\n\t\t}\n\t} else {\n\t\tvar err error\n\t\thost, err = parseDaemonHost(host)\n\t\tif err != nil {\n\t\t\treturn val, err\n\t\t}\n\t}\n\treturn host, nil\n}"}, {"instruction": "// getCgroupConfig returns a ResourceConfig object that can be used to create or update cgroups via CgroupManager interface.", "input": "go language", "output": "func getCgroupConfig(rl v1.ResourceList) *ResourceConfig {\n\t// TODO(vishh): Set CPU Quota if necessary.\n\tif rl == nil {\n\t\treturn nil\n\t}\n\tvar rc ResourceConfig\n\tif q, exists := rl[v1.ResourceMemory]; exists {\n\t\t// Memory is defined in bytes.\n\t\tval := q.Value()\n\t\trc.Memory = &val\n\t}\n\tif q, exists := rl[v1.ResourceCPU]; exists {\n\t\t// CPU is defined in milli-cores.\n\t\tval := MilliCPUToShares(q.MilliValue())\n\t\trc.CpuShares = &val\n\t}\n\tif q, exists := rl[pidlimit.PIDs]; exists {\n\t\tval := q.Value()\n\t\trc.PidsLimit = &val\n\t}\n\trc.HugePageLimit = HugePageLimits(rl)\n\n\treturn &rc\n}"}, {"instruction": "// AddFlags adds flags related to GarbageCollectorController for controller manager to the specified FlagSet.", "input": "go language", "output": "func (o *GarbageCollectorControllerOptions) AddFlags(fs *pflag.FlagSet) {\n\tif o == nil {\n\t\treturn\n\t}\n\n\tfs.Int32Var(&o.ConcurrentGCSyncs, \"concurrent-gc-syncs\", o.ConcurrentGCSyncs, \"The number of garbage collector workers that are allowed to sync concurrently.\")\n\tfs.BoolVar(&o.EnableGarbageCollector, \"enable-garbage-collector\", o.EnableGarbageCollector, \"Enables the generic garbage collector. MUST be synced with the corresponding flag of the kube-apiserver.\")\n}"}, {"instruction": "// LocalChangedFiles returns a paginated list of currently needed files in\n// progress, queued, and to be queued on next puller iteration, as well as the\n// total number of files currently needed.", "input": "go language", "output": "func (m *model) LocalChangedFiles(folder string, page, perpage int) []db.FileInfoTruncated {\n\tm.fmut.RLock()\n\trf, ok := m.folderFiles[folder]\n\tfcfg := m.folderCfgs[folder]\n\tm.fmut.RUnlock()\n\n\tif !ok {\n\t\treturn nil\n\t}\n\tif fcfg.Type != config.FolderTypeReceiveOnly {\n\t\treturn nil\n\t}\n\tif rf.ReceiveOnlyChangedSize().TotalItems() == 0 {\n\t\treturn nil\n\t}\n\n\tfiles := make([]db.FileInfoTruncated, 0, perpage)\n\n\tskip := (page - 1) * perpage\n\tget := perpage\n\n\trf.WithHaveTruncated(protocol.LocalDeviceID, func(f db.FileIntf) bool {\n\t\tif !f.IsReceiveOnlyChanged() {\n\t\t\treturn true\n\t\t}\n\t\tif skip > 0 {\n\t\t\tskip--\n\t\t\treturn true\n\t\t}\n\t\tft := f.(db.FileInfoTruncated)\n\t\tfiles = append(files, ft)\n\t\tget--\n\t\treturn get > 0\n\t})\n\n\treturn files\n}"}, {"instruction": "// findMaxScores returns the indexes of nodes in the \"priorityList\" that has the highest \"Score\".", "input": "go language", "output": "func findMaxScores(priorityList schedulerapi.HostPriorityList) []int {\n\tmaxScoreIndexes := make([]int, 0, len(priorityList)/2)\n\tmaxScore := priorityList[0].Score\n\tfor i, hp := range priorityList {\n\t\tif hp.Score > maxScore {\n\t\t\tmaxScore = hp.Score\n\t\t\tmaxScoreIndexes = maxScoreIndexes[:0]\n\t\t\tmaxScoreIndexes = append(maxScoreIndexes, i)\n\t\t} else if hp.Score == maxScore {\n\t\t\tmaxScoreIndexes = append(maxScoreIndexes, i)\n\t\t}\n\t}\n\treturn maxScoreIndexes\n}"}, {"instruction": "// checkName checks the provided name against the request", "input": "go language", "output": "func checkName(obj runtime.Object, name, namespace string, namer ScopeNamer) error {\n\tobjNamespace, objName, err := namer.ObjectName(obj)\n\tif err != nil {\n\t\treturn errors.NewBadRequest(fmt.Sprintf(\n\t\t\t\"the name of the object (%s based on URL) was undeterminable: %v\", name, err))\n\t}\n\tif objName != name {\n\t\treturn errors.NewBadRequest(fmt.Sprintf(\n\t\t\t\"the name of the object (%s) does not match the name on the URL (%s)\", objName, name))\n\t}\n\tif len(namespace) > 0 {\n\t\tif len(objNamespace) > 0 && objNamespace != namespace {\n\t\t\treturn errors.NewBadRequest(fmt.Sprintf(\n\t\t\t\t\"the namespace of the object (%s) does not match the namespace on the request (%s)\", objNamespace, namespace))\n\t\t}\n\t}\n\n\treturn nil\n}"}, {"instruction": "//Swap implements the protocols.Balance interface\n//Add is the (sole) accounting function", "input": "go language", "output": "func (s *Swap) Add(amount int64, peer *protocols.Peer) (err error) {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\t//load existing balances from the state store\n\terr = s.loadState(peer)\n\tif err != nil && err != state.ErrNotFound {\n\t\treturn\n\t}\n\t//adjust the balance\n\t//if amount is negative, it will decrease, otherwise increase\n\ts.balances[peer.ID()] += amount\n\t//save the new balance to the state store\n\tpeerBalance := s.balances[peer.ID()]\n\terr = s.stateStore.Put(peer.ID().String(), &peerBalance)\n\n\tlog.Debug(fmt.Sprintf(\"balance for peer %s: %s\", peer.ID().String(), strconv.FormatInt(peerBalance, 10)))\n\treturn err\n}"}, {"instruction": "// AttachFileDevice takes a path to a regular file and makes it available as an\n// attached block device.", "input": "go language", "output": "func (v VolumePathHandler) AttachFileDevice(path string) (string, error) {\n\tblockDevicePath, err := v.GetLoopDevice(path)\n\tif err != nil && err.Error() != ErrDeviceNotFound {\n\t\treturn \"\", err\n\t}\n\n\t// If no existing loop device for the path, create one\n\tif blockDevicePath == \"\" {\n\t\tklog.V(4).Infof(\"Creating device for path: %s\", path)\n\t\tblockDevicePath, err = makeLoopDevice(path)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\treturn blockDevicePath, nil\n}"}, {"instruction": "// New creates a new Cluster instance using provided config.", "input": "go language", "output": "func New(config Config) (*Cluster, error) {\n\troot := filepath.Join(config.Root, swarmDirName)\n\tif err := os.MkdirAll(root, 0700); err != nil {\n\t\treturn nil, err\n\t}\n\tif config.RuntimeRoot == \"\" {\n\t\tconfig.RuntimeRoot = root\n\t}\n\tif config.RaftHeartbeatTick == 0 {\n\t\tconfig.RaftHeartbeatTick = 1\n\t}\n\tif config.RaftElectionTick == 0 {\n\t\t// 10X heartbeat tick is the recommended ratio according to etcd docs.\n\t\tconfig.RaftElectionTick = 10 * config.RaftHeartbeatTick\n\t}\n\n\tif err := os.MkdirAll(config.RuntimeRoot, 0700); err != nil {\n\t\treturn nil, err\n\t}\n\tc := &Cluster{\n\t\troot:        root,\n\t\tconfig:      config,\n\t\tconfigEvent: make(chan lncluster.ConfigEventType, 10),\n\t\truntimeRoot: config.RuntimeRoot,\n\t\tattachers:   make(map[string]*attacher),\n\t\twatchStream: config.WatchStream,\n\t}\n\treturn c, nil\n}"}, {"instruction": "// clearAttachableNetworks removes the attachable networks\n// after disconnecting any connected container", "input": "go language", "output": "func (daemon *Daemon) clearAttachableNetworks() {\n\tfor _, n := range daemon.getAllNetworks() {\n\t\tif !n.Info().Attachable() {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, ep := range n.Endpoints() {\n\t\t\tepInfo := ep.Info()\n\t\t\tif epInfo == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tsb := epInfo.Sandbox()\n\t\t\tif sb == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcontainerID := sb.ContainerID()\n\t\t\tif err := daemon.DisconnectContainerFromNetwork(containerID, n.ID(), true); err != nil {\n\t\t\t\tlogrus.Warnf(\"Failed to disconnect container %s from swarm network %s on cluster leave: %v\",\n\t\t\t\t\tcontainerID, n.Name(), err)\n\t\t\t}\n\t\t}\n\t\tif err := daemon.DeleteManagedNetwork(n.ID()); err != nil {\n\t\t\tlogrus.Warnf(\"Failed to remove swarm network %s on cluster leave: %v\", n.Name(), err)\n\t\t}\n\t}\n}"}, {"instruction": "// Injectable for testing", "input": "go language", "output": "func processRoutes(routeTable network.RouteTable, exists bool, err error) ([]*cloudprovider.Route, error) {\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !exists {\n\t\treturn []*cloudprovider.Route{}, nil\n\t}\n\n\tvar kubeRoutes []*cloudprovider.Route\n\tif routeTable.RouteTablePropertiesFormat != nil && routeTable.Routes != nil {\n\t\tkubeRoutes = make([]*cloudprovider.Route, len(*routeTable.Routes))\n\t\tfor i, route := range *routeTable.Routes {\n\t\t\tinstance := mapRouteNameToNodeName(*route.Name)\n\t\t\tcidr := *route.AddressPrefix\n\t\t\tklog.V(10).Infof(\"ListRoutes: * instance=%q, cidr=%q\", instance, cidr)\n\n\t\t\tkubeRoutes[i] = &cloudprovider.Route{\n\t\t\t\tName:            *route.Name,\n\t\t\t\tTargetNode:      instance,\n\t\t\t\tDestinationCIDR: cidr,\n\t\t\t}\n\t\t}\n\t}\n\n\tklog.V(10).Info(\"ListRoutes: FINISH\")\n\treturn kubeRoutes, nil\n}"}, {"instruction": "// GetOrganizationalUnits returns the OU for this instance", "input": "go language", "output": "func (id *identity) GetOrganizationalUnits() []*OUIdentifier {\n\tif id.cert == nil {\n\t\treturn nil\n\t}\n\n\tcid, err := id.msp.getCertificationChainIdentifier(id)\n\tif err != nil {\n\t\tmspIdentityLogger.Errorf(\"Failed getting certification chain identifier for [%v]: [%+v]\", id, err)\n\n\t\treturn nil\n\t}\n\n\tres := []*OUIdentifier{}\n\tfor _, unit := range id.cert.Subject.OrganizationalUnit {\n\t\tres = append(res, &OUIdentifier{\n\t\t\tOrganizationalUnitIdentifier: unit,\n\t\t\tCertifiersIdentifier:         cid,\n\t\t})\n\t}\n\n\treturn res\n}"}, {"instruction": "// worker processes the queue of namespace objects.\n// Each namespace can be in the queue at most once.\n// The system ensures that no two workers can process\n// the same namespace at the same time.", "input": "go language", "output": "func (nm *NamespaceController) worker() {\n\tworkFunc := func() bool {\n\t\tkey, quit := nm.queue.Get()\n\t\tif quit {\n\t\t\treturn true\n\t\t}\n\t\tdefer nm.queue.Done(key)\n\n\t\terr := nm.syncNamespaceFromKey(key.(string))\n\t\tif err == nil {\n\t\t\t// no error, forget this entry and return\n\t\t\tnm.queue.Forget(key)\n\t\t\treturn false\n\t\t}\n\n\t\tif estimate, ok := err.(*deletion.ResourcesRemainingError); ok {\n\t\t\tt := estimate.Estimate/2 + 1\n\t\t\tklog.V(4).Infof(\"Content remaining in namespace %s, waiting %d seconds\", key, t)\n\t\t\tnm.queue.AddAfter(key, time.Duration(t)*time.Second)\n\t\t} else {\n\t\t\t// rather than wait for a full resync, re-add the namespace to the queue to be processed\n\t\t\tnm.queue.AddRateLimited(key)\n\t\t\tutilruntime.HandleError(err)\n\t\t}\n\t\treturn false\n\t}\n\n\tfor {\n\t\tquit := workFunc()\n\n\t\tif quit {\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// Receive is called to deposit the latest cheque to the incoming Inbox.\n// The given promise must be a *Cheque.", "input": "go language", "output": "func (i *Inbox) Receive(promise swap.Promise) (*big.Int, error) {\n\tch := promise.(*Cheque)\n\n\tdefer i.lock.Unlock()\n\ti.lock.Lock()\n\n\tvar sum *big.Int\n\tif i.cheque == nil {\n\t\t// the sum is checked against the blockchain once a cheque is received\n\t\ttally, err := i.session.Sent(i.beneficiary)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"inbox: error calling backend to set amount: %v\", err)\n\t\t}\n\t\tsum = tally\n\t} else {\n\t\tsum = i.cheque.Amount\n\t}\n\n\tamount, err := ch.Verify(i.signer, i.contract, i.beneficiary, sum)\n\tvar uncashed *big.Int\n\tif err == nil {\n\t\ti.cheque = ch\n\n\t\tif i.maxUncashed != nil {\n\t\t\tuncashed = new(big.Int).Sub(ch.Amount, i.cashed)\n\t\t\tif i.maxUncashed.Cmp(uncashed) < 0 {\n\t\t\t\ti.Cash()\n\t\t\t}\n\t\t}\n\t\ti.log.Trace(\"Received cheque in chequebook inbox\", \"amount\", amount, \"uncashed\", uncashed)\n\t}\n\n\treturn amount, err\n}"}, {"instruction": "// GetUnlockKey returns the unlock key for the swarm.", "input": "go language", "output": "func (c *Cluster) GetUnlockKey() (string, error) {\n\tvar resp *swarmapi.GetUnlockKeyResponse\n\tif err := c.lockedManagerAction(func(ctx context.Context, state nodeState) error {\n\t\tclient := swarmapi.NewCAClient(state.grpcConn)\n\n\t\tr, err := client.GetUnlockKey(ctx, &swarmapi.GetUnlockKeyRequest{})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tresp = r\n\t\treturn nil\n\t}); err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(resp.UnlockKey) == 0 {\n\t\t// no key\n\t\treturn \"\", nil\n\t}\n\treturn encryption.HumanReadableKey(resp.UnlockKey), nil\n}"}, {"instruction": "// evalDuration evals a builtinAddDurationAndStringSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_addtime", "input": "go language", "output": "func (b *builtinAddDurationAndStringSig) evalDuration(row chunk.Row) (types.Duration, bool, error) {\n\targ0, isNull, err := b.args[0].EvalDuration(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn types.ZeroDuration, isNull, err\n\t}\n\ts, isNull, err := b.args[1].EvalString(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn types.ZeroDuration, isNull, err\n\t}\n\tif !isDuration(s) {\n\t\treturn types.ZeroDuration, true, nil\n\t}\n\targ1, err := types.ParseDuration(b.ctx.GetSessionVars().StmtCtx, s, types.GetFsp(s))\n\tif err != nil {\n\t\treturn types.ZeroDuration, true, err\n\t}\n\tresult, err := arg0.Add(arg1)\n\tif err != nil {\n\t\treturn types.ZeroDuration, true, err\n\t}\n\treturn result, false, nil\n}"}, {"instruction": "// GraphNodeEvalable", "input": "go language", "output": "func (n *NodePlannableResourceInstance) EvalTree() EvalNode {\n\taddr := n.ResourceInstanceAddr()\n\n\t// State still uses legacy-style internal ids, so we need to shim to get\n\t// a suitable key to use.\n\tstateId := NewLegacyResourceInstanceAddress(addr).stateId()\n\n\t// Determine the dependencies for the state.\n\tstateDeps := n.StateReferences()\n\n\t// Eval info is different depending on what kind of resource this is\n\tswitch addr.Resource.Resource.Mode {\n\tcase addrs.ManagedResourceMode:\n\t\treturn n.evalTreeManagedResource(addr, stateId, stateDeps)\n\tcase addrs.DataResourceMode:\n\t\treturn n.evalTreeDataResource(addr, stateId, stateDeps)\n\tdefault:\n\t\tpanic(fmt.Errorf(\"unsupported resource mode %s\", n.Config.Mode))\n\t}\n}"}, {"instruction": "// Create creates a volume with the given name and driver\n// If the volume needs to be created with a reference to prevent race conditions\n// with volume cleanup, make sure to use the `CreateWithReference` option.", "input": "go language", "output": "func (s *VolumeStore) Create(ctx context.Context, name, driverName string, createOpts ...opts.CreateOption) (volume.Volume, error) {\n\tvar cfg opts.CreateConfig\n\tfor _, o := range createOpts {\n\t\to(&cfg)\n\t}\n\n\tname = normalizeVolumeName(name)\n\ts.locks.Lock(name)\n\tdefer s.locks.Unlock(name)\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\tv, err := s.create(ctx, name, driverName, cfg.Options, cfg.Labels)\n\tif err != nil {\n\t\tif _, ok := err.(*OpErr); ok {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn nil, &OpErr{Err: err, Name: name, Op: \"create\"}\n\t}\n\n\ts.setNamed(v, cfg.Reference)\n\treturn v, nil\n}"}, {"instruction": "// GET /api/teams/:teamId/members", "input": "go language", "output": "func GetTeamMembers(c *m.ReqContext) Response {\n\tquery := m.GetTeamMembersQuery{OrgId: c.OrgId, TeamId: c.ParamsInt64(\":teamId\")}\n\n\tif err := bus.Dispatch(&query); err != nil {\n\t\treturn Error(500, \"Failed to get Team Members\", err)\n\t}\n\n\tfor _, member := range query.Result {\n\t\tmember.AvatarUrl = dtos.GetGravatarUrl(member.Email)\n\t\tmember.Labels = []string{}\n\n\t\tif setting.IsEnterprise && setting.LdapEnabled && member.External {\n\t\t\tmember.Labels = append(member.Labels, \"LDAP\")\n\t\t}\n\t}\n\n\treturn JSON(200, query.Result)\n}"}, {"instruction": "// wantsCompressedResponse reads the Accept-Encoding header to see if and which encoding is requested.", "input": "go language", "output": "func wantsCompressedResponse(req *http.Request) (bool, string) {\n\t// don't compress watches\n\tctx := req.Context()\n\tinfo, ok := request.RequestInfoFrom(ctx)\n\tif !ok {\n\t\treturn false, \"\"\n\t}\n\tif !info.IsResourceRequest {\n\t\treturn false, \"\"\n\t}\n\tif info.Verb == \"watch\" {\n\t\treturn false, \"\"\n\t}\n\theader := req.Header.Get(headerAcceptEncoding)\n\tgi := strings.Index(header, encodingGzip)\n\tzi := strings.Index(header, encodingDeflate)\n\t// use in order of appearance\n\tswitch {\n\tcase gi == -1:\n\t\treturn zi != -1, encodingDeflate\n\tcase zi == -1:\n\t\treturn gi != -1, encodingGzip\n\tcase gi < zi:\n\t\treturn true, encodingGzip\n\tdefault:\n\t\treturn true, encodingDeflate\n\t}\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *ShowExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\treq.GrowAndReset(e.maxChunkSize)\n\tif e.result == nil {\n\t\te.result = e.newFirstChunk()\n\t\terr := e.fetchAll()\n\t\tif err != nil {\n\t\t\treturn errors.Trace(err)\n\t\t}\n\t\titer := chunk.NewIterator4Chunk(e.result)\n\t\tfor colIdx := 0; colIdx < e.Schema().Len(); colIdx++ {\n\t\t\tretType := e.Schema().Columns[colIdx].RetType\n\t\t\tif !types.IsTypeVarchar(retType.Tp) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor row := iter.Begin(); row != iter.End(); row = iter.Next() {\n\t\t\t\tif valLen := len(row.GetString(colIdx)); retType.Flen < valLen {\n\t\t\t\t\tretType.Flen = valLen\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif e.cursor >= e.result.NumRows() {\n\t\treturn nil\n\t}\n\tnumCurBatch := mathutil.Min(req.Capacity(), e.result.NumRows()-e.cursor)\n\treq.Append(e.result, e.cursor, e.cursor+numCurBatch)\n\te.cursor += numCurBatch\n\treturn nil\n}"}, {"instruction": "// NewREST returns a RESTStorage object that will work against pod disruption budgets.", "input": "go language", "output": "func NewREST(optsGetter generic.RESTOptionsGetter) *REST {\n\tstore := &genericregistry.Store{\n\t\tNewFunc:     func() runtime.Object { return &admissionregistration.ValidatingWebhookConfiguration{} },\n\t\tNewListFunc: func() runtime.Object { return &admissionregistration.ValidatingWebhookConfigurationList{} },\n\t\tObjectNameFunc: func(obj runtime.Object) (string, error) {\n\t\t\treturn obj.(*admissionregistration.ValidatingWebhookConfiguration).Name, nil\n\t\t},\n\t\tDefaultQualifiedResource: admissionregistration.Resource(\"validatingwebhookconfigurations\"),\n\n\t\tCreateStrategy: validatingwebhookconfiguration.Strategy,\n\t\tUpdateStrategy: validatingwebhookconfiguration.Strategy,\n\t\tDeleteStrategy: validatingwebhookconfiguration.Strategy,\n\t}\n\toptions := &generic.StoreOptions{RESTOptions: optsGetter}\n\tif err := store.CompleteWithOptions(options); err != nil {\n\t\tpanic(err) // TODO: Propagate error up\n\t}\n\treturn &REST{store}\n}"}, {"instruction": "// Func gets the translate func for the given language, or for the default\n// configured language if not found.", "input": "go language", "output": "func (t Translator) Func(lang string) bundle.TranslateFunc {\n\tif f, ok := t.translateFuncs[lang]; ok {\n\t\treturn f\n\t}\n\tt.logger.INFO.Printf(\"Translation func for language %v not found, use default.\", lang)\n\tif f, ok := t.translateFuncs[t.cfg.GetString(\"defaultContentLanguage\")]; ok {\n\t\treturn f\n\t}\n\tt.logger.INFO.Println(\"i18n not initialized; if you need string translations, check that you have a bundle in /i18n that matches the site language or the default language.\")\n\treturn func(translationID string, args ...interface{}) string {\n\t\treturn \"\"\n\t}\n\n}"}, {"instruction": "// ValidateUpdate is the default update validation for an end user.", "input": "go language", "output": "func (jobStrategy) ValidateUpdate(ctx context.Context, obj, old runtime.Object) field.ErrorList {\n\tjob := obj.(*batch.Job)\n\toldJob := old.(*batch.Job)\n\tvalidationErrorList := validation.ValidateJob(job)\n\tupdateErrorList := validation.ValidateJobUpdate(job, oldJob)\n\tupdateErrorList = append(updateErrorList, corevalidation.ValidateConditionalPodTemplate(&job.Spec.Template, &oldJob.Spec.Template, field.NewPath(\"spec.template\"))...)\n\treturn append(validationErrorList, updateErrorList...)\n}"}, {"instruction": "// getResourceNamesForGroup is a private method for getting the canonical names for each resource to build in an api group", "input": "go language", "output": "func getResourceNamesForGroup(apiPrefix string, apiGroupInfo *APIGroupInfo, pathsToIgnore openapiutil.Trie) ([]string, error) {\n\t// Get the canonical names of every resource we need to build in this api group\n\tresourceNames := make([]string, 0)\n\tfor _, groupVersion := range apiGroupInfo.PrioritizedVersions {\n\t\tfor resource, storage := range apiGroupInfo.VersionedResourcesStorageMap[groupVersion.Version] {\n\t\t\tpath := gpath.Join(apiPrefix, groupVersion.Group, groupVersion.Version, resource)\n\t\t\tif !pathsToIgnore.HasPrefix(path) {\n\t\t\t\tkind, err := genericapi.GetResourceKind(groupVersion, storage, apiGroupInfo.Scheme)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tsampleObject, err := apiGroupInfo.Scheme.New(kind)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tname := openapiutil.GetCanonicalTypeName(sampleObject)\n\t\t\t\tresourceNames = append(resourceNames, name)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn resourceNames, nil\n}"}, {"instruction": "// tryAccessIdx tries to find index entry. If found then increments the access\n// count for garbage collection and returns the index entry and true for found,\n// otherwise returns nil and false.", "input": "go language", "output": "func (s *LDBStore) tryAccessIdx(addr Address, po uint8) (*dpaDBIndex, bool) {\n\tikey := getIndexKey(addr)\n\tidata, err := s.db.Get(ikey)\n\tif err != nil {\n\t\treturn nil, false\n\t}\n\n\tindex := new(dpaDBIndex)\n\tdecodeIndex(idata, index)\n\toldGCIdxKey := getGCIdxKey(index)\n\ts.batch.Put(keyAccessCnt, U64ToBytes(s.accessCnt))\n\tindex.Access = s.accessCnt\n\tidata = encodeIndex(index)\n\ts.accessCnt++\n\ts.batch.Put(ikey, idata)\n\tnewGCIdxKey := getGCIdxKey(index)\n\tnewGCIdxData := getGCIdxValue(index, po, ikey[1:])\n\ts.batch.Delete(oldGCIdxKey)\n\ts.batch.Put(newGCIdxKey, newGCIdxData)\n\tselect {\n\tcase s.batchesC <- struct{}{}:\n\tdefault:\n\t}\n\treturn index, true\n}"}, {"instruction": "// evalTime evals DATE(expr).\n// See https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_date", "input": "go language", "output": "func (b *builtinDateSig) evalTime(row chunk.Row) (types.Time, bool, error) {\n\texpr, isNull, err := b.args[0].EvalTime(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn types.Time{}, true, handleInvalidTimeError(b.ctx, err)\n\t}\n\n\tif expr.IsZero() {\n\t\treturn types.Time{}, true, handleInvalidTimeError(b.ctx, types.ErrIncorrectDatetimeValue.GenWithStackByArgs(expr.String()))\n\t}\n\n\texpr.Time = types.FromDate(expr.Time.Year(), expr.Time.Month(), expr.Time.Day(), 0, 0, 0, 0)\n\texpr.Type = mysql.TypeDate\n\treturn expr, false, nil\n}"}, {"instruction": "// NodeKeys returns a paginated list of keys on a node with provided address.", "input": "go language", "output": "func (s *GlobalStore) NodeKeys(addr common.Address, startKey []byte, limit int) (keys mock.Keys, err error) {\n\ts.mu.RLock()\n\tdefer s.mu.RUnlock()\n\n\tvar i int\n\tif startKey != nil {\n\t\ti, _ = s.nodeKeyIndex(addr, startKey)\n\t}\n\ttotal := len(s.nodeKeys[addr])\n\tmax := maxIndex(i, limit, total)\n\tkeys.Keys = make([][]byte, 0, max-i)\n\tfor ; i < max; i++ {\n\t\tkeys.Keys = append(keys.Keys, append([]byte(nil), s.nodeKeys[addr][i]...))\n\t}\n\tif total > max {\n\t\tkeys.Next = s.nodeKeys[addr][max]\n\t}\n\treturn keys, nil\n}"}, {"instruction": "// DoMakeRShared is common implementation of MakeRShared on Linux. It checks if\n// path is shared and bind-mounts it as rshared if needed. mountCmd and\n// mountArgs are expected to contain mount-like command, DoMakeRShared will add\n// '--bind <path> <path>' and '--make-rshared <path>' to mountArgs.", "input": "go language", "output": "func DoMakeRShared(path string, mountInfoFilename string) error {\n\tshared, err := isShared(path, mountInfoFilename)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif shared {\n\t\tklog.V(4).Infof(\"Directory %s is already on a shared mount\", path)\n\t\treturn nil\n\t}\n\n\tklog.V(2).Infof(\"Bind-mounting %q with shared mount propagation\", path)\n\t// mount --bind /var/lib/kubelet /var/lib/kubelet\n\tif err := syscall.Mount(path, path, \"\" /*fstype*/, syscall.MS_BIND, \"\" /*data*/); err != nil {\n\t\treturn fmt.Errorf(\"failed to bind-mount %s: %v\", path, err)\n\t}\n\n\t// mount --make-rshared /var/lib/kubelet\n\tif err := syscall.Mount(path, path, \"\" /*fstype*/, syscall.MS_SHARED|syscall.MS_REC, \"\" /*data*/); err != nil {\n\t\treturn fmt.Errorf(\"failed to make %s rshared: %v\", path, err)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// nodeCheckTxn is used as the inner method to handle reading a health check\n// from the state store.", "input": "go language", "output": "func (s *Store) getNodeCheckTxn(tx *memdb.Txn, nodeName string, checkID types.CheckID) (uint64, *structs.HealthCheck, error) {\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, \"checks\")\n\n\t// Return the check.\n\tcheck, err := tx.First(\"checks\", \"id\", nodeName, string(checkID))\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed check lookup: %s\", err)\n\t}\n\n\tif check != nil {\n\t\treturn idx, check.(*structs.HealthCheck), nil\n\t}\n\treturn idx, nil, nil\n}"}, {"instruction": "// Filter iterates over the list of transactions and removes all of them for which\n// the specified function evaluates to true.", "input": "go language", "output": "func (m *txSortedMap) Filter(filter func(*types.Transaction) bool) types.Transactions {\n\tvar removed types.Transactions\n\n\t// Collect all the transactions to filter out\n\tfor nonce, tx := range m.items {\n\t\tif filter(tx) {\n\t\t\tremoved = append(removed, tx)\n\t\t\tdelete(m.items, nonce)\n\t\t}\n\t}\n\t// If transactions were removed, the heap and cache are ruined\n\tif len(removed) > 0 {\n\t\t*m.index = make([]uint64, 0, len(m.items))\n\t\tfor nonce := range m.items {\n\t\t\t*m.index = append(*m.index, nonce)\n\t\t}\n\t\theap.Init(m.index)\n\n\t\tm.cache = nil\n\t}\n\treturn removed\n}"}, {"instruction": "// Set associates key with value.", "input": "go language", "output": "func (m *memDbBuffer) Set(k Key, v []byte) error {\n\tif len(v) == 0 {\n\t\treturn errors.Trace(ErrCannotSetNilValue)\n\t}\n\tif len(k)+len(v) > m.entrySizeLimit {\n\t\treturn ErrEntryTooLarge.GenWithStackByArgs(m.entrySizeLimit, len(k)+len(v))\n\t}\n\n\terr := m.db.Put(k, v)\n\tif m.Size() > m.bufferSizeLimit {\n\t\treturn ErrTxnTooLarge.GenWithStack(\"transaction too large, size:%d\", m.Size())\n\t}\n\tif m.Len() > int(m.bufferLenLimit) {\n\t\treturn ErrTxnTooLarge.GenWithStack(\"transaction too large, len:%d\", m.Len())\n\t}\n\treturn errors.Trace(err)\n}"}, {"instruction": "// processPorts returns the configured port.\n// An explicitly specified port is preferred. If none is specified, it selects\n// one of the available port. The first such found port is returned unless an\n// optional index is provided.", "input": "go language", "output": "func processPorts(app marathon.Application, task marathon.Task, serverPort string) (int, error) {\n\tif len(serverPort) > 0 && !strings.HasPrefix(serverPort, \"index:\") {\n\t\tport, err := strconv.Atoi(serverPort)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\tif port <= 0 {\n\t\t\treturn 0, fmt.Errorf(\"explicitly specified port %d must be greater than zero\", port)\n\t\t} else if port > 0 {\n\t\t\treturn port, nil\n\t\t}\n\t}\n\n\tports := retrieveAvailablePorts(app, task)\n\tif len(ports) == 0 {\n\t\treturn 0, errors.New(\"no port found\")\n\t}\n\n\tportIndex := 0\n\tif strings.HasPrefix(serverPort, \"index:\") {\n\t\tsplit := strings.SplitN(serverPort, \":\", 2)\n\t\tindex, err := strconv.Atoi(split[1])\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\tif index < 0 || index > len(ports)-1 {\n\t\t\treturn 0, fmt.Errorf(\"index %d must be within range (0, %d)\", index, len(ports)-1)\n\t\t}\n\t\tportIndex = index\n\t}\n\treturn ports[portIndex], nil\n}"}, {"instruction": "// AddFlags receives a *cobra.Command reference and binds\n// flags related to humanreadable and template printing.", "input": "go language", "output": "func (f *PrintFlags) AddFlags(cmd *cobra.Command) {\n\tf.JSONYamlPrintFlags.AddFlags(cmd)\n\tf.NamePrintFlags.AddFlags(cmd)\n\tf.TemplateFlags.AddFlags(cmd)\n\tf.HumanReadableFlags.AddFlags(cmd)\n\tf.CustomColumnsFlags.AddFlags(cmd)\n\n\tif f.OutputFormat != nil {\n\t\tcmd.Flags().StringVarP(f.OutputFormat, \"output\", \"o\", *f.OutputFormat, \"Output format. One of: json|yaml|wide|name|custom-columns=...|custom-columns-file=...|go-template=...|go-template-file=...|jsonpath=...|jsonpath-file=... See custom columns [http://kubernetes.io/docs/user-guide/kubectl-overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [http://kubernetes.io/docs/user-guide/jsonpath].\")\n\t}\n\tif f.NoHeaders != nil {\n\t\tcmd.Flags().BoolVar(f.NoHeaders, \"no-headers\", *f.NoHeaders, \"When using the default or custom-column output format, don't print headers (default print headers).\")\n\t}\n}"}, {"instruction": "// SubscribeFilterLogs subscribes to the results of a streaming filter query.", "input": "go language", "output": "func (ec *EthereumClient) SubscribeFilterLogs(ctx *Context, query *FilterQuery, handler FilterLogsHandler, buffer int) (sub *Subscription, _ error) {\n\t// Subscribe to the event internally\n\tch := make(chan types.Log, buffer)\n\trawSub, err := ec.client.SubscribeFilterLogs(ctx.context, query.query, ch)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Start up a dispatcher to feed into the callback\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase log := <-ch:\n\t\t\t\thandler.OnFilterLogs(&Log{&log})\n\n\t\t\tcase err := <-rawSub.Err():\n\t\t\t\tif err != nil {\n\t\t\t\t\thandler.OnError(err.Error())\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\treturn &Subscription{rawSub}, nil\n}"}, {"instruction": "// ImageStatus returns the status of the image, returns nil if the image doesn't present.", "input": "go language", "output": "func (ds *dockerService) ImageStatus(_ context.Context, r *runtimeapi.ImageStatusRequest) (*runtimeapi.ImageStatusResponse, error) {\n\timage := r.GetImage()\n\n\timageInspect, err := ds.client.InspectImageByRef(image.Image)\n\tif err != nil {\n\t\tif libdocker.IsImageNotFoundError(err) {\n\t\t\treturn &runtimeapi.ImageStatusResponse{}, nil\n\t\t}\n\t\treturn nil, err\n\t}\n\n\timageStatus, err := imageInspectToRuntimeAPIImage(imageInspect)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres := runtimeapi.ImageStatusResponse{Image: imageStatus}\n\tif r.GetVerbose() {\n\t\tres.Info = imageInspect.Config.Labels\n\t}\n\treturn &res, nil\n}"}, {"instruction": "// interpolationFuncSlice returns a portion of the input list between from, inclusive and to, exclusive.", "input": "go language", "output": "func interpolationFuncSlice() ast.Function {\n\treturn ast.Function{\n\t\tArgTypes: []ast.Type{\n\t\t\tast.TypeList, // inputList\n\t\t\tast.TypeInt,  // from\n\t\t\tast.TypeInt,  // to\n\t\t},\n\t\tReturnType: ast.TypeList,\n\t\tVariadic:   false,\n\t\tCallback: func(args []interface{}) (interface{}, error) {\n\t\t\tinputList := args[0].([]ast.Variable)\n\t\t\tfrom := args[1].(int)\n\t\t\tto := args[2].(int)\n\n\t\t\tif from < 0 {\n\t\t\t\treturn nil, fmt.Errorf(\"from index must be >= 0\")\n\t\t\t}\n\t\t\tif to > len(inputList) {\n\t\t\t\treturn nil, fmt.Errorf(\"to index must be <= length of the input list\")\n\t\t\t}\n\t\t\tif from > to {\n\t\t\t\treturn nil, fmt.Errorf(\"from index must be <= to index\")\n\t\t\t}\n\n\t\t\tvar outputList []ast.Variable\n\t\t\tfor i, val := range inputList {\n\t\t\t\tif i >= from && i < to {\n\t\t\t\t\toutputList = append(outputList, val)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn outputList, nil\n\t\t},\n\t}\n}"}, {"instruction": "// MarkForFSResize marks pvc with condition that indicates a fs resize is pending", "input": "go language", "output": "func (resizeMap *volumeResizeMap) MarkForFSResize(pvcr *PVCWithResizeRequest) error {\n\tpvcCondition := v1.PersistentVolumeClaimCondition{\n\t\tType:               v1.PersistentVolumeClaimFileSystemResizePending,\n\t\tStatus:             v1.ConditionTrue,\n\t\tLastTransitionTime: metav1.Now(),\n\t\tMessage:            \"Waiting for user to (re-)start a pod to finish file system resize of volume on node.\",\n\t}\n\tconditions := []v1.PersistentVolumeClaimCondition{pvcCondition}\n\tnewPVC := pvcr.PVC.DeepCopy()\n\tnewPVC = util.MergeResizeConditionOnPVC(newPVC, conditions)\n\t_, err := util.PatchPVCStatus(pvcr.PVC /*oldPVC*/, newPVC, resizeMap.kubeClient)\n\treturn err\n}"}, {"instruction": "// getBucketScore gets the score for merge this bucket with previous one.\n// TODO: We also need to consider the bucket hit count.", "input": "go language", "output": "func getBucketScore(bkts []bucket, totalCount float64, id int) bucketScore {\n\tpreCount, count := float64(bkts[id-1].Count), float64(bkts[id].Count)\n\t// do not merge if the result bucket is too large\n\tif (preCount + count) > maxBucketFraction*totalCount {\n\t\treturn bucketScore{id, math.MaxFloat64}\n\t}\n\t// Merge them if the result bucket is already too small.\n\tif (preCount + count) < minBucketFraction*totalCount {\n\t\treturn bucketScore{id, 0}\n\t}\n\tlow, mid, high := bkts[id-1].Lower, bkts[id-1].Upper, bkts[id].Upper\n\t// If we choose to merge, err is the absolute estimate error for the previous bucket.\n\terr := calcFraction4Datums(low, high, mid)*(preCount+count) - preCount\n\treturn bucketScore{id, math.Abs(err / (preCount + count))}\n}"}, {"instruction": "// ValidateObjectMetaUpdate validates an object's metadata when updated", "input": "go language", "output": "func ValidateObjectMetaUpdate(newMeta, oldMeta *metav1.ObjectMeta, fldPath *field.Path) field.ErrorList {\n\tnewMetadata, err := meta.Accessor(newMeta)\n\tif err != nil {\n\t\tallErrs := field.ErrorList{}\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, newMeta, err.Error()))\n\t\treturn allErrs\n\t}\n\toldMetadata, err := meta.Accessor(oldMeta)\n\tif err != nil {\n\t\tallErrs := field.ErrorList{}\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, oldMeta, err.Error()))\n\t\treturn allErrs\n\t}\n\treturn ValidateObjectMetaAccessorUpdate(newMetadata, oldMetadata, fldPath)\n}"}, {"instruction": "// Enables callback for keys received from a key exchange request", "input": "go language", "output": "func (ctl *HandshakeController) alertHandshake(pubkeyid string, symkeys []string) chan []string {\n\tctl.keyCMu.Lock()\n\tdefer ctl.keyCMu.Unlock()\n\tif len(symkeys) > 0 {\n\t\tif _, ok := ctl.keyC[pubkeyid]; ok {\n\t\t\tctl.keyC[pubkeyid] <- symkeys\n\t\t\tclose(ctl.keyC[pubkeyid])\n\t\t\tdelete(ctl.keyC, pubkeyid)\n\t\t}\n\t\treturn nil\n\t}\n\tif _, ok := ctl.keyC[pubkeyid]; !ok {\n\t\tctl.keyC[pubkeyid] = make(chan []string)\n\t}\n\treturn ctl.keyC[pubkeyid]\n}"}, {"instruction": "// SignIntermediate returns a signed CA certificate with a path length constraint\n// of 0 to ensure that the certificate cannot be used to generate further CA certs.", "input": "go language", "output": "func (v *VaultProvider) SignIntermediate(csr *x509.CertificateRequest) (string, error) {\n\tvar pemBuf bytes.Buffer\n\terr := pem.Encode(&pemBuf, &pem.Block{Type: \"CERTIFICATE REQUEST\", Bytes: csr.Raw})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// Sign the CSR with the root backend.\n\tdata, err := v.client.Logical().Write(v.config.RootPKIPath+\"root/sign-intermediate\", map[string]interface{}{\n\t\t\"csr\":             pemBuf.String(),\n\t\t\"format\":          \"pem_bundle\",\n\t\t\"max_path_length\": 0,\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif data == nil || data.Data[\"certificate\"] == \"\" {\n\t\treturn \"\", fmt.Errorf(\"got empty value when generating intermediate certificate\")\n\t}\n\n\tintermediate, ok := data.Data[\"certificate\"].(string)\n\tif !ok {\n\t\treturn \"\", fmt.Errorf(\"signed intermediate result is not a string\")\n\t}\n\n\treturn intermediate, nil\n}"}, {"instruction": "// getFsInfo writes metrics.Capacity, metrics.Used and metrics.Available from the filesystem info", "input": "go language", "output": "func (md *metricsStatFS) getFsInfo(metrics *Metrics) error {\n\tavailable, capacity, usage, inodes, inodesFree, inodesUsed, err := fs.FsInfo(md.path)\n\tif err != nil {\n\t\treturn NewFsInfoFailedError(err)\n\t}\n\tmetrics.Available = resource.NewQuantity(available, resource.BinarySI)\n\tmetrics.Capacity = resource.NewQuantity(capacity, resource.BinarySI)\n\tmetrics.Used = resource.NewQuantity(usage, resource.BinarySI)\n\tmetrics.Inodes = resource.NewQuantity(inodes, resource.BinarySI)\n\tmetrics.InodesFree = resource.NewQuantity(inodesFree, resource.BinarySI)\n\tmetrics.InodesUsed = resource.NewQuantity(inodesUsed, resource.BinarySI)\n\treturn nil\n}"}, {"instruction": "// ValidateLogOpt looks for syslog specific log options\n// syslog-address, syslog-facility.", "input": "go language", "output": "func ValidateLogOpt(cfg map[string]string) error {\n\tfor key := range cfg {\n\t\tswitch key {\n\t\tcase \"env\":\n\t\tcase \"env-regex\":\n\t\tcase \"labels\":\n\t\tcase \"labels-regex\":\n\t\tcase \"syslog-address\":\n\t\tcase \"syslog-facility\":\n\t\tcase \"syslog-tls-ca-cert\":\n\t\tcase \"syslog-tls-cert\":\n\t\tcase \"syslog-tls-key\":\n\t\tcase \"syslog-tls-skip-verify\":\n\t\tcase \"tag\":\n\t\tcase \"syslog-format\":\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"unknown log opt '%s' for syslog log driver\", key)\n\t\t}\n\t}\n\tif _, _, err := parseAddress(cfg[\"syslog-address\"]); err != nil {\n\t\treturn err\n\t}\n\tif _, err := parseFacility(cfg[\"syslog-facility\"]); err != nil {\n\t\treturn err\n\t}\n\tif _, _, err := parseLogFormat(cfg[\"syslog-format\"], \"\"); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// DefaultConfigDir is the default config directory to use for the vaults and other\n// persistence requirements.", "input": "go language", "output": "func DefaultConfigDir() string {\n\t// Try to place the data folder in the user's home dir\n\thome := homeDir()\n\tif home != \"\" {\n\t\tif runtime.GOOS == \"darwin\" {\n\t\t\treturn filepath.Join(home, \"Library\", \"Signer\")\n\t\t} else if runtime.GOOS == \"windows\" {\n\t\t\tappdata := os.Getenv(\"APPDATA\")\n\t\t\tif appdata != \"\" {\n\t\t\t\treturn filepath.Join(appdata, \"Signer\")\n\t\t\t} else {\n\t\t\t\treturn filepath.Join(home, \"AppData\", \"Roaming\", \"Signer\")\n\t\t\t}\n\t\t} else {\n\t\t\treturn filepath.Join(home, \".clef\")\n\t\t}\n\t}\n\t// As we cannot guess a stable location, return empty and handle later\n\treturn \"\"\n}"}, {"instruction": "// PrepareForCreate clears the status of a CustomResource before creation.", "input": "go language", "output": "func (a customResourceStrategy) PrepareForCreate(ctx context.Context, obj runtime.Object) {\n\tif utilfeature.DefaultFeatureGate.Enabled(apiextensionsfeatures.CustomResourceSubresources) && a.status != nil {\n\t\tcustomResourceObject := obj.(*unstructured.Unstructured)\n\t\tcustomResource := customResourceObject.UnstructuredContent()\n\n\t\t// create cannot set status\n\t\tif _, ok := customResource[\"status\"]; ok {\n\t\t\tdelete(customResource, \"status\")\n\t\t}\n\t}\n\n\taccessor, _ := meta.Accessor(obj)\n\taccessor.SetGeneration(1)\n}"}, {"instruction": "// Read is used to perform a read-only transaction that doesn't modify the state\n// store. This is much more scalable since it doesn't go through Raft and\n// supports staleness, so this should be preferred if you're just performing\n// reads.", "input": "go language", "output": "func (t *Txn) Read(args *structs.TxnReadRequest, reply *structs.TxnReadResponse) error {\n\tif done, err := t.srv.forward(\"Txn.Read\", args, args, reply); done {\n\t\treturn err\n\t}\n\tdefer metrics.MeasureSince([]string{\"txn\", \"read\"}, time.Now())\n\n\t// We have to do this ourselves since we are not doing a blocking RPC.\n\tt.srv.setQueryMeta(&reply.QueryMeta)\n\tif args.RequireConsistent {\n\t\tif err := t.srv.consistentRead(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Run the pre-checks before we perform the read.\n\tauthorizer, err := t.srv.ResolveToken(args.Token)\n\tif err != nil {\n\t\treturn err\n\t}\n\treply.Errors = t.preCheck(authorizer, args.Ops)\n\tif len(reply.Errors) > 0 {\n\t\treturn nil\n\t}\n\n\t// Run the read transaction.\n\tstate := t.srv.fsm.State()\n\treply.Results, reply.Errors = state.TxnRO(args.Ops)\n\tif authorizer != nil {\n\t\treply.Results = FilterTxnResults(authorizer, reply.Results)\n\t}\n\treturn nil\n}"}, {"instruction": "// Create a container", "input": "go language", "output": "func (c *containerManager) Create(runConfig *container.Config, hostConfig *container.HostConfig) (container.ContainerCreateCreatedBody, error) {\n\tcontainer, err := c.backend.ContainerCreateIgnoreImagesArgsEscaped(types.ContainerCreateConfig{\n\t\tConfig:     runConfig,\n\t\tHostConfig: hostConfig,\n\t})\n\tif err != nil {\n\t\treturn container, err\n\t}\n\tc.tmpContainers[container.ID] = struct{}{}\n\treturn container, nil\n}"}, {"instruction": "// AddWrapper binds the passed type to the passed wrapper.\n// Notice that that wrapper must be an instance of one of the following interfaces:\n// KeyGenerator, KeyDeriver, KeyImporter, Encryptor, Decryptor, Signer, Verifier, Hasher.", "input": "go language", "output": "func (csp *CSP) AddWrapper(t reflect.Type, w interface{}) error {\n\tif t == nil {\n\t\treturn errors.Errorf(\"type cannot be nil\")\n\t}\n\tif w == nil {\n\t\treturn errors.Errorf(\"wrapper cannot be nil\")\n\t}\n\tswitch dt := w.(type) {\n\tcase KeyGenerator:\n\t\tcsp.KeyGenerators[t] = dt\n\tcase KeyImporter:\n\t\tcsp.KeyImporters[t] = dt\n\tcase KeyDeriver:\n\t\tcsp.KeyDerivers[t] = dt\n\tcase Encryptor:\n\t\tcsp.Encryptors[t] = dt\n\tcase Decryptor:\n\t\tcsp.Decryptors[t] = dt\n\tcase Signer:\n\t\tcsp.Signers[t] = dt\n\tcase Verifier:\n\t\tcsp.Verifiers[t] = dt\n\tcase Hasher:\n\t\tcsp.Hashers[t] = dt\n\tdefault:\n\t\treturn errors.Errorf(\"wrapper type not valid, must be on of: KeyGenerator, KeyDeriver, KeyImporter, Encryptor, Decryptor, Signer, Verifier, Hasher\")\n\t}\n\treturn nil\n}"}, {"instruction": "// Write sends the buffer to the underneath writer.\n// It inserts the prefix header before the buffer,\n// so stdcopy.StdCopy knows where to multiplex the output.\n// It makes stdWriter to implement io.Writer.", "input": "go language", "output": "func (w *stdWriter) Write(p []byte) (n int, err error) {\n\tif w == nil || w.Writer == nil {\n\t\treturn 0, errors.New(\"Writer not instantiated\")\n\t}\n\tif p == nil {\n\t\treturn 0, nil\n\t}\n\n\theader := [stdWriterPrefixLen]byte{stdWriterFdIndex: w.prefix}\n\tbinary.BigEndian.PutUint32(header[stdWriterSizeIndex:], uint32(len(p)))\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Write(header[:])\n\tbuf.Write(p)\n\n\tn, err = w.Writer.Write(buf.Bytes())\n\tn -= stdWriterPrefixLen\n\tif n < 0 {\n\t\tn = 0\n\t}\n\n\tbuf.Reset()\n\tbufPool.Put(buf)\n\treturn\n}"}, {"instruction": "// Function to call on webhook failure; behavior determined by defaultAllow flag", "input": "go language", "output": "func (a *Plugin) webhookError(pod *api.Pod, attributes admission.Attributes, err error) error {\n\tif err != nil {\n\t\tklog.V(2).Infof(\"error contacting webhook backend: %s\", err)\n\t\tif a.defaultAllow {\n\t\t\tattributes.AddAnnotation(AuditKeyPrefix+ImagePolicyFailedOpenKeySuffix, \"true\")\n\t\t\t// TODO(wteiken): Remove the annotation code for the 1.13 release\n\t\t\tannotations := pod.GetAnnotations()\n\t\t\tif annotations == nil {\n\t\t\t\tannotations = make(map[string]string)\n\t\t\t}\n\t\t\tannotations[api.ImagePolicyFailedOpenKey] = \"true\"\n\t\t\tpod.ObjectMeta.SetAnnotations(annotations)\n\n\t\t\tklog.V(2).Infof(\"resource allowed in spite of webhook backend failure\")\n\t\t\treturn nil\n\t\t}\n\t\tklog.V(2).Infof(\"resource not allowed due to webhook backend failure \")\n\t\treturn admission.NewForbidden(attributes, err)\n\t}\n\treturn nil\n}"}, {"instruction": "// StopContainer stops a running container with a grace period (i.e., timeout).", "input": "go language", "output": "func (r *RemoteRuntimeService) StopContainer(containerID string, timeout int64) error {\n\t// Use timeout + default timeout (2 minutes) as timeout to leave extra time\n\t// for SIGKILL container and request latency.\n\tt := r.timeout + time.Duration(timeout)*time.Second\n\tctx, cancel := getContextWithTimeout(t)\n\tdefer cancel()\n\n\tr.logReduction.ClearID(containerID)\n\t_, err := r.runtimeClient.StopContainer(ctx, &runtimeapi.StopContainerRequest{\n\t\tContainerId: containerID,\n\t\tTimeout:     timeout,\n\t})\n\tif err != nil {\n\t\tklog.Errorf(\"StopContainer %q from runtime service failed: %v\", containerID, err)\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// EvalReference evaluates the given reference in the receiving scope and\n// returns the resulting value. The value will be converted to the given type before\n// it is returned if possible, or else an error diagnostic will be produced\n// describing the conversion error.\n//\n// Pass an expected type of cty.DynamicPseudoType to skip automatic conversion\n// and just obtain the returned value directly.\n//\n// If the returned diagnostics contains errors then the result may be\n// incomplete, but will always be of the requested type.", "input": "go language", "output": "func (s *Scope) EvalReference(ref *addrs.Reference, wantType cty.Type) (cty.Value, tfdiags.Diagnostics) {\n\tvar diags tfdiags.Diagnostics\n\n\t// We cheat a bit here and just build an EvalContext for our requested\n\t// reference with the \"self\" address overridden, and then pull the \"self\"\n\t// result out of it to return.\n\tctx, ctxDiags := s.evalContext([]*addrs.Reference{ref}, ref.Subject)\n\tdiags = diags.Append(ctxDiags)\n\tval := ctx.Variables[\"self\"]\n\tif val == cty.NilVal {\n\t\tval = cty.DynamicVal\n\t}\n\n\tvar convErr error\n\tval, convErr = convert.Convert(val, wantType)\n\tif convErr != nil {\n\t\tval = cty.UnknownVal(wantType)\n\t\tdiags = diags.Append(&hcl.Diagnostic{\n\t\t\tSeverity: hcl.DiagError,\n\t\t\tSummary:  \"Incorrect value type\",\n\t\t\tDetail:   fmt.Sprintf(\"Invalid expression value: %s.\", tfdiags.FormatError(convErr)),\n\t\t\tSubject:  ref.SourceRange.ToHCL().Ptr(),\n\t\t})\n\t}\n\n\treturn val, diags\n}"}, {"instruction": "// TryLoadCertFromDisk tries to load the cert from the disk and validates that it is valid", "input": "go language", "output": "func TryLoadCertFromDisk(pkiPath, name string) (*x509.Certificate, error) {\n\tcertificatePath := pathForCert(pkiPath, name)\n\n\tcerts, err := certutil.CertsFromFile(certificatePath)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"couldn't load the certificate file %s\", certificatePath)\n\t}\n\n\t// We are only putting one certificate in the certificate pem file, so it's safe to just pick the first one\n\t// TODO: Support multiple certs here in order to be able to rotate certs\n\tcert := certs[0]\n\n\t// Check so that the certificate is valid now\n\tnow := time.Now()\n\tif now.Before(cert.NotBefore) {\n\t\treturn nil, errors.New(\"the certificate is not valid yet\")\n\t}\n\tif now.After(cert.NotAfter) {\n\t\treturn nil, errors.New(\"the certificate has expired\")\n\t}\n\n\treturn cert, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *Policy) DeepCopyInto(out *Policy) {\n\t*out = *in\n\tout.TypeMeta = in.TypeMeta\n\tif in.Predicates != nil {\n\t\tin, out := &in.Predicates, &out.Predicates\n\t\t*out = make([]PredicatePolicy, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.Priorities != nil {\n\t\tin, out := &in.Priorities, &out.Priorities\n\t\t*out = make([]PriorityPolicy, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.ExtenderConfigs != nil {\n\t\tin, out := &in.ExtenderConfigs, &out.ExtenderConfigs\n\t\t*out = make([]ExtenderConfig, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// GetRoleReferenceRules attempts to resolve the RoleBinding or ClusterRoleBinding.", "input": "go language", "output": "func (r *DefaultRuleResolver) GetRoleReferenceRules(roleRef rbacv1.RoleRef, bindingNamespace string) ([]rbacv1.PolicyRule, error) {\n\tswitch roleRef.Kind {\n\tcase \"Role\":\n\t\trole, err := r.roleGetter.GetRole(bindingNamespace, roleRef.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn role.Rules, nil\n\n\tcase \"ClusterRole\":\n\t\tclusterRole, err := r.clusterRoleGetter.GetClusterRole(roleRef.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn clusterRole.Rules, nil\n\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported role reference kind: %q\", roleRef.Kind)\n\t}\n}"}, {"instruction": "// dropInitContainerAnnotations returns a copy of the annotations with init container annotations removed,\n// or the original annotations if no init container annotations were present.\n//\n// this can be removed once no clients prior to 1.8 are supported, and no kubelets prior to 1.8 can be run\n// (we don't support kubelets older than 2 versions skewed from the apiserver, but we don't prevent them, either)", "input": "go language", "output": "func dropInitContainerAnnotations(oldAnnotations map[string]string) map[string]string {\n\tif len(oldAnnotations) == 0 {\n\t\treturn oldAnnotations\n\t}\n\n\tfound := false\n\tfor k := range initContainerAnnotations {\n\t\tif _, ok := oldAnnotations[k]; ok {\n\t\t\tfound = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !found {\n\t\treturn oldAnnotations\n\t}\n\n\tnewAnnotations := make(map[string]string, len(oldAnnotations))\n\tfor k, v := range oldAnnotations {\n\t\tif !initContainerAnnotations[k] {\n\t\t\tnewAnnotations[k] = v\n\t\t}\n\t}\n\treturn newAnnotations\n}"}, {"instruction": "//setIPSetDefaults sets some IPSet fields if not present to their default values.", "input": "go language", "output": "func (set *IPSet) setIPSetDefaults() {\n\t// Setting default values if not present\n\tif set.HashSize == 0 {\n\t\tset.HashSize = 1024\n\t}\n\tif set.MaxElem == 0 {\n\t\tset.MaxElem = 65536\n\t}\n\t// Default protocol is IPv4\n\tif set.HashFamily == \"\" {\n\t\tset.HashFamily = ProtocolFamilyIPV4\n\t}\n\t// Default ipset type is \"hash:ip,port\"\n\tif len(set.SetType) == 0 {\n\t\tset.SetType = HashIPPort\n\t}\n\tif len(set.PortRange) == 0 {\n\t\tset.PortRange = DefaultPortRange\n\t}\n}"}, {"instruction": "// Subscribe creates a subscription for events of the given types. The\n// subscription's channel is closed when it is unsubscribed\n// or the mux is closed.", "input": "go language", "output": "func (mux *TypeMux) Subscribe(types ...interface{}) *TypeMuxSubscription {\n\tsub := newsub(mux)\n\tmux.mutex.Lock()\n\tdefer mux.mutex.Unlock()\n\tif mux.stopped {\n\t\t// set the status to closed so that calling Unsubscribe after this\n\t\t// call will short circuit.\n\t\tsub.closed = true\n\t\tclose(sub.postC)\n\t} else {\n\t\tif mux.subm == nil {\n\t\t\tmux.subm = make(map[reflect.Type][]*TypeMuxSubscription)\n\t\t}\n\t\tfor _, t := range types {\n\t\t\trtyp := reflect.TypeOf(t)\n\t\t\toldsubs := mux.subm[rtyp]\n\t\t\tif find(oldsubs, sub) != -1 {\n\t\t\t\tpanic(fmt.Sprintf(\"event: duplicate type %s in Subscribe\", rtyp))\n\t\t\t}\n\t\t\tsubs := make([]*TypeMuxSubscription, len(oldsubs)+1)\n\t\t\tcopy(subs, oldsubs)\n\t\t\tsubs[len(oldsubs)] = sub\n\t\t\tmux.subm[rtyp] = subs\n\t\t}\n\t}\n\treturn sub\n}"}, {"instruction": "// CreateEnvelope creates a common.Envelope with given tx bytes, header, and Signer", "input": "go language", "output": "func CreateEnvelope(data []byte, header *common.Header, signer SignerIdentity) (*common.Envelope, error) {\n\tpayload := &common.Payload{\n\t\tHeader: header,\n\t\tData:   data,\n\t}\n\n\tpayloadBytes, err := proto.Marshal(payload)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal common.Payload\")\n\t}\n\n\tsignature, err := signer.Sign(payloadBytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttxEnvelope := &common.Envelope{\n\t\tPayload:   payloadBytes,\n\t\tSignature: signature,\n\t}\n\n\treturn txEnvelope, nil\n}"}, {"instruction": "// Status returns the status of the runtime.", "input": "go language", "output": "func (r *RemoteRuntimeService) Status() (*runtimeapi.RuntimeStatus, error) {\n\tctx, cancel := getContextWithTimeout(r.timeout)\n\tdefer cancel()\n\n\tresp, err := r.runtimeClient.Status(ctx, &runtimeapi.StatusRequest{})\n\tif err != nil {\n\t\tklog.Errorf(\"Status from runtime service failed: %v\", err)\n\t\treturn nil, err\n\t}\n\n\tif resp.Status == nil || len(resp.Status.Conditions) < 2 {\n\t\terrorMessage := \"RuntimeReady or NetworkReady condition are not set\"\n\t\tklog.Errorf(\"Status failed: %s\", errorMessage)\n\t\treturn nil, errors.New(errorMessage)\n\t}\n\n\treturn resp.Status, nil\n}"}, {"instruction": "// CommonAccessor returns a Common interface for the provided object or an error if the object does\n// not provide List.", "input": "go language", "output": "func CommonAccessor(obj interface{}) (metav1.Common, error) {\n\tswitch t := obj.(type) {\n\tcase List:\n\t\treturn t, nil\n\tcase metav1.ListInterface:\n\t\treturn t, nil\n\tcase ListMetaAccessor:\n\t\tif m := t.GetListMeta(); m != nil {\n\t\t\treturn m, nil\n\t\t}\n\t\treturn nil, errNotCommon\n\tcase metav1.ListMetaAccessor:\n\t\tif m := t.GetListMeta(); m != nil {\n\t\t\treturn m, nil\n\t\t}\n\t\treturn nil, errNotCommon\n\tcase metav1.Object:\n\t\treturn t, nil\n\tcase metav1.ObjectMetaAccessor:\n\t\tif m := t.GetObjectMeta(); m != nil {\n\t\t\treturn m, nil\n\t\t}\n\t\treturn nil, errNotCommon\n\tdefault:\n\t\treturn nil, errNotCommon\n\t}\n}"}, {"instruction": "// MetadataFromConfigValue reads and translates configuration updates from config value into raft metadata", "input": "go language", "output": "func MetadataFromConfigValue(configValue *common.ConfigValue) (*etcdraft.ConfigMetadata, error) {\n\tconsensusTypeValue := &orderer.ConsensusType{}\n\tif err := proto.Unmarshal(configValue.Value, consensusTypeValue); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to unmarshal consensusType config update\")\n\t}\n\n\tupdatedMetadata := &etcdraft.ConfigMetadata{}\n\tif err := proto.Unmarshal(consensusTypeValue.Metadata, updatedMetadata); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to unmarshal updated (new) etcdraft metadata configuration\")\n\t}\n\n\treturn updatedMetadata, nil\n}"}, {"instruction": "// InstallRelease creates a release using kubeClient.Create", "input": "go language", "output": "func (r *ReleaseModuleServiceServer) InstallRelease(ctx context.Context, in *rudderAPI.InstallReleaseRequest) (*rudderAPI.InstallReleaseResponse, error) {\n\tgrpclog.Print(\"install\")\n\tb := bytes.NewBufferString(in.Release.Manifest)\n\terr := kubeClient.Create(in.Release.Namespace, b, 500, false)\n\tif err != nil {\n\t\tgrpclog.Printf(\"error when creating release: %v\", err)\n\t}\n\treturn &rudderAPI.InstallReleaseResponse{}, err\n}"}, {"instruction": "// getExistingChains get iptables-save output so we can check for existing chains and rules.\n// This will be a map of chain name to chain with rules as stored in iptables-save/iptables-restore\n// Result may SHARE memory with contents of buffer.", "input": "go language", "output": "func (proxier *Proxier) getExistingChains(buffer *bytes.Buffer, table utiliptables.Table) map[utiliptables.Chain][]byte {\n\tbuffer.Reset()\n\terr := proxier.iptables.SaveInto(table, buffer)\n\tif err != nil { // if we failed to get any rules\n\t\tklog.Errorf(\"Failed to execute iptables-save, syncing all rules: %v\", err)\n\t} else { // otherwise parse the output\n\t\treturn utiliptables.GetChainLines(table, buffer.Bytes())\n\t}\n\treturn nil\n}"}, {"instruction": "// podKiller launches a goroutine to kill a pod received from the channel if\n// another goroutine isn't already in action.", "input": "go language", "output": "func (kl *Kubelet) podKiller() {\n\tkilling := sets.NewString()\n\t// guard for the killing set\n\tlock := sync.Mutex{}\n\tfor podPair := range kl.podKillingCh {\n\t\trunningPod := podPair.RunningPod\n\t\tapiPod := podPair.APIPod\n\n\t\tlock.Lock()\n\t\texists := killing.Has(string(runningPod.ID))\n\t\tif !exists {\n\t\t\tkilling.Insert(string(runningPod.ID))\n\t\t}\n\t\tlock.Unlock()\n\n\t\tif !exists {\n\t\t\tgo func(apiPod *v1.Pod, runningPod *kubecontainer.Pod) {\n\t\t\t\tklog.V(2).Infof(\"Killing unwanted pod %q\", runningPod.Name)\n\t\t\t\terr := kl.killPod(apiPod, runningPod, nil, nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\tklog.Errorf(\"Failed killing the pod %q: %v\", runningPod.Name, err)\n\t\t\t\t}\n\t\t\t\tlock.Lock()\n\t\t\t\tkilling.Delete(string(runningPod.ID))\n\t\t\t\tlock.Unlock()\n\t\t\t}(apiPod, runningPod)\n\t\t}\n\t}\n}"}, {"instruction": "// GetOperatingSystem gets the name of the current operating system.", "input": "go language", "output": "func GetOperatingSystem() (string, error) {\n\n\t// Default return value\n\tret := \"Unknown Operating System\"\n\n\tk, err := registry.OpenKey(registry.LOCAL_MACHINE, `SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion`, registry.QUERY_VALUE)\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tdefer k.Close()\n\n\tpn, _, err := k.GetStringValue(\"ProductName\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tret = pn\n\n\tri, _, err := k.GetStringValue(\"ReleaseId\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tret = fmt.Sprintf(\"%s Version %s\", ret, ri)\n\n\tcbn, _, err := k.GetStringValue(\"CurrentBuildNumber\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\n\tubr, _, err := k.GetIntegerValue(\"UBR\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tret = fmt.Sprintf(\"%s (OS Build %s.%d)\", ret, cbn, ubr)\n\n\treturn ret, nil\n}"}, {"instruction": "// validateArgs is a checker to ensure tests are not running commands which are\n// not supported on platforms. Specifically on Windows this is 'busybox top'.", "input": "go language", "output": "func validateArgs(args ...string) error {\n\tif testEnv.OSType != \"windows\" {\n\t\treturn nil\n\t}\n\tfoundBusybox := -1\n\tfor key, value := range args {\n\t\tif strings.ToLower(value) == \"busybox\" {\n\t\t\tfoundBusybox = key\n\t\t}\n\t\tif (foundBusybox != -1) && (key == foundBusybox+1) && (strings.ToLower(value) == \"top\") {\n\t\t\treturn errors.New(\"cannot use 'busybox top' in tests on Windows. Use runSleepingContainer()\")\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// DownloadIndexFile fetches the index from a repository.\n//\n// cachePath is prepended to any index that does not have an absolute path. This\n// is for pre-2.2.0 repo files.", "input": "go language", "output": "func (r *ChartRepository) DownloadIndexFile(cachePath string) error {\n\tvar indexURL string\n\tparsedURL, err := url.Parse(r.Config.URL)\n\tif err != nil {\n\t\treturn err\n\t}\n\tparsedURL.Path = strings.TrimSuffix(parsedURL.Path, \"/\") + \"/index.yaml\"\n\n\tindexURL = parsedURL.String()\n\n\tr.setCredentials()\n\tresp, err := r.Client.Get(indexURL)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tindex, err := ioutil.ReadAll(resp)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := loadIndex(index); err != nil {\n\t\treturn err\n\t}\n\n\t// In Helm 2.2.0 the config.cache was accidentally switched to an absolute\n\t// path, which broke backward compatibility. This fixes it by prepending a\n\t// global cache path to relative paths.\n\t//\n\t// It is changed on DownloadIndexFile because that was the method that\n\t// originally carried the cache path.\n\tcp := r.Config.Cache\n\tif !filepath.IsAbs(cp) {\n\t\tcp = filepath.Join(cachePath, cp)\n\t}\n\n\treturn ioutil.WriteFile(cp, index, 0644)\n}"}, {"instruction": "// Format produces and returns a text representation of the receiving plan\n// intended for display in a terminal.\n//\n// If color is not nil, it is used to colorize the output.", "input": "go language", "output": "func (p *Plan) Format(color *colorstring.Colorize) string {\n\tif p.Empty() {\n\t\treturn \"This plan does nothing.\"\n\t}\n\n\tif color == nil {\n\t\tcolor = &colorstring.Colorize{\n\t\t\tColors: colorstring.DefaultColors,\n\t\t\tReset:  false,\n\t\t}\n\t}\n\n\t// Find the longest path length of all the paths that are changing,\n\t// so we can align them all.\n\tkeyLen := 0\n\tfor _, r := range p.Resources {\n\t\tfor _, attr := range r.Attributes {\n\t\t\tkey := attr.Path\n\n\t\t\tif len(key) > keyLen {\n\t\t\t\tkeyLen = len(key)\n\t\t\t}\n\t\t}\n\t}\n\n\tbuf := new(bytes.Buffer)\n\tfor _, r := range p.Resources {\n\t\tformatPlanInstanceDiff(buf, r, keyLen, color)\n\t}\n\n\treturn strings.TrimSpace(buf.String())\n}"}, {"instruction": "// Flatten creates a nonce-sorted slice of transactions based on the loosely\n// sorted internal representation. The result of the sorting is cached in case\n// it's requested again before any modifications are made to the contents.", "input": "go language", "output": "func (m *txSortedMap) Flatten() types.Transactions {\n\t// If the sorting was not cached yet, create and cache it\n\tif m.cache == nil {\n\t\tm.cache = make(types.Transactions, 0, len(m.items))\n\t\tfor _, tx := range m.items {\n\t\t\tm.cache = append(m.cache, tx)\n\t\t}\n\t\tsort.Sort(types.TxByNonce(m.cache))\n\t}\n\t// Copy the cache to prevent accidental modifications\n\ttxs := make(types.Transactions, len(m.cache))\n\tcopy(txs, m.cache)\n\treturn txs\n}"}, {"instruction": "// MockPumpsClient creates a PumpsClient, used for test.", "input": "go language", "output": "func MockPumpsClient(client binlog.PumpClient) *pumpcli.PumpsClient {\n\tnodeID := \"pump-1\"\n\tpump := &pumpcli.PumpStatus{\n\t\tStatus: node.Status{\n\t\t\tNodeID: nodeID,\n\t\t\tState:  node.Online,\n\t\t},\n\t\tClient: client,\n\t}\n\n\tpumpInfos := &pumpcli.PumpInfos{\n\t\tPumps:            make(map[string]*pumpcli.PumpStatus),\n\t\tAvaliablePumps:   make(map[string]*pumpcli.PumpStatus),\n\t\tUnAvaliablePumps: make(map[string]*pumpcli.PumpStatus),\n\t}\n\tpumpInfos.Pumps[nodeID] = pump\n\tpumpInfos.AvaliablePumps[nodeID] = pump\n\n\tpCli := &pumpcli.PumpsClient{\n\t\tClusterID:          1,\n\t\tPumps:              pumpInfos,\n\t\tSelector:           pumpcli.NewSelector(pumpcli.Range),\n\t\tBinlogWriteTimeout: time.Second,\n\t}\n\tpCli.Selector.SetPumps([]*pumpcli.PumpStatus{pump})\n\n\treturn pCli\n}"}, {"instruction": "// When a pod is deleted, enqueue the services the pod used to be a member of.\n// obj could be an *v1.Pod, or a DeletionFinalStateUnknown marker item.", "input": "go language", "output": "func (e *EndpointController) deletePod(obj interface{}) {\n\tif _, ok := obj.(*v1.Pod); ok {\n\t\t// Enqueue all the services that the pod used to be a member\n\t\t// of. This happens to be exactly the same thing we do when a\n\t\t// pod is added.\n\t\te.addPod(obj)\n\t\treturn\n\t}\n\t// If we reached here it means the pod was deleted but its final state is unrecorded.\n\ttombstone, ok := obj.(cache.DeletedFinalStateUnknown)\n\tif !ok {\n\t\tutilruntime.HandleError(fmt.Errorf(\"Couldn't get object from tombstone %#v\", obj))\n\t\treturn\n\t}\n\tpod, ok := tombstone.Obj.(*v1.Pod)\n\tif !ok {\n\t\tutilruntime.HandleError(fmt.Errorf(\"Tombstone contained object that is not a Pod: %#v\", obj))\n\t\treturn\n\t}\n\tklog.V(4).Infof(\"Enqueuing services of deleted pod %s/%s having final state unrecorded\", pod.Namespace, pod.Name)\n\te.addPod(pod)\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ResourceQuotaSpec) DeepCopyInto(out *ResourceQuotaSpec) {\n\t*out = *in\n\tif in.Hard != nil {\n\t\tin, out := &in.Hard, &out.Hard\n\t\t*out = make(ResourceList, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val.DeepCopy()\n\t\t}\n\t}\n\tif in.Scopes != nil {\n\t\tin, out := &in.Scopes, &out.Scopes\n\t\t*out = make([]ResourceQuotaScope, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.ScopeSelector != nil {\n\t\tin, out := &in.ScopeSelector, &out.ScopeSelector\n\t\t*out = new(ScopeSelector)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\treturn\n}"}, {"instruction": "// InstanceID returns the cloud provider ID of the node with the specified nodeName.", "input": "go language", "output": "func (c *Cloud) InstanceID(ctx context.Context, nodeName types.NodeName) (string, error) {\n\t// In the future it is possible to also return an endpoint as:\n\t// <endpoint>/<zone>/<instanceid>\n\tif c.selfAWSInstance.nodeName == nodeName {\n\t\treturn \"/\" + c.selfAWSInstance.availabilityZone + \"/\" + c.selfAWSInstance.awsID, nil\n\t}\n\tinst, err := c.getInstanceByNodeName(nodeName)\n\tif err != nil {\n\t\tif err == cloudprovider.InstanceNotFound {\n\t\t\t// The Instances interface requires that we return InstanceNotFound (without wrapping)\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"getInstanceByNodeName failed for %q with %q\", nodeName, err)\n\t}\n\treturn \"/\" + aws.StringValue(inst.Placement.AvailabilityZone) + \"/\" + aws.StringValue(inst.InstanceId), nil\n}"}, {"instruction": "// CreateProposalResponseFailure creates a proposal response for cases where\n// endorsement proposal fails either due to a endorsement failure or a\n// chaincode failure (chaincode response status >= shim.ERRORTHRESHOLD)", "input": "go language", "output": "func CreateProposalResponseFailure(hdrbytes []byte, payl []byte, response *peer.Response, results []byte, events []byte, ccid *peer.ChaincodeID, visibility []byte) (*peer.ProposalResponse, error) {\n\thdr, err := GetHeader(hdrbytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// obtain the proposal hash given proposal header, payload and the requested visibility\n\tpHashBytes, err := GetProposalHash1(hdr, payl, visibility)\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, \"error computing proposal hash\")\n\t}\n\n\t// get the bytes of the proposal response payload\n\tprpBytes, err := GetBytesProposalResponsePayload(pHashBytes, response, results, events, ccid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresp := &peer.ProposalResponse{\n\t\t// Timestamp: TODO!\n\t\tPayload:  prpBytes,\n\t\tResponse: response,\n\t}\n\n\treturn resp, nil\n}"}, {"instruction": "// ipcListen will create a Unix socket on the given endpoint.", "input": "go language", "output": "func ipcListen(endpoint string) (net.Listener, error) {\n\tif len(endpoint) > int(C.max_socket_path_size()) {\n\t\tlog.Warn(fmt.Sprintf(\"The ipc endpoint is longer than %d characters. \", C.max_socket_path_size()),\n\t\t\t\"endpoint\", endpoint)\n\t}\n\n\t// Ensure the IPC path exists and remove any previous leftover\n\tif err := os.MkdirAll(filepath.Dir(endpoint), 0751); err != nil {\n\t\treturn nil, err\n\t}\n\tos.Remove(endpoint)\n\tl, err := net.Listen(\"unix\", endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tos.Chmod(endpoint, 0600)\n\treturn l, nil\n}"}, {"instruction": "// setGraphQL creates the GraphQL listener interface string from the set\n// command line flags, returning empty if the GraphQL endpoint is disabled.", "input": "go language", "output": "func setGraphQL(ctx *cli.Context, cfg *node.Config) {\n\tif ctx.GlobalBool(GraphQLEnabledFlag.Name) && cfg.GraphQLHost == \"\" {\n\t\tcfg.GraphQLHost = \"127.0.0.1\"\n\t\tif ctx.GlobalIsSet(GraphQLListenAddrFlag.Name) {\n\t\t\tcfg.GraphQLHost = ctx.GlobalString(GraphQLListenAddrFlag.Name)\n\t\t}\n\t}\n\tcfg.GraphQLPort = ctx.GlobalInt(GraphQLPortFlag.Name)\n\tif ctx.GlobalIsSet(GraphQLCORSDomainFlag.Name) {\n\t\tcfg.GraphQLCors = splitAndTrim(ctx.GlobalString(GraphQLCORSDomainFlag.Name))\n\t}\n\tif ctx.GlobalIsSet(GraphQLVirtualHostsFlag.Name) {\n\t\tcfg.GraphQLVirtualHosts = splitAndTrim(ctx.GlobalString(GraphQLVirtualHostsFlag.Name))\n\t}\n}"}, {"instruction": "// PrintSections prints the given names flag sets in sections, with the maximal given column number.\n// If cols is zero, lines are not wrapped.", "input": "go language", "output": "func PrintSections(w io.Writer, fss NamedFlagSets, cols int) {\n\tfor _, name := range fss.Order {\n\t\tfs := fss.FlagSets[name]\n\t\tif !fs.HasFlags() {\n\t\t\tcontinue\n\t\t}\n\n\t\twideFS := pflag.NewFlagSet(\"\", pflag.ExitOnError)\n\t\twideFS.AddFlagSet(fs)\n\n\t\tvar zzz string\n\t\tif cols > 24 {\n\t\t\tzzz = strings.Repeat(\"z\", cols-24)\n\t\t\twideFS.Int(zzz, 0, strings.Repeat(\"z\", cols-24))\n\t\t}\n\n\t\tvar buf bytes.Buffer\n\t\tfmt.Fprintf(&buf, \"\\n%s flags:\\n\\n%s\", strings.ToUpper(name[:1])+name[1:], wideFS.FlagUsagesWrapped(cols))\n\n\t\tif cols > 24 {\n\t\t\ti := strings.Index(buf.String(), zzz)\n\t\t\tlines := strings.Split(buf.String()[:i], \"\\n\")\n\t\t\tfmt.Fprint(w, strings.Join(lines[:len(lines)-1], \"\\n\"))\n\t\t\tfmt.Fprintln(w)\n\t\t} else {\n\t\t\tfmt.Fprint(w, buf.String())\n\t\t}\n\t}\n}"}, {"instruction": "// HandleDelete handles a DELETE request to bzz:/<manifest>/<path>, removes\n// <path> from <manifest> and returns the resulting manifest hash as a\n// text/plain response", "input": "go language", "output": "func (s *Server) HandleDelete(w http.ResponseWriter, r *http.Request) {\n\truid := GetRUID(r.Context())\n\turi := GetURI(r.Context())\n\tlog.Debug(\"handle.delete\", \"ruid\", ruid)\n\tdeleteCount.Inc(1)\n\tnewKey, err := s.api.Delete(r.Context(), uri.Addr, uri.Path)\n\tif err != nil {\n\t\tdeleteFail.Inc(1)\n\t\trespondError(w, r, fmt.Sprintf(\"could not delete from manifest: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\tw.WriteHeader(http.StatusOK)\n\tfmt.Fprint(w, newKey)\n}"}, {"instruction": "// DefaultServiceIPRange takes a the serviceIPRange flag and returns the defaulted service ip range (if  needed),\n// api server service IP, and an error", "input": "go language", "output": "func DefaultServiceIPRange(passedServiceClusterIPRange net.IPNet) (net.IPNet, net.IP, error) {\n\tserviceClusterIPRange := passedServiceClusterIPRange\n\tif passedServiceClusterIPRange.IP == nil {\n\t\tklog.Infof(\"Network range for service cluster IPs is unspecified. Defaulting to %v.\", kubeoptions.DefaultServiceIPCIDR)\n\t\tserviceClusterIPRange = kubeoptions.DefaultServiceIPCIDR\n\t}\n\tif size := ipallocator.RangeSize(&serviceClusterIPRange); size < 8 {\n\t\treturn net.IPNet{}, net.IP{}, fmt.Errorf(\"The service cluster IP range must be at least %d IP addresses\", 8)\n\t}\n\n\t// Select the first valid IP from ServiceClusterIPRange to use as the GenericAPIServer service IP.\n\tapiServerServiceIP, err := ipallocator.GetIndexedIP(&serviceClusterIPRange, 1)\n\tif err != nil {\n\t\treturn net.IPNet{}, net.IP{}, err\n\t}\n\tklog.V(4).Infof(\"Setting service IP to %q (read-write).\", apiServerServiceIP)\n\n\treturn serviceClusterIPRange, apiServerServiceIP, nil\n}"}, {"instruction": "// getOpenAPIModels is a private method for getting the OpenAPI models", "input": "go language", "output": "func (s *GenericAPIServer) getOpenAPIModels(apiPrefix string, apiGroupInfos ...*APIGroupInfo) (openapiproto.Models, error) {\n\tif s.openAPIConfig == nil {\n\t\treturn nil, nil\n\t}\n\tpathsToIgnore := openapiutil.NewTrie(s.openAPIConfig.IgnorePrefixes)\n\tresourceNames := make([]string, 0)\n\tfor _, apiGroupInfo := range apiGroupInfos {\n\t\tgroupResources, err := getResourceNamesForGroup(apiPrefix, apiGroupInfo, pathsToIgnore)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresourceNames = append(resourceNames, groupResources...)\n\t}\n\n\t// Build the openapi definitions for those resources and convert it to proto models\n\topenAPISpec, err := openapibuilder.BuildOpenAPIDefinitionsForResources(s.openAPIConfig, resourceNames...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn utilopenapi.ToProtoModels(openAPISpec)\n}"}, {"instruction": "// Hex returns an EIP55-compliant hex string representation of the address.", "input": "go language", "output": "func (a Address) Hex() string {\n\tunchecksummed := hex.EncodeToString(a[:])\n\tsha := sha3.NewLegacyKeccak256()\n\tsha.Write([]byte(unchecksummed))\n\thash := sha.Sum(nil)\n\n\tresult := []byte(unchecksummed)\n\tfor i := 0; i < len(result); i++ {\n\t\thashByte := hash[i/2]\n\t\tif i%2 == 0 {\n\t\t\thashByte = hashByte >> 4\n\t\t} else {\n\t\t\thashByte &= 0xf\n\t\t}\n\t\tif result[i] > '9' && hashByte > 7 {\n\t\t\tresult[i] -= 32\n\t\t}\n\t}\n\treturn \"0x\" + string(result)\n}"}, {"instruction": "// ExportChain exports a blockchain into the specified file, truncating any data\n// already present in the file.", "input": "go language", "output": "func ExportChain(blockchain *core.BlockChain, fn string) error {\n\tlog.Info(\"Exporting blockchain\", \"file\", fn)\n\n\t// Open the file handle and potentially wrap with a gzip stream\n\tfh, err := os.OpenFile(fn, os.O_CREATE|os.O_WRONLY|os.O_TRUNC, os.ModePerm)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer fh.Close()\n\n\tvar writer io.Writer = fh\n\tif strings.HasSuffix(fn, \".gz\") {\n\t\twriter = gzip.NewWriter(writer)\n\t\tdefer writer.(*gzip.Writer).Close()\n\t}\n\t// Iterate over the blocks and export them\n\tif err := blockchain.Export(writer); err != nil {\n\t\treturn err\n\t}\n\tlog.Info(\"Exported blockchain\", \"file\", fn)\n\n\treturn nil\n}"}, {"instruction": "// CreateOrUpdateLB invokes az.LoadBalancerClient.CreateOrUpdate with exponential backoff retry", "input": "go language", "output": "func (az *Cloud) CreateOrUpdateLB(service *v1.Service, lb network.LoadBalancer) error {\n\tif az.Config.shouldOmitCloudProviderBackoff() {\n\t\tctx, cancel := getContextWithCancel()\n\t\tdefer cancel()\n\n\t\tresp, err := az.LoadBalancerClient.CreateOrUpdate(ctx, az.ResourceGroup, *lb.Name, lb)\n\t\tklog.V(10).Infof(\"LoadBalancerClient.CreateOrUpdate(%s): end\", *lb.Name)\n\t\tif err == nil {\n\t\t\tif isSuccessHTTPResponse(resp) {\n\t\t\t\t// Invalidate the cache right after updating\n\t\t\t\taz.lbCache.Delete(*lb.Name)\n\t\t\t} else if resp != nil {\n\t\t\t\treturn fmt.Errorf(\"HTTP response %q\", resp.Status)\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\n\treturn az.createOrUpdateLBWithRetry(service, lb)\n}"}, {"instruction": "// doExecMount calls exec(mount <what> <where>) using given exec interface.", "input": "go language", "output": "func (m *execMounter) doExecMount(source, target, fstype string, options []string) error {\n\tklog.V(5).Infof(\"Exec Mounting %s %s %s %v\", source, target, fstype, options)\n\tmountArgs := mount.MakeMountArgs(source, target, fstype, options)\n\toutput, err := m.exec.Run(\"mount\", mountArgs...)\n\tklog.V(5).Infof(\"Exec mounted %v: %v: %s\", mountArgs, err, string(output))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"mount failed: %v\\nMounting command: %s\\nMounting arguments: %s %s %s %v\\nOutput: %s\",\n\t\t\terr, \"mount\", source, target, fstype, options, string(output))\n\t}\n\n\treturn err\n}"}, {"instruction": "// parsePersistentNodes parses a list of discovery node URLs loaded from a .json\n// file from within the data directory.", "input": "go language", "output": "func (c *Config) parsePersistentNodes(w *bool, path string) []*enode.Node {\n\t// Short circuit if no node config is present\n\tif c.DataDir == \"\" {\n\t\treturn nil\n\t}\n\tif _, err := os.Stat(path); err != nil {\n\t\treturn nil\n\t}\n\tc.warnOnce(w, \"Found deprecated node list file %s, please use the TOML config file instead.\", path)\n\n\t// Load the nodes from the config file.\n\tvar nodelist []string\n\tif err := common.LoadJSON(path, &nodelist); err != nil {\n\t\tlog.Error(fmt.Sprintf(\"Can't load node list file: %v\", err))\n\t\treturn nil\n\t}\n\t// Interpret the list as a discovery node array\n\tvar nodes []*enode.Node\n\tfor _, url := range nodelist {\n\t\tif url == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tnode, err := enode.ParseV4(url)\n\t\tif err != nil {\n\t\t\tlog.Error(fmt.Sprintf(\"Node URL %s: %v\\n\", url, err))\n\t\t\tcontinue\n\t\t}\n\t\tnodes = append(nodes, node)\n\t}\n\treturn nodes\n}"}, {"instruction": "// Delete an existing Group expression.", "input": "go language", "output": "func (g *Group) Delete(e *GroupExpr) {\n\tfingerprint := e.FingerPrint()\n\tequiv, ok := g.Fingerprints[fingerprint]\n\tif !ok {\n\t\treturn // Can not find the target GroupExpr.\n\t}\n\n\tg.Equivalents.Remove(equiv)\n\tdelete(g.Fingerprints, fingerprint)\n\n\toperand := GetOperand(equiv.Value.(*GroupExpr).ExprNode)\n\tif g.FirstExpr[operand] != equiv {\n\t\treturn // The target GroupExpr is not the first Element of the same Operand.\n\t}\n\n\tnextElem := equiv.Next()\n\tif nextElem != nil && GetOperand(nextElem.Value.(*GroupExpr).ExprNode) == operand {\n\t\tg.FirstExpr[operand] = nextElem\n\t\treturn // The first Element of the same Operand has been changed.\n\t}\n\tdelete(g.FirstExpr, operand)\n}"}, {"instruction": "// TranslateCSIPVToInTree takes a PV with CSIPersistentVolumeSource set and\n// translates the Cinder CSI source to a Cinder In-tree source.", "input": "go language", "output": "func (t *osCinderCSITranslator) TranslateCSIPVToInTree(pv *v1.PersistentVolume) (*v1.PersistentVolume, error) {\n\tif pv == nil || pv.Spec.CSI == nil {\n\t\treturn nil, fmt.Errorf(\"pv is nil or CSI source not defined on pv\")\n\t}\n\n\tcsiSource := pv.Spec.CSI\n\n\tcinderSource := &v1.CinderPersistentVolumeSource{\n\t\tVolumeID: csiSource.VolumeHandle,\n\t\tFSType:   csiSource.FSType,\n\t\tReadOnly: csiSource.ReadOnly,\n\t}\n\n\tpv.Spec.CSI = nil\n\tpv.Spec.Cinder = cinderSource\n\treturn pv, nil\n}"}, {"instruction": "// Deprecated informs about a deprecation, but only once for a given set of arguments' values.\n// If the err flag is enabled, it logs as an ERROR (will exit with -1) and the text will\n// point at the next Hugo release.\n// The idea is two remove an item in two Hugo releases to give users and theme authors\n// plenty of time to fix their templates.", "input": "go language", "output": "func Deprecated(object, item, alternative string, err bool) {\n\tif !strings.HasSuffix(alternative, \".\") {\n\t\talternative += \".\"\n\t}\n\n\tif err {\n\t\tDistinctErrorLog.Printf(\"%s's %s is deprecated and will be removed in Hugo %s. %s\", object, item, hugo.CurrentVersion.Next().ReleaseVersion(), alternative)\n\n\t} else {\n\t\tDistinctWarnLog.Printf(\"%s's %s is deprecated and will be removed in a future release. %s\", object, item, alternative)\n\t}\n}"}, {"instruction": "// PerformStaticPodUpgrade performs the upgrade of the control plane components for a static pod hosted cluster", "input": "go language", "output": "func PerformStaticPodUpgrade(client clientset.Interface, waiter apiclient.Waiter, internalcfg *kubeadmapi.InitConfiguration, etcdUpgrade, renewCerts bool) error {\n\tpathManager, err := GetPathManagerForUpgrade(internalcfg, etcdUpgrade)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The arguments oldEtcdClient and newEtdClient, are uninitialized because passing in the clients allow for mocking the client during testing\n\treturn upgrade.StaticPodControlPlane(client, waiter, pathManager, internalcfg, etcdUpgrade, renewCerts, nil, nil)\n}"}, {"instruction": "// howSimilar is a naive diff implementation that returns\n// a number between 0-100 indicating how similar a and b are.\n// 100 is when all words in a also exists in b.", "input": "go language", "output": "func howSimilarStrings(a, b string) int {\n\n\t// Give some weight to the word positions.\n\tconst partitionSize = 4\n\n\taf, bf := strings.Fields(a), strings.Fields(b)\n\tif len(bf) > len(af) {\n\t\taf, bf = bf, af\n\t}\n\n\tm1 := make(map[string]bool)\n\tfor i, x := range bf {\n\t\tpartition := partition(i, partitionSize)\n\t\tkey := x + \"/\" + strconv.Itoa(partition)\n\t\tm1[key] = true\n\t}\n\n\tcommon := 0\n\tfor i, x := range af {\n\t\tpartition := partition(i, partitionSize)\n\t\tkey := x + \"/\" + strconv.Itoa(partition)\n\t\tif m1[key] {\n\t\t\tcommon++\n\t\t}\n\t}\n\n\treturn int(math.Floor((float64(common) / float64(len(af)) * 100)))\n}"}, {"instruction": "// RunConfigView gets the configuration persisted in the cluster", "input": "go language", "output": "func RunConfigView(out io.Writer, client clientset.Interface) error {\n\n\tklog.V(1).Infoln(\"[config] getting the cluster configuration\")\n\tcfgConfigMap, err := client.CoreV1().ConfigMaps(metav1.NamespaceSystem).Get(constants.KubeadmConfigConfigMap, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\t// No need to append \\n as that already exists in the ConfigMap\n\tfmt.Fprintf(out, \"%s\", cfgConfigMap.Data[constants.ClusterConfigurationConfigMapKey])\n\treturn nil\n}"}, {"instruction": "// GeneratePrivateKey creates a private key and stores it in keystorePath", "input": "go language", "output": "func GeneratePrivateKey(keystorePath string) (bccsp.Key,\n\tcrypto.Signer, error) {\n\n\tvar err error\n\tvar priv bccsp.Key\n\tvar s crypto.Signer\n\n\topts := &factory.FactoryOpts{\n\t\tProviderName: \"SW\",\n\t\tSwOpts: &factory.SwOpts{\n\t\t\tHashFamily: \"SHA2\",\n\t\t\tSecLevel:   256,\n\n\t\t\tFileKeystore: &factory.FileKeystoreOpts{\n\t\t\t\tKeyStorePath: keystorePath,\n\t\t\t},\n\t\t},\n\t}\n\tcsp, err := factory.GetBCCSPFromOpts(opts)\n\tif err == nil {\n\t\t// generate a key\n\t\tpriv, err = csp.KeyGen(&bccsp.ECDSAP256KeyGenOpts{Temporary: false})\n\t\tif err == nil {\n\t\t\t// create a crypto.Signer\n\t\t\ts, err = signer.New(csp, priv)\n\t\t}\n\t}\n\treturn priv, s, err\n}"}, {"instruction": "// notify sends notifications for pod with the given id, if the requirements\n// are met. Note that the caller should acquire the lock.", "input": "go language", "output": "func (c *cache) notify(id types.UID, timestamp time.Time) {\n\tlist, ok := c.subscribers[id]\n\tif !ok {\n\t\t// No one to notify.\n\t\treturn\n\t}\n\tnewList := []*subRecord{}\n\tfor i, r := range list {\n\t\tif timestamp.Before(r.time) {\n\t\t\t// Doesn't meet the time requirement; keep the record.\n\t\t\tnewList = append(newList, list[i])\n\t\t\tcontinue\n\t\t}\n\t\tr.ch <- c.get(id)\n\t\tclose(r.ch)\n\t}\n\tif len(newList) == 0 {\n\t\tdelete(c.subscribers, id)\n\t} else {\n\t\tc.subscribers[id] = newList\n\t}\n}"}, {"instruction": "// SetIntermediate writes the incoming intermediate and root certificates to the\n// intermediate backend (as a chain).", "input": "go language", "output": "func (v *VaultProvider) SetIntermediate(intermediatePEM, rootPEM string) error {\n\tif v.isRoot {\n\t\treturn fmt.Errorf(\"cannot set an intermediate using another root in the primary datacenter\")\n\t}\n\n\t_, err := v.client.Logical().Write(v.config.IntermediatePKIPath+\"intermediate/set-signed\", map[string]interface{}{\n\t\t\"certificate\": fmt.Sprintf(\"%s\\n%s\", intermediatePEM, rootPEM),\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// Verify checks that the passed signatures is valid with the respect to the passed digest, issuer public key,\n// and pseudonym public key.", "input": "go language", "output": "func (*NymSignatureScheme) Verify(ipk handlers.IssuerPublicKey, Nym handlers.Ecp, signature, digest []byte) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = errors.Errorf(\"failure [%s]\", r)\n\t\t}\n\t}()\n\n\tiipk, ok := ipk.(*IssuerPublicKey)\n\tif !ok {\n\t\treturn errors.Errorf(\"invalid issuer public key, expected *IssuerPublicKey, got [%T]\", ipk)\n\t}\n\tinym, ok := Nym.(*Ecp)\n\tif !ok {\n\t\treturn errors.Errorf(\"invalid nym public key, expected *Ecp, got [%T]\", Nym)\n\t}\n\n\tsig := &cryptolib.NymSignature{}\n\terr = proto.Unmarshal(signature, sig)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"error unmarshalling signature\")\n\t}\n\n\treturn sig.Ver(inym.E, iipk.PK, digest)\n}"}, {"instruction": "// InitializeStdio is called by libcontainerd to connect the stdio.", "input": "go language", "output": "func (container *Container) InitializeStdio(iop *cio.DirectIO) (cio.IO, error) {\n\tif err := container.startLogging(); err != nil {\n\t\tcontainer.Reset(false)\n\t\treturn nil, err\n\t}\n\n\tcontainer.StreamConfig.CopyToPipe(iop)\n\n\tif container.StreamConfig.Stdin() == nil && !container.Config.Tty {\n\t\tif iop.Stdin != nil {\n\t\t\tif err := iop.Stdin.Close(); err != nil {\n\t\t\t\tlogrus.Warnf(\"error closing stdin: %+v\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn &rio{IO: iop, sc: container.StreamConfig}, nil\n}"}, {"instruction": "// ShutdownTimeout returns the timeout (in seconds) before containers are forcibly\n// killed during shutdown. The default timeout can be configured both on the daemon\n// and per container, and the longest timeout will be used. A grace-period of\n// 5 seconds is added to the configured timeout.\n//\n// A negative (-1) timeout means \"indefinitely\", which means that containers\n// are not forcibly killed, and the daemon shuts down after all containers exit.", "input": "go language", "output": "func (daemon *Daemon) ShutdownTimeout() int {\n\tshutdownTimeout := daemon.configStore.ShutdownTimeout\n\tif shutdownTimeout < 0 {\n\t\treturn -1\n\t}\n\tif daemon.containers == nil {\n\t\treturn shutdownTimeout\n\t}\n\n\tgraceTimeout := 5\n\tfor _, c := range daemon.containers.List() {\n\t\tstopTimeout := c.StopTimeout()\n\t\tif stopTimeout < 0 {\n\t\t\treturn -1\n\t\t}\n\t\tif stopTimeout+graceTimeout > shutdownTimeout {\n\t\t\tshutdownTimeout = stopTimeout + graceTimeout\n\t\t}\n\t}\n\treturn shutdownTimeout\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *CheckIndexExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\tif e.done {\n\t\treturn nil\n\t}\n\tdefer func() { e.done = true }()\n\n\terr := admin.CheckIndicesCount(e.ctx, e.dbName, e.tableName, []string{e.idxName})\n\tif err != nil {\n\t\treturn err\n\t}\n\tchk := e.src.newFirstChunk()\n\tfor {\n\t\terr := e.src.Next(ctx, chunk.NewRecordBatch(chk))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif chk.NumRows() == 0 {\n\t\t\tbreak\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// GetSnapshot retrieves the state snapshot at a given block.", "input": "go language", "output": "func (api *API) GetSnapshot(number *rpc.BlockNumber) (*Snapshot, error) {\n\t// Retrieve the requested block number (or current if none requested)\n\tvar header *types.Header\n\tif number == nil || *number == rpc.LatestBlockNumber {\n\t\theader = api.chain.CurrentHeader()\n\t} else {\n\t\theader = api.chain.GetHeaderByNumber(uint64(number.Int64()))\n\t}\n\t// Ensure we have an actually valid block and return its snapshot\n\tif header == nil {\n\t\treturn nil, errUnknownBlock\n\t}\n\treturn api.clique.snapshot(api.chain, header.Number.Uint64(), header.Hash(), nil)\n}"}, {"instruction": "// NewAccessEntryACT creates a manifest AccessEntry in order to create an ACT protected by a combination of EC keys and passwords", "input": "go language", "output": "func NewAccessEntryACT(publisher string, salt []byte, act string) (*AccessEntry, error) {\n\tif len(salt) != 32 {\n\t\treturn nil, fmt.Errorf(\"salt should be 32 bytes long\")\n\t}\n\tif len(publisher) != 66 {\n\t\treturn nil, fmt.Errorf(\"publisher should be 66 characters long\")\n\t}\n\n\treturn &AccessEntry{\n\t\tType:      AccessTypeACT,\n\t\tPublisher: publisher,\n\t\tSalt:      salt,\n\t\tAct:       act,\n\t\tKdfParams: DefaultKdfParams,\n\t}, nil\n}"}, {"instruction": "// ValidateSocketPath validates format of socket path or url", "input": "go language", "output": "func ValidateSocketPath(socket string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\tu, err := url.Parse(socket)\n\tif err != nil {\n\t\treturn append(allErrs, field.Invalid(fldPath, socket, fmt.Sprintf(\"URL parsing error: %v\", err)))\n\t}\n\n\tif u.Scheme == \"\" {\n\t\tif !filepath.IsAbs(u.Path) {\n\t\t\treturn append(allErrs, field.Invalid(fldPath, socket, fmt.Sprintf(\"path is not absolute: %s\", socket)))\n\t\t}\n\t} else if u.Scheme != kubeadmapiv1beta2.DefaultUrlScheme {\n\t\treturn append(allErrs, field.Invalid(fldPath, socket, fmt.Sprintf(\"URL scheme %s is not supported\", u.Scheme)))\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *CustomResourceDefinitionVersion) DeepCopyInto(out *CustomResourceDefinitionVersion) {\n\t*out = *in\n\tif in.Schema != nil {\n\t\tin, out := &in.Schema, &out.Schema\n\t\t*out = new(CustomResourceValidation)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.Subresources != nil {\n\t\tin, out := &in.Subresources, &out.Subresources\n\t\t*out = new(CustomResourceSubresources)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.AdditionalPrinterColumns != nil {\n\t\tin, out := &in.AdditionalPrinterColumns, &out.AdditionalPrinterColumns\n\t\t*out = make([]CustomResourceColumnDefinition, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\treturn\n}"}, {"instruction": "// SamplePercentiles returns a slice of arbitrary percentiles of the slice of\n// int64.", "input": "go language", "output": "func SamplePercentiles(values int64Slice, ps []float64) []float64 {\n\tscores := make([]float64, len(ps))\n\tsize := len(values)\n\tif size > 0 {\n\t\tsort.Sort(values)\n\t\tfor i, p := range ps {\n\t\t\tpos := p * float64(size+1)\n\t\t\tif pos < 1.0 {\n\t\t\t\tscores[i] = float64(values[0])\n\t\t\t} else if pos >= float64(size) {\n\t\t\t\tscores[i] = float64(values[size-1])\n\t\t\t} else {\n\t\t\t\tlower := float64(values[int(pos)-1])\n\t\t\t\tupper := float64(values[int(pos)])\n\t\t\t\tscores[i] = lower + (pos-math.Floor(pos))*(upper-lower)\n\t\t\t}\n\t\t}\n\t}\n\treturn scores\n}"}, {"instruction": "// LogicalJoin can generates hash join, index join and sort merge join.\n// Firstly we check the hint, if hint is figured by user, we force to choose the corresponding physical plan.\n// If the hint is not matched, it will get other candidates.\n// If the hint is not figured, we will pick all candidates.", "input": "go language", "output": "func (p *LogicalJoin) exhaustPhysicalPlans(prop *property.PhysicalProperty) []PhysicalPlan {\n\tmergeJoins := p.getMergeJoin(prop)\n\tif (p.preferJoinType & preferMergeJoin) > 0 {\n\t\treturn mergeJoins\n\t}\n\tjoins := make([]PhysicalPlan, 0, 5)\n\tjoins = append(joins, mergeJoins...)\n\n\tindexJoins, forced := p.tryToGetIndexJoin(prop)\n\tif forced {\n\t\treturn indexJoins\n\t}\n\tjoins = append(joins, indexJoins...)\n\n\thashJoins := p.getHashJoins(prop)\n\tif (p.preferJoinType & preferHashJoin) > 0 {\n\t\treturn hashJoins\n\t}\n\tjoins = append(joins, hashJoins...)\n\treturn joins\n}"}, {"instruction": "// NewInbox creates an Inbox. An Inboxes is not persisted, the cumulative sum is updated\n// from blockchain when first cheque is received.", "input": "go language", "output": "func NewInbox(prvKey *ecdsa.PrivateKey, contractAddr, beneficiary common.Address, signer *ecdsa.PublicKey, abigen bind.ContractBackend) (*Inbox, error) {\n\tif signer == nil {\n\t\treturn nil, fmt.Errorf(\"signer is null\")\n\t}\n\tchbook, err := contract.NewChequebook(contractAddr, abigen)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttransactOpts := bind.NewKeyedTransactor(prvKey)\n\ttransactOpts.GasLimit = gasToCash\n\tsession := &contract.ChequebookSession{\n\t\tContract:     chbook,\n\t\tTransactOpts: *transactOpts,\n\t}\n\tsender := transactOpts.From\n\n\tinbox := &Inbox{\n\t\tcontract:    contractAddr,\n\t\tbeneficiary: beneficiary,\n\t\tsender:      sender,\n\t\tsigner:      signer,\n\t\tsession:     session,\n\t\tcashed:      new(big.Int).Set(common.Big0),\n\t\tlog:         log.New(\"contract\", contractAddr),\n\t}\n\tinbox.log.Trace(\"New chequebook inbox initialized\", \"beneficiary\", inbox.beneficiary, \"signer\", hexutil.Bytes(crypto.FromECDSAPub(signer)))\n\treturn inbox, nil\n}"}, {"instruction": "// Compile compiles the current tokens and returns a\n// binary string that can be interpreted by the EVM\n// and an error if it failed.\n//\n// compile is the second stage in the compile phase\n// which compiles the tokens to EVM instructions.", "input": "go language", "output": "func (c *Compiler) Compile() (string, []error) {\n\tvar errors []error\n\t// continue looping over the tokens until\n\t// the stack has been exhausted.\n\tfor c.pos < len(c.tokens) {\n\t\tif err := c.compileLine(); err != nil {\n\t\t\terrors = append(errors, err)\n\t\t}\n\t}\n\n\t// turn the binary to hex\n\tvar bin string\n\tfor _, v := range c.binary {\n\t\tswitch v := v.(type) {\n\t\tcase vm.OpCode:\n\t\t\tbin += fmt.Sprintf(\"%x\", []byte{byte(v)})\n\t\tcase []byte:\n\t\t\tbin += fmt.Sprintf(\"%x\", v)\n\t\t}\n\t}\n\treturn bin, errors\n}"}, {"instruction": "// GetLogs returns logs matching the given argument that are stored within the state.\n//\n// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getlogs", "input": "go language", "output": "func (api *PublicFilterAPI) GetLogs(ctx context.Context, crit FilterCriteria) ([]*types.Log, error) {\n\tvar filter *Filter\n\tif crit.BlockHash != nil {\n\t\t// Block filter requested, construct a single-shot filter\n\t\tfilter = NewBlockFilter(api.backend, *crit.BlockHash, crit.Addresses, crit.Topics)\n\t} else {\n\t\t// Convert the RPC block numbers into internal representations\n\t\tbegin := rpc.LatestBlockNumber.Int64()\n\t\tif crit.FromBlock != nil {\n\t\t\tbegin = crit.FromBlock.Int64()\n\t\t}\n\t\tend := rpc.LatestBlockNumber.Int64()\n\t\tif crit.ToBlock != nil {\n\t\t\tend = crit.ToBlock.Int64()\n\t\t}\n\t\t// Construct the range filter\n\t\tfilter = NewRangeFilter(api.backend, begin, end, crit.Addresses, crit.Topics)\n\t}\n\t// Run the filter and return all the logs\n\tlogs, err := filter.Logs(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn returnLogs(logs), err\n}"}, {"instruction": "// DiskIsAttached returns if disk is attached to the VM using controllers supported by the plugin.", "input": "go language", "output": "func (pc *PCCloud) DiskIsAttached(ctx context.Context, pdID string, nodeName k8stypes.NodeName) (bool, error) {\n\tphotonClient, err := getPhotonClient(pc)\n\tif err != nil {\n\t\tklog.Errorf(\"Photon Cloud Provider: Failed to get photon client for DiskIsAttached, error: [%v]\", err)\n\t\treturn false, err\n\t}\n\n\tdisk, err := photonClient.Disks.Get(pdID)\n\tif err != nil {\n\t\tklog.Errorf(\"Photon Cloud Provider: Failed to Get disk with pdID %s. Error[%v]\", pdID, err)\n\t\treturn false, err\n\t}\n\n\tvmID, err := pc.InstanceID(ctx, nodeName)\n\tif err == cloudprovider.InstanceNotFound {\n\t\tklog.Infof(\"Instance %q does not exist, disk %s will be detached automatically.\", nodeName, pdID)\n\t\treturn false, nil\n\t}\n\tif err != nil {\n\t\tklog.Errorf(\"Photon Cloud Provider: pc.InstanceID failed for DiskIsAttached. Error[%v]\", err)\n\t\treturn false, err\n\t}\n\n\tfor _, vm := range disk.VMs {\n\t\tif vm == vmID {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}"}, {"instruction": "// ConvertJSONToFloat casts JSON into float64.", "input": "go language", "output": "func ConvertJSONToFloat(sc *stmtctx.StatementContext, j json.BinaryJSON) (float64, error) {\n\tswitch j.TypeCode {\n\tcase json.TypeCodeObject, json.TypeCodeArray:\n\t\treturn 0, nil\n\tcase json.TypeCodeLiteral:\n\t\tswitch j.Value[0] {\n\t\tcase json.LiteralNil, json.LiteralFalse:\n\t\t\treturn 0, nil\n\t\tdefault:\n\t\t\treturn 1, nil\n\t\t}\n\tcase json.TypeCodeInt64:\n\t\treturn float64(j.GetInt64()), nil\n\tcase json.TypeCodeUint64:\n\t\tu, err := ConvertIntToUint(sc, j.GetInt64(), IntergerUnsignedUpperBound(mysql.TypeLonglong), mysql.TypeLonglong)\n\t\treturn float64(u), errors.Trace(err)\n\tcase json.TypeCodeFloat64:\n\t\treturn j.GetFloat64(), nil\n\tcase json.TypeCodeString:\n\t\tstr := string(hack.String(j.GetString()))\n\t\treturn StrToFloat(sc, str)\n\t}\n\treturn 0, errors.New(\"Unknown type code in JSON\")\n}"}, {"instruction": "// evalDecimal evals a builtinCaseWhenDecimalSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/case.html", "input": "go language", "output": "func (b *builtinCaseWhenDecimalSig) evalDecimal(row chunk.Row) (ret *types.MyDecimal, isNull bool, err error) {\n\tvar condition int64\n\targs, l := b.getArgs(), len(b.getArgs())\n\tfor i := 0; i < l-1; i += 2 {\n\t\tcondition, isNull, err = args[i].EvalInt(b.ctx, row)\n\t\tif err != nil {\n\t\t\treturn nil, isNull, err\n\t\t}\n\t\tif isNull || condition == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tret, isNull, err = args[i+1].EvalDecimal(b.ctx, row)\n\t\treturn ret, isNull, err\n\t}\n\t// when clause(condition, result) -> args[i], args[i+1]; (i >= 0 && i+1 < l-1)\n\t// else clause -> args[l-1]\n\t// If case clause has else clause, l%2 == 1.\n\tif l%2 == 1 {\n\t\tret, isNull, err = args[l-1].EvalDecimal(b.ctx, row)\n\t\treturn ret, isNull, err\n\t}\n\treturn ret, true, nil\n}"}, {"instruction": "// defaultProxyCommand returns the default Connect managed proxy command.", "input": "go language", "output": "func defaultProxyCommand(agentCfg *config.RuntimeConfig) ([]string, error) {\n\t// Get the path to the current executable. This is cached once by the\n\t// library so this is effectively just a variable read.\n\texecPath, err := os.Executable()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// \"consul connect proxy\" default value for managed daemon proxy\n\tcmd := []string{execPath, \"connect\", \"proxy\"}\n\n\tif agentCfg != nil && agentCfg.LogLevel != \"INFO\" {\n\t\tcmd = append(cmd, \"-log-level\", agentCfg.LogLevel)\n\t}\n\treturn cmd, nil\n}"}, {"instruction": "// NotSupported returns a *Error indicating \"unsupported value\".\n// This is used to report unknown values for enumerated fields (e.g. a list of\n// valid values).", "input": "go language", "output": "func NotSupported(field *Path, value interface{}, validValues []string) *Error {\n\tdetail := \"\"\n\tif validValues != nil && len(validValues) > 0 {\n\t\tquotedValues := make([]string, len(validValues))\n\t\tfor i, v := range validValues {\n\t\t\tquotedValues[i] = strconv.Quote(v)\n\t\t}\n\t\tdetail = \"supported values: \" + strings.Join(quotedValues, \", \")\n\t}\n\treturn &Error{ErrorTypeNotSupported, field.String(), value, detail}\n}"}, {"instruction": "// ReadDataSource returns the data source's current state.", "input": "go language", "output": "func (p *Provider) ReadDataSource(req providers.ReadDataSourceRequest) providers.ReadDataSourceResponse {\n\t// call function\n\tvar res providers.ReadDataSourceResponse\n\n\t// This should not happen\n\tif req.TypeName != \"terraform_remote_state\" {\n\t\tres.Diagnostics.Append(fmt.Errorf(\"Error: unsupported data source %s\", req.TypeName))\n\t\treturn res\n\t}\n\n\tnewState, diags := dataSourceRemoteStateRead(&req.Config)\n\n\tres.State = newState\n\tres.Diagnostics = diags\n\n\treturn res\n}"}, {"instruction": "// Returns the list of component status. Note that the label and field are both ignored.\n// Note that this call doesn't support labels or selectors.", "input": "go language", "output": "func (rs *REST) List(ctx context.Context, options *metainternalversion.ListOptions) (runtime.Object, error) {\n\tservers := rs.GetServersToValidate()\n\n\twait := sync.WaitGroup{}\n\twait.Add(len(servers))\n\tstatuses := make(chan api.ComponentStatus, len(servers))\n\tfor k, v := range servers {\n\t\tgo func(name string, server *Server) {\n\t\t\tdefer wait.Done()\n\t\t\tstatus := rs.getComponentStatus(name, server)\n\t\t\tstatuses <- *status\n\t\t}(k, v)\n\t}\n\twait.Wait()\n\tclose(statuses)\n\n\treply := []api.ComponentStatus{}\n\tfor status := range statuses {\n\t\treply = append(reply, status)\n\t}\n\treturn &api.ComponentStatusList{Items: reply}, nil\n}"}, {"instruction": "// ListLeases retrieves a list of the current master IPs from storage", "input": "go language", "output": "func (s *storageLeases) ListLeases() ([]string, error) {\n\tipInfoList := &corev1.EndpointsList{}\n\tif err := s.storage.List(apirequest.NewDefaultContext(), s.baseKey, \"0\", storage.Everything, ipInfoList); err != nil {\n\t\treturn nil, err\n\t}\n\n\tipList := make([]string, len(ipInfoList.Items))\n\tfor i, ip := range ipInfoList.Items {\n\t\tipList[i] = ip.Subsets[0].Addresses[0].IP\n\t}\n\n\tklog.V(6).Infof(\"Current master IPs listed in storage are %v\", ipList)\n\n\treturn ipList, nil\n}"}, {"instruction": "// NewController returns a new instance of the IPAM controller.", "input": "go language", "output": "func NewController(\n\tconfig *Config,\n\tkubeClient clientset.Interface,\n\tcloud cloudprovider.Interface,\n\tclusterCIDR, serviceCIDR *net.IPNet,\n\tnodeCIDRMaskSize int) (*Controller, error) {\n\n\tif !nodesync.IsValidMode(config.Mode) {\n\t\treturn nil, fmt.Errorf(\"invalid IPAM controller mode %q\", config.Mode)\n\t}\n\n\tgceCloud, ok := cloud.(*gce.Cloud)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"cloud IPAM controller does not support %q provider\", cloud.ProviderName())\n\t}\n\n\tset, err := cidrset.NewCIDRSet(clusterCIDR, nodeCIDRMaskSize)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc := &Controller{\n\t\tconfig:  config,\n\t\tadapter: newAdapter(kubeClient, gceCloud),\n\t\tsyncers: make(map[string]*nodesync.NodeSync),\n\t\tset:     set,\n\t}\n\n\tif err := occupyServiceCIDR(c.set, clusterCIDR, serviceCIDR); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// KillApplicationTasks provides a mock function with given fields: applicationID, opts", "input": "go language", "output": "func (_m *Marathon) KillApplicationTasks(applicationID string, opts *marathon.KillApplicationTasksOpts) (*marathon.Tasks, error) {\n\tret := _m.Called(applicationID, opts)\n\n\tvar r0 *marathon.Tasks\n\tif rf, ok := ret.Get(0).(func(string, *marathon.KillApplicationTasksOpts) *marathon.Tasks); ok {\n\t\tr0 = rf(applicationID, opts)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*marathon.Tasks)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(string, *marathon.KillApplicationTasksOpts) error); ok {\n\t\tr1 = rf(applicationID, opts)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// Open initializes the secure channel.", "input": "go language", "output": "func (s *SecureChannelSession) Open() error {\n\tif s.iv != nil {\n\t\treturn fmt.Errorf(\"Session already opened\")\n\t}\n\n\tresponse, err := s.open()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Generate the encryption/mac key by hashing our shared secret,\n\t// pairing key, and the first bytes returned from the Open APDU.\n\tmd := sha512.New()\n\tmd.Write(s.secret)\n\tmd.Write(s.PairingKey)\n\tmd.Write(response.Data[:scSecretLength])\n\tkeyData := md.Sum(nil)\n\ts.sessionEncKey = keyData[:scSecretLength]\n\ts.sessionMacKey = keyData[scSecretLength : scSecretLength*2]\n\n\t// The IV is the last bytes returned from the Open APDU.\n\ts.iv = response.Data[scSecretLength:]\n\n\treturn s.mutuallyAuthenticate()\n}"}, {"instruction": "// returnStream is used when done with a stream\n// to allow re-use by a future RPC", "input": "go language", "output": "func (c *Conn) returnClient(client *StreamClient) {\n\tdidSave := false\n\tc.clientLock.Lock()\n\tif c.clients.Len() < c.pool.MaxStreams && atomic.LoadInt32(&c.shouldClose) == 0 {\n\t\tc.clients.PushFront(client)\n\t\tdidSave = true\n\n\t\t// If this is a Yamux stream, shrink the internal buffers so that\n\t\t// we can GC the idle memory\n\t\tif ys, ok := client.stream.(*yamux.Stream); ok {\n\t\t\tys.Shrink()\n\t\t}\n\t}\n\tc.clientLock.Unlock()\n\tif !didSave {\n\t\tclient.Close()\n\t}\n}"}, {"instruction": "// enqueueTx inserts a new transaction into the non-executable transaction queue.\n//\n// Note, this method assumes the pool lock is held!", "input": "go language", "output": "func (pool *TxPool) enqueueTx(hash common.Hash, tx *types.Transaction) (bool, error) {\n\t// Try to insert the transaction into the future queue\n\tfrom, _ := types.Sender(pool.signer, tx) // already validated\n\tif pool.queue[from] == nil {\n\t\tpool.queue[from] = newTxList(false)\n\t}\n\tinserted, old := pool.queue[from].Add(tx, pool.config.PriceBump)\n\tif !inserted {\n\t\t// An older transaction was better, discard this\n\t\tqueuedDiscardCounter.Inc(1)\n\t\treturn false, ErrReplaceUnderpriced\n\t}\n\t// Discard any previous transaction and mark this\n\tif old != nil {\n\t\tpool.all.Remove(old.Hash())\n\t\tpool.priced.Removed()\n\t\tqueuedReplaceCounter.Inc(1)\n\t}\n\tif pool.all.Get(hash) == nil {\n\t\tpool.all.Add(tx)\n\t\tpool.priced.Put(tx)\n\t}\n\treturn old != nil, nil\n}"}, {"instruction": "// handleDivisionByZeroError reports error or warning depend on the context.", "input": "go language", "output": "func handleDivisionByZeroError(ctx sessionctx.Context) error {\n\tsc := ctx.GetSessionVars().StmtCtx\n\tif sc.InInsertStmt || sc.InUpdateStmt || sc.InDeleteStmt {\n\t\tif !ctx.GetSessionVars().SQLMode.HasErrorForDivisionByZeroMode() {\n\t\t\treturn nil\n\t\t}\n\t\tif ctx.GetSessionVars().StrictSQLMode && !sc.DividedByZeroAsWarning {\n\t\t\treturn ErrDivisionByZero\n\t\t}\n\t}\n\tsc.AppendWarning(ErrDivisionByZero)\n\treturn nil\n}"}, {"instruction": "// Upload performs the upload of the directory and default path", "input": "go language", "output": "func (d *DirectoryUploader) Upload(upload UploadFn) error {\n\treturn filepath.Walk(d.Dir, func(path string, f os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif f.IsDir() {\n\t\t\treturn nil\n\t\t}\n\t\tfile, err := Open(path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\trelPath, err := filepath.Rel(d.Dir, path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfile.Path = filepath.ToSlash(relPath)\n\t\treturn upload(file)\n\t})\n}"}, {"instruction": "// equalFoldRight is a specialization of bytes.EqualFold when s is\n// known to be all ASCII (including punctuation), but contains an 's',\n// 'S', 'k', or 'K', requiring a Unicode fold on the bytes in t.\n// See comments on foldFunc.", "input": "go language", "output": "func equalFoldRight(s, t []byte) bool {\n\tfor _, sb := range s {\n\t\tif len(t) == 0 {\n\t\t\treturn false\n\t\t}\n\t\ttb := t[0]\n\t\tif tb < utf8.RuneSelf {\n\t\t\tif sb != tb {\n\t\t\t\tsbUpper := sb & caseMask\n\t\t\t\tif 'A' <= sbUpper && sbUpper <= 'Z' {\n\t\t\t\t\tif sbUpper != tb&caseMask {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tt = t[1:]\n\t\t\tcontinue\n\t\t}\n\t\t// sb is ASCII and t is not. t must be either kelvin\n\t\t// sign or long s; sb must be s, S, k, or K.\n\t\ttr, size := utf8.DecodeRune(t)\n\t\tswitch sb {\n\t\tcase 's', 'S':\n\t\t\tif tr != smallLongEss {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase 'k', 'K':\n\t\t\tif tr != kelvin {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t\tt = t[size:]\n\n\t}\n\tif len(t) > 0 {\n\t\treturn false\n\t}\n\treturn true\n}"}, {"instruction": "// ValidateIPBlock validates a cidr and the except fields of an IpBlock NetworkPolicyPeer", "input": "go language", "output": "func ValidateIPBlock(ipb *networking.IPBlock, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tif len(ipb.CIDR) == 0 || ipb.CIDR == \"\" {\n\t\tallErrs = append(allErrs, field.Required(fldPath.Child(\"cidr\"), \"\"))\n\t\treturn allErrs\n\t}\n\tcidrIPNet, err := apivalidation.ValidateCIDR(ipb.CIDR)\n\tif err != nil {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath.Child(\"cidr\"), ipb.CIDR, \"not a valid CIDR\"))\n\t\treturn allErrs\n\t}\n\texceptCIDR := ipb.Except\n\tfor i, exceptIP := range exceptCIDR {\n\t\texceptPath := fldPath.Child(\"except\").Index(i)\n\t\texceptCIDR, err := apivalidation.ValidateCIDR(exceptIP)\n\t\tif err != nil {\n\t\t\tallErrs = append(allErrs, field.Invalid(exceptPath, exceptIP, \"not a valid CIDR\"))\n\t\t\treturn allErrs\n\t\t}\n\t\tif !cidrIPNet.Contains(exceptCIDR.IP) {\n\t\t\tallErrs = append(allErrs, field.Invalid(exceptPath, exceptCIDR.IP, \"not within CIDR range\"))\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// SelectorFromValidatedSet returns a Selector which will match exactly the given Set.\n// A nil and empty Sets are considered equivalent to Everything().\n// It assumes that Set is already validated and doesn't do any validation.", "input": "go language", "output": "func SelectorFromValidatedSet(ls Set) Selector {\n\tif ls == nil || len(ls) == 0 {\n\t\treturn internalSelector{}\n\t}\n\tvar requirements internalSelector\n\tfor label, value := range ls {\n\t\trequirements = append(requirements, Requirement{key: label, operator: selection.Equals, strValues: []string{value}})\n\t}\n\t// sort to have deterministic string representation\n\tsort.Sort(ByKey(requirements))\n\treturn requirements\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of CertificateSigningRequests that match those selectors.", "input": "go language", "output": "func (c *FakeCertificateSigningRequests) List(opts v1.ListOptions) (result *v1beta1.CertificateSigningRequestList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootListAction(certificatesigningrequestsResource, certificatesigningrequestsKind, opts), &v1beta1.CertificateSigningRequestList{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta1.CertificateSigningRequestList{ListMeta: obj.(*v1beta1.CertificateSigningRequestList).ListMeta}\n\tfor _, item := range obj.(*v1beta1.CertificateSigningRequestList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// WithIPv4 sets the specified ip for the specified network of the container", "input": "go language", "output": "func WithIPv4(network, ip string) func(*TestContainerConfig) {\n\treturn func(c *TestContainerConfig) {\n\t\tif c.NetworkingConfig.EndpointsConfig == nil {\n\t\t\tc.NetworkingConfig.EndpointsConfig = map[string]*networktypes.EndpointSettings{}\n\t\t}\n\t\tif v, ok := c.NetworkingConfig.EndpointsConfig[network]; !ok || v == nil {\n\t\t\tc.NetworkingConfig.EndpointsConfig[network] = &networktypes.EndpointSettings{}\n\t\t}\n\t\tif c.NetworkingConfig.EndpointsConfig[network].IPAMConfig == nil {\n\t\t\tc.NetworkingConfig.EndpointsConfig[network].IPAMConfig = &networktypes.EndpointIPAMConfig{}\n\t\t}\n\t\tc.NetworkingConfig.EndpointsConfig[network].IPAMConfig.IPv4Address = ip\n\t}\n}"}, {"instruction": "// Get is used to lookup a single key.", "input": "go language", "output": "func (k *KVS) Get(args *structs.KeyRequest, reply *structs.IndexedDirEntries) error {\n\tif done, err := k.srv.forward(\"KVS.Get\", args, args, reply); done {\n\t\treturn err\n\t}\n\n\taclRule, err := k.srv.ResolveToken(args.Token)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn k.srv.blockingQuery(\n\t\t&args.QueryOptions,\n\t\t&reply.QueryMeta,\n\t\tfunc(ws memdb.WatchSet, state *state.Store) error {\n\t\t\tindex, ent, err := state.KVSGet(ws, args.Key)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif aclRule != nil && !aclRule.KeyRead(args.Key) {\n\t\t\t\treturn acl.ErrPermissionDenied\n\t\t\t}\n\n\t\t\tif ent == nil {\n\t\t\t\t// Must provide non-zero index to prevent blocking\n\t\t\t\t// Index 1 is impossible anyways (due to Raft internals)\n\t\t\t\tif index == 0 {\n\t\t\t\t\treply.Index = 1\n\t\t\t\t} else {\n\t\t\t\t\treply.Index = index\n\t\t\t\t}\n\t\t\t\treply.Entries = nil\n\t\t\t} else {\n\t\t\t\treply.Index = ent.ModifyIndex\n\t\t\t\treply.Entries = structs.DirEntries{ent}\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n}"}, {"instruction": "// NewImageManager instantiates a new ImageManager object.", "input": "go language", "output": "func NewImageManager(recorder record.EventRecorder, imageService kubecontainer.ImageService, imageBackOff *flowcontrol.Backoff, serialized bool, qps float32, burst int) ImageManager {\n\timageService = throttleImagePulling(imageService, qps, burst)\n\n\tvar puller imagePuller\n\tif serialized {\n\t\tpuller = newSerialImagePuller(imageService)\n\t} else {\n\t\tpuller = newParallelImagePuller(imageService)\n\t}\n\treturn &imageManager{\n\t\trecorder:     recorder,\n\t\timageService: imageService,\n\t\tbackOff:      imageBackOff,\n\t\tpuller:       puller,\n\t}\n}"}, {"instruction": "// ReadReceipt retrieves a specific transaction receipt from the database, along with\n// its added positional metadata.", "input": "go language", "output": "func ReadReceipt(db ethdb.Reader, hash common.Hash, config *params.ChainConfig) (*types.Receipt, common.Hash, uint64, uint64) {\n\t// Retrieve the context of the receipt based on the transaction hash\n\tblockNumber := ReadTxLookupEntry(db, hash)\n\tif blockNumber == nil {\n\t\treturn nil, common.Hash{}, 0, 0\n\t}\n\tblockHash := ReadCanonicalHash(db, *blockNumber)\n\tif blockHash == (common.Hash{}) {\n\t\treturn nil, common.Hash{}, 0, 0\n\t}\n\t// Read all the receipts from the block and return the one with the matching hash\n\treceipts := ReadReceipts(db, blockHash, *blockNumber, config)\n\tfor receiptIndex, receipt := range receipts {\n\t\tif receipt.TxHash == hash {\n\t\t\treturn receipt, blockHash, *blockNumber, uint64(receiptIndex)\n\t\t}\n\t}\n\tlog.Error(\"Receipt not found\", \"number\", blockNumber, \"hash\", blockHash, \"txhash\", hash)\n\treturn nil, common.Hash{}, 0, 0\n}"}, {"instruction": "// peek creates the next state of the iterator.", "input": "go language", "output": "func (it *nodeIterator) peek(descend bool) (*nodeIteratorState, *int, []byte, error) {\n\tif len(it.stack) == 0 {\n\t\t// Initialize the iterator if we've just started.\n\t\troot := it.trie.Hash()\n\t\tstate := &nodeIteratorState{node: it.trie.root, index: -1}\n\t\tif root != emptyRoot {\n\t\t\tstate.hash = root\n\t\t}\n\t\terr := state.resolve(it.trie, nil)\n\t\treturn state, nil, nil, err\n\t}\n\tif !descend {\n\t\t// If we're skipping children, pop the current node first\n\t\tit.pop()\n\t}\n\n\t// Continue iteration to the next child\n\tfor len(it.stack) > 0 {\n\t\tparent := it.stack[len(it.stack)-1]\n\t\tancestor := parent.hash\n\t\tif (ancestor == common.Hash{}) {\n\t\t\tancestor = parent.parent\n\t\t}\n\t\tstate, path, ok := it.nextChild(parent, ancestor)\n\t\tif ok {\n\t\t\tif err := state.resolve(it.trie, path); err != nil {\n\t\t\t\treturn parent, &parent.index, path, err\n\t\t\t}\n\t\t\treturn state, &parent.index, path, nil\n\t\t}\n\t\t// No more child nodes, move back up.\n\t\tit.pop()\n\t}\n\treturn nil, nil, nil, errIteratorEnd\n}"}, {"instruction": "// assignPod assigns the given pod to the given machine.", "input": "go language", "output": "func (r *BindingREST) assignPod(ctx context.Context, podID string, machine string, annotations map[string]string, dryRun bool) (err error) {\n\tif _, err = r.setPodHostAndAnnotations(ctx, podID, \"\", machine, annotations, dryRun); err != nil {\n\t\terr = storeerr.InterpretGetError(err, api.Resource(\"pods\"), podID)\n\t\terr = storeerr.InterpretUpdateError(err, api.Resource(\"pods\"), podID)\n\t\tif _, ok := err.(*errors.StatusError); !ok {\n\t\t\terr = errors.NewConflict(api.Resource(\"pods/binding\"), podID, err)\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// NewPeerClientForAddress creates an instance of a PeerClient using the\n// provided peer address and, if TLS is enabled, the TLS root cert file", "input": "go language", "output": "func NewPeerClientForAddress(address, tlsRootCertFile string) (*PeerClient, error) {\n\tif address == \"\" {\n\t\treturn nil, errors.New(\"peer address must be set\")\n\t}\n\n\t_, override, clientConfig, err := configFromEnv(\"peer\")\n\tif clientConfig.SecOpts.UseTLS {\n\t\tif tlsRootCertFile == \"\" {\n\t\t\treturn nil, errors.New(\"tls root cert file must be set\")\n\t\t}\n\t\tcaPEM, res := ioutil.ReadFile(tlsRootCertFile)\n\t\tif res != nil {\n\t\t\terr = errors.WithMessage(res, fmt.Sprintf(\"unable to load TLS root cert file from %s\", tlsRootCertFile))\n\t\t\treturn nil, err\n\t\t}\n\t\tclientConfig.SecOpts.ServerRootCAs = [][]byte{caPEM}\n\t}\n\treturn newPeerClientForClientConfig(address, override, clientConfig)\n}"}, {"instruction": "// Get returns the previously stored value, or the empty string if it does not exist or key is of 0-length", "input": "go language", "output": "func (s *AESEncryptedStorage) Get(key string) string {\n\tif len(key) == 0 {\n\t\treturn \"\"\n\t}\n\tdata, err := s.readEncryptedStorage()\n\tif err != nil {\n\t\tlog.Warn(\"Failed to read encrypted storage\", \"err\", err, \"file\", s.filename)\n\t\treturn \"\"\n\t}\n\tencrypted, exist := data[key]\n\tif !exist {\n\t\tlog.Warn(\"Key does not exist\", \"key\", key)\n\t\treturn \"\"\n\t}\n\tentry, err := decrypt(s.key, encrypted.Iv, encrypted.CipherText, []byte(key))\n\tif err != nil {\n\t\tlog.Warn(\"Failed to decrypt key\", \"key\", key)\n\t\treturn \"\"\n\t}\n\treturn string(entry)\n}"}, {"instruction": "// NewECDSASignerEntity returns a signer entity that is capable of signing using ECDSA", "input": "go language", "output": "func NewECDSASignerEntity(ID string, b bccsp.BCCSP, signKeyBytes []byte) (*BCCSPSignerEntity, error) {\n\tif b == nil {\n\t\treturn nil, errors.New(\"nil BCCSP\")\n\t}\n\n\tbl, _ := pem.Decode(signKeyBytes)\n\tif bl == nil {\n\t\treturn nil, errors.New(\"pem.Decode returns nil\")\n\t}\n\n\tsignKey, err := b.KeyImport(bl.Bytes, &bccsp.ECDSAPrivateKeyImportOpts{Temporary: true})\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, \"bccspInst.KeyImport failed\")\n\t}\n\n\treturn NewSignerEntity(ID, b, signKey, nil, &bccsp.SHA256Opts{})\n}"}, {"instruction": "// <endpointsMap> is updated by this function (based on the given changes).\n// <changes> map is cleared after applying them.", "input": "go language", "output": "func (proxier *Proxier) updateEndpointsMap() (result updateEndpointMapResult) {\n\tresult.staleEndpoints = make(map[endpointServicePair]bool)\n\tresult.staleServiceNames = make(map[proxy.ServicePortName]bool)\n\n\tvar endpointsMap proxyEndpointsMap = proxier.endpointsMap\n\tvar changes *endpointsChangeMap = &proxier.endpointsChanges\n\n\tfunc() {\n\t\tchanges.lock.Lock()\n\t\tdefer changes.lock.Unlock()\n\t\tfor _, change := range changes.items {\n\t\t\tendpointsMap.unmerge(change.previous, proxier.serviceMap)\n\t\t\tendpointsMap.merge(change.current, proxier.serviceMap)\n\t\t}\n\t\tchanges.items = make(map[types.NamespacedName]*endpointsChange)\n\t}()\n\n\t// TODO: If this will appear to be computationally expensive, consider\n\t// computing this incrementally similarly to endpointsMap.\n\tresult.hcEndpoints = make(map[types.NamespacedName]int)\n\tlocalIPs := getLocalIPs(endpointsMap)\n\tfor nsn, ips := range localIPs {\n\t\tresult.hcEndpoints[nsn] = len(ips)\n\t}\n\n\treturn result\n}"}, {"instruction": "// grantColumnPriv manipulates mysql.tables_priv table.", "input": "go language", "output": "func (e *GrantExec) grantColumnPriv(priv *ast.PrivElem, user *ast.UserSpec) error {\n\tdbName, tbl, err := getTargetSchemaAndTable(e.ctx, e.Level.DBName, e.Level.TableName, e.is)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, c := range priv.Cols {\n\t\tcol := table.FindCol(tbl.Cols(), c.Name.L)\n\t\tif col == nil {\n\t\t\treturn errors.Errorf(\"Unknown column: %s\", c)\n\t\t}\n\t\tasgns, err := composeColumnPrivUpdateForGrant(e.ctx, priv.Priv, user.User.Username, user.User.Hostname, dbName, tbl.Meta().Name.O, col.Name.O)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsql := fmt.Sprintf(`UPDATE %s.%s SET %s WHERE User='%s' AND Host='%s' AND DB='%s' AND Table_name='%s' AND Column_name='%s';`, mysql.SystemDB, mysql.ColumnPrivTable, asgns, user.User.Username, user.User.Hostname, dbName, tbl.Meta().Name.O, col.Name.O)\n\t\t_, _, err = e.ctx.(sqlexec.RestrictedSQLExecutor).ExecRestrictedSQL(e.ctx, sql)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// bumpInBucket moves the given node to the front of the bucket entry list\n// if it is contained in that list.", "input": "go language", "output": "func (tab *Table) bumpInBucket(b *bucket, n *node) bool {\n\tfor i := range b.entries {\n\t\tif b.entries[i].ID() == n.ID() {\n\t\t\tif !n.IP().Equal(b.entries[i].IP()) {\n\t\t\t\t// Endpoint has changed, ensure that the new IP fits into table limits.\n\t\t\t\ttab.removeIP(b, b.entries[i].IP())\n\t\t\t\tif !tab.addIP(b, n.IP()) {\n\t\t\t\t\t// It doesn't, put the previous one back.\n\t\t\t\t\ttab.addIP(b, b.entries[i].IP())\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Move it to the front.\n\t\t\tcopy(b.entries[1:], b.entries[:i])\n\t\t\tb.entries[0] = n\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}"}, {"instruction": "// EqualDatums compare if a and b contains the same datum values.", "input": "go language", "output": "func EqualDatums(sc *stmtctx.StatementContext, a []Datum, b []Datum) (bool, error) {\n\tif len(a) != len(b) {\n\t\treturn false, nil\n\t}\n\tif a == nil && b == nil {\n\t\treturn true, nil\n\t}\n\tif a == nil || b == nil {\n\t\treturn false, nil\n\t}\n\tfor i, ai := range a {\n\t\tv, err := ai.CompareDatum(sc, &b[i])\n\t\tif err != nil {\n\t\t\treturn false, errors.Trace(err)\n\t\t}\n\t\tif v != 0 {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}"}, {"instruction": "// SyntaxError converts parser error to TiDB's syntax error.", "input": "go language", "output": "func SyntaxError(err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\tlogutil.Logger(context.Background()).Error(\"syntax error\", zap.Error(err))\n\n\t// If the error is already a terror with stack, pass it through.\n\tif errors.HasStack(err) {\n\t\tcause := errors.Cause(err)\n\t\tif _, ok := cause.(*terror.Error); ok {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn parser.ErrParse.GenWithStackByArgs(syntaxErrorPrefix, err.Error())\n}"}, {"instruction": "// DeleteTeam will delete a team, its member and any permissions connected to the team", "input": "go language", "output": "func DeleteTeam(cmd *m.DeleteTeamCommand) error {\n\treturn inTransaction(func(sess *DBSession) error {\n\t\tif _, err := teamExists(cmd.OrgId, cmd.Id, sess); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdeletes := []string{\n\t\t\t\"DELETE FROM team_member WHERE org_id=? and team_id = ?\",\n\t\t\t\"DELETE FROM team WHERE org_id=? and id = ?\",\n\t\t\t\"DELETE FROM dashboard_acl WHERE org_id=? and team_id = ?\",\n\t\t}\n\n\t\tfor _, sql := range deletes {\n\t\t\t_, err := sess.Exec(sql, cmd.OrgId, cmd.Id)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}"}, {"instruction": "// NodeAddressesByProviderID will not be called from the node that is requesting this ID.\n// i.e. metadata service and other local methods cannot be used here", "input": "go language", "output": "func (g *Cloud) NodeAddressesByProviderID(ctx context.Context, providerID string) ([]v1.NodeAddress, error) {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\t_, zone, name, err := splitProviderID(providerID)\n\tif err != nil {\n\t\treturn []v1.NodeAddress{}, err\n\t}\n\n\tinstance, err := g.c.Instances().Get(ctx, meta.ZonalKey(canonicalizeInstanceName(name), zone))\n\tif err != nil {\n\t\treturn []v1.NodeAddress{}, fmt.Errorf(\"error while querying for providerID %q: %v\", providerID, err)\n\t}\n\n\tif len(instance.NetworkInterfaces) < 1 {\n\t\treturn []v1.NodeAddress{}, fmt.Errorf(\"could not find network interfaces for providerID %q\", providerID)\n\t}\n\tnetworkInterface := instance.NetworkInterfaces[0]\n\n\tnodeAddresses := []v1.NodeAddress{{Type: v1.NodeInternalIP, Address: networkInterface.NetworkIP}}\n\tfor _, config := range networkInterface.AccessConfigs {\n\t\tnodeAddresses = append(nodeAddresses, v1.NodeAddress{Type: v1.NodeExternalIP, Address: config.NatIP})\n\t}\n\n\treturn nodeAddresses, nil\n}"}, {"instruction": "// evalString evals a builtinPasswordSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/encryption-functions.html#function_password", "input": "go language", "output": "func (b *builtinPasswordSig) evalString(row chunk.Row) (d string, isNull bool, err error) {\n\tpass, isNull, err := b.args[0].EvalString(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn \"\", err != nil, err\n\t}\n\n\tif len(pass) == 0 {\n\t\treturn \"\", false, nil\n\t}\n\n\t// We should append a warning here because function \"PASSWORD\" is deprecated since MySQL 5.7.6.\n\t// See https://dev.mysql.com/doc/refman/5.7/en/encryption-functions.html#function_password\n\tb.ctx.GetSessionVars().StmtCtx.AppendWarning(errDeprecatedSyntaxNoReplacement.GenWithStackByArgs(\"PASSWORD\"))\n\n\treturn auth.EncodePassword(pass), false, nil\n}"}, {"instruction": "// AddFlags adds flags for the insecure serving options.", "input": "go language", "output": "func (o *CombinedInsecureServingOptions) AddFlags(fs *pflag.FlagSet) {\n\tif o == nil {\n\t\treturn\n\t}\n\n\tfs.StringVar(&o.BindAddress, \"address\", o.BindAddress, \"DEPRECATED: the IP address on which to listen for the --port port (set to 0.0.0.0 for all IPv4 interfaces and :: for all IPv6 interfaces). See --bind-address instead.\")\n\t// MarkDeprecated hides the flag from the help. We don't want that:\n\t// fs.MarkDeprecated(\"address\", \"see --bind-address instead.\")\n\tfs.IntVar(&o.BindPort, \"port\", o.BindPort, \"DEPRECATED: the port on which to serve HTTP insecurely without authentication and authorization. If 0, don't serve HTTPS at all. See --secure-port instead.\")\n\t// MarkDeprecated hides the flag from the help. We don't want that:\n\t// fs.MarkDeprecated(\"port\", \"see --secure-port instead.\")\n}"}, {"instruction": "// Scan queries continuous kv pairs in range [startKey, endKey), up to limit pairs.\n// If endKey is empty, it means unbounded.\n// If you want to exclude the startKey or include the endKey, append a '\\0' to the key. For example, to scan\n// (startKey, endKey], you can write:\n// `Scan(append(startKey, '\\0'), append(endKey, '\\0'), limit)`.", "input": "go language", "output": "func (c *RawKVClient) Scan(startKey, endKey []byte, limit int) (keys [][]byte, values [][]byte, err error) {\n\tstart := time.Now()\n\tdefer func() { tikvRawkvCmdHistogramWithRawScan.Observe(time.Since(start).Seconds()) }()\n\n\tif limit > MaxRawKVScanLimit {\n\t\treturn nil, nil, errors.Trace(ErrMaxScanLimitExceeded)\n\t}\n\n\tfor len(keys) < limit {\n\t\treq := &tikvrpc.Request{\n\t\t\tType: tikvrpc.CmdRawScan,\n\t\t\tRawScan: &kvrpcpb.RawScanRequest{\n\t\t\t\tStartKey: startKey,\n\t\t\t\tEndKey:   endKey,\n\t\t\t\tLimit:    uint32(limit - len(keys)),\n\t\t\t},\n\t\t}\n\t\tresp, loc, err := c.sendReq(startKey, req, false)\n\t\tif err != nil {\n\t\t\treturn nil, nil, errors.Trace(err)\n\t\t}\n\t\tcmdResp := resp.RawScan\n\t\tif cmdResp == nil {\n\t\t\treturn nil, nil, errors.Trace(ErrBodyMissing)\n\t\t}\n\t\tfor _, pair := range cmdResp.Kvs {\n\t\t\tkeys = append(keys, pair.Key)\n\t\t\tvalues = append(values, pair.Value)\n\t\t}\n\t\tstartKey = loc.EndKey\n\t\tif len(startKey) == 0 {\n\t\t\tbreak\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// GetFromKubeletConfigMap returns the pointer to the ComponentConfig API object read from the kubelet-config-version\n// ConfigMap map stored in the cluster", "input": "go language", "output": "func GetFromKubeletConfigMap(client clientset.Interface, version *version.Version) (runtime.Object, error) {\n\n\t// Read the ConfigMap from the cluster based on what version the kubelet is\n\tconfigMapName := kubeadmconstants.GetKubeletConfigMapName(version)\n\tkubeletCfg, err := client.CoreV1().ConfigMaps(metav1.NamespaceSystem).Get(configMapName, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tkubeletConfigData, ok := kubeletCfg.Data[kubeadmconstants.KubeletBaseConfigurationConfigMapKey]\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"unexpected error when reading %s ConfigMap: %s key value pair missing\",\n\t\t\tconfigMapName, kubeadmconstants.KubeletBaseConfigurationConfigMapKey)\n\t}\n\n\t// Decodes the kubeletConfigData into the internal component config\n\tobj := &kubeletconfig.KubeletConfiguration{}\n\terr = unmarshalObject(obj, []byte(kubeletConfigData))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn obj, nil\n}"}, {"instruction": "// writeToTar writes a single file to a tar archive.", "input": "go language", "output": "func writeToTar(out *tar.Writer, name string, body []byte) error {\n\t// TODO: Do we need to create dummy parent directory names if none exist?\n\th := &tar.Header{\n\t\tName:    filepath.ToSlash(name),\n\t\tMode:    0755,\n\t\tSize:    int64(len(body)),\n\t\tModTime: time.Now(),\n\t}\n\tif err := out.WriteHeader(h); err != nil {\n\t\treturn err\n\t}\n\tif _, err := out.Write(body); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// MakePortMappings creates internal port mapping from api port mapping.", "input": "go language", "output": "func MakePortMappings(container *v1.Container) (ports []PortMapping) {\n\tnames := make(map[string]struct{})\n\tfor _, p := range container.Ports {\n\t\tpm := PortMapping{\n\t\t\tHostPort:      int(p.HostPort),\n\t\t\tContainerPort: int(p.ContainerPort),\n\t\t\tProtocol:      p.Protocol,\n\t\t\tHostIP:        p.HostIP,\n\t\t}\n\n\t\t// We need to create some default port name if it's not specified, since\n\t\t// this is necessary for rkt.\n\t\t// http://issue.k8s.io/7710\n\t\tif p.Name == \"\" {\n\t\t\tpm.Name = fmt.Sprintf(\"%s-%s:%d\", container.Name, p.Protocol, p.ContainerPort)\n\t\t} else {\n\t\t\tpm.Name = fmt.Sprintf(\"%s-%s\", container.Name, p.Name)\n\t\t}\n\n\t\t// Protect against exposing the same protocol-port more than once in a container.\n\t\tif _, ok := names[pm.Name]; ok {\n\t\t\tklog.Warningf(\"Port name conflicted, %q is defined more than once\", pm.Name)\n\t\t\tcontinue\n\t\t}\n\t\tports = append(ports, pm)\n\t\tnames[pm.Name] = struct{}{}\n\t}\n\treturn\n}"}, {"instruction": "// login calls SessionManager.LoginByToken if certificate and private key are configured,\n// otherwise calls SessionManager.Login with user and password.", "input": "go language", "output": "func (connection *VSphereConnection) login(ctx context.Context, client *vim25.Client) error {\n\tm := session.NewManager(client)\n\tconnection.credentialsLock.Lock()\n\tdefer connection.credentialsLock.Unlock()\n\n\tsigner, err := connection.Signer(ctx, client)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif signer == nil {\n\t\tklog.V(3).Infof(\"SessionManager.Login with username %q\", connection.Username)\n\t\treturn m.Login(ctx, neturl.UserPassword(connection.Username, connection.Password))\n\t}\n\n\tklog.V(3).Infof(\"SessionManager.LoginByToken with certificate %q\", connection.Username)\n\n\theader := soap.Header{Security: signer}\n\n\treturn m.LoginByToken(client.WithHeader(ctx, header))\n}"}, {"instruction": "// AuthMethodDelete deletes an auth method given its Name.", "input": "go language", "output": "func (a *ACL) AuthMethodDelete(methodName string, q *WriteOptions) (*WriteMeta, error) {\n\tif methodName == \"\" {\n\t\treturn nil, fmt.Errorf(\"Must specify a Name in Auth Method Delete\")\n\t}\n\n\tr := a.c.newRequest(\"DELETE\", \"/v1/acl/auth-method/\"+url.QueryEscape(methodName))\n\tr.setWriteOptions(q)\n\trtt, resp, err := requireOK(a.c.doRequest(r))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresp.Body.Close()\n\n\twm := &WriteMeta{RequestTime: rtt}\n\treturn wm, nil\n}"}, {"instruction": "// TranslateInTreePVToCSI takes a PV with Cinder set from in-tree\n// and converts the Cinder source to a CSIPersistentVolumeSource", "input": "go language", "output": "func (t *osCinderCSITranslator) TranslateInTreePVToCSI(pv *v1.PersistentVolume) (*v1.PersistentVolume, error) {\n\tif pv == nil || pv.Spec.Cinder == nil {\n\t\treturn nil, fmt.Errorf(\"pv is nil or Cinder not defined on pv\")\n\t}\n\n\tcinderSource := pv.Spec.Cinder\n\n\tcsiSource := &v1.CSIPersistentVolumeSource{\n\t\tDriver:           CinderDriverName,\n\t\tVolumeHandle:     cinderSource.VolumeID,\n\t\tReadOnly:         cinderSource.ReadOnly,\n\t\tFSType:           cinderSource.FSType,\n\t\tVolumeAttributes: map[string]string{},\n\t}\n\n\tpv.Spec.Cinder = nil\n\tpv.Spec.CSI = csiSource\n\treturn pv, nil\n}"}, {"instruction": "// GetLabelsForVolume gets the volume labels for a volume", "input": "go language", "output": "func (c *Cloud) GetLabelsForVolume(ctx context.Context, pv *v1.PersistentVolume) (map[string]string, error) {\n\t// Ignore if not AWSElasticBlockStore.\n\tif pv.Spec.AWSElasticBlockStore == nil {\n\t\treturn nil, nil\n\t}\n\n\t// Ignore any volumes that are being provisioned\n\tif pv.Spec.AWSElasticBlockStore.VolumeID == cloudvolume.ProvisionedVolumeName {\n\t\treturn nil, nil\n\t}\n\n\tspec := KubernetesVolumeID(pv.Spec.AWSElasticBlockStore.VolumeID)\n\tlabels, err := c.GetVolumeLabels(spec)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn labels, nil\n}"}, {"instruction": "// cleanupStaleStickySessions cleans up any stale sticky session records in the hash map.", "input": "go language", "output": "func (proxier *Proxier) cleanupStaleStickySessions() {\n\tproxier.mu.Lock()\n\tdefer proxier.mu.Unlock()\n\tservicePortNameMap := make(map[proxy.ServicePortName]bool)\n\tfor name := range proxier.serviceMap {\n\t\tservicePortName := proxy.ServicePortName{\n\t\t\tNamespacedName: types.NamespacedName{\n\t\t\t\tNamespace: name.Namespace,\n\t\t\t\tName:      name.Name,\n\t\t\t},\n\t\t\tPort: name.Port,\n\t\t}\n\t\tif servicePortNameMap[servicePortName] == false {\n\t\t\t// ensure cleanup sticky sessions only gets called once per serviceportname\n\t\t\tservicePortNameMap[servicePortName] = true\n\t\t\tproxier.loadBalancer.CleanupStaleStickySessions(servicePortName)\n\t\t}\n\t}\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *ShowDDLJobQueriesExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\treq.GrowAndReset(e.maxChunkSize)\n\tif e.cursor >= len(e.jobs) {\n\t\treturn nil\n\t}\n\tif len(e.jobIDs) >= len(e.jobs) {\n\t\treturn nil\n\t}\n\tnumCurBatch := mathutil.Min(req.Capacity(), len(e.jobs)-e.cursor)\n\tfor _, id := range e.jobIDs {\n\t\tfor i := e.cursor; i < e.cursor+numCurBatch; i++ {\n\t\t\tif id == e.jobs[i].ID {\n\t\t\t\treq.AppendString(0, e.jobs[i].Query)\n\t\t\t}\n\t\t}\n\t}\n\te.cursor += numCurBatch\n\treturn nil\n}"}, {"instruction": "// Format the ExprNode into a Writer.", "input": "go language", "output": "func (n *ValueExpr) Format(w io.Writer) {\n\tvar s string\n\tswitch n.Kind() {\n\tcase types.KindNull:\n\t\ts = \"NULL\"\n\tcase types.KindInt64:\n\t\tif n.Type.Flag&mysql.IsBooleanFlag != 0 {\n\t\t\tif n.GetInt64() > 0 {\n\t\t\t\ts = \"TRUE\"\n\t\t\t} else {\n\t\t\t\ts = \"FALSE\"\n\t\t\t}\n\t\t} else {\n\t\t\ts = strconv.FormatInt(n.GetInt64(), 10)\n\t\t}\n\tcase types.KindUint64:\n\t\ts = strconv.FormatUint(n.GetUint64(), 10)\n\tcase types.KindFloat32:\n\t\ts = strconv.FormatFloat(n.GetFloat64(), 'e', -1, 32)\n\tcase types.KindFloat64:\n\t\ts = strconv.FormatFloat(n.GetFloat64(), 'e', -1, 64)\n\tcase types.KindString, types.KindBytes:\n\t\ts = strconv.Quote(n.GetString())\n\tcase types.KindMysqlDecimal:\n\t\ts = n.GetMysqlDecimal().String()\n\tcase types.KindBinaryLiteral:\n\t\tif n.Type.Flag&mysql.UnsignedFlag != 0 {\n\t\t\ts = fmt.Sprintf(\"x'%x'\", n.GetBytes())\n\t\t} else {\n\t\t\ts = n.GetBinaryLiteral().ToBitLiteralString(true)\n\t\t}\n\tdefault:\n\t\tpanic(\"Can't format to string\")\n\t}\n\tfmt.Fprint(w, s)\n}"}, {"instruction": "// RequestHeadersByHash implements downloader.Peer, returning a batch of headers\n// defined by the origin hash and the associated query parameters.", "input": "go language", "output": "func (p *FakePeer) RequestHeadersByHash(hash common.Hash, amount int, skip int, reverse bool) error {\n\tvar (\n\t\theaders []*types.Header\n\t\tunknown bool\n\t)\n\tfor !unknown && len(headers) < amount {\n\t\torigin := p.hc.GetHeaderByHash(hash)\n\t\tif origin == nil {\n\t\t\tbreak\n\t\t}\n\t\tnumber := origin.Number.Uint64()\n\t\theaders = append(headers, origin)\n\t\tif reverse {\n\t\t\tfor i := 0; i <= skip; i++ {\n\t\t\t\tif header := p.hc.GetHeader(hash, number); header != nil {\n\t\t\t\t\thash = header.ParentHash\n\t\t\t\t\tnumber--\n\t\t\t\t} else {\n\t\t\t\t\tunknown = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tvar (\n\t\t\t\tcurrent = origin.Number.Uint64()\n\t\t\t\tnext    = current + uint64(skip) + 1\n\t\t\t)\n\t\t\tif header := p.hc.GetHeaderByNumber(next); header != nil {\n\t\t\t\tif p.hc.GetBlockHashesFromHash(header.Hash(), uint64(skip+1))[skip] == hash {\n\t\t\t\t\thash = header.Hash()\n\t\t\t\t} else {\n\t\t\t\t\tunknown = true\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tunknown = true\n\t\t\t}\n\t\t}\n\t}\n\tp.dl.DeliverHeaders(p.id, headers)\n\treturn nil\n}"}, {"instruction": "// DeployENS deploys a new Ethereum contract, binding an instance of ENS to it.", "input": "go language", "output": "func DeployENS(auth *bind.TransactOpts, backend bind.ContractBackend) (common.Address, *types.Transaction, *ENS, error) {\n\tparsed, err := abi.JSON(strings.NewReader(ENSABI))\n\tif err != nil {\n\t\treturn common.Address{}, nil, nil, err\n\t}\n\taddress, tx, contract, err := bind.DeployContract(auth, parsed, common.FromHex(ENSBin), backend)\n\tif err != nil {\n\t\treturn common.Address{}, nil, nil, err\n\t}\n\treturn address, tx, &ENS{ENSCaller: ENSCaller{contract: contract}, ENSTransactor: ENSTransactor{contract: contract}, ENSFilterer: ENSFilterer{contract: contract}}, nil\n}"}, {"instruction": "// milliCPUToShares converts milliCPU to CPU shares", "input": "go language", "output": "func milliCPUToShares(milliCPU int64, hyperv bool) int64 {\n\tvar minShares int64 = minSharesProcess\n\tif hyperv {\n\t\tminShares = minSharesHyperV\n\t}\n\n\tif milliCPU == 0 {\n\t\t// Return here to really match kernel default for zero milliCPU.\n\t\treturn minShares\n\t}\n\n\t// Conceptually (milliCPU / milliCPUToCPU) * sharesPerCPU, but factored to improve rounding.\n\ttotalCPU := sysinfo.NumCPU()\n\tshares := (milliCPU * (maxShares - minShares)) / int64(totalCPU) / milliCPUToCPU\n\tif shares < minShares {\n\t\treturn minShares\n\t}\n\tif shares > maxShares {\n\t\treturn maxShares\n\t}\n\treturn shares\n}"}, {"instruction": "// NewOwnerManager creates a new Manager.", "input": "go language", "output": "func NewOwnerManager(etcdCli *clientv3.Client, prompt, id, key string, cancel context.CancelFunc) Manager {\n\tlogPrefix := fmt.Sprintf(\"[%s] %s ownerManager %s\", prompt, key, id)\n\treturn &ownerManager{\n\t\tetcdCli:   etcdCli,\n\t\tid:        id,\n\t\tkey:       key,\n\t\tprompt:    prompt,\n\t\tcancel:    cancel,\n\t\tlogPrefix: logPrefix,\n\t\tlogCtx:    logutil.WithKeyValue(context.Background(), \"owner info\", logPrefix),\n\t}\n}"}, {"instruction": "// String implements the fmt.Stringer interface.", "input": "go language", "output": "func (c *ChainConfig) String() string {\n\tvar engine interface{}\n\tswitch {\n\tcase c.Ethash != nil:\n\t\tengine = c.Ethash\n\tcase c.Clique != nil:\n\t\tengine = c.Clique\n\tdefault:\n\t\tengine = \"unknown\"\n\t}\n\treturn fmt.Sprintf(\"{ChainID: %v Homestead: %v DAO: %v DAOSupport: %v EIP150: %v EIP155: %v EIP158: %v Byzantium: %v Constantinople: %v  ConstantinopleFix: %v Engine: %v}\",\n\t\tc.ChainID,\n\t\tc.HomesteadBlock,\n\t\tc.DAOForkBlock,\n\t\tc.DAOForkSupport,\n\t\tc.EIP150Block,\n\t\tc.EIP155Block,\n\t\tc.EIP158Block,\n\t\tc.ByzantiumBlock,\n\t\tc.ConstantinopleBlock,\n\t\tc.PetersburgBlock,\n\t\tengine,\n\t)\n}"}, {"instruction": "// SetNamedPortsOfInstanceGroup sets the list of named ports on a given instance group", "input": "go language", "output": "func (g *Cloud) SetNamedPortsOfInstanceGroup(igName, zone string, namedPorts []*compute.NamedPort) error {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\tmc := newInstanceGroupMetricContext(\"set_namedports\", zone)\n\treq := &compute.InstanceGroupsSetNamedPortsRequest{NamedPorts: namedPorts}\n\treturn mc.Observe(g.c.InstanceGroups().SetNamedPorts(ctx, meta.ZonalKey(igName, zone), req))\n}"}, {"instruction": "// getAttach handles requests to attach to a container.", "input": "go language", "output": "func (s *Server) getAttach(request *restful.Request, response *restful.Response) {\n\tparams := getExecRequestParams(request)\n\tstreamOpts, err := remotecommandserver.NewOptions(request.Request)\n\tif err != nil {\n\t\tutilruntime.HandleError(err)\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tpod, ok := s.host.GetPodByName(params.podNamespace, params.podName)\n\tif !ok {\n\t\tresponse.WriteError(http.StatusNotFound, fmt.Errorf(\"pod does not exist\"))\n\t\treturn\n\t}\n\n\tpodFullName := kubecontainer.GetPodFullName(pod)\n\turl, err := s.host.GetAttach(podFullName, params.podUID, params.containerName, *streamOpts)\n\tif err != nil {\n\t\tstreaming.WriteError(err, response.ResponseWriter)\n\t\treturn\n\t}\n\n\tif s.redirectContainerStreaming {\n\t\thttp.Redirect(response.ResponseWriter, request.Request, url.String(), http.StatusFound)\n\t\treturn\n\t}\n\tproxyStream(response.ResponseWriter, request.Request, url)\n}"}, {"instruction": "// podDiskUsage aggregates pod disk usage and inode consumption for the specified stats to measure.", "input": "go language", "output": "func podDiskUsage(podStats statsapi.PodStats, pod *v1.Pod, statsToMeasure []fsStatsType) (v1.ResourceList, error) {\n\tdisk := resource.Quantity{Format: resource.BinarySI}\n\tinodes := resource.Quantity{Format: resource.DecimalSI}\n\n\tcontainerUsageList := containerUsage(podStats, statsToMeasure)\n\tdisk.Add(containerUsageList[v1.ResourceEphemeralStorage])\n\tinodes.Add(containerUsageList[resourceInodes])\n\n\tif hasFsStatsType(statsToMeasure, fsStatsLocalVolumeSource) {\n\t\tvolumeNames := localVolumeNames(pod)\n\t\tpodLocalVolumeUsageList := podLocalVolumeUsage(volumeNames, podStats)\n\t\tdisk.Add(podLocalVolumeUsageList[v1.ResourceEphemeralStorage])\n\t\tinodes.Add(podLocalVolumeUsageList[resourceInodes])\n\t}\n\treturn v1.ResourceList{\n\t\tv1.ResourceEphemeralStorage: disk,\n\t\tresourceInodes:              inodes,\n\t}, nil\n}"}, {"instruction": "// GetDiskLun finds the lun on the host that the vhd is attached to, given a vhd's diskName and diskURI.", "input": "go language", "output": "func (c *controllerCommon) GetDiskLun(diskName, diskURI string, nodeName types.NodeName) (int32, error) {\n\tdisks, err := c.getNodeDataDisks(nodeName)\n\tif err != nil {\n\t\tklog.Errorf(\"error of getting data disks for node %q: %v\", nodeName, err)\n\t\treturn -1, err\n\t}\n\n\tfor _, disk := range disks {\n\t\tif disk.Lun != nil && (disk.Name != nil && diskName != \"\" && *disk.Name == diskName) ||\n\t\t\t(disk.Vhd != nil && disk.Vhd.URI != nil && diskURI != \"\" && *disk.Vhd.URI == diskURI) ||\n\t\t\t(disk.ManagedDisk != nil && *disk.ManagedDisk.ID == diskURI) {\n\t\t\t// found the disk\n\t\t\tklog.V(2).Infof(\"azureDisk - find disk: lun %d name %q uri %q\", *disk.Lun, diskName, diskURI)\n\t\t\treturn *disk.Lun, nil\n\t\t}\n\t}\n\treturn -1, fmt.Errorf(\"Cannot find Lun for disk %s\", diskName)\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *LabelSelector) DeepCopyInto(out *LabelSelector) {\n\t*out = *in\n\tif in.MatchLabels != nil {\n\t\tin, out := &in.MatchLabels, &out.MatchLabels\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.MatchExpressions != nil {\n\t\tin, out := &in.MatchExpressions, &out.MatchExpressions\n\t\t*out = make([]LabelSelectorRequirement, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// simplifyNode traverses the hierarchy of an expanded memory node and discards\n// all the internal caches, returning a node that only contains the raw data.", "input": "go language", "output": "func simplifyNode(n node) node {\n\tswitch n := n.(type) {\n\tcase *shortNode:\n\t\t// Short nodes discard the flags and cascade\n\t\treturn &rawShortNode{Key: n.Key, Val: simplifyNode(n.Val)}\n\n\tcase *fullNode:\n\t\t// Full nodes discard the flags and cascade\n\t\tnode := rawFullNode(n.Children)\n\t\tfor i := 0; i < len(node); i++ {\n\t\t\tif node[i] != nil {\n\t\t\t\tnode[i] = simplifyNode(node[i])\n\t\t\t}\n\t\t}\n\t\treturn node\n\n\tcase valueNode, hashNode, rawNode:\n\t\treturn n\n\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unknown node type: %T\", n))\n\t}\n}"}, {"instruction": "// MaybeFixUpResourceInstanceAddressForCount deals with the situation where a\n// resource has changed from having \"count\" set to not set, or vice-versa, and\n// so we need to rename the zeroth instance key to no key at all, or vice-versa.\n//\n// Set countEnabled to true if the resource has count set in its new\n// configuration, or false if it does not.\n//\n// The state is modified in-place if necessary, moving a resource instance\n// between the two addresses. The return value is true if a change was made,\n// and false otherwise.", "input": "go language", "output": "func (s *SyncState) MaybeFixUpResourceInstanceAddressForCount(addr addrs.AbsResource, countEnabled bool) bool {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\tms := s.state.Module(addr.Module)\n\tif ms == nil {\n\t\treturn false\n\t}\n\n\trelAddr := addr.Resource\n\trs := ms.Resource(relAddr)\n\tif rs == nil {\n\t\treturn false\n\t}\n\thuntKey := addrs.NoKey\n\treplaceKey := addrs.InstanceKey(addrs.IntKey(0))\n\tif !countEnabled {\n\t\thuntKey, replaceKey = replaceKey, huntKey\n\t}\n\n\tis, exists := rs.Instances[huntKey]\n\tif !exists {\n\t\treturn false\n\t}\n\n\tif _, exists := rs.Instances[replaceKey]; exists {\n\t\t// If the replacement key also exists then we'll do nothing and keep both.\n\t\treturn false\n\t}\n\n\t// If we get here then we need to \"rename\" from hunt to replace\n\trs.Instances[replaceKey] = is\n\tdelete(rs.Instances, huntKey)\n\treturn true\n}"}, {"instruction": "//----------------------------------------------------------------------------------\n// InitViper()\n//----------------------------------------------------------------------------------\n// Performs basic initialization of our viper-based configuration layer.\n// Primary thrust is to establish the paths that should be consulted to find\n// the configuration we need.  If v == nil, we will initialize the global\n// Viper instance\n//----------------------------------------------------------------------------------", "input": "go language", "output": "func InitViper(v *viper.Viper, configName string) error {\n\tvar altPath = os.Getenv(\"FABRIC_CFG_PATH\")\n\tif altPath != \"\" {\n\t\t// If the user has overridden the path with an envvar, its the only path\n\t\t// we will consider\n\n\t\tif !dirExists(altPath) {\n\t\t\treturn fmt.Errorf(\"FABRIC_CFG_PATH %s does not exist\", altPath)\n\t\t}\n\n\t\tAddConfigPath(v, altPath)\n\t} else {\n\t\t// If we get here, we should use the default paths in priority order:\n\t\t//\n\t\t// *) CWD\n\t\t// *) /etc/hyperledger/fabric\n\n\t\t// CWD\n\t\tAddConfigPath(v, \"./\")\n\n\t\t// And finally, the official path\n\t\tif dirExists(OfficialPath) {\n\t\t\tAddConfigPath(v, OfficialPath)\n\t\t}\n\t}\n\n\t// Now set the configuration file.\n\tif v != nil {\n\t\tv.SetConfigName(configName)\n\t} else {\n\t\tviper.SetConfigName(configName)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// newerObject checks the mutation cache for a newer object and returns one if found. If the\n// mutated object is older than the backing object, it is removed from the  Must be\n// called while the lock is held.", "input": "go language", "output": "func (c *mutationCache) newerObject(key string, backing runtime.Object) runtime.Object {\n\tmutatedObj, exists := c.mutationCache.Get(key)\n\tif !exists {\n\t\treturn backing\n\t}\n\tmutatedObjRuntime, ok := mutatedObj.(runtime.Object)\n\tif !ok {\n\t\treturn backing\n\t}\n\tif c.comparator.CompareResourceVersion(backing, mutatedObjRuntime) >= 0 {\n\t\tc.mutationCache.Remove(key)\n\t\treturn backing\n\t}\n\treturn mutatedObjRuntime\n}"}, {"instruction": "// validateMetaPair checks that the given key/value pair is in a valid format", "input": "go language", "output": "func validateMetaPair(key, value string, allowConsulPrefix bool) error {\n\tif key == \"\" {\n\t\treturn fmt.Errorf(\"Key cannot be blank\")\n\t}\n\tif !metaKeyFormat(key) {\n\t\treturn fmt.Errorf(\"Key contains invalid characters\")\n\t}\n\tif len(key) > metaKeyMaxLength {\n\t\treturn fmt.Errorf(\"Key is too long (limit: %d characters)\", metaKeyMaxLength)\n\t}\n\tif strings.HasPrefix(key, metaKeyReservedPrefix) && !allowConsulPrefix {\n\t\treturn fmt.Errorf(\"Key prefix '%s' is reserved for internal use\", metaKeyReservedPrefix)\n\t}\n\tif len(value) > metaValueMaxLength {\n\t\treturn fmt.Errorf(\"Value is too long (limit: %d characters)\", metaValueMaxLength)\n\t}\n\treturn nil\n}"}, {"instruction": "// Get implements the Retriever interface.", "input": "go language", "output": "func (us *unionStore) Get(k Key) ([]byte, error) {\n\tv, err := us.MemBuffer.Get(k)\n\tif IsErrNotFound(err) {\n\t\tif _, ok := us.opts.Get(PresumeKeyNotExists); ok {\n\t\t\te, ok := us.opts.Get(PresumeKeyNotExistsError)\n\t\t\tif ok && e != nil {\n\t\t\t\tus.markLazyConditionPair(k, nil, e.(error))\n\t\t\t} else {\n\t\t\t\tus.markLazyConditionPair(k, nil, ErrKeyExists)\n\t\t\t}\n\t\t\treturn nil, ErrNotExist\n\t\t}\n\t}\n\tif IsErrNotFound(err) {\n\t\tv, err = us.BufferStore.r.Get(k)\n\t}\n\tif err != nil {\n\t\treturn v, err\n\t}\n\tif len(v) == 0 {\n\t\treturn nil, ErrNotExist\n\t}\n\treturn v, nil\n}"}, {"instruction": "// BeforeSign is added to the Sign chain; called before each request", "input": "go language", "output": "func (c *CrossRequestRetryDelay) BeforeSign(r *request.Request) {\n\tnow := time.Now()\n\tdelay := c.backoff.ComputeDelayForRequest(now)\n\tif delay > 0 {\n\t\tklog.Warningf(\"Inserting delay before AWS request (%s) to avoid RequestLimitExceeded: %s\",\n\t\t\tdescribeRequest(r), delay.String())\n\n\t\tif sleepFn := r.Config.SleepDelay; sleepFn != nil {\n\t\t\t// Support SleepDelay for backwards compatibility\n\t\t\tsleepFn(delay)\n\t\t} else if err := aws.SleepWithContext(r.Context(), delay); err != nil {\n\t\t\tr.Error = awserr.New(request.CanceledErrorCode, \"request context canceled\", err)\n\t\t\tr.Retryable = aws.Bool(false)\n\t\t\treturn\n\t\t}\n\n\t\t// Avoid clock skew problems\n\t\tr.Time = now\n\t}\n}"}, {"instruction": "// RegisterServices registers the given Services which can then be used to\n// start devp2p nodes using either the Exec or Docker adapters.\n//\n// It should be called in an init function so that it has the opportunity to\n// execute the services before main() is called.", "input": "go language", "output": "func RegisterServices(services Services) {\n\tfor name, f := range services {\n\t\tif _, exists := serviceFuncs[name]; exists {\n\t\t\tpanic(fmt.Sprintf(\"node service already exists: %q\", name))\n\t\t}\n\t\tserviceFuncs[name] = f\n\t}\n\n\t// now we have registered the services, run reexec.Init() which will\n\t// potentially start one of the services if the current binary has\n\t// been exec'd with argv[0] set to \"p2p-node\"\n\tif reexec.Init() {\n\t\tos.Exit(0)\n\t}\n}"}, {"instruction": "// rewriteWithPreprocess is for handling the situation that we need to adjust the input ast tree\n// before really using its node in `expressionRewriter.Leave`. In that case, we first call\n// er.preprocess(expr), which returns a new expr. Then we use the new expr in `Leave`.", "input": "go language", "output": "func (b *PlanBuilder) rewriteWithPreprocess(exprNode ast.ExprNode, p LogicalPlan, aggMapper map[*ast.AggregateFuncExpr]int, asScalar bool, preprocess func(ast.Node) ast.Node) (expression.Expression, LogicalPlan, error) {\n\tb.rewriterCounter++\n\tdefer func() { b.rewriterCounter-- }()\n\n\trewriter := b.getExpressionRewriter(p)\n\t// The rewriter maybe is obtained from \"b.rewriterPool\", \"rewriter.err\" is\n\t// not nil means certain previous procedure has not handled this error.\n\t// Here we give us one more chance to make a correct behavior by handling\n\t// this missed error.\n\tif rewriter.err != nil {\n\t\treturn nil, nil, rewriter.err\n\t}\n\n\trewriter.aggrMap = aggMapper\n\trewriter.asScalar = asScalar\n\trewriter.preprocess = preprocess\n\n\texpr, resultPlan, err := b.rewriteExprNode(rewriter, exprNode, asScalar)\n\treturn expr, resultPlan, err\n}"}, {"instruction": "// executeKeyringOpMgr executes the appropriate keyring-related function based on\n// the type of keyring operation in the request. It takes the KeyManager as an\n// argument, so it can handle any operation for either LAN or WAN pools.", "input": "go language", "output": "func (m *Internal) executeKeyringOpMgr(\n\tmgr *serf.KeyManager,\n\targs *structs.KeyringRequest,\n\treply *structs.KeyringResponses,\n\twan bool,\n\tsegment string) {\n\tvar serfResp *serf.KeyResponse\n\tvar err error\n\n\topts := &serf.KeyRequestOptions{RelayFactor: args.RelayFactor}\n\tswitch args.Operation {\n\tcase structs.KeyringList:\n\t\tserfResp, err = mgr.ListKeysWithOptions(opts)\n\tcase structs.KeyringInstall:\n\t\tserfResp, err = mgr.InstallKeyWithOptions(args.Key, opts)\n\tcase structs.KeyringUse:\n\t\tserfResp, err = mgr.UseKeyWithOptions(args.Key, opts)\n\tcase structs.KeyringRemove:\n\t\tserfResp, err = mgr.RemoveKeyWithOptions(args.Key, opts)\n\t}\n\n\terrStr := \"\"\n\tif err != nil {\n\t\terrStr = err.Error()\n\t}\n\n\treply.Responses = append(reply.Responses, &structs.KeyringResponse{\n\t\tWAN:        wan,\n\t\tDatacenter: m.srv.config.Datacenter,\n\t\tSegment:    segment,\n\t\tMessages:   serfResp.Messages,\n\t\tKeys:       serfResp.Keys,\n\t\tNumNodes:   serfResp.NumNodes,\n\t\tError:      errStr,\n\t})\n}"}, {"instruction": "// ParseAbsProviderConfigStr is a helper wrapper around ParseAbsProviderConfig\n// that takes a string and parses it with the HCL native syntax traversal parser\n// before interpreting it.\n//\n// This should be used only in specialized situations since it will cause the\n// created references to not have any meaningful source location information.\n// If a reference string is coming from a source that should be identified in\n// error messages then the caller should instead parse it directly using a\n// suitable function from the HCL API and pass the traversal itself to\n// ParseAbsProviderConfig.\n//\n// Error diagnostics are returned if either the parsing fails or the analysis\n// of the traversal fails. There is no way for the caller to distinguish the\n// two kinds of diagnostics programmatically. If error diagnostics are returned\n// the returned address is invalid.", "input": "go language", "output": "func ParseAbsProviderConfigStr(str string) (AbsProviderConfig, tfdiags.Diagnostics) {\n\tvar diags tfdiags.Diagnostics\n\n\ttraversal, parseDiags := hclsyntax.ParseTraversalAbs([]byte(str), \"\", hcl.Pos{Line: 1, Column: 1})\n\tdiags = diags.Append(parseDiags)\n\tif parseDiags.HasErrors() {\n\t\treturn AbsProviderConfig{}, diags\n\t}\n\n\taddr, addrDiags := ParseAbsProviderConfig(traversal)\n\tdiags = diags.Append(addrDiags)\n\treturn addr, diags\n}"}, {"instruction": "// getChaincodeSpec get chaincode spec from the cli cmd pramameters", "input": "go language", "output": "func getChaincodeSpec(cmd *cobra.Command) (*pb.ChaincodeSpec, error) {\n\tspec := &pb.ChaincodeSpec{}\n\tif err := checkChaincodeCmdParams(cmd); err != nil {\n\t\t// unset usage silence because it's a command line usage error\n\t\tcmd.SilenceUsage = false\n\t\treturn spec, err\n\t}\n\n\t// Build the spec\n\tinput := &pb.ChaincodeInput{}\n\tif err := json.Unmarshal([]byte(chaincodeCtorJSON), &input); err != nil {\n\t\treturn spec, errors.Wrap(err, \"chaincode argument error\")\n\t}\n\n\tchaincodeLang = strings.ToUpper(chaincodeLang)\n\tspec = &pb.ChaincodeSpec{\n\t\tType:        pb.ChaincodeSpec_Type(pb.ChaincodeSpec_Type_value[chaincodeLang]),\n\t\tChaincodeId: &pb.ChaincodeID{Path: chaincodePath, Name: chaincodeName, Version: chaincodeVersion},\n\t\tInput:       input,\n\t}\n\treturn spec, nil\n}"}, {"instruction": "// nodesWatch is used to watch the list of available nodes", "input": "go language", "output": "func nodesWatch(params map[string]interface{}) (WatcherFunc, error) {\n\tstale := false\n\tif err := assignValueBool(params, \"stale\", &stale); err != nil {\n\t\treturn nil, err\n\t}\n\n\tfn := func(p *Plan) (BlockingParamVal, interface{}, error) {\n\t\tcatalog := p.client.Catalog()\n\t\topts := makeQueryOptionsWithContext(p, stale)\n\t\tdefer p.cancelFunc()\n\t\tnodes, meta, err := catalog.Nodes(&opts)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\treturn WaitIndexVal(meta.LastIndex), nodes, err\n\t}\n\treturn fn, nil\n}"}, {"instruction": "// convertPodNamedPortToNumber converts named ports into port numbers\n// It returns an error when a named port can't be found in the pod containers", "input": "go language", "output": "func convertPodNamedPortToNumber(ports []string, pod corev1.Pod) ([]string, error) {\n\tvar converted []string\n\tfor _, port := range ports {\n\t\tlocalPort, remotePort := splitPort(port)\n\n\t\tcontainerPortStr := remotePort\n\t\t_, err := strconv.Atoi(remotePort)\n\t\tif err != nil {\n\t\t\tcontainerPort, err := util.LookupContainerPortNumberByName(pod, remotePort)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tcontainerPortStr = strconv.Itoa(int(containerPort))\n\t\t}\n\n\t\tif localPort != remotePort {\n\t\t\tconverted = append(converted, fmt.Sprintf(\"%s:%s\", localPort, containerPortStr))\n\t\t} else {\n\t\t\tconverted = append(converted, containerPortStr)\n\t\t}\n\t}\n\n\treturn converted, nil\n}"}, {"instruction": "// Hash returns a hash of either a ConfigMap or a Secret", "input": "go language", "output": "func (h *KustHash) Hash(m map[string]interface{}) (string, error) {\n\tu := unstructured.Unstructured{\n\t\tObject: m,\n\t}\n\tkind := u.GetKind()\n\tswitch kind {\n\tcase \"ConfigMap\":\n\t\tcm, err := unstructuredToConfigmap(u)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn ConfigMapHash(cm)\n\tcase \"Secret\":\n\t\tsec, err := unstructuredToSecret(u)\n\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn SecretHash(sec)\n\tdefault:\n\t\treturn \"\", fmt.Errorf(\"type %s is supported for hashing in %v\", kind, m)\n\t}\n}"}, {"instruction": "// LoadMetadata loads the chaincode metadata stored at the specified path", "input": "go language", "output": "func (s *Store) LoadMetadata(path string) (name, version string, err error) {\n\tmetadataBytes, err := s.ReadWriter.ReadFile(path)\n\tif err != nil {\n\t\terr = errors.Wrapf(err, \"error reading metadata at %s\", path)\n\t\treturn \"\", \"\", err\n\t}\n\tccMetadata := &ChaincodeMetadata{}\n\terr = json.Unmarshal(metadataBytes, ccMetadata)\n\tif err != nil {\n\t\terr = errors.Wrapf(err, \"error unmarshaling metadata at %s\", path)\n\t\treturn \"\", \"\", err\n\t}\n\n\treturn ccMetadata.Name, ccMetadata.Version, nil\n}"}, {"instruction": "// Attempt to decrypt, validate and unpack an asymmetrically encrypted message.\n// If successful, returns the unpacked whisper ReceivedMessage struct\n// encapsulating the decrypted message, and the byte representation of\n// the public key used to decrypt the message.\n// It fails if decryption of message fails, or if the message is corrupted.", "input": "go language", "output": "func (ks *Pss) processAsym(envelope *whisper.Envelope) (*whisper.ReceivedMessage, string, PssAddress, error) {\n\tmetrics.GetOrRegisterCounter(\"pss.process.asym\", nil).Inc(1)\n\n\trecvmsg, err := envelope.OpenAsymmetric(ks.privateKey)\n\tif err != nil {\n\t\treturn nil, \"\", nil, fmt.Errorf(\"could not decrypt message: %s\", err)\n\t}\n\t// check signature (if signed), strip padding\n\tif !recvmsg.ValidateAndParse() {\n\t\treturn nil, \"\", nil, errors.New(\"invalid message\")\n\t}\n\tpubkeyid := common.ToHex(crypto.FromECDSAPub(recvmsg.Src))\n\tvar from PssAddress\n\tks.mx.RLock()\n\tif ks.pubKeyPool[pubkeyid][Topic(envelope.Topic)] != nil {\n\t\tfrom = ks.pubKeyPool[pubkeyid][Topic(envelope.Topic)].address\n\t}\n\tks.mx.RUnlock()\n\treturn recvmsg, pubkeyid, from, nil\n}"}, {"instruction": "// UpdateVmssVMWithRetry invokes az.VirtualMachineScaleSetVMsClient.Update with exponential backoff retry", "input": "go language", "output": "func (az *Cloud) UpdateVmssVMWithRetry(resourceGroupName string, VMScaleSetName string, instanceID string, parameters compute.VirtualMachineScaleSetVM) error {\n\treturn wait.ExponentialBackoff(az.requestBackoff(), func() (bool, error) {\n\t\tctx, cancel := getContextWithCancel()\n\t\tdefer cancel()\n\n\t\tresp, err := az.VirtualMachineScaleSetVMsClient.Update(ctx, resourceGroupName, VMScaleSetName, instanceID, parameters)\n\t\tklog.V(10).Infof(\"VirtualMachinesClient.CreateOrUpdate(%s,%s): end\", VMScaleSetName, instanceID)\n\t\treturn az.processHTTPRetryResponse(nil, \"\", resp, err)\n\t})\n}"}, {"instruction": "// ObjectKinds returns a slice of one element with the group,version,kind of the\n// provided object, or an error if the object is not runtime.Unstructured or\n// has no group,version,kind information. unversionedType will always be false\n// because runtime.Unstructured object should always have group,version,kind\n// information set.", "input": "go language", "output": "func (d *UnstructuredObjectTyper) ObjectKinds(obj runtime.Object) (gvks []schema.GroupVersionKind, unversionedType bool, err error) {\n\tif _, ok := obj.(runtime.Unstructured); ok {\n\t\tgvk := obj.GetObjectKind().GroupVersionKind()\n\t\tif len(gvk.Kind) == 0 {\n\t\t\treturn nil, false, runtime.NewMissingKindErr(\"object has no kind field \")\n\t\t}\n\t\tif len(gvk.Version) == 0 {\n\t\t\treturn nil, false, runtime.NewMissingVersionErr(\"object has no apiVersion field\")\n\t\t}\n\t\treturn []schema.GroupVersionKind{gvk}, false, nil\n\t}\n\n\treturn nil, false, runtime.NewNotRegisteredErrForType(\"crdserverscheme.UnstructuredObjectTyper\", reflect.TypeOf(obj))\n}"}, {"instruction": "// Get returns the rootfs path for the id. It is reference counted and\n// effectively can be thought of as a \"mount the layer into the utility\n// vm if it isn't already\". The contract from the caller of this is that\n// all Gets and Puts are matched. It -should- be the case that on cleanup,\n// nothing is mounted.\n//\n// For optimisation, we don't actually mount the filesystem (which in our\n// case means [hot-]adding it to a service VM. But we track that and defer\n// the actual adding to the point we need to access it.", "input": "go language", "output": "func (d *Driver) Get(id, mountLabel string) (containerfs.ContainerFS, error) {\n\ttitle := fmt.Sprintf(\"lcowdriver: get: %s\", id)\n\tlogrus.Debugf(title)\n\n\t// Generate the mounts needed for the deferred operation.\n\tdisks, err := d.getAllMounts(id)\n\tif err != nil {\n\t\tlogrus.Debugf(\"%s failed to get all layer details for %s: %s\", title, d.dir(id), err)\n\t\treturn nil, fmt.Errorf(\"%s failed to get layer details for %s: %s\", title, d.dir(id), err)\n\t}\n\n\tlogrus.Debugf(\"%s: got layer mounts: %+v\", title, disks)\n\treturn &lcowfs{\n\t\troot:        unionMountName(disks),\n\t\td:           d,\n\t\tmappedDisks: disks,\n\t\tvmID:        d.getVMID(id),\n\t}, nil\n}"}, {"instruction": "// DeepCopy creates a copy of the receiver where any pointers to nested mutable\n// values are also copied, thus ensuring that future mutations of the receiver\n// will not affect the copy.\n//\n// Some types used within a resource change are immutable by convention even\n// though the Go language allows them to be mutated, such as the types from\n// the addrs package. These are _not_ copied by this method, under the\n// assumption that callers will behave themselves.", "input": "go language", "output": "func (rcs *ResourceInstanceChangeSrc) DeepCopy() *ResourceInstanceChangeSrc {\n\tif rcs == nil {\n\t\treturn nil\n\t}\n\tret := *rcs\n\n\tret.RequiredReplace = cty.NewPathSet(ret.RequiredReplace.List()...)\n\n\tif len(ret.Private) != 0 {\n\t\tprivate := make([]byte, len(ret.Private))\n\t\tcopy(private, ret.Private)\n\t\tret.Private = private\n\t}\n\n\tret.ChangeSrc.Before = ret.ChangeSrc.Before.Copy()\n\tret.ChangeSrc.After = ret.ChangeSrc.After.Copy()\n\n\treturn &ret\n}"}, {"instruction": "// waitForJob is a helper that waits for a job to complete.\n//\n// This operates on an event returned from a watcher.", "input": "go language", "output": "func (c *Client) waitForJob(e watch.Event, name string) (bool, error) {\n\tjob := &batch.Job{}\n\terr := legacyscheme.Scheme.Convert(e.Object, job, nil)\n\tif err != nil {\n\t\treturn true, err\n\t}\n\n\tfor _, c := range job.Status.Conditions {\n\t\tif c.Type == batch.JobComplete && c.Status == v1.ConditionTrue {\n\t\t\treturn true, nil\n\t\t} else if c.Type == batch.JobFailed && c.Status == v1.ConditionTrue {\n\t\t\treturn true, fmt.Errorf(\"Job failed: %s\", c.Reason)\n\t\t}\n\t}\n\n\tc.Log(\"%s: Jobs active: %d, jobs failed: %d, jobs succeeded: %d\", name, job.Status.Active, job.Status.Failed, job.Status.Succeeded)\n\treturn false, nil\n}"}, {"instruction": "// Start starts a containerd daemon and monitors it", "input": "go language", "output": "func Start(ctx context.Context, rootDir, stateDir string, opts ...DaemonOpt) (Daemon, error) {\n\tr := &remote{\n\t\trootDir:  rootDir,\n\t\tstateDir: stateDir,\n\t\tConfig: config.Config{\n\t\t\tRoot:  filepath.Join(rootDir, \"daemon\"),\n\t\t\tState: filepath.Join(stateDir, \"daemon\"),\n\t\t},\n\t\tpluginConfs:   pluginConfigs{make(map[string]interface{})},\n\t\tdaemonPid:     -1,\n\t\tlogger:        logrus.WithField(\"module\", \"libcontainerd\"),\n\t\tdaemonStartCh: make(chan error, 1),\n\t\tdaemonStopCh:  make(chan struct{}),\n\t}\n\n\tfor _, opt := range opts {\n\t\tif err := opt(r); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tr.setDefaults()\n\n\tif err := system.MkdirAll(stateDir, 0700, \"\"); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgo r.monitorDaemon(ctx)\n\n\tselect {\n\tcase <-time.After(startupTimeout):\n\t\treturn nil, errors.New(\"timeout waiting for containerd to start\")\n\tcase err := <-r.daemonStartCh:\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn r, nil\n}"}, {"instruction": "// autoDeposit starts a goroutine that periodically sends funds to the chequebook\n// contract caller holds the lock the go routine terminates if Chequebook.quit is closed.", "input": "go language", "output": "func (cb *Chequebook) autoDeposit(interval time.Duration) {\n\tif cb.quit != nil {\n\t\tclose(cb.quit)\n\t\tcb.quit = nil\n\t}\n\t// if threshold >= balance autodeposit after every cheque issued\n\tif interval == time.Duration(0) || cb.threshold != nil && cb.buffer != nil && cb.threshold.Cmp(cb.buffer) >= 0 {\n\t\treturn\n\t}\n\n\tticker := time.NewTicker(interval)\n\tcb.quit = make(chan bool)\n\tquit := cb.quit\n\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-quit:\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\tcb.lock.Lock()\n\t\t\t\tif cb.balance.Cmp(cb.buffer) < 0 {\n\t\t\t\t\tamount := new(big.Int).Sub(cb.buffer, cb.balance)\n\t\t\t\t\ttxhash, err := cb.deposit(amount)\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\tcb.txhash = txhash\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcb.lock.Unlock()\n\t\t\t}\n\t\t}\n\t}()\n}"}, {"instruction": "// Cleanup aufs and unmount all mountpoints", "input": "go language", "output": "func (a *Driver) Cleanup() error {\n\tvar dirs []string\n\tif err := filepath.Walk(a.mntPath(), func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !info.IsDir() {\n\t\t\treturn nil\n\t\t}\n\t\tdirs = append(dirs, path)\n\t\treturn nil\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, m := range dirs {\n\t\tif err := a.unmount(m); err != nil {\n\t\t\tlogger.Debugf(\"error unmounting %s: %s\", m, err)\n\t\t}\n\t}\n\treturn mount.RecursiveUnmount(a.root)\n}"}, {"instruction": "// createSessionLocal is used to create a new session in a foreign datacenter\n// This is more complex since the local agent cannot be used to create\n// a session, and we must associate with a node in the remote datacenter.", "input": "go language", "output": "func (c *cmd) createSessionForeign() (string, error) {\n\t// Look for a remote node to bind to\n\thealth := c.apiclient.Health()\n\tservices, _, err := health.Service(\"consul\", \"\", true, nil)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"Failed to find Consul server in remote datacenter: %v\", err)\n\t}\n\tif len(services) == 0 {\n\t\treturn \"\", fmt.Errorf(\"Failed to find Consul server in remote datacenter\")\n\t}\n\tnode := services[0].Node.Node\n\tif c.conf.verbose {\n\t\tc.UI.Info(fmt.Sprintf(\"Binding session to remote node %s@%s\", node, c.http.Datacenter()))\n\t}\n\n\tsession := c.apiclient.Session()\n\tse := api.SessionEntry{\n\t\tName:     fmt.Sprintf(\"Remote Exec via %s@%s\", c.conf.localNode, c.conf.localDC),\n\t\tNode:     node,\n\t\tChecks:   []string{},\n\t\tBehavior: api.SessionBehaviorDelete,\n\t\tTTL:      rExecTTL,\n\t}\n\tid, _, err := session.CreateNoChecks(&se, nil)\n\treturn id, err\n}"}, {"instruction": "// GetUncleByBlockHashAndIndex returns the uncle block for the given block hash and index. When fullTx is true\n// all transactions in the block are returned in full detail, otherwise only the transaction hash is returned.", "input": "go language", "output": "func (s *PublicBlockChainAPI) GetUncleByBlockHashAndIndex(ctx context.Context, blockHash common.Hash, index hexutil.Uint) (map[string]interface{}, error) {\n\tblock, err := s.b.GetBlock(ctx, blockHash)\n\tif block != nil {\n\t\tuncles := block.Uncles()\n\t\tif index >= hexutil.Uint(len(uncles)) {\n\t\t\tlog.Debug(\"Requested uncle not found\", \"number\", block.Number(), \"hash\", blockHash, \"index\", index)\n\t\t\treturn nil, nil\n\t\t}\n\t\tblock = types.NewBlockWithHeader(uncles[index])\n\t\treturn s.rpcOutputBlock(block, false, false)\n\t}\n\treturn nil, err\n}"}, {"instruction": "// New creates a new custom error pages middleware.", "input": "go language", "output": "func New(ctx context.Context, next http.Handler, config config.ErrorPage, serviceBuilder serviceBuilder, name string) (http.Handler, error) {\n\tmiddlewares.GetLogger(ctx, name, typeName).Debug(\"Creating middleware\")\n\n\thttpCodeRanges, err := types.NewHTTPCodeRanges(config.Status)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tbackend, err := serviceBuilder.BuildHTTP(ctx, config.Service, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &customErrors{\n\t\tname:           name,\n\t\tnext:           next,\n\t\tbackendHandler: backend,\n\t\thttpCodeRanges: httpCodeRanges,\n\t\tbackendQuery:   config.Query,\n\t}, nil\n}"}, {"instruction": "// SelectorFromSet returns a Selector which will match exactly the given Set. A\n// nil and empty Sets are considered equivalent to Everything().", "input": "go language", "output": "func SelectorFromSet(ls Set) Selector {\n\tif ls == nil || len(ls) == 0 {\n\t\treturn internalSelector{}\n\t}\n\tvar requirements internalSelector\n\tfor label, value := range ls {\n\t\tr, err := NewRequirement(label, selection.Equals, []string{value})\n\t\tif err == nil {\n\t\t\trequirements = append(requirements, *r)\n\t\t} else {\n\t\t\t//TODO: double check errors when input comes from serialization?\n\t\t\treturn internalSelector{}\n\t\t}\n\t}\n\t// sort to have deterministic string representation\n\tsort.Sort(ByKey(requirements))\n\treturn requirements\n}"}, {"instruction": "// NewPodInformer creates a shared index informer that returns only non-terminal pods.", "input": "go language", "output": "func NewPodInformer(client clientset.Interface, resyncPeriod time.Duration) coreinformers.PodInformer {\n\tselector := fields.ParseSelectorOrDie(\n\t\t\"status.phase!=\" + string(v1.PodSucceeded) +\n\t\t\t\",status.phase!=\" + string(v1.PodFailed))\n\tlw := cache.NewListWatchFromClient(client.CoreV1().RESTClient(), string(v1.ResourcePods), metav1.NamespaceAll, selector)\n\treturn &podInformer{\n\t\tinformer: cache.NewSharedIndexInformer(lw, &v1.Pod{}, resyncPeriod, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc}),\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ISCSIPersistentVolumeSource) DeepCopyInto(out *ISCSIPersistentVolumeSource) {\n\t*out = *in\n\tif in.Portals != nil {\n\t\tin, out := &in.Portals, &out.Portals\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.SecretRef != nil {\n\t\tin, out := &in.SecretRef, &out.SecretRef\n\t\t*out = new(SecretReference)\n\t\t**out = **in\n\t}\n\tif in.InitiatorName != nil {\n\t\tin, out := &in.InitiatorName, &out.InitiatorName\n\t\t*out = new(string)\n\t\t**out = **in\n\t}\n\treturn\n}"}, {"instruction": "// uniqueToken generates a random URL-safe token and ensures uniqueness.", "input": "go language", "output": "func (c *requestCache) uniqueToken() (string, error) {\n\tconst maxTries = 10\n\t// Number of bytes to be tokenLen when base64 encoded.\n\ttokenSize := math.Ceil(float64(tokenLen) * 6 / 8)\n\trawToken := make([]byte, int(tokenSize))\n\tfor i := 0; i < maxTries; i++ {\n\t\tif _, err := rand.Read(rawToken); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tencoded := base64.RawURLEncoding.EncodeToString(rawToken)\n\t\ttoken := encoded[:tokenLen]\n\t\t// If it's unique, return it. Otherwise retry.\n\t\tif _, exists := c.tokens[encoded]; !exists {\n\t\t\treturn token, nil\n\t\t}\n\t}\n\treturn \"\", fmt.Errorf(\"failed to generate unique token\")\n}"}, {"instruction": "// Detach checks with the GCE cloud provider if the specified volume is already\n// attached to the specified node. If the volume is not attached, it succeeds\n// (returns nil). If it is attached, Detach issues a call to the GCE cloud\n// provider to attach it.\n// Callers are responsible for retrying on failure.\n// Callers are responsible for thread safety between concurrent attach and detach\n// operations.", "input": "go language", "output": "func (detacher *gcePersistentDiskDetacher) Detach(volumeName string, nodeName types.NodeName) error {\n\tpdName := path.Base(volumeName)\n\n\tattached, err := detacher.gceDisks.DiskIsAttached(pdName, nodeName)\n\tif err != nil {\n\t\t// Log error and continue with detach\n\t\tklog.Errorf(\n\t\t\t\"Error checking if PD (%q) is already attached to current node (%q). Will continue and try detach anyway. err=%v\",\n\t\t\tpdName, nodeName, err)\n\t}\n\n\tif err == nil && !attached {\n\t\t// Volume is not attached to node. Success!\n\t\tklog.Infof(\"Detach operation is successful. PD %q was not attached to node %q.\", pdName, nodeName)\n\t\treturn nil\n\t}\n\n\tif err = detacher.gceDisks.DetachDisk(pdName, nodeName); err != nil {\n\t\tklog.Errorf(\"Error detaching PD %q from node %q: %v\", pdName, nodeName, err)\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// points2Ranges build index ranges from range points.\n// Only one column is built there. If there're multiple columns, use appendPoints2Ranges.", "input": "go language", "output": "func points2Ranges(sc *stmtctx.StatementContext, rangePoints []point, tp *types.FieldType) ([]*Range, error) {\n\tranges := make([]*Range, 0, len(rangePoints)/2)\n\tfor i := 0; i < len(rangePoints); i += 2 {\n\t\tstartPoint, err := convertPoint(sc, rangePoints[i], tp)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tendPoint, err := convertPoint(sc, rangePoints[i+1], tp)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tless, err := validInterval(sc, startPoint, endPoint)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tif !less {\n\t\t\tcontinue\n\t\t}\n\t\t// If column has not null flag, [null, null] should be removed.\n\t\tif mysql.HasNotNullFlag(tp.Flag) && endPoint.value.Kind() == types.KindNull {\n\t\t\tcontinue\n\t\t}\n\n\t\tran := &Range{\n\t\t\tLowVal:      []types.Datum{startPoint.value},\n\t\t\tLowExclude:  startPoint.excl,\n\t\t\tHighVal:     []types.Datum{endPoint.value},\n\t\t\tHighExclude: endPoint.excl,\n\t\t}\n\t\tranges = append(ranges, ran)\n\t}\n\treturn ranges, nil\n}"}, {"instruction": "// Validate makes sure provided values for EnvOptions are valid", "input": "go language", "output": "func (o *EnvOptions) Validate() error {\n\tif len(o.Filenames) == 0 && len(o.resources) < 1 {\n\t\treturn fmt.Errorf(\"one or more resources must be specified as <resource> <name> or <resource>/<name>\")\n\t}\n\tif o.List && len(o.output) > 0 {\n\t\treturn fmt.Errorf(\"--list and --output may not be specified together\")\n\t}\n\tif len(o.Keys) > 0 && len(o.From) == 0 {\n\t\treturn fmt.Errorf(\"when specifying --keys, a configmap or secret must be provided with --from\")\n\t}\n\treturn nil\n}"}, {"instruction": "// InstallReleaseFromChart installs a new chart and returns the release response.", "input": "go language", "output": "func (h *Client) InstallReleaseFromChart(chart *chart.Chart, ns string, opts ...InstallOption) (*rls.InstallReleaseResponse, error) {\n\t// apply the install options\n\treqOpts := h.opts\n\tfor _, opt := range opts {\n\t\topt(&reqOpts)\n\t}\n\treq := &reqOpts.instReq\n\treq.Chart = chart\n\treq.Namespace = ns\n\treq.DryRun = reqOpts.dryRun\n\treq.DisableHooks = reqOpts.disableHooks\n\treq.DisableCrdHook = reqOpts.disableCRDHook\n\treq.ReuseName = reqOpts.reuseName\n\tctx := NewContext()\n\n\tif reqOpts.before != nil {\n\t\tif err := reqOpts.before(ctx, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr := chartutil.ProcessRequirementsEnabled(req.Chart, req.Values)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = chartutil.ProcessRequirementsImportValues(req.Chart)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn h.install(ctx, req)\n}"}, {"instruction": "// NewFilter creates a new filter and returns the filter id. It can be\n// used to retrieve logs when the state changes. This method cannot be\n// used to fetch logs that are already stored in the state.\n//\n// Default criteria for the from and to block are \"latest\".\n// Using \"latest\" as block number will return logs for mined blocks.\n// Using \"pending\" as block number returns logs for not yet mined (pending) blocks.\n// In case logs are removed (chain reorg) previously returned logs are returned\n// again but with the removed property set to true.\n//\n// In case \"fromBlock\" > \"toBlock\" an error is returned.\n//\n// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_newfilter", "input": "go language", "output": "func (api *PublicFilterAPI) NewFilter(crit FilterCriteria) (rpc.ID, error) {\n\tlogs := make(chan []*types.Log)\n\tlogsSub, err := api.events.SubscribeLogs(ethereum.FilterQuery(crit), logs)\n\tif err != nil {\n\t\treturn rpc.ID(\"\"), err\n\t}\n\n\tapi.filtersMu.Lock()\n\tapi.filters[logsSub.ID] = &filter{typ: LogsSubscription, crit: crit, deadline: time.NewTimer(deadline), logs: make([]*types.Log, 0), s: logsSub}\n\tapi.filtersMu.Unlock()\n\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase l := <-logs:\n\t\t\t\tapi.filtersMu.Lock()\n\t\t\t\tif f, found := api.filters[logsSub.ID]; found {\n\t\t\t\t\tf.logs = append(f.logs, l...)\n\t\t\t\t}\n\t\t\t\tapi.filtersMu.Unlock()\n\t\t\tcase <-logsSub.Err():\n\t\t\t\tapi.filtersMu.Lock()\n\t\t\t\tdelete(api.filters, logsSub.ID)\n\t\t\t\tapi.filtersMu.Unlock()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn logsSub.ID, nil\n}"}, {"instruction": "// create is used as the entry function for \"create\" app command.", "input": "go language", "output": "func create(ctx *cli.Context) error {\n\tlog.PrintOrigins(true)\n\tlog.Root().SetHandler(log.LvlFilterHandler(log.Lvl(ctx.Int(\"verbosity\")), log.StreamHandler(os.Stdout, log.TerminalFormat(true))))\n\n\tif len(ctx.Args()) < 1 {\n\t\treturn errors.New(\"argument should be the filename to verify or write-to\")\n\t}\n\tfilename, err := touchPath(ctx.Args()[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn createSnapshot(filename, ctx.Int(\"nodes\"), strings.Split(ctx.String(\"services\"), \",\"))\n}"}, {"instruction": "// Error returns detailed information of why the pod failed to fit on each node", "input": "go language", "output": "func (f *FitError) Error() string {\n\treasons := make(map[string]int)\n\tfor _, predicates := range f.FailedPredicates {\n\t\tfor _, pred := range predicates {\n\t\t\treasons[pred.GetReason()]++\n\t\t}\n\t}\n\n\tsortReasonsHistogram := func() []string {\n\t\treasonStrings := []string{}\n\t\tfor k, v := range reasons {\n\t\t\treasonStrings = append(reasonStrings, fmt.Sprintf(\"%v %v\", v, k))\n\t\t}\n\t\tsort.Strings(reasonStrings)\n\t\treturn reasonStrings\n\t}\n\treasonMsg := fmt.Sprintf(NoNodeAvailableMsg+\": %v.\", f.NumAllNodes, strings.Join(sortReasonsHistogram(), \", \"))\n\treturn reasonMsg\n}"}, {"instruction": "// Init returns a new VFS driver.\n// This sets the home directory for the driver and returns NaiveDiffDriver.", "input": "go language", "output": "func Init(home string, options []string, uidMaps, gidMaps []idtools.IDMap) (graphdriver.Driver, error) {\n\td := &Driver{\n\t\thome:      home,\n\t\tidMapping: idtools.NewIDMappingsFromMaps(uidMaps, gidMaps),\n\t}\n\n\tif err := d.parseOptions(options); err != nil {\n\t\treturn nil, err\n\t}\n\n\trootIDs := d.idMapping.RootPair()\n\tif err := idtools.MkdirAllAndChown(home, 0700, rootIDs); err != nil {\n\t\treturn nil, err\n\t}\n\n\tsetupDriverQuota(d)\n\n\tif size := d.getQuotaOpt(); !d.quotaSupported() && size > 0 {\n\t\treturn nil, quota.ErrQuotaNotSupported\n\t}\n\n\treturn graphdriver.NewNaiveDiffDriver(d, uidMaps, gidMaps), nil\n}"}, {"instruction": "// following functions are used by the instruction jump  table\n// make log instruction function", "input": "go language", "output": "func makeLog(size int) executionFunc {\n\treturn func(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {\n\t\ttopics := make([]common.Hash, size)\n\t\tmStart, mSize := stack.pop(), stack.pop()\n\t\tfor i := 0; i < size; i++ {\n\t\t\ttopics[i] = common.BigToHash(stack.pop())\n\t\t}\n\n\t\td := memory.Get(mStart.Int64(), mSize.Int64())\n\t\tinterpreter.evm.StateDB.AddLog(&types.Log{\n\t\t\tAddress: contract.Address(),\n\t\t\tTopics:  topics,\n\t\t\tData:    d,\n\t\t\t// This is a non-consensus field, but assigned here because\n\t\t\t// core/state doesn't know the current block number.\n\t\t\tBlockNumber: interpreter.evm.BlockNumber.Uint64(),\n\t\t})\n\n\t\tinterpreter.intPool.put(mStart, mSize)\n\t\treturn nil, nil\n\t}\n}"}, {"instruction": "// setProjectQuota - set the quota for project id on xfs block device", "input": "go language", "output": "func setProjectQuota(backingFsBlockDev string, projectID uint32, quota Quota) error {\n\tvar d C.fs_disk_quota_t\n\td.d_version = C.FS_DQUOT_VERSION\n\td.d_id = C.__u32(projectID)\n\td.d_flags = C.XFS_PROJ_QUOTA\n\n\td.d_fieldmask = C.FS_DQ_BHARD | C.FS_DQ_BSOFT\n\td.d_blk_hardlimit = C.__u64(quota.Size / 512)\n\td.d_blk_softlimit = d.d_blk_hardlimit\n\n\tvar cs = C.CString(backingFsBlockDev)\n\tdefer C.free(unsafe.Pointer(cs))\n\n\t_, _, errno := unix.Syscall6(unix.SYS_QUOTACTL, C.Q_XSETPQLIM,\n\t\tuintptr(unsafe.Pointer(cs)), uintptr(d.d_id),\n\t\tuintptr(unsafe.Pointer(&d)), 0, 0)\n\tif errno != 0 {\n\t\treturn errors.Wrapf(errno, \"failed to set quota limit for projid %d on %s\",\n\t\t\tprojectID, backingFsBlockDev)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// reloadShutdownTimeout updates configuration with daemon shutdown timeout option\n// and updates the passed attributes", "input": "go language", "output": "func (daemon *Daemon) reloadShutdownTimeout(conf *config.Config, attributes map[string]string) {\n\t// update corresponding configuration\n\tif conf.IsValueSet(\"shutdown-timeout\") {\n\t\tdaemon.configStore.ShutdownTimeout = conf.ShutdownTimeout\n\t\tlogrus.Debugf(\"Reset Shutdown Timeout: %d\", daemon.configStore.ShutdownTimeout)\n\t}\n\n\t// prepare reload event attributes with updatable configurations\n\tattributes[\"shutdown-timeout\"] = fmt.Sprintf(\"%d\", daemon.configStore.ShutdownTimeout)\n}"}, {"instruction": "// SetContentHash sets the content hash associated with a name. Only works if the caller\n// owns the name, and the associated resolver implements a `setContenthash` function.", "input": "go language", "output": "func (ens *ENS) SetContentHash(name string, hash []byte) (*types.Transaction, error) {\n\tnode := EnsNode(name)\n\n\tresolver, err := ens.getResolver(node)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\topts := ens.TransactOpts\n\topts.GasLimit = 200000\n\n\t// IMPORTANT: The old contract is deprecated. This code should be removed latest on June 1st 2019\n\tsupported, err := resolver.SupportsInterface(contentHash_Interface_Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !supported {\n\t\tresolver, err := ens.getFallbackResolver(node)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\topts := ens.TransactOpts\n\t\topts.GasLimit = 200000\n\t\tvar b [32]byte\n\t\tcopy(b[:], hash)\n\t\treturn resolver.Contract.SetContent(&opts, node, b)\n\t}\n\n\t// END DEPRECATED CODE\n\treturn resolver.Contract.SetContenthash(&opts, node, hash)\n}"}, {"instruction": "// NewCmdWait returns a cobra command for waiting", "input": "go language", "output": "func NewCmdWait(restClientGetter genericclioptions.RESTClientGetter, streams genericclioptions.IOStreams) *cobra.Command {\n\tflags := NewWaitFlags(restClientGetter, streams)\n\n\tcmd := &cobra.Command{\n\t\tUse:     \"wait ([-f FILENAME] | resource.group/resource.name | resource.group [(-l label | --all)]) [--for=delete|--for condition=available]\",\n\t\tShort:   \"Experimental: Wait for a specific condition on one or many resources.\",\n\t\tLong:    waitLong,\n\t\tExample: waitExample,\n\n\t\tDisableFlagsInUseLine: true,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\to, err := flags.ToOptions(args)\n\t\t\tcmdutil.CheckErr(err)\n\t\t\terr = o.RunWait()\n\t\t\tcmdutil.CheckErr(err)\n\t\t},\n\t\tSuggestFor: []string{\"list\", \"ps\"},\n\t}\n\n\tflags.AddFlags(cmd)\n\n\treturn cmd\n}"}, {"instruction": "// NewFilteredCertificateSigningRequestInformer constructs a new informer for CertificateSigningRequest type.\n// Always prefer using an informer factory to get a shared informer instead of getting an independent\n// one. This reduces memory footprint and number of connections to the server.", "input": "go language", "output": "func NewFilteredCertificateSigningRequestInformer(client kubernetes.Interface, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\n\treturn cache.NewSharedIndexInformer(\n\t\t&cache.ListWatch{\n\t\t\tListFunc: func(options v1.ListOptions) (runtime.Object, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.CertificatesV1beta1().CertificateSigningRequests().List(options)\n\t\t\t},\n\t\t\tWatchFunc: func(options v1.ListOptions) (watch.Interface, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.CertificatesV1beta1().CertificateSigningRequests().Watch(options)\n\t\t\t},\n\t\t},\n\t\t&certificatesv1beta1.CertificateSigningRequest{},\n\t\tresyncPeriod,\n\t\tindexers,\n\t)\n}"}, {"instruction": "// PlannedDataResourceObject is similar to ProposedNewObject but tailored for\n// planning data resources in particular. Specifically, it replaces the values\n// of any Computed attributes not set in the configuration with an unknown\n// value, which serves as a placeholder for a value to be filled in by the\n// provider when the data resource is finally read.\n//\n// Data resources are different because the planning of them is handled\n// entirely within Terraform Core and not subject to customization by the\n// provider. This function is, in effect, producing an equivalent result to\n// passing the ProposedNewObject result into a provider's PlanResourceChange\n// function, assuming a fixed implementation of PlanResourceChange that just\n// fills in unknown values as needed.", "input": "go language", "output": "func PlannedDataResourceObject(schema *configschema.Block, config cty.Value) cty.Value {\n\t// Our trick here is to run the ProposedNewObject logic with an\n\t// entirely-unknown prior value. Because of cty's unknown short-circuit\n\t// behavior, any operation on prior returns another unknown, and so\n\t// unknown values propagate into all of the parts of the resulting value\n\t// that would normally be filled in by preserving the prior state.\n\tprior := cty.UnknownVal(schema.ImpliedType())\n\treturn proposedNewObject(schema, prior, config)\n}"}, {"instruction": "// GetZoneByNodeName gets availability zone for the specified node. If the node is not running\n// with availability zone, then it returns fault domain.", "input": "go language", "output": "func (as *availabilitySet) GetZoneByNodeName(name string) (cloudprovider.Zone, error) {\n\tvm, err := as.getVirtualMachine(types.NodeName(name))\n\tif err != nil {\n\t\treturn cloudprovider.Zone{}, err\n\t}\n\n\tvar failureDomain string\n\tif vm.Zones != nil && len(*vm.Zones) > 0 {\n\t\t// Get availability zone for the node.\n\t\tzones := *vm.Zones\n\t\tzoneID, err := strconv.Atoi(zones[0])\n\t\tif err != nil {\n\t\t\treturn cloudprovider.Zone{}, fmt.Errorf(\"failed to parse zone %q: %v\", zones, err)\n\t\t}\n\n\t\tfailureDomain = as.makeZone(zoneID)\n\t} else {\n\t\t// Availability zone is not used for the node, falling back to fault domain.\n\t\tfailureDomain = strconv.Itoa(int(*vm.VirtualMachineProperties.InstanceView.PlatformFaultDomain))\n\t}\n\n\tzone := cloudprovider.Zone{\n\t\tFailureDomain: failureDomain,\n\t\tRegion:        *(vm.Location),\n\t}\n\treturn zone, nil\n}"}, {"instruction": "// IntentionGet returns the given intention by ID.", "input": "go language", "output": "func (s *Store) IntentionGet(ws memdb.WatchSet, id string) (uint64, *structs.Intention, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, intentionsTableName)\n\tif idx < 1 {\n\t\tidx = 1\n\t}\n\n\t// Look up by its ID.\n\twatchCh, intention, err := tx.FirstWatch(intentionsTableName, \"id\", id)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed intention lookup: %s\", err)\n\t}\n\tws.Add(watchCh)\n\n\t// Convert the interface{} if it is non-nil\n\tvar result *structs.Intention\n\tif intention != nil {\n\t\tresult = intention.(*structs.Intention)\n\t}\n\n\treturn idx, result, nil\n}"}, {"instruction": "// writePacket writes data that already have header", "input": "go language", "output": "func (p *packetIO) writePacket(data []byte) error {\n\tlength := len(data) - 4\n\n\tfor length >= mysql.MaxPayloadLen {\n\t\tdata[0] = 0xff\n\t\tdata[1] = 0xff\n\t\tdata[2] = 0xff\n\n\t\tdata[3] = p.sequence\n\n\t\tif n, err := p.bufWriter.Write(data[:4+mysql.MaxPayloadLen]); err != nil {\n\t\t\treturn errors.Trace(mysql.ErrBadConn)\n\t\t} else if n != (4 + mysql.MaxPayloadLen) {\n\t\t\treturn errors.Trace(mysql.ErrBadConn)\n\t\t} else {\n\t\t\tp.sequence++\n\t\t\tlength -= mysql.MaxPayloadLen\n\t\t\tdata = data[mysql.MaxPayloadLen:]\n\t\t}\n\t}\n\n\tdata[0] = byte(length)\n\tdata[1] = byte(length >> 8)\n\tdata[2] = byte(length >> 16)\n\tdata[3] = p.sequence\n\n\tif n, err := p.bufWriter.Write(data); err != nil {\n\t\tterror.Log(errors.Trace(err))\n\t\treturn errors.Trace(mysql.ErrBadConn)\n\t} else if n != len(data) {\n\t\treturn errors.Trace(mysql.ErrBadConn)\n\t} else {\n\t\tp.sequence++\n\t\treturn nil\n\t}\n}"}, {"instruction": "// defaultPodLimitsForDownwardAPI copies the input pod, and optional container,\n// and applies default resource limits. it returns a copy of the input pod,\n// and a copy of the input container (if specified) with default limits\n// applied. if a container has no limit specified, it will default the limit to\n// the node allocatable.\n// TODO: if/when we have pod level resources, we need to update this function\n// to use those limits instead of node allocatable.", "input": "go language", "output": "func (kl *Kubelet) defaultPodLimitsForDownwardAPI(pod *v1.Pod, container *v1.Container) (*v1.Pod, *v1.Container, error) {\n\tif pod == nil {\n\t\treturn nil, nil, fmt.Errorf(\"invalid input, pod cannot be nil\")\n\t}\n\n\tnode, err := kl.getNodeAnyWay()\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to find node object, expected a node\")\n\t}\n\tallocatable := node.Status.Allocatable\n\tklog.Infof(\"allocatable: %v\", allocatable)\n\toutputPod := pod.DeepCopy()\n\tfor idx := range outputPod.Spec.Containers {\n\t\tresource.MergeContainerResourceLimits(&outputPod.Spec.Containers[idx], allocatable)\n\t}\n\n\tvar outputContainer *v1.Container\n\tif container != nil {\n\t\toutputContainer = container.DeepCopy()\n\t\tresource.MergeContainerResourceLimits(outputContainer, allocatable)\n\t}\n\treturn outputPod, outputContainer, nil\n}"}, {"instruction": "// TODO: could this use the regular daemon PullImage ?", "input": "go language", "output": "func (i *ImageService) pullForBuilder(ctx context.Context, name string, authConfigs map[string]types.AuthConfig, output io.Writer, platform *specs.Platform) (*image.Image, error) {\n\tref, err := reference.ParseNormalizedNamed(name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tref = reference.TagNameOnly(ref)\n\n\tpullRegistryAuth := &types.AuthConfig{}\n\tif len(authConfigs) > 0 {\n\t\t// The request came with a full auth config, use it\n\t\trepoInfo, err := i.registryService.ResolveRepository(ref)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tresolvedConfig := registry.ResolveAuthConfig(authConfigs, repoInfo.Index)\n\t\tpullRegistryAuth = &resolvedConfig\n\t}\n\n\tif err := i.pullImageWithReference(ctx, ref, platform, nil, pullRegistryAuth, output); err != nil {\n\t\treturn nil, err\n\t}\n\treturn i.GetImage(name)\n}"}, {"instruction": "// NewOnAddresses creates a new PortForwarder with custom listen addresses.", "input": "go language", "output": "func NewOnAddresses(dialer httpstream.Dialer, addresses []string, ports []string, stopChan <-chan struct{}, readyChan chan struct{}, out, errOut io.Writer) (*PortForwarder, error) {\n\tif len(addresses) == 0 {\n\t\treturn nil, errors.New(\"You must specify at least 1 address\")\n\t}\n\tparsedAddresses, err := parseAddresses(addresses)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(ports) == 0 {\n\t\treturn nil, errors.New(\"You must specify at least 1 port\")\n\t}\n\tparsedPorts, err := parsePorts(ports)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &PortForwarder{\n\t\tdialer:    dialer,\n\t\taddresses: parsedAddresses,\n\t\tports:     parsedPorts,\n\t\tstopChan:  stopChan,\n\t\tReady:     readyChan,\n\t\tout:       out,\n\t\terrOut:    errOut,\n\t}, nil\n}"}, {"instruction": "// StartWSEndpoint starts a websocket endpoint", "input": "go language", "output": "func StartWSEndpoint(endpoint string, apis []API, modules []string, wsOrigins []string, exposeAll bool) (net.Listener, *Server, error) {\n\n\t// Generate the whitelist based on the allowed modules\n\twhitelist := make(map[string]bool)\n\tfor _, module := range modules {\n\t\twhitelist[module] = true\n\t}\n\t// Register all the APIs exposed by the services\n\thandler := NewServer()\n\tfor _, api := range apis {\n\t\tif exposeAll || whitelist[api.Namespace] || (len(whitelist) == 0 && api.Public) {\n\t\t\tif err := handler.RegisterName(api.Namespace, api.Service); err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tlog.Debug(\"WebSocket registered\", \"service\", api.Service, \"namespace\", api.Namespace)\n\t\t}\n\t}\n\t// All APIs registered, start the HTTP listener\n\tvar (\n\t\tlistener net.Listener\n\t\terr      error\n\t)\n\tif listener, err = net.Listen(\"tcp\", endpoint); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tgo NewWSServer(wsOrigins, handler).Serve(listener)\n\treturn listener, handler, err\n\n}"}, {"instruction": "// NewDatabaseWithCache creates a new trie database to store ephemeral trie content\n// before its written out to disk or garbage collected. It also acts as a read cache\n// for nodes loaded from disk.", "input": "go language", "output": "func NewDatabaseWithCache(diskdb ethdb.KeyValueStore, cache int) *Database {\n\tvar cleans *bigcache.BigCache\n\tif cache > 0 {\n\t\tcleans, _ = bigcache.NewBigCache(bigcache.Config{\n\t\t\tShards:             1024,\n\t\t\tLifeWindow:         time.Hour,\n\t\t\tMaxEntriesInWindow: cache * 1024,\n\t\t\tMaxEntrySize:       512,\n\t\t\tHardMaxCacheSize:   cache,\n\t\t\tHasher:             trienodeHasher{},\n\t\t})\n\t}\n\treturn &Database{\n\t\tdiskdb: diskdb,\n\t\tcleans: cleans,\n\t\tdirties: map[common.Hash]*cachedNode{{}: {\n\t\t\tchildren: make(map[common.Hash]uint16),\n\t\t}},\n\t\tpreimages: make(map[common.Hash][]byte),\n\t}\n}"}, {"instruction": "// HInc increments the integer value of a hash field, by step, returns\n// the value after the increment.", "input": "go language", "output": "func (t *TxStructure) HInc(key []byte, field []byte, step int64) (int64, error) {\n\tif t.readWriter == nil {\n\t\treturn 0, errWriteOnSnapshot\n\t}\n\tbase := int64(0)\n\terr := t.updateHash(key, field, func(oldValue []byte) ([]byte, error) {\n\t\tif oldValue != nil {\n\t\t\tvar err error\n\t\t\tbase, err = strconv.ParseInt(string(oldValue), 10, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Trace(err)\n\t\t\t}\n\t\t}\n\t\tbase += step\n\t\treturn t.hashFieldIntegerVal(base), nil\n\t})\n\n\treturn base, errors.Trace(err)\n}"}, {"instruction": "// New creates a new ledger factory", "input": "go language", "output": "func New(directory string) blockledger.Factory {\n\tlogger.Debugf(\"Initializing ledger at: %s\", directory)\n\tif err := os.MkdirAll(directory, 0700); err != nil {\n\t\tlogger.Panicf(\"Could not create directory %s: %s\", directory, err)\n\t}\n\n\tjlf := &jsonLedgerFactory{\n\t\tdirectory: directory,\n\t\tledgers:   make(map[string]blockledger.ReadWriter),\n\t}\n\n\tinfos, err := ioutil.ReadDir(jlf.directory)\n\tif err != nil {\n\t\tlogger.Panicf(\"Error reading from directory %s while initializing ledger: %s\", jlf.directory, err)\n\t}\n\n\tfor _, info := range infos {\n\t\tif !info.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tvar chainID string\n\t\t_, err := fmt.Sscanf(info.Name(), chainDirectoryFormatString, &chainID)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tjlf.GetOrCreate(chainID)\n\t}\n\n\treturn jlf\n}"}, {"instruction": "// Parses awslogs-multiline-pattern and awslogs-datetime-format options\n// If awslogs-datetime-format is present, convert the format from strftime\n// to regexp and return.\n// If awslogs-multiline-pattern is present, compile regexp and return", "input": "go language", "output": "func parseMultilineOptions(info logger.Info) (*regexp.Regexp, error) {\n\tdateTimeFormat := info.Config[datetimeFormatKey]\n\tmultilinePatternKey := info.Config[multilinePatternKey]\n\t// strftime input is parsed into a regular expression\n\tif dateTimeFormat != \"\" {\n\t\t// %. matches each strftime format sequence and ReplaceAllStringFunc\n\t\t// looks up each format sequence in the conversion table strftimeToRegex\n\t\t// to replace with a defined regular expression\n\t\tr := regexp.MustCompile(\"%.\")\n\t\tmultilinePatternKey = r.ReplaceAllStringFunc(dateTimeFormat, func(s string) string {\n\t\t\treturn strftimeToRegex[s]\n\t\t})\n\t}\n\tif multilinePatternKey != \"\" {\n\t\tmultilinePattern, err := regexp.Compile(multilinePatternKey)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"awslogs could not parse multiline pattern key %q\", multilinePatternKey)\n\t\t}\n\t\treturn multilinePattern, nil\n\t}\n\treturn nil, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *Event) DeepCopyInto(out *Event) {\n\t*out = *in\n\tout.TypeMeta = in.TypeMeta\n\tin.ObjectMeta.DeepCopyInto(&out.ObjectMeta)\n\tin.EventTime.DeepCopyInto(&out.EventTime)\n\tif in.Series != nil {\n\t\tin, out := &in.Series, &out.Series\n\t\t*out = new(EventSeries)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tout.Regarding = in.Regarding\n\tif in.Related != nil {\n\t\tin, out := &in.Related, &out.Related\n\t\t*out = new(v1.ObjectReference)\n\t\t**out = **in\n\t}\n\tout.DeprecatedSource = in.DeprecatedSource\n\tin.DeprecatedFirstTimestamp.DeepCopyInto(&out.DeprecatedFirstTimestamp)\n\tin.DeprecatedLastTimestamp.DeepCopyInto(&out.DeprecatedLastTimestamp)\n\treturn\n}"}, {"instruction": "// Generate an elliptic curve public / private keypair. If params is nil,\n// the recommended default parameters for the key will be chosen.", "input": "go language", "output": "func GenerateKey(rand io.Reader, curve elliptic.Curve, params *ECIESParams) (prv *PrivateKey, err error) {\n\tpb, x, y, err := elliptic.GenerateKey(curve, rand)\n\tif err != nil {\n\t\treturn\n\t}\n\tprv = new(PrivateKey)\n\tprv.PublicKey.X = x\n\tprv.PublicKey.Y = y\n\tprv.PublicKey.Curve = curve\n\tprv.D = new(big.Int).SetBytes(pb)\n\tif params == nil {\n\t\tparams = ParamsFromCurve(curve)\n\t}\n\tprv.PublicKey.Params = params\n\treturn\n}"}, {"instruction": "// Encrypt encrypts a payload with a given secret.", "input": "go language", "output": "func Encrypt(payload []byte, secret string) ([]byte, error) {\n\tsalt := GetRandomString(saltLength)\n\n\tkey := encryptionKeyToBytes(secret, salt)\n\tblock, err := aes.NewCipher(key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The IV needs to be unique, but not secure. Therefore it's common to\n\t// include it at the beginning of the ciphertext.\n\tciphertext := make([]byte, saltLength+aes.BlockSize+len(payload))\n\tcopy(ciphertext[:saltLength], []byte(salt))\n\tiv := ciphertext[saltLength : saltLength+aes.BlockSize]\n\tif _, err := io.ReadFull(rand.Reader, iv); err != nil {\n\t\treturn nil, err\n\t}\n\n\tstream := cipher.NewCFBEncrypter(block, iv)\n\tstream.XORKeyStream(ciphertext[saltLength+aes.BlockSize:], payload)\n\n\treturn ciphertext, nil\n}"}, {"instruction": "// ValidateTokenGroups validates token groups", "input": "go language", "output": "func ValidateTokenGroups(usages []string, groups []string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\t// adding groups only makes sense for authentication\n\tusagesSet := sets.NewString(usages...)\n\tusageAuthentication := strings.TrimPrefix(bootstrapapi.BootstrapTokenUsageAuthentication, bootstrapapi.BootstrapTokenUsagePrefix)\n\tif len(groups) > 0 && !usagesSet.Has(usageAuthentication) {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, groups, fmt.Sprintf(\"token groups cannot be specified unless --usages includes %q\", usageAuthentication)))\n\t}\n\n\t// validate any extra group names\n\tfor _, group := range groups {\n\t\tif err := bootstraputil.ValidateBootstrapGroupName(group); err != nil {\n\t\t\tallErrs = append(allErrs, field.Invalid(fldPath, groups, err.Error()))\n\t\t}\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// setMessage sets info message(ERR_INSERT_INFO) generated by INSERT statement", "input": "go language", "output": "func (e *InsertExec) setMessage() {\n\tstmtCtx := e.ctx.GetSessionVars().StmtCtx\n\tnumRecords := stmtCtx.RecordRows()\n\tif e.SelectExec != nil || numRecords > 1 {\n\t\tnumWarnings := stmtCtx.WarningCount()\n\t\tvar numDuplicates uint64\n\t\tif stmtCtx.DupKeyAsWarning {\n\t\t\t// if ignoreErr\n\t\t\tnumDuplicates = numRecords - stmtCtx.CopiedRows()\n\t\t} else {\n\t\t\tif e.ctx.GetSessionVars().ClientCapability&mysql.ClientFoundRows > 0 {\n\t\t\t\tnumDuplicates = stmtCtx.TouchedRows()\n\t\t\t} else {\n\t\t\t\tnumDuplicates = stmtCtx.UpdatedRows()\n\t\t\t}\n\t\t}\n\t\tmsg := fmt.Sprintf(mysql.MySQLErrName[mysql.ErrInsertInfo], numRecords, numDuplicates, numWarnings)\n\t\tstmtCtx.SetMessage(msg)\n\t}\n}"}, {"instruction": "// IsPodCgroup returns true if the literal cgroupfs name corresponds to a pod", "input": "go language", "output": "func (m *podContainerManagerImpl) IsPodCgroup(cgroupfs string) (bool, types.UID) {\n\t// convert the literal cgroupfs form to the driver specific value\n\tcgroupName := m.cgroupManager.CgroupName(cgroupfs)\n\tqosContainersList := [3]CgroupName{m.qosContainersInfo.BestEffort, m.qosContainersInfo.Burstable, m.qosContainersInfo.Guaranteed}\n\tbasePath := \"\"\n\tfor _, qosContainerName := range qosContainersList {\n\t\t// a pod cgroup is a direct child of a qos node, so check if its a match\n\t\tif len(cgroupName) == len(qosContainerName)+1 {\n\t\t\tbasePath = cgroupName[len(qosContainerName)]\n\t\t}\n\t}\n\tif basePath == \"\" {\n\t\treturn false, types.UID(\"\")\n\t}\n\tif !strings.HasPrefix(basePath, podCgroupNamePrefix) {\n\t\treturn false, types.UID(\"\")\n\t}\n\tparts := strings.Split(basePath, podCgroupNamePrefix)\n\tif len(parts) != 2 {\n\t\treturn false, types.UID(\"\")\n\t}\n\treturn true, types.UID(parts[1])\n}"}, {"instruction": "// isSingleReference returns true when all references are from one repository\n// and there is at most one tag. Returns false for empty input.", "input": "go language", "output": "func isSingleReference(repoRefs []reference.Named) bool {\n\tif len(repoRefs) <= 1 {\n\t\treturn len(repoRefs) == 1\n\t}\n\tvar singleRef reference.Named\n\tcanonicalRefs := map[string]struct{}{}\n\tfor _, repoRef := range repoRefs {\n\t\tif _, isCanonical := repoRef.(reference.Canonical); isCanonical {\n\t\t\tcanonicalRefs[repoRef.Name()] = struct{}{}\n\t\t} else if singleRef == nil {\n\t\t\tsingleRef = repoRef\n\t\t} else {\n\t\t\treturn false\n\t\t}\n\t}\n\tif singleRef == nil {\n\t\t// Just use first canonical ref\n\t\tsingleRef = repoRefs[0]\n\t}\n\t_, ok := canonicalRefs[singleRef.Name()]\n\treturn len(canonicalRefs) == 1 && ok\n}"}, {"instruction": "// Parse API configuration from parameters or secret", "input": "go language", "output": "func parseAPIConfig(params map[string]string) (*storageosAPIConfig, error) {\n\n\tif len(params) == 0 {\n\t\treturn nil, fmt.Errorf(\"empty API config\")\n\t}\n\n\tc := &storageosAPIConfig{}\n\n\tfor name, data := range params {\n\t\tswitch strings.ToLower(name) {\n\t\tcase \"apiaddress\":\n\t\t\tc.apiAddr = string(data)\n\t\tcase \"apiusername\":\n\t\t\tc.apiUser = string(data)\n\t\tcase \"apipassword\":\n\t\t\tc.apiPass = string(data)\n\t\tcase \"apiversion\":\n\t\t\tc.apiVersion = string(data)\n\t\t}\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// Execute executes the command", "input": "go language", "output": "func (pc *ConfigCmd) Execute(conf common.Config) error {\n\tif pc.server == nil || *pc.server == \"\" {\n\t\treturn errors.New(\"no server specified\")\n\t}\n\tif pc.channel == nil || *pc.channel == \"\" {\n\t\treturn errors.New(\"no channel specified\")\n\t}\n\n\tserver := *pc.server\n\tchannel := *pc.channel\n\n\treq := discovery.NewRequest().OfChannel(channel).AddConfigQuery()\n\tres, err := pc.stub.Send(server, conf, req)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn pc.parser.ParseResponse(channel, res)\n}"}, {"instruction": "// snapshot is the internal function analogous to Snapshot but expects\n// a lock to already be held.\n//\n// checkDup when set will store the snapshot on lastSnapshot and use\n// reflect.DeepEqual to verify that its not writing an identical snapshot.", "input": "go language", "output": "func (m *Manager) snapshot(path string, checkDup bool) error {\n\t// Build the snapshot\n\ts := snapshot{\n\t\tVersion: snapshotVersion,\n\t\tProxies: make(map[string]snapshotProxy, len(m.proxies)),\n\t}\n\tfor id, p := range m.proxies {\n\t\t// Get the snapshot configuration. If the configuration is nil or\n\t\t// empty then we don't persist this proxy.\n\t\tconfig := p.MarshalSnapshot()\n\t\tif len(config) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\ts.Proxies[id] = snapshotProxy{\n\t\t\tMode:   proxyExecMode(p),\n\t\t\tConfig: config,\n\t\t}\n\t}\n\n\t// Dup detection, if the snapshot is identical to the last, do nothing\n\tif checkDup && reflect.DeepEqual(m.lastSnapshot, &s) {\n\t\treturn nil\n\t}\n\n\t// Encode as JSON\n\tencoded, err := json.Marshal(&s)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Write the file\n\terr = file.WriteAtomic(path, encoded)\n\n\t// If we are checking for dups and we had a successful write, store\n\t// it so we don't rewrite the same value.\n\tif checkDup && err == nil {\n\t\tm.lastSnapshot = &s\n\t}\n\treturn err\n}"}, {"instruction": "// UpdateStatus was generated because the type contains a Status member.\n// Add a +genclient:noStatus comment above the type to avoid generating UpdateStatus().", "input": "go language", "output": "func (c *FakeReplicationControllers) UpdateStatus(replicationController *corev1.ReplicationController) (*corev1.ReplicationController, error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewUpdateSubresourceAction(replicationcontrollersResource, \"status\", c.ns, replicationController), &corev1.ReplicationController{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*corev1.ReplicationController), err\n}"}, {"instruction": "// JWTTokenGenerator returns a TokenGenerator that generates signed JWT tokens, using the given privateKey.\n// privateKey is a PEM-encoded byte array of a private RSA key.\n// JWTTokenAuthenticator()", "input": "go language", "output": "func JWTTokenGenerator(iss string, privateKey interface{}) (TokenGenerator, error) {\n\tvar alg jose.SignatureAlgorithm\n\tswitch pk := privateKey.(type) {\n\tcase *rsa.PrivateKey:\n\t\talg = jose.RS256\n\tcase *ecdsa.PrivateKey:\n\t\tswitch pk.Curve {\n\t\tcase elliptic.P256():\n\t\t\talg = jose.ES256\n\t\tcase elliptic.P384():\n\t\t\talg = jose.ES384\n\t\tcase elliptic.P521():\n\t\t\talg = jose.ES512\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unknown private key curve, must be 256, 384, or 521\")\n\t\t}\n\tcase jose.OpaqueSigner:\n\t\talg = jose.SignatureAlgorithm(pk.Public().Algorithm)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unknown private key type %T, must be *rsa.PrivateKey, *ecdsa.PrivateKey, or jose.OpaqueSigner\", privateKey)\n\t}\n\n\tsigner, err := jose.NewSigner(\n\t\tjose.SigningKey{\n\t\t\tAlgorithm: alg,\n\t\t\tKey:       privateKey,\n\t\t},\n\t\tnil,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &jwtTokenGenerator{\n\t\tiss:    iss,\n\t\tsigner: signer,\n\t}, nil\n}"}, {"instruction": "// StringInSlice returns a SchemaValidateFunc which tests if the provided value\n// is of type string and matches the value of an element in the valid slice\n// will test with in lower case if ignoreCase is true", "input": "go language", "output": "func StringInSlice(valid []string, ignoreCase bool) schema.SchemaValidateFunc {\n\treturn func(i interface{}, k string) (s []string, es []error) {\n\t\tv, ok := i.(string)\n\t\tif !ok {\n\t\t\tes = append(es, fmt.Errorf(\"expected type of %s to be string\", k))\n\t\t\treturn\n\t\t}\n\n\t\tfor _, str := range valid {\n\t\t\tif v == str || (ignoreCase && strings.ToLower(v) == strings.ToLower(str)) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tes = append(es, fmt.Errorf(\"expected %s to be one of %v, got %s\", k, valid, v))\n\t\treturn\n\t}\n}"}, {"instruction": "// WaitForCacheSync waits for caches to populate.  It returns true if it was successful, false\n// if the controller should shutdown", "input": "go language", "output": "func WaitForCacheSync(stopCh <-chan struct{}, cacheSyncs ...InformerSynced) bool {\n\terr := wait.PollUntil(syncedPollPeriod,\n\t\tfunc() (bool, error) {\n\t\t\tfor _, syncFunc := range cacheSyncs {\n\t\t\t\tif !syncFunc() {\n\t\t\t\t\treturn false, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true, nil\n\t\t},\n\t\tstopCh)\n\tif err != nil {\n\t\tklog.V(2).Infof(\"stop requested\")\n\t\treturn false\n\t}\n\n\tklog.V(4).Infof(\"caches populated\")\n\treturn true\n}"}, {"instruction": "// PeersInfo returns an array of metadata objects describing connected peers.", "input": "go language", "output": "func (srv *Server) PeersInfo() []*PeerInfo {\n\t// Gather all the generic and sub-protocol specific infos\n\tinfos := make([]*PeerInfo, 0, srv.PeerCount())\n\tfor _, peer := range srv.Peers() {\n\t\tif peer != nil {\n\t\t\tinfos = append(infos, peer.Info())\n\t\t}\n\t}\n\t// Sort the result array alphabetically by node identifier\n\tfor i := 0; i < len(infos); i++ {\n\t\tfor j := i + 1; j < len(infos); j++ {\n\t\t\tif infos[i].ID > infos[j].ID {\n\t\t\t\tinfos[i], infos[j] = infos[j], infos[i]\n\t\t\t}\n\t\t}\n\t}\n\treturn infos\n}"}, {"instruction": "// SetPBColumnsDefaultValue sets the default values of tipb.ColumnInfos.", "input": "go language", "output": "func SetPBColumnsDefaultValue(ctx sessionctx.Context, pbColumns []*tipb.ColumnInfo, columns []*model.ColumnInfo) error {\n\tfor i, c := range columns {\n\t\tif c.OriginDefaultValue == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tsessVars := ctx.GetSessionVars()\n\t\toriginStrict := sessVars.StrictSQLMode\n\t\tsessVars.StrictSQLMode = false\n\t\td, err := table.GetColOriginDefaultValue(ctx, c)\n\t\tsessVars.StrictSQLMode = originStrict\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpbColumns[i].DefaultVal, err = tablecodec.EncodeValue(ctx.GetSessionVars().StmtCtx, d)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// ensureHomeIfIAmStatic ensure $HOME to be set if dockerversion.IAmStatic is \"true\".\n// See issue #29344: gcplogs segfaults (static binary)\n// If HOME is not set, logging.NewClient() will call os/user.Current() via oauth2/google.\n// However, in static binary, os/user.Current() leads to segfault due to a glibc issue that won't be fixed\n// in a short term. (golang/go#13470, https://sourceware.org/bugzilla/show_bug.cgi?id=19341)\n// So we forcibly set HOME so as to avoid call to os/user/Current()", "input": "go language", "output": "func ensureHomeIfIAmStatic() error {\n\t// Note: dockerversion.IAmStatic and homedir.GetStatic() is only available for linux.\n\t// So we need to use them in this gcplogging_linux.go rather than in gcplogging.go\n\tif dockerversion.IAmStatic == \"true\" && os.Getenv(\"HOME\") == \"\" {\n\t\thome, err := homedir.GetStatic()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogrus.Warnf(\"gcplogs requires HOME to be set for static daemon binary. Forcibly setting HOME to %s.\", home)\n\t\tos.Setenv(\"HOME\", home)\n\t}\n\treturn nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *HorizontalPodAutoscalerStatus) DeepCopyInto(out *HorizontalPodAutoscalerStatus) {\n\t*out = *in\n\tif in.ObservedGeneration != nil {\n\t\tin, out := &in.ObservedGeneration, &out.ObservedGeneration\n\t\t*out = new(int64)\n\t\t**out = **in\n\t}\n\tif in.LastScaleTime != nil {\n\t\tin, out := &in.LastScaleTime, &out.LastScaleTime\n\t\t*out = (*in).DeepCopy()\n\t}\n\tif in.CurrentMetrics != nil {\n\t\tin, out := &in.CurrentMetrics, &out.CurrentMetrics\n\t\t*out = make([]MetricStatus, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.Conditions != nil {\n\t\tin, out := &in.Conditions, &out.Conditions\n\t\t*out = make([]HorizontalPodAutoscalerCondition, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// deocodeEIP1577ContentHash decodes a chain-stored content hash from an ENS record according to EIP-1577\n// a successful decode will result the different parts of the content hash in accordance to the CID spec\n// Note: only CIDv1 is supported", "input": "go language", "output": "func decodeEIP1577ContentHash(buf []byte) (storageNs, contentType, hashType, hashLength uint64, hash []byte, err error) {\n\tif len(buf) < 10 {\n\t\treturn 0, 0, 0, 0, nil, errors.New(\"buffer too short\")\n\t}\n\n\tstorageNs, n := binary.Uvarint(buf)\n\n\tbuf = buf[n:]\n\tvers, n := binary.Uvarint(buf)\n\n\tif vers != 1 {\n\t\treturn 0, 0, 0, 0, nil, fmt.Errorf(\"expected cid v1, got: %d\", vers)\n\t}\n\tbuf = buf[n:]\n\tcontentType, n = binary.Uvarint(buf)\n\n\tbuf = buf[n:]\n\thashType, n = binary.Uvarint(buf)\n\n\tbuf = buf[n:]\n\thashLength, n = binary.Uvarint(buf)\n\n\thash = buf[n:]\n\n\tif len(hash) != int(hashLength) {\n\t\treturn 0, 0, 0, 0, nil, errors.New(\"hash length mismatch\")\n\t}\n\treturn storageNs, contentType, hashType, hashLength, hash, nil\n}"}, {"instruction": "// toggleRecursorHandlerFromConfig enables or disables the recursor handler based on config idempotently", "input": "go language", "output": "func (d *DNSServer) toggleRecursorHandlerFromConfig(cfg *dnsConfig) {\n\tshouldEnable := len(cfg.Recursors) > 0\n\n\tif shouldEnable && atomic.CompareAndSwapUint32(&d.recursorEnabled, 0, 1) {\n\t\td.mux.HandleFunc(\".\", d.handleRecurse)\n\t\td.logger.Println(\"[DEBUG] dns: recursor enabled\")\n\t\treturn\n\t}\n\n\tif !shouldEnable && atomic.CompareAndSwapUint32(&d.recursorEnabled, 1, 0) {\n\t\td.mux.HandleRemove(\".\")\n\t\td.logger.Println(\"[DEBUG] dns: recursor disabled\")\n\t\treturn\n\t}\n}"}]