[{"instruction": "Log docker to AWS.\n@param region\n@param accountId\n@param username\n@param password\n@returns {Promise}", "input": "JavaScript", "output": "function loginToAws(region, accountId, username, password) {\n    const commandLine = `docker login --username AWS --password ${password} https://${accountId}.dkr.ecr.${region}.amazonaws.com`;\n    return new Promise(\n        (resolve, reject) =>\n            command(commandLine, (err, stdout) => {\n                if (err) {\n                    reject(err);\n                }\n                resolve(stdout);\n            }),\n        { silent: true }\n    );\n}"}, {"instruction": "Closes the row stream.\n\n@param {Error} [err]", "input": "JavaScript", "output": "function(err)\n  {\n    // if we have a result stream, stop listening to events on it\n    if (resultStream)\n    {\n      resultStream.removeListener('data', onResultStreamData);\n      resultStream.removeListener('close', onResultStreamClose);\n    }\n\n    // we're done, so time to clean up\n    rowBuffer = null;\n    rowIndex = 0;\n    resultStream = null;\n    numResultStreamInterrupts = 0;\n\n    if (err)\n    {\n      emitError(err);\n    }\n    else\n    {\n      self.push(null);\n    }\n  }"}, {"instruction": "render html from uml\n@param {string} umlCode - plant uml code text\n@returns {string} - rendered html", "input": "JavaScript", "output": "function plantUMLReplacer(umlCode) {\n    let renderedHTML;\n\n    try {\n      if (!plantumlEncoder) {\n        throw new Error('plantuml-encoder dependency required');\n      }\n      renderedHTML = `<img src=\"${rendererURL}${plantumlEncoder.encode(umlCode)}\" />`;\n    } catch (err) {\n      renderedHTML = `Error occurred on encoding uml: ${err.message}`;\n    }\n\n    return renderedHTML;\n  }"}, {"instruction": "Add command for bot to clear the room history (requires client reload).\ne.g. \"bot clr\" or \"@bot clear room\" or \"bot clr from June 3, 2018 17:30\".\n@param {Robot} robot The Hubot instance", "input": "JavaScript", "output": "function load (robot) {\n  robot.respond(/\\b(clean room|clr)( from (.*))?(\\.|!|)?$/i, async (res) => {\n    try {\n      const from = res.match[3] || 'May 19, 2015 04:36:09' // clear all if not given date\n      const oldest = new Date(from).toISOString()\n      const cleaned = await cleanRoomHistory(robot, res.message.user, oldest).catch()\n      if (typeof cleaned === 'undefined') {\n        res.reply(`Sorry, I'm afraid I can't do that.`)\n      }\n    } catch (err) {\n      res.reply(`That wasn't a valid date`)\n    }\n  })\n}"}, {"instruction": "image-specific code (override to implement e.g. Canvas or SVG tile layer)", "input": "JavaScript", "output": "function (tilePoint) {\n\t\treturn L.Util.template(this._url, L.extend({\n\t\t\ts: this._getSubdomain(tilePoint),\n\t\t\tz: tilePoint.z,\n\t\t\tx: tilePoint.x,\n\t\t\ty: tilePoint.y\n\t\t}, this.options));\n\t}"}, {"instruction": "amount of pixels to drag to determine direction of swipe", "input": "JavaScript", "output": "function(e, isDown) {\n\t    _preventObj.prevent = !_closestElement(e.target, _options.isClickableElement);\n\n\t\t_shout('preventDragEvent', e, isDown, _preventObj);\n\t\treturn _preventObj.prevent;\n\n\t}"}, {"instruction": "Returns whether the busy indicator is visible. It is considered as visible when the busy indicator element exists in the DOM as\na child of the table element. It is not checked whether the indicator is actually visible on the screen.\n\n@param {sap.ui.table.Table} oTable Instance of the table.\n@returns {boolean} Whether the busy indicator is visible.", "input": "JavaScript", "output": "function(oTable) {\n\t\t\tif (!oTable || !oTable.getDomRef()) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\treturn oTable.getDomRef().querySelector(\"#\" + oTable.getId() + \"-sapUiTableGridCnt > .sapUiLocalBusyIndicator\") != null;\n\t\t}"}, {"instruction": "/*\nConvert an array of little-endian words to a hex string.", "input": "JavaScript", "output": "function (binarray) {\r\n        var hex_tab = \"0123456789abcdef\";\r\n        var str = \"\";\r\n        for(var i = 0; i < binarray.length * 4; i++)\r\n        {\r\n            str += hex_tab.charAt((binarray[i>>2] >> ((i%4)*8+4)) & 0xF) +\r\n                hex_tab.charAt((binarray[i>>2] >> ((i%4)*8  )) & 0xF);\r\n        }\r\n        return str;\r\n    }"}, {"instruction": "tracks which channels are active", "input": "JavaScript", "output": "function connect() {\r\n    easyrtc.enableDebug(false);\r\n    easyrtc.enableDataChannels(true);\r\n    easyrtc.enableVideo(false);\r\n    easyrtc.enableAudio(false);\r\n    easyrtc.enableVideoReceive(false);\r\n    easyrtc.enableAudioReceive(false);\r\n    easyrtc.setDataChannelOpenListener(openListener);\r\n    easyrtc.setDataChannelCloseListener(closeListener);\r\n    easyrtc.setPeerListener(addToConversation);\r\n    easyrtc.setRoomOccupantListener(convertListToButtons);\r\n    easyrtc.connect(\"easyrtc.dataMessaging\", loginSuccess, loginFailure);\r\n}"}, {"instruction": "Convolve the image with the specified kernel.\n\n@example\nsharp(input)\n.convolve({\nwidth: 3,\nheight: 3,\nkernel: [-1, 0, 1, -2, 0, 2, -1, 0, 1]\n})\n.raw()\n.toBuffer(function(err, data, info) {\n// data contains the raw pixel data representing the convolution\n// of the input image with the horizontal Sobel operator\n});\n\n@param {Object} kernel\n@param {Number} kernel.width - width of the kernel in pixels.\n@param {Number} kernel.height - width of the kernel in pixels.\n@param {Array<Number>} kernel.kernel - Array of length `width*height` containing the kernel values.\n@param {Number} [kernel.scale=sum] - the scale of the kernel in pixels.\n@param {Number} [kernel.offset=0] - the offset of the kernel in pixels.\n@returns {Sharp}\n@throws {Error} Invalid parameters", "input": "JavaScript", "output": "function convolve (kernel) {\n  if (!is.object(kernel) || !Array.isArray(kernel.kernel) ||\n      !is.integer(kernel.width) || !is.integer(kernel.height) ||\n      !is.inRange(kernel.width, 3, 1001) || !is.inRange(kernel.height, 3, 1001) ||\n      kernel.height * kernel.width !== kernel.kernel.length\n  ) {\n    // must pass in a kernel\n    throw new Error('Invalid convolution kernel');\n  }\n  // Default scale is sum of kernel values\n  if (!is.integer(kernel.scale)) {\n    kernel.scale = kernel.kernel.reduce(function (a, b) {\n      return a + b;\n    }, 0);\n  }\n  // Clip scale to a minimum value of 1\n  if (kernel.scale < 1) {\n    kernel.scale = 1;\n  }\n  if (!is.integer(kernel.offset)) {\n    kernel.offset = 0;\n  }\n  this.options.convKernel = kernel;\n  return this;\n}"}, {"instruction": "Monkey-patch CodeMirror to prevent modes from being overwritten by extensions.\nWe may rely on the tokens provided by some of these modes.", "input": "JavaScript", "output": "function _patchCodeMirror() {\n        var _original_CodeMirror_defineMode = CodeMirror.defineMode;\n        function _wrapped_CodeMirror_defineMode(name) {\n            if (CodeMirror.modes[name]) {\n                console.error(\"There already is a CodeMirror mode with the name \\\"\" + name + \"\\\"\");\n                return;\n            }\n            _original_CodeMirror_defineMode.apply(CodeMirror, arguments);\n        }\n        CodeMirror.defineMode = _wrapped_CodeMirror_defineMode;\n    }"}, {"instruction": "/* Older versions of node do not have fs.exists so we implement our own", "input": "JavaScript", "output": "function checkFileExists(filename, callback) {\n  if (fs.exists !== undefined) {\n    fs.exists(filename, callback);\n  } else {\n    fs.stat(filename, function (err) {\n      callback(!err);\n    });\n  }\n}"}, {"instruction": "Encrypt plaintext input.\n@param  {Uint8Array} plaintext   The cleartext input to be encrypted\n@param  {Uint8Array} nonce       The nonce (16 bytes)\n@param  {Uint8Array} adata       Associated data to sign\n@returns {Promise<Uint8Array>}    The ciphertext output", "input": "JavaScript", "output": "async function(plaintext, nonce, adata) {\n      const [\n        omacNonce,\n        omacAdata\n      ] = await Promise.all([\n        omac(zero, nonce),\n        omac(one, adata)\n      ]);\n      const ciphered = await ctr(plaintext, omacNonce);\n      const omacCiphered = await omac(two, ciphered);\n      const tag = omacCiphered; // Assumes that omac(*).length === tagLength.\n      for (let i = 0; i < tagLength; i++) {\n        tag[i] ^= omacAdata[i] ^ omacNonce[i];\n      }\n      return util.concatUint8Array([ciphered, tag]);\n    }"}, {"instruction": "Returns the events of a search job with given parameters.\n\n@example\n\nvar job = service.jobs().item(\"mysid\");\njob.events({count: 10}, function(err, events, job) {\nconsole.log(\"Fields: \", events.fields);\n});\n\n@param {Object} params The parameters for retrieving events. For a list of available parameters, see the <a href=\"http://docs.splunk.com/Documentation/Splunk/latest/RESTAPI/RESTsearch#GET_search.2Fjobs.2F.7Bsearch_id.7D.2Fevents\" target=\"_blank\">GET search/jobs/{search_id}/events</a> endpoint in the REST API documentation.\n@param {Function} callback A function to call when the events are retrieved: `(err, events, job)`.\n\n@endpoint search/jobs/{search_id}/events\n@method splunkjs.Service.Job", "input": "JavaScript", "output": "function(params, callback) {\n            callback = callback || function() {};\n            params = params || {};\n            params.output_mode = params.output_mode || \"json_rows\"; \n            \n            var that = this;\n            return this.get(\"events\", params, function(err, response) {\n                if (err) {\n                    callback(err);\n                }\n                else {\n                    callback(null, response.data, that);\n                }\n            });\n        }"}, {"instruction": "return path to found, project first", "input": "JavaScript", "output": "function projectOrHereRequire(id,root) {\n\ttry {\n\t\treturn resolve.sync(id, {\n\t\t\tpackage: path.join(root,'package.json'),\n\t\t\tpaths: [root],\n\t\t\tbasedir:root\n\t\t});\n\t} catch(ex) {\n\t\t// console.error(ex);\n\t}\n\n\tvar here = path.join(__dirname,'..','..');\n\ttry {\n\t\tvar p = resolve.sync(id, {\n\t\t\tpackage: path.join(here,'package.json'),\n\t\t\tpaths: [here],\n\t\t\tbasedir:here\n\t\t});\n\t\treturn p;\n\t} catch(ex) {\n\t\t// console.error(ex);\n\t}\n}"}, {"instruction": "@\n#.destroy\n@comp Crafty Core\n@kind Method\n\n@sign public this .destroy(void)\nWill remove all event listeners and delete all properties as well as removing from the stage", "input": "JavaScript", "output": "function() {\n        //remove all event handlers, delete from entities\n        this.each(function() {\n            var comp;\n            this.trigger(\"Remove\");\n            for (var compName in this.__c) {\n                comp = components[compName];\n                if (comp && \"remove\" in comp) comp.remove.call(this, true);\n\n                // update map from component to (entityId -> entity)\n                delete compEntities[compName][this[0]];\n            }\n            this._unbindAll();\n            delete entities[this[0]];\n        });\n    }"}, {"instruction": "Parses comma separated list of numbers and returns them an array. Used internally by the TextParser", "input": "JavaScript", "output": "function parseNumberArray( value ) {\n\n\t\tvar array = value.split( ',' ).map( function ( val ) {\n\n\t\t\treturn parseFloat( val );\n\n\t\t} );\n\n\t\treturn array;\n\n\t}"}, {"instruction": "Based off of the plugin by Clint Helfers, with permission. http://blindsignals.com/index.php/2009/07/jquery-delay/", "input": "JavaScript", "output": "function( time, type ) {\n\t\ttime = jQuery.fx ? jQuery.fx.speeds[time] || time : time;\n\t\ttype = type || \"fx\";\n\n\t\treturn this.queue( type, function() {\n\t\t\tvar elem = this;\n\t\t\tsetTimeout(function() {\n\t\t\t\tjQuery.dequeue( elem, type );\n\t\t\t}, time );\n\t\t});\n\t}"}, {"instruction": "Given an AST and an array of variableDeclaration nodes, return a new AST with\nall the declarations at the top of the AST.", "input": "JavaScript", "output": "function addTopDeclarationNodes(ast: Object, declarationNodes: Object[]) {\n  const statements = [];\n  declarationNodes.forEach(declarationNode => {\n    statements.push(getDeclarations(declarationNode));\n  });\n  statements.push(ast);\n  return t.program(statements);\n}"}, {"instruction": "Allowing namespace constraints such as ES6:String to only build for that namespace.", "input": "JavaScript", "output": "function getNamespaceConstraints() {\n    var map = {};\n    getModuleNames(m).forEach(function(n) {\n      var split = n.split(':');\n      var moduleName = split[0];\n      var namespaceName = split[1];\n      if (namespaceName) {\n        if (SPLIT_MODULES.indexOf(moduleName) === -1) {\n          warn('Module ' + moduleName + ' is not ready to be split!');\n          warn('Exiting...');\n          process.exit();\n        }\n        var constraints = map[moduleName] || {};\n        constraints[namespaceName] = true;\n        map[moduleName] = constraints;\n      }\n    });\n    return map;\n  }"}, {"instruction": "Get coordinates of a rectangle's lower right corner from its top points\nand its lower left corner.\n\n@param  {object} A rectangle defined by two points (x1, y1) and (x2, y2).\n@param  {object} A corner's coordinates (x, y).\n@return {object} Coordinates of the corner (x, y).", "input": "JavaScript", "output": "function(r, llc) {\n      return {\n        x: llc.x - r.x1 + r.x2,\n        y: llc.y - r.y1 + r.y2\n      };\n    }"}, {"instruction": "### Parse Options\nTake the given options and ensure they are valid pagination options, else use the defaults\n@param {options} options\n@returns {options} options sanitised for pagination", "input": "JavaScript", "output": "function parseOptions(options) {\n        options = _.defaults(options || {}, defaults);\n\n        if (options.limit !== 'all') {\n            options.limit = parseInt(options.limit, 10) || defaults.limit;\n        }\n\n        options.page = parseInt(options.page, 10) || defaults.page;\n\n        return options;\n    }"}, {"instruction": "This function memoize results for _computeMarkerId\nsince many of the times user will be playing around with the same zoom\nfactor, we can take advantage of this and cache the results for a\ngiven combination of highlight state, zoom transform value and maxZoom config.\n@returns{Function} memoize wrapper to the _computeMarkerId operation.\n@memberof Marker/helper", "input": "JavaScript", "output": "function _memoizedComputeMarkerId() {\n    let cache = {};\n\n    return (highlight, transform, { maxZoom }) => {\n        const cacheKey = `${highlight};${transform};${maxZoom}`;\n\n        if (cache[cacheKey]) {\n            return cache[cacheKey];\n        }\n\n        const markerId = _computeMarkerId(highlight, transform, { maxZoom });\n\n        cache[cacheKey] = markerId;\n\n        return markerId;\n    };\n}"}, {"instruction": "//////////////////////////////////////////////////////////// Converts a connection string or object into its safe copy: if password is present, it is masked with symbol '#'.", "input": "JavaScript", "output": "function getSafeConnection(cn) {\n    if (typeof cn === 'object') {\n        const copy = Object.assign({}, cn);\n        if (typeof copy.password === 'string') {\n            copy.password = copy.password.replace(/./g, '#');\n        }\n        if (typeof copy.connectionString === 'string') {\n            copy.connectionString = maskPassword(copy.connectionString);\n        }\n        return copy;\n    }\n    return maskPassword(cn);\n}"}, {"instruction": "Returns the spherical area for a list of coordinates.\n\n[Reference](https://trs-new.jpl.nasa.gov/handle/2014/40409)\nRobert. G. Chamberlain and William H. Duquette, \"Some Algorithms for\nPolygons on a Sphere\", JPL Publication 07-03, Jet Propulsion\nLaboratory, Pasadena, CA, June 2007\n\n@param {Array<import(\"./coordinate.js\").Coordinate>} coordinates List of coordinates of a linear\nring. If the ring is oriented clockwise, the area will be positive,\notherwise it will be negative.\n@param {number} radius The sphere radius.\n@return {number} Area (in square meters).", "input": "JavaScript", "output": "function getAreaInternal(coordinates, radius) {\n  let area = 0;\n  const len = coordinates.length;\n  let x1 = coordinates[len - 1][0];\n  let y1 = coordinates[len - 1][1];\n  for (let i = 0; i < len; i++) {\n    const x2 = coordinates[i][0];\n    const y2 = coordinates[i][1];\n    area += toRadians(x2 - x1) *\n        (2 + Math.sin(toRadians(y1)) +\n        Math.sin(toRadians(y2)));\n    x1 = x2;\n    y1 = y2;\n  }\n  return area * radius * radius / 2.0;\n}"}, {"instruction": "// AddPreShutdownHook allows you to add a PreShutdownHook.", "input": "go language", "output": "func (s *GenericAPIServer) AddPreShutdownHook(name string, hook PreShutdownHookFunc) error {\n\tif len(name) == 0 {\n\t\treturn fmt.Errorf(\"missing name\")\n\t}\n\tif hook == nil {\n\t\treturn nil\n\t}\n\n\ts.preShutdownHookLock.Lock()\n\tdefer s.preShutdownHookLock.Unlock()\n\n\tif s.preShutdownHooksCalled {\n\t\treturn fmt.Errorf(\"unable to add %q because PreShutdownHooks have already been called\", name)\n\t}\n\tif _, exists := s.preShutdownHooks[name]; exists {\n\t\treturn fmt.Errorf(\"unable to add %q because it is already registered\", name)\n\t}\n\n\ts.preShutdownHooks[name] = preShutdownHookEntry{hook: hook}\n\n\treturn nil\n}"}, {"instruction": "// setMessage sets info message(ERR_INSERT_INFO) generated by INSERT statement", "input": "go language", "output": "func (e *InsertExec) setMessage() {\n\tstmtCtx := e.ctx.GetSessionVars().StmtCtx\n\tnumRecords := stmtCtx.RecordRows()\n\tif e.SelectExec != nil || numRecords > 1 {\n\t\tnumWarnings := stmtCtx.WarningCount()\n\t\tvar numDuplicates uint64\n\t\tif stmtCtx.DupKeyAsWarning {\n\t\t\t// if ignoreErr\n\t\t\tnumDuplicates = numRecords - stmtCtx.CopiedRows()\n\t\t} else {\n\t\t\tif e.ctx.GetSessionVars().ClientCapability&mysql.ClientFoundRows > 0 {\n\t\t\t\tnumDuplicates = stmtCtx.TouchedRows()\n\t\t\t} else {\n\t\t\t\tnumDuplicates = stmtCtx.UpdatedRows()\n\t\t\t}\n\t\t}\n\t\tmsg := fmt.Sprintf(mysql.MySQLErrName[mysql.ErrInsertInfo], numRecords, numDuplicates, numWarnings)\n\t\tstmtCtx.SetMessage(msg)\n\t}\n}"}, {"instruction": "// handleFromEnvFileSource adds the specified env file source information\n// into the provided secret", "input": "go language", "output": "func handleFromEnvFileSource(secret *v1.Secret, envFileSource string) error {\n\tinfo, err := os.Stat(envFileSource)\n\tif err != nil {\n\t\tswitch err := err.(type) {\n\t\tcase *os.PathError:\n\t\t\treturn fmt.Errorf(\"error reading %s: %v\", envFileSource, err.Err)\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"error reading %s: %v\", envFileSource, err)\n\t\t}\n\t}\n\tif info.IsDir() {\n\t\treturn fmt.Errorf(\"env secret file cannot be a directory\")\n\t}\n\n\treturn addFromEnvFile(envFileSource, func(key, value string) error {\n\t\treturn addKeyFromLiteralToSecret(secret, key, []byte(value))\n\t})\n}"}, {"instruction": "//send the metrics to the DB", "input": "go language", "output": "func (r *reporter) save() error {\n\t//create a LevelDB Batch\n\tbatch := leveldb.Batch{}\n\t//for each metric in the registry (which is independent)...\n\tr.reg.Each(func(name string, i interface{}) {\n\t\tmetric, ok := i.(metrics.Counter)\n\t\tif ok {\n\t\t\t//assuming every metric here to be a Counter (separate registry)\n\t\t\t//...create a snapshot...\n\t\t\tms := metric.Snapshot()\n\t\t\tbyteVal := make([]byte, 8)\n\t\t\tbinary.BigEndian.PutUint64(byteVal, uint64(ms.Count()))\n\t\t\t//...and save the value to the DB\n\t\t\tbatch.Put([]byte(name), byteVal)\n\t\t}\n\t})\n\treturn r.db.Write(&batch, nil)\n}"}, {"instruction": "// TranslateCSIPVToInTree takes a PV with CSIPersistentVolumeSource set and\n// translates the Cinder CSI source to a Cinder In-tree source.", "input": "go language", "output": "func (t *osCinderCSITranslator) TranslateCSIPVToInTree(pv *v1.PersistentVolume) (*v1.PersistentVolume, error) {\n\tif pv == nil || pv.Spec.CSI == nil {\n\t\treturn nil, fmt.Errorf(\"pv is nil or CSI source not defined on pv\")\n\t}\n\n\tcsiSource := pv.Spec.CSI\n\n\tcinderSource := &v1.CinderPersistentVolumeSource{\n\t\tVolumeID: csiSource.VolumeHandle,\n\t\tFSType:   csiSource.FSType,\n\t\tReadOnly: csiSource.ReadOnly,\n\t}\n\n\tpv.Spec.CSI = nil\n\tpv.Spec.Cinder = cinderSource\n\treturn pv, nil\n}"}, {"instruction": "// InstanceType returns the type of the specified instance.\n// Note that if the instance does not exist or is no longer running, we must return (\"\", cloudprovider.InstanceNotFound)\n// (Implementer Note): This is used by kubelet. Kubelet will label the node. Real log from kubelet:\n//       Adding node label from cloud provider: beta.kubernetes.io/instance-type=[value]", "input": "go language", "output": "func (az *Cloud) InstanceType(ctx context.Context, name types.NodeName) (string, error) {\n\t// Returns \"\" for unmanaged nodes because azure cloud provider couldn't fetch information for them.\n\tunmanaged, err := az.IsNodeUnmanaged(string(name))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif unmanaged {\n\t\tklog.V(4).Infof(\"InstanceType: omitting unmanaged node %q\", name)\n\t\treturn \"\", nil\n\t}\n\n\tif az.UseInstanceMetadata {\n\t\tmetadata, err := az.metadata.GetMetadata()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tif metadata.Compute == nil {\n\t\t\treturn \"\", fmt.Errorf(\"failure of getting instance metadata\")\n\t\t}\n\n\t\tisLocalInstance, err := az.isCurrentInstance(name, metadata.Compute.Name)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tif isLocalInstance {\n\t\t\tif metadata.Compute.VMSize != \"\" {\n\t\t\t\treturn metadata.Compute.VMSize, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn az.vmSet.GetInstanceTypeByNodeName(string(name))\n}"}, {"instruction": "// waitForMembershipStabilization waits for membership view to stabilize\n// or until a time limit expires, or until a peer declares itself as a leader", "input": "go language", "output": "func (le *leaderElectionSvcImpl) waitForMembershipStabilization(timeLimit time.Duration) {\n\tle.logger.Debug(le.id, \": Entering\")\n\tdefer le.logger.Debug(le.id, \": Exiting, peers found\", len(le.adapter.Peers()))\n\tendTime := time.Now().Add(timeLimit)\n\tviewSize := len(le.adapter.Peers())\n\tfor !le.shouldStop() {\n\t\ttime.Sleep(le.config.MembershipSampleInterval)\n\t\tnewSize := len(le.adapter.Peers())\n\t\tif newSize == viewSize || time.Now().After(endTime) || le.isLeaderExists() {\n\t\t\treturn\n\t\t}\n\t\tviewSize = newSize\n\t}\n}"}, {"instruction": "// TODO: could this use the regular daemon PullImage ?", "input": "go language", "output": "func (i *ImageService) pullForBuilder(ctx context.Context, name string, authConfigs map[string]types.AuthConfig, output io.Writer, platform *specs.Platform) (*image.Image, error) {\n\tref, err := reference.ParseNormalizedNamed(name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tref = reference.TagNameOnly(ref)\n\n\tpullRegistryAuth := &types.AuthConfig{}\n\tif len(authConfigs) > 0 {\n\t\t// The request came with a full auth config, use it\n\t\trepoInfo, err := i.registryService.ResolveRepository(ref)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tresolvedConfig := registry.ResolveAuthConfig(authConfigs, repoInfo.Index)\n\t\tpullRegistryAuth = &resolvedConfig\n\t}\n\n\tif err := i.pullImageWithReference(ctx, ref, platform, nil, pullRegistryAuth, output); err != nil {\n\t\treturn nil, err\n\t}\n\treturn i.GetImage(name)\n}"}, {"instruction": "// dropDisabledRunAsGroupField removes disabled fields from PodSpec related\n// to RunAsGroup", "input": "go language", "output": "func dropDisabledRunAsGroupField(podSpec, oldPodSpec *api.PodSpec) {\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.RunAsGroup) && !runAsGroupInUse(oldPodSpec) {\n\t\tif podSpec.SecurityContext != nil {\n\t\t\tpodSpec.SecurityContext.RunAsGroup = nil\n\t\t}\n\t\tfor i := range podSpec.Containers {\n\t\t\tif podSpec.Containers[i].SecurityContext != nil {\n\t\t\t\tpodSpec.Containers[i].SecurityContext.RunAsGroup = nil\n\t\t\t}\n\t\t}\n\t\tfor i := range podSpec.InitContainers {\n\t\t\tif podSpec.InitContainers[i].SecurityContext != nil {\n\t\t\t\tpodSpec.InitContainers[i].SecurityContext.RunAsGroup = nil\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// dial establishes the gRPC communication with the registered device plugin. https://godoc.org/google.golang.org/grpc#Dial", "input": "go language", "output": "func dial(unixSocketPath string) (pluginapi.DevicePluginClient, *grpc.ClientConn, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\n\tc, err := grpc.DialContext(ctx, unixSocketPath, grpc.WithInsecure(), grpc.WithBlock(),\n\t\tgrpc.WithDialer(func(addr string, timeout time.Duration) (net.Conn, error) {\n\t\t\treturn net.DialTimeout(\"unix\", addr, timeout)\n\t\t}),\n\t)\n\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(errFailedToDialDevicePlugin+\" %v\", err)\n\t}\n\n\treturn pluginapi.NewDevicePluginClient(c), c, nil\n}"}, {"instruction": "// ImageStatus returns the status of the image, returns nil if the image doesn't present.", "input": "go language", "output": "func (ds *dockerService) ImageStatus(_ context.Context, r *runtimeapi.ImageStatusRequest) (*runtimeapi.ImageStatusResponse, error) {\n\timage := r.GetImage()\n\n\timageInspect, err := ds.client.InspectImageByRef(image.Image)\n\tif err != nil {\n\t\tif libdocker.IsImageNotFoundError(err) {\n\t\t\treturn &runtimeapi.ImageStatusResponse{}, nil\n\t\t}\n\t\treturn nil, err\n\t}\n\n\timageStatus, err := imageInspectToRuntimeAPIImage(imageInspect)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres := runtimeapi.ImageStatusResponse{Image: imageStatus}\n\tif r.GetVerbose() {\n\t\tres.Info = imageInspect.Config.Labels\n\t}\n\treturn &res, nil\n}"}, {"instruction": "// deocodeEIP1577ContentHash decodes a chain-stored content hash from an ENS record according to EIP-1577\n// a successful decode will result the different parts of the content hash in accordance to the CID spec\n// Note: only CIDv1 is supported", "input": "go language", "output": "func decodeEIP1577ContentHash(buf []byte) (storageNs, contentType, hashType, hashLength uint64, hash []byte, err error) {\n\tif len(buf) < 10 {\n\t\treturn 0, 0, 0, 0, nil, errors.New(\"buffer too short\")\n\t}\n\n\tstorageNs, n := binary.Uvarint(buf)\n\n\tbuf = buf[n:]\n\tvers, n := binary.Uvarint(buf)\n\n\tif vers != 1 {\n\t\treturn 0, 0, 0, 0, nil, fmt.Errorf(\"expected cid v1, got: %d\", vers)\n\t}\n\tbuf = buf[n:]\n\tcontentType, n = binary.Uvarint(buf)\n\n\tbuf = buf[n:]\n\thashType, n = binary.Uvarint(buf)\n\n\tbuf = buf[n:]\n\thashLength, n = binary.Uvarint(buf)\n\n\thash = buf[n:]\n\n\tif len(hash) != int(hashLength) {\n\t\treturn 0, 0, 0, 0, nil, errors.New(\"hash length mismatch\")\n\t}\n\treturn storageNs, contentType, hashType, hashLength, hash, nil\n}"}, {"instruction": "// CreateOrUpdateLB invokes az.LoadBalancerClient.CreateOrUpdate with exponential backoff retry", "input": "go language", "output": "func (az *Cloud) CreateOrUpdateLB(service *v1.Service, lb network.LoadBalancer) error {\n\tif az.Config.shouldOmitCloudProviderBackoff() {\n\t\tctx, cancel := getContextWithCancel()\n\t\tdefer cancel()\n\n\t\tresp, err := az.LoadBalancerClient.CreateOrUpdate(ctx, az.ResourceGroup, *lb.Name, lb)\n\t\tklog.V(10).Infof(\"LoadBalancerClient.CreateOrUpdate(%s): end\", *lb.Name)\n\t\tif err == nil {\n\t\t\tif isSuccessHTTPResponse(resp) {\n\t\t\t\t// Invalidate the cache right after updating\n\t\t\t\taz.lbCache.Delete(*lb.Name)\n\t\t\t} else if resp != nil {\n\t\t\t\treturn fmt.Errorf(\"HTTP response %q\", resp.Status)\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\n\treturn az.createOrUpdateLBWithRetry(service, lb)\n}"}, {"instruction": "// This function sets limiters according to corresponding DeviceConfiguration", "input": "go language", "output": "func (lim *limiter) setLimitsLocked(device config.DeviceConfiguration) bool {\n\treadLimiter := lim.getReadLimiterLocked(device.DeviceID)\n\twriteLimiter := lim.getWriteLimiterLocked(device.DeviceID)\n\n\t// limiters for this device are created so we can store previous rates for logging\n\tpreviousReadLimit := readLimiter.Limit()\n\tpreviousWriteLimit := writeLimiter.Limit()\n\tcurrentReadLimit := rate.Limit(device.MaxRecvKbps) * 1024\n\tcurrentWriteLimit := rate.Limit(device.MaxSendKbps) * 1024\n\tif device.MaxSendKbps <= 0 {\n\t\tcurrentWriteLimit = rate.Inf\n\t}\n\tif device.MaxRecvKbps <= 0 {\n\t\tcurrentReadLimit = rate.Inf\n\t}\n\t// Nothing about this device has changed. Start processing next device\n\tif previousWriteLimit == currentWriteLimit && previousReadLimit == currentReadLimit {\n\t\treturn false\n\t}\n\n\treadLimiter.SetLimit(currentReadLimit)\n\twriteLimiter.SetLimit(currentWriteLimit)\n\n\treturn true\n}"}, {"instruction": "// Unmount runs umount(8) in the host's mount namespace.", "input": "go language", "output": "func (n *Mounter) Unmount(target string) error {\n\targs := []string{target}\n\t// No need to execute systemd-run here, it's enough that unmount is executed\n\t// in the host's mount namespace. It will finish appropriate fuse daemon(s)\n\t// running in any scope.\n\tklog.V(5).Infof(\"nsenter unmount args: %v\", args)\n\toutputBytes, err := n.ne.Exec(\"umount\", args).CombinedOutput()\n\tif len(outputBytes) != 0 {\n\t\tklog.V(5).Infof(\"Output of unmounting %s: %v\", target, string(outputBytes))\n\t}\n\treturn err\n}"}, {"instruction": "// getExistingChains get iptables-save output so we can check for existing chains and rules.\n// This will be a map of chain name to chain with rules as stored in iptables-save/iptables-restore\n// Result may SHARE memory with contents of buffer.", "input": "go language", "output": "func (proxier *Proxier) getExistingChains(buffer *bytes.Buffer, table utiliptables.Table) map[utiliptables.Chain][]byte {\n\tbuffer.Reset()\n\terr := proxier.iptables.SaveInto(table, buffer)\n\tif err != nil { // if we failed to get any rules\n\t\tklog.Errorf(\"Failed to execute iptables-save, syncing all rules: %v\", err)\n\t} else { // otherwise parse the output\n\t\treturn utiliptables.GetChainLines(table, buffer.Bytes())\n\t}\n\treturn nil\n}"}, {"instruction": "// setStatus recreates the status of the given HPA, updating the current and\n// desired replicas, as well as the metric statuses", "input": "go language", "output": "func (a *HorizontalController) setStatus(hpa *autoscalingv2.HorizontalPodAutoscaler, currentReplicas, desiredReplicas int32, metricStatuses []autoscalingv2.MetricStatus, rescale bool) {\n\thpa.Status = autoscalingv2.HorizontalPodAutoscalerStatus{\n\t\tCurrentReplicas: currentReplicas,\n\t\tDesiredReplicas: desiredReplicas,\n\t\tLastScaleTime:   hpa.Status.LastScaleTime,\n\t\tCurrentMetrics:  metricStatuses,\n\t\tConditions:      hpa.Status.Conditions,\n\t}\n\n\tif rescale {\n\t\tnow := metav1.NewTime(time.Now())\n\t\thpa.Status.LastScaleTime = &now\n\t}\n}"}, {"instruction": "// GetDiskLun finds the lun on the host that the vhd is attached to, given a vhd's diskName and diskURI.", "input": "go language", "output": "func (c *controllerCommon) GetDiskLun(diskName, diskURI string, nodeName types.NodeName) (int32, error) {\n\tdisks, err := c.getNodeDataDisks(nodeName)\n\tif err != nil {\n\t\tklog.Errorf(\"error of getting data disks for node %q: %v\", nodeName, err)\n\t\treturn -1, err\n\t}\n\n\tfor _, disk := range disks {\n\t\tif disk.Lun != nil && (disk.Name != nil && diskName != \"\" && *disk.Name == diskName) ||\n\t\t\t(disk.Vhd != nil && disk.Vhd.URI != nil && diskURI != \"\" && *disk.Vhd.URI == diskURI) ||\n\t\t\t(disk.ManagedDisk != nil && *disk.ManagedDisk.ID == diskURI) {\n\t\t\t// found the disk\n\t\t\tklog.V(2).Infof(\"azureDisk - find disk: lun %d name %q uri %q\", *disk.Lun, diskName, diskURI)\n\t\t\treturn *disk.Lun, nil\n\t\t}\n\t}\n\treturn -1, fmt.Errorf(\"Cannot find Lun for disk %s\", diskName)\n}"}, {"instruction": "// Round returns the nearest integer, rounding half away from zero.\n//\n// Special cases are:\n//\tRound(\u00b10) = \u00b10\n//\tRound(\u00b1Inf) = \u00b1Inf\n//\tRound(NaN) = NaN", "input": "go language", "output": "func _round(x float64) float64 {\n\t// Round is a faster implementation of:\n\t//\n\t// func Round(x float64) float64 {\n\t//   t := Trunc(x)\n\t//   if Abs(x-t) >= 0.5 {\n\t//     return t + Copysign(1, x)\n\t//   }\n\t//   return t\n\t// }\n\tconst (\n\t\tsignMask = 1 << 63\n\t\tfracMask = 1<<shift - 1\n\t\thalf     = 1 << (shift - 1)\n\t\tone      = bias << shift\n\t)\n\n\tbits := math.Float64bits(x)\n\te := uint(bits>>shift) & mask\n\tif e < bias {\n\t\t// Round abs(x) < 1 including denormals.\n\t\tbits &= signMask // +-0\n\t\tif e == bias-1 {\n\t\t\tbits |= one // +-1\n\t\t}\n\t} else if e < bias+shift {\n\t\t// Round any abs(x) >= 1 containing a fractional component [0,1).\n\t\t//\n\t\t// Numbers with larger exponents are returned unchanged since they\n\t\t// must be either an integer, infinity, or NaN.\n\t\te -= bias\n\t\tbits += half >> e\n\t\tbits &^= fracMask >> e\n\t}\n\treturn math.Float64frombits(bits)\n}"}, {"instruction": "// InstallReleaseFromChart installs a new chart and returns the release response.", "input": "go language", "output": "func (h *Client) InstallReleaseFromChart(chart *chart.Chart, ns string, opts ...InstallOption) (*rls.InstallReleaseResponse, error) {\n\t// apply the install options\n\treqOpts := h.opts\n\tfor _, opt := range opts {\n\t\topt(&reqOpts)\n\t}\n\treq := &reqOpts.instReq\n\treq.Chart = chart\n\treq.Namespace = ns\n\treq.DryRun = reqOpts.dryRun\n\treq.DisableHooks = reqOpts.disableHooks\n\treq.DisableCrdHook = reqOpts.disableCRDHook\n\treq.ReuseName = reqOpts.reuseName\n\tctx := NewContext()\n\n\tif reqOpts.before != nil {\n\t\tif err := reqOpts.before(ctx, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr := chartutil.ProcessRequirementsEnabled(req.Chart, req.Values)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = chartutil.ProcessRequirementsImportValues(req.Chart)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn h.install(ctx, req)\n}"}, {"instruction": "// ValidateWebhook validates the webhook", "input": "go language", "output": "func ValidateWebhook(w auditregistration.Webhook, fldPath *field.Path) field.ErrorList {\n\tvar allErrs field.ErrorList\n\tif w.Throttle != nil {\n\t\tallErrs = append(allErrs, ValidateWebhookThrottleConfig(w.Throttle, fldPath.Child(\"throttle\"))...)\n\t}\n\n\tcc := w.ClientConfig\n\tswitch {\n\tcase (cc.URL == nil) == (cc.Service == nil):\n\t\tallErrs = append(allErrs, field.Required(fldPath.Child(\"clientConfig\"), \"exactly one of url or service is required\"))\n\tcase cc.URL != nil:\n\t\tallErrs = append(allErrs, webhook.ValidateWebhookURL(fldPath.Child(\"clientConfig\").Child(\"url\"), *cc.URL, false)...)\n\tcase cc.Service != nil:\n\t\tallErrs = append(allErrs, webhook.ValidateWebhookService(fldPath.Child(\"clientConfig\").Child(\"service\"), cc.Service.Name, cc.Service.Namespace, cc.Service.Path, cc.Service.Port)...)\n\t}\n\treturn allErrs\n}"}, {"instruction": "// NewProviderAggregator returns an aggregate of all the providers configured in the static configuration.", "input": "go language", "output": "func NewProviderAggregator(conf static.Providers) ProviderAggregator {\n\tp := ProviderAggregator{}\n\n\tif conf.File != nil {\n\t\tp.quietAddProvider(conf.File)\n\t}\n\n\tif conf.Docker != nil {\n\t\tp.quietAddProvider(conf.Docker)\n\t}\n\n\tif conf.Marathon != nil {\n\t\tp.quietAddProvider(conf.Marathon)\n\t}\n\n\tif conf.Rest != nil {\n\t\tp.quietAddProvider(conf.Rest)\n\t}\n\n\tif conf.Kubernetes != nil {\n\t\tp.quietAddProvider(conf.Kubernetes)\n\t}\n\n\tif conf.KubernetesCRD != nil {\n\t\tp.quietAddProvider(conf.KubernetesCRD)\n\t}\n\tif conf.Rancher != nil {\n\t\tp.quietAddProvider(conf.Rancher)\n\t}\n\n\treturn p\n}"}, {"instruction": "// Create creates a WAL ready for appending records. The given metadata is\n// recorded at the head of each WAL file, and can be retrieved with ReadAll.", "input": "go language", "output": "func Create(dirpath string, metadata []byte) (*WAL, error) {\n\tif Exist(dirpath) {\n\t\treturn nil, os.ErrExist\n\t}\n\n\tif err := os.MkdirAll(dirpath, privateDirMode); err != nil {\n\t\treturn nil, err\n\t}\n\n\tp := path.Join(dirpath, walName(0, 0))\n\tf, err := os.OpenFile(p, os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0600)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tl, err := fileutil.NewLock(f.Name())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err = l.Lock(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tw := &WAL{\n\t\tdir:      dirpath,\n\t\tmetadata: metadata,\n\t\tseq:      0,\n\t\tf:        f,\n\t\tencoder:  newEncoder(f, 0),\n\t}\n\tw.locks = append(w.locks, l)\n\tif err := w.saveCrc(0); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := w.encoder.encode(&walpb.Record{Type: metadataType, Data: metadata}); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := w.SaveSnapshot(walpb.Snapshot{}); err != nil {\n\t\treturn nil, err\n\t}\n\treturn w, nil\n}"}, {"instruction": "// CASetProviderState is used to set the current built-in CA provider state.", "input": "go language", "output": "func (s *Store) CASetProviderState(idx uint64, state *structs.CAConsulProviderState) (bool, error) {\n\ttx := s.db.Txn(true)\n\tdefer tx.Abort()\n\n\t// Check for an existing config\n\texisting, err := tx.First(caBuiltinProviderTableName, \"id\", state.ID)\n\tif err != nil {\n\t\treturn false, fmt.Errorf(\"failed built-in CA state lookup: %s\", err)\n\t}\n\n\t// Set the indexes.\n\tif existing != nil {\n\t\tstate.CreateIndex = existing.(*structs.CAConsulProviderState).CreateIndex\n\t} else {\n\t\tstate.CreateIndex = idx\n\t}\n\tstate.ModifyIndex = idx\n\n\tif err := tx.Insert(caBuiltinProviderTableName, state); err != nil {\n\t\treturn false, fmt.Errorf(\"failed updating built-in CA state: %s\", err)\n\t}\n\n\t// Update the index\n\tif err := tx.Insert(\"index\", &IndexEntry{caBuiltinProviderTableName, idx}); err != nil {\n\t\treturn false, fmt.Errorf(\"failed updating index: %s\", err)\n\t}\n\n\ttx.Commit()\n\n\treturn true, nil\n}"}, {"instruction": "// AuthMethodDelete deletes an auth method given its Name.", "input": "go language", "output": "func (a *ACL) AuthMethodDelete(methodName string, q *WriteOptions) (*WriteMeta, error) {\n\tif methodName == \"\" {\n\t\treturn nil, fmt.Errorf(\"Must specify a Name in Auth Method Delete\")\n\t}\n\n\tr := a.c.newRequest(\"DELETE\", \"/v1/acl/auth-method/\"+url.QueryEscape(methodName))\n\tr.setWriteOptions(q)\n\trtt, resp, err := requireOK(a.c.doRequest(r))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresp.Body.Close()\n\n\twm := &WriteMeta{RequestTime: rtt}\n\treturn wm, nil\n}"}, {"instruction": "// AddFlags receives a *cobra.Command reference and binds\n// flags related to humanreadable and template printing.", "input": "go language", "output": "func (f *PrintFlags) AddFlags(cmd *cobra.Command) {\n\tf.JSONYamlPrintFlags.AddFlags(cmd)\n\tf.NamePrintFlags.AddFlags(cmd)\n\tf.TemplateFlags.AddFlags(cmd)\n\tf.HumanReadableFlags.AddFlags(cmd)\n\tf.CustomColumnsFlags.AddFlags(cmd)\n\n\tif f.OutputFormat != nil {\n\t\tcmd.Flags().StringVarP(f.OutputFormat, \"output\", \"o\", *f.OutputFormat, \"Output format. One of: json|yaml|wide|name|custom-columns=...|custom-columns-file=...|go-template=...|go-template-file=...|jsonpath=...|jsonpath-file=... See custom columns [http://kubernetes.io/docs/user-guide/kubectl-overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [http://kubernetes.io/docs/user-guide/jsonpath].\")\n\t}\n\tif f.NoHeaders != nil {\n\t\tcmd.Flags().BoolVar(f.NoHeaders, \"no-headers\", *f.NoHeaders, \"When using the default or custom-column output format, don't print headers (default print headers).\")\n\t}\n}"}, {"instruction": "// Load loads a directory of charts as if it were a repository.\n//\n// It requires the presence of an index.yaml file in the directory.", "input": "go language", "output": "func (r *ChartRepository) Load() error {\n\tdirInfo, err := os.Stat(r.Config.Name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !dirInfo.IsDir() {\n\t\treturn fmt.Errorf(\"%q is not a directory\", r.Config.Name)\n\t}\n\n\t// FIXME: Why are we recursively walking directories?\n\t// FIXME: Why are we not reading the repositories.yaml to figure out\n\t// what repos to use?\n\tfilepath.Walk(r.Config.Name, func(path string, f os.FileInfo, err error) error {\n\t\tif !f.IsDir() {\n\t\t\tif strings.Contains(f.Name(), \"-index.yaml\") {\n\t\t\t\ti, err := LoadIndexFile(path)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tr.IndexFile = i\n\t\t\t} else if strings.HasSuffix(f.Name(), \".tgz\") {\n\t\t\t\tr.ChartPaths = append(r.ChartPaths, path)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\treturn nil\n}"}, {"instruction": "// NewEvaluatorSuite creates an EvaluatorSuite to evaluate all the exprs.\n// avoidColumnEvaluator can be removed after column pool is supported.", "input": "go language", "output": "func NewEvaluatorSuite(exprs []Expression, avoidColumnEvaluator bool) *EvaluatorSuite {\n\te := &EvaluatorSuite{}\n\n\tfor i := 0; i < len(exprs); i++ {\n\t\tif col, isCol := exprs[i].(*Column); isCol && !avoidColumnEvaluator {\n\t\t\tif e.columnEvaluator == nil {\n\t\t\t\te.columnEvaluator = &columnEvaluator{inputIdxToOutputIdxes: make(map[int][]int)}\n\t\t\t}\n\t\t\tinputIdx, outputIdx := col.Index, i\n\t\t\te.columnEvaluator.inputIdxToOutputIdxes[inputIdx] = append(e.columnEvaluator.inputIdxToOutputIdxes[inputIdx], outputIdx)\n\t\t\tcontinue\n\t\t}\n\t\tif e.defaultEvaluator == nil {\n\t\t\te.defaultEvaluator = &defaultEvaluator{\n\t\t\t\toutputIdxes: make([]int, 0, len(exprs)),\n\t\t\t\texprs:       make([]Expression, 0, len(exprs)),\n\t\t\t}\n\t\t}\n\t\te.defaultEvaluator.exprs = append(e.defaultEvaluator.exprs, exprs[i])\n\t\te.defaultEvaluator.outputIdxes = append(e.defaultEvaluator.outputIdxes, i)\n\t}\n\n\tif e.defaultEvaluator != nil {\n\t\te.defaultEvaluator.vectorizable = Vectorizable(e.defaultEvaluator.exprs)\n\t}\n\treturn e\n}"}, {"instruction": "// ServerGroups returns the supported groups, with information like supported\n// versions and the preferred version.", "input": "go language", "output": "func (c *FakeDiscovery) ServerGroups() (*metav1.APIGroupList, error) {\n\taction := testing.ActionImpl{\n\t\tVerb:     \"get\",\n\t\tResource: schema.GroupVersionResource{Resource: \"group\"},\n\t}\n\tc.Invokes(action, nil)\n\n\tgroups := map[string]*metav1.APIGroup{}\n\n\tfor _, res := range c.Resources {\n\t\tgv, err := schema.ParseGroupVersion(res.GroupVersion)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tgroup := groups[gv.Group]\n\t\tif group == nil {\n\t\t\tgroup = &metav1.APIGroup{\n\t\t\t\tName: gv.Group,\n\t\t\t\tPreferredVersion: metav1.GroupVersionForDiscovery{\n\t\t\t\t\tGroupVersion: res.GroupVersion,\n\t\t\t\t\tVersion:      gv.Version,\n\t\t\t\t},\n\t\t\t}\n\t\t\tgroups[gv.Group] = group\n\t\t}\n\n\t\tgroup.Versions = append(group.Versions, metav1.GroupVersionForDiscovery{\n\t\t\tGroupVersion: res.GroupVersion,\n\t\t\tVersion:      gv.Version,\n\t\t})\n\t}\n\n\tlist := &metav1.APIGroupList{}\n\tfor _, apiGroup := range groups {\n\t\tlist.Groups = append(list.Groups, *apiGroup)\n\t}\n\n\treturn list, nil\n\n}"}, {"instruction": "// priorityClassPermittedInNamespace returns true if we allow the given priority class name in the\n// given namespace. It currently checks that system priorities are created only in the system namespace.", "input": "go language", "output": "func priorityClassPermittedInNamespace(priorityClassName string, namespace string) bool {\n\t// Only allow system priorities in the system namespace. This is to prevent abuse or incorrect\n\t// usage of these priorities. Pods created at these priorities could preempt system critical\n\t// components.\n\tfor _, spc := range scheduling.SystemPriorityClasses() {\n\t\tif spc.Name == priorityClassName && namespace != metav1.NamespaceSystem {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of Pods that match those selectors.", "input": "go language", "output": "func (c *FakePods) List(opts v1.ListOptions) (result *corev1.PodList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(podsResource, podsKind, c.ns, opts), &corev1.PodList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &corev1.PodList{ListMeta: obj.(*corev1.PodList).ListMeta}\n\tfor _, item := range obj.(*corev1.PodList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// Intersect tries to return a pair of coordinates which are compatible with the\n// current set and a given set. We employ some special knowledge about network\n// segments to avoid doing a full intersection, since this is in several hot\n// paths. This might return nil for either coordinate in the output pair if an\n// intersection cannot be found. The ComputeDistance function above is designed\n// to deal with that.", "input": "go language", "output": "func (cs CoordinateSet) Intersect(other CoordinateSet) (*coordinate.Coordinate, *coordinate.Coordinate) {\n\t// Use the empty segment by default.\n\tsegment := \"\"\n\n\t// If we have a single segment, then let our segment take priority since\n\t// we are possibly a client. Any node with more than one segment can only\n\t// be a server, which means it should be in all segments.\n\tif len(cs) == 1 {\n\t\tfor s := range cs {\n\t\t\tsegment = s\n\t\t}\n\t}\n\n\t// Likewise for the other set.\n\tif len(other) == 1 {\n\t\tfor s := range other {\n\t\t\tsegment = s\n\t\t}\n\t}\n\n\treturn cs[segment], other[segment]\n}"}, {"instruction": "// LookupRuntimeHandler returns the RuntimeHandler string associated with the given RuntimeClass\n// name (or the default of \"\" for nil). If the RuntimeClass is not found, it returns an\n// errors.NotFound error.", "input": "go language", "output": "func (m *Manager) LookupRuntimeHandler(runtimeClassName *string) (string, error) {\n\tif runtimeClassName == nil || *runtimeClassName == \"\" {\n\t\t// The default RuntimeClass always resolves to the empty runtime handler.\n\t\treturn \"\", nil\n\t}\n\n\tname := *runtimeClassName\n\n\trc, err := m.lister.Get(name)\n\tif err != nil {\n\t\tif errors.IsNotFound(err) {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"Failed to lookup RuntimeClass %s: %v\", name, err)\n\t}\n\n\treturn rc.Handler, nil\n}"}, {"instruction": "// Resize perform resize of file system", "input": "go language", "output": "func (resizefs *ResizeFs) Resize(devicePath string, deviceMountPath string) (bool, error) {\n\tformat, err := resizefs.mounter.GetDiskFormat(devicePath)\n\n\tif err != nil {\n\t\tformatErr := fmt.Errorf(\"ResizeFS.Resize - error checking format for device %s: %v\", devicePath, err)\n\t\treturn false, formatErr\n\t}\n\n\t// If disk has no format, there is no need to resize the disk because mkfs.*\n\t// by default will use whole disk anyways.\n\tif format == \"\" {\n\t\treturn false, nil\n\t}\n\n\tklog.V(3).Infof(\"ResizeFS.Resize - Expanding mounted volume %s\", devicePath)\n\tswitch format {\n\tcase \"ext3\", \"ext4\":\n\t\treturn resizefs.extResize(devicePath)\n\tcase \"xfs\":\n\t\treturn resizefs.xfsResize(deviceMountPath)\n\t}\n\treturn false, fmt.Errorf(\"ResizeFS.Resize - resize of format %s is not supported for device %s mounted at %s\", format, devicePath, deviceMountPath)\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *IndexLookUpExecutor) Open(ctx context.Context) error {\n\tvar err error\n\tif e.corColInAccess {\n\t\te.ranges, err = rebuildIndexRanges(e.ctx, e.idxPlans[0].(*plannercore.PhysicalIndexScan), e.idxCols, e.colLens)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\te.kvRanges, err = distsql.IndexRangesToKVRanges(e.ctx.GetSessionVars().StmtCtx, getPhysicalTableID(e.table), e.index.ID, e.ranges, e.feedback)\n\tif err != nil {\n\t\te.feedback.Invalidate()\n\t\treturn err\n\t}\n\terr = e.open(ctx)\n\tif err != nil {\n\t\te.feedback.Invalidate()\n\t}\n\treturn err\n}"}, {"instruction": "// PreparedQueryList returns all the prepared queries.", "input": "go language", "output": "func (s *Store) PreparedQueryList(ws memdb.WatchSet) (uint64, structs.PreparedQueries, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, \"prepared-queries\")\n\n\t// Query all of the prepared queries in the state store.\n\tqueries, err := tx.Get(\"prepared-queries\", \"id\")\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed prepared query lookup: %s\", err)\n\t}\n\tws.Add(queries.WatchCh())\n\n\t// Go over all of the queries and build the response.\n\tvar result structs.PreparedQueries\n\tfor wrapped := queries.Next(); wrapped != nil; wrapped = queries.Next() {\n\t\tresult = append(result, toPreparedQuery(wrapped))\n\t}\n\treturn idx, result, nil\n}"}, {"instruction": "// handleResponse processes method call responses.", "input": "go language", "output": "func (h *handler) handleResponse(msg *jsonrpcMessage) {\n\top := h.respWait[string(msg.ID)]\n\tif op == nil {\n\t\th.log.Debug(\"Unsolicited RPC response\", \"reqid\", idForLog{msg.ID})\n\t\treturn\n\t}\n\tdelete(h.respWait, string(msg.ID))\n\t// For normal responses, just forward the reply to Call/BatchCall.\n\tif op.sub == nil {\n\t\top.resp <- msg\n\t\treturn\n\t}\n\t// For subscription responses, start the subscription if the server\n\t// indicates success. EthSubscribe gets unblocked in either case through\n\t// the op.resp channel.\n\tdefer close(op.resp)\n\tif msg.Error != nil {\n\t\top.err = msg.Error\n\t\treturn\n\t}\n\tif op.err = json.Unmarshal(msg.Result, &op.sub.subid); op.err == nil {\n\t\tgo op.sub.start()\n\t\th.clientSubs[op.sub.subid] = op.sub\n\t}\n}"}, {"instruction": "// importPreimages imports preimage data from the specified file.", "input": "go language", "output": "func importPreimages(ctx *cli.Context) error {\n\tif len(ctx.Args()) < 1 {\n\t\tutils.Fatalf(\"This command requires an argument.\")\n\t}\n\tstack := makeFullNode(ctx)\n\tdefer stack.Close()\n\n\tdb := utils.MakeChainDatabase(ctx, stack)\n\tstart := time.Now()\n\n\tif err := utils.ImportPreimages(db, ctx.Args().First()); err != nil {\n\t\tutils.Fatalf(\"Import error: %v\\n\", err)\n\t}\n\tfmt.Printf(\"Import done in %v\\n\", time.Since(start))\n\treturn nil\n}"}, {"instruction": "// MaybeFixUpResourceInstanceAddressForCount deals with the situation where a\n// resource has changed from having \"count\" set to not set, or vice-versa, and\n// so we need to rename the zeroth instance key to no key at all, or vice-versa.\n//\n// Set countEnabled to true if the resource has count set in its new\n// configuration, or false if it does not.\n//\n// The state is modified in-place if necessary, moving a resource instance\n// between the two addresses. The return value is true if a change was made,\n// and false otherwise.", "input": "go language", "output": "func (s *SyncState) MaybeFixUpResourceInstanceAddressForCount(addr addrs.AbsResource, countEnabled bool) bool {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\tms := s.state.Module(addr.Module)\n\tif ms == nil {\n\t\treturn false\n\t}\n\n\trelAddr := addr.Resource\n\trs := ms.Resource(relAddr)\n\tif rs == nil {\n\t\treturn false\n\t}\n\thuntKey := addrs.NoKey\n\treplaceKey := addrs.InstanceKey(addrs.IntKey(0))\n\tif !countEnabled {\n\t\thuntKey, replaceKey = replaceKey, huntKey\n\t}\n\n\tis, exists := rs.Instances[huntKey]\n\tif !exists {\n\t\treturn false\n\t}\n\n\tif _, exists := rs.Instances[replaceKey]; exists {\n\t\t// If the replacement key also exists then we'll do nothing and keep both.\n\t\treturn false\n\t}\n\n\t// If we get here then we need to \"rename\" from hunt to replace\n\trs.Instances[replaceKey] = is\n\tdelete(rs.Instances, huntKey)\n\treturn true\n}"}, {"instruction": "// DefaultConfigDir is the default config directory to use for the vaults and other\n// persistence requirements.", "input": "go language", "output": "func DefaultConfigDir() string {\n\t// Try to place the data folder in the user's home dir\n\thome := homeDir()\n\tif home != \"\" {\n\t\tif runtime.GOOS == \"darwin\" {\n\t\t\treturn filepath.Join(home, \"Library\", \"Signer\")\n\t\t} else if runtime.GOOS == \"windows\" {\n\t\t\tappdata := os.Getenv(\"APPDATA\")\n\t\t\tif appdata != \"\" {\n\t\t\t\treturn filepath.Join(appdata, \"Signer\")\n\t\t\t} else {\n\t\t\t\treturn filepath.Join(home, \"AppData\", \"Roaming\", \"Signer\")\n\t\t\t}\n\t\t} else {\n\t\t\treturn filepath.Join(home, \".clef\")\n\t\t}\n\t}\n\t// As we cannot guess a stable location, return empty and handle later\n\treturn \"\"\n}"}, {"instruction": "// sendSummary send the summary events for a single folder", "input": "go language", "output": "func (c *folderSummaryService) sendSummary(folder string) {\n\t// The folder summary contains how many bytes, files etc\n\t// are in the folder and how in sync we are.\n\tdata, err := c.Summary(folder)\n\tif err != nil {\n\t\treturn\n\t}\n\tevents.Default.Log(events.FolderSummary, map[string]interface{}{\n\t\t\"folder\":  folder,\n\t\t\"summary\": data,\n\t})\n\n\tfor _, devCfg := range c.cfg.Folders()[folder].Devices {\n\t\tif devCfg.DeviceID.Equals(c.id) {\n\t\t\t// We already know about ourselves.\n\t\t\tcontinue\n\t\t}\n\t\tif _, ok := c.model.Connection(devCfg.DeviceID); !ok {\n\t\t\t// We're not interested in disconnected devices.\n\t\t\tcontinue\n\t\t}\n\n\t\t// Get completion percentage of this folder for the\n\t\t// remote device.\n\t\tcomp := c.model.Completion(devCfg.DeviceID, folder).Map()\n\t\tcomp[\"folder\"] = folder\n\t\tcomp[\"device\"] = devCfg.DeviceID.String()\n\t\tevents.Default.Log(events.FolderCompletion, comp)\n\t}\n}"}, {"instruction": "// SamplePercentiles returns a slice of arbitrary percentiles of the slice of\n// int64.", "input": "go language", "output": "func SamplePercentiles(values int64Slice, ps []float64) []float64 {\n\tscores := make([]float64, len(ps))\n\tsize := len(values)\n\tif size > 0 {\n\t\tsort.Sort(values)\n\t\tfor i, p := range ps {\n\t\t\tpos := p * float64(size+1)\n\t\t\tif pos < 1.0 {\n\t\t\t\tscores[i] = float64(values[0])\n\t\t\t} else if pos >= float64(size) {\n\t\t\t\tscores[i] = float64(values[size-1])\n\t\t\t} else {\n\t\t\t\tlower := float64(values[int(pos)-1])\n\t\t\t\tupper := float64(values[int(pos)])\n\t\t\t\tscores[i] = lower + (pos-math.Floor(pos))*(upper-lower)\n\t\t\t}\n\t\t}\n\t}\n\treturn scores\n}"}, {"instruction": "// evalInt evals INSTR(str,substr), case insensitive\n// See https://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_instr", "input": "go language", "output": "func (b *builtinInstrSig) evalInt(row chunk.Row) (int64, bool, error) {\n\tstr, IsNull, err := b.args[0].EvalString(b.ctx, row)\n\tif IsNull || err != nil {\n\t\treturn 0, true, err\n\t}\n\tstr = strings.ToLower(str)\n\n\tsubstr, IsNull, err := b.args[1].EvalString(b.ctx, row)\n\tif IsNull || err != nil {\n\t\treturn 0, true, err\n\t}\n\tsubstr = strings.ToLower(substr)\n\n\tidx := strings.Index(str, substr)\n\tif idx == -1 {\n\t\treturn 0, false, nil\n\t}\n\treturn int64(utf8.RuneCountInString(str[:idx]) + 1), false, nil\n}"}, {"instruction": "// NewHTTPCodeRanges creates HTTPCodeRanges from a given []string.\n// Break out the http status code ranges into a low int and high int\n// for ease of use at runtime", "input": "go language", "output": "func NewHTTPCodeRanges(strBlocks []string) (HTTPCodeRanges, error) {\n\tvar blocks HTTPCodeRanges\n\tfor _, block := range strBlocks {\n\t\tcodes := strings.Split(block, \"-\")\n\t\t// if only a single HTTP code was configured, assume the best and create the correct configuration on the user's behalf\n\t\tif len(codes) == 1 {\n\t\t\tcodes = append(codes, codes[0])\n\t\t}\n\t\tlowCode, err := strconv.Atoi(codes[0])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\thighCode, err := strconv.Atoi(codes[1])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tblocks = append(blocks, [2]int{lowCode, highCode})\n\t}\n\treturn blocks, nil\n}"}, {"instruction": "// GetQuota - get the quota limits of a directory that was configured with SetQuota", "input": "go language", "output": "func (q *Control) GetQuota(targetPath string, quota *Quota) error {\n\n\tprojectID, ok := q.quotas[targetPath]\n\tif !ok {\n\t\treturn errors.Errorf(\"quota not found for path: %s\", targetPath)\n\t}\n\n\t//\n\t// get the quota limit for the container's project id\n\t//\n\tvar d C.fs_disk_quota_t\n\n\tvar cs = C.CString(q.backingFsBlockDev)\n\tdefer C.free(unsafe.Pointer(cs))\n\n\t_, _, errno := unix.Syscall6(unix.SYS_QUOTACTL, C.Q_XGETPQUOTA,\n\t\tuintptr(unsafe.Pointer(cs)), uintptr(C.__u32(projectID)),\n\t\tuintptr(unsafe.Pointer(&d)), 0, 0)\n\tif errno != 0 {\n\t\treturn errors.Wrapf(errno, \"Failed to get quota limit for projid %d on %s\",\n\t\t\tprojectID, q.backingFsBlockDev)\n\t}\n\tquota.Size = uint64(d.d_blk_hardlimit) * 512\n\n\treturn nil\n}"}, {"instruction": "// Coordinates queries for all nodes with coordinates.", "input": "go language", "output": "func (s *Store) Coordinates(ws memdb.WatchSet) (uint64, structs.Coordinates, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, \"coordinates\")\n\n\t// Pull all the coordinates.\n\titer, err := tx.Get(\"coordinates\", \"id\")\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed coordinate lookup: %s\", err)\n\t}\n\tws.Add(iter.WatchCh())\n\n\tvar results structs.Coordinates\n\tfor coord := iter.Next(); coord != nil; coord = iter.Next() {\n\t\tresults = append(results, coord.(*structs.Coordinate))\n\t}\n\treturn idx, results, nil\n}"}, {"instruction": "// ValidateContainerStateTransition test to if any illegal container state transitions are being attempted", "input": "go language", "output": "func ValidateContainerStateTransition(newStatuses, oldStatuses []core.ContainerStatus, fldpath *field.Path, restartPolicy core.RestartPolicy) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\t// If we should always restart, containers are allowed to leave the terminated state\n\tif restartPolicy == core.RestartPolicyAlways {\n\t\treturn allErrs\n\t}\n\tfor i, oldStatus := range oldStatuses {\n\t\t// Skip any container that is not terminated\n\t\tif oldStatus.State.Terminated == nil {\n\t\t\tcontinue\n\t\t}\n\t\t// Skip any container that failed but is allowed to restart\n\t\tif oldStatus.State.Terminated.ExitCode != 0 && restartPolicy == core.RestartPolicyOnFailure {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, newStatus := range newStatuses {\n\t\t\tif oldStatus.Name == newStatus.Name && newStatus.State.Terminated == nil {\n\t\t\t\tallErrs = append(allErrs, field.Forbidden(fldpath.Index(i).Child(\"state\"), \"may not be transitioned to non-terminated state\"))\n\t\t\t}\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// ConfigList returns the list of configs.", "input": "go language", "output": "func (cli *Client) ConfigList(ctx context.Context, options types.ConfigListOptions) ([]swarm.Config, error) {\n\tif err := cli.NewVersionError(\"1.30\", \"config list\"); err != nil {\n\t\treturn nil, err\n\t}\n\tquery := url.Values{}\n\n\tif options.Filters.Len() > 0 {\n\t\tfilterJSON, err := filters.ToJSON(options.Filters)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tquery.Set(\"filters\", filterJSON)\n\t}\n\n\tresp, err := cli.get(ctx, \"/configs\", query, nil)\n\tdefer ensureReaderClosed(resp)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar configs []swarm.Config\n\terr = json.NewDecoder(resp.body).Decode(&configs)\n\treturn configs, err\n}"}, {"instruction": "// RemoveString returns a newly created []string that contains all items from slice that\n// are not equal to s and modifier(s) in case modifier func is provided.", "input": "go language", "output": "func RemoveString(slice []string, s string, modifier func(s string) string) []string {\n\tnewSlice := make([]string, 0)\n\tfor _, item := range slice {\n\t\tif item == s {\n\t\t\tcontinue\n\t\t}\n\t\tif modifier != nil && modifier(item) == s {\n\t\t\tcontinue\n\t\t}\n\t\tnewSlice = append(newSlice, item)\n\t}\n\tif len(newSlice) == 0 {\n\t\t// Sanitize for unit tests so we don't need to distinguish empty array\n\t\t// and nil.\n\t\tnewSlice = nil\n\t}\n\treturn newSlice\n}"}, {"instruction": "// RunServer listens on the given port if listener is not given,\n// then spawns a go-routine continuously serving until the stopCh is closed.\n// It returns a stoppedCh that is closed when all non-hijacked active requests\n// have been processed.\n// This function does not block\n// TODO: make private when insecure serving is gone from the kube-apiserver", "input": "go language", "output": "func RunServer(\n\tserver *http.Server,\n\tln net.Listener,\n\tshutDownTimeout time.Duration,\n\tstopCh <-chan struct{},\n) (<-chan struct{}, error) {\n\tif ln == nil {\n\t\treturn nil, fmt.Errorf(\"listener must not be nil\")\n\t}\n\n\t// Shutdown server gracefully.\n\tstoppedCh := make(chan struct{})\n\tgo func() {\n\t\tdefer close(stoppedCh)\n\t\t<-stopCh\n\t\tctx, cancel := context.WithTimeout(context.Background(), shutDownTimeout)\n\t\tserver.Shutdown(ctx)\n\t\tcancel()\n\t}()\n\n\tgo func() {\n\t\tdefer utilruntime.HandleCrash()\n\n\t\tvar listener net.Listener\n\t\tlistener = tcpKeepAliveListener{ln.(*net.TCPListener)}\n\t\tif server.TLSConfig != nil {\n\t\t\tlistener = tls.NewListener(listener, server.TLSConfig)\n\t\t}\n\n\t\terr := server.Serve(listener)\n\n\t\tmsg := fmt.Sprintf(\"Stopped listening on %s\", ln.Addr().String())\n\t\tselect {\n\t\tcase <-stopCh:\n\t\t\tklog.Info(msg)\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"%s due to error: %v\", msg, err))\n\t\t}\n\t}()\n\n\treturn stoppedCh, nil\n}"}, {"instruction": "// LoadMetadata loads the chaincode metadata stored at the specified path", "input": "go language", "output": "func (s *Store) LoadMetadata(path string) (name, version string, err error) {\n\tmetadataBytes, err := s.ReadWriter.ReadFile(path)\n\tif err != nil {\n\t\terr = errors.Wrapf(err, \"error reading metadata at %s\", path)\n\t\treturn \"\", \"\", err\n\t}\n\tccMetadata := &ChaincodeMetadata{}\n\terr = json.Unmarshal(metadataBytes, ccMetadata)\n\tif err != nil {\n\t\terr = errors.Wrapf(err, \"error unmarshaling metadata at %s\", path)\n\t\treturn \"\", \"\", err\n\t}\n\n\treturn ccMetadata.Name, ccMetadata.Version, nil\n}"}, {"instruction": "// Delete the eligible dead container instances in a pod. Depending on the configuration, the latest dead containers may be kept around.", "input": "go language", "output": "func (kl *Kubelet) cleanUpContainersInPod(podID types.UID, exitedContainerID string) {\n\tif podStatus, err := kl.podCache.Get(podID); err == nil {\n\t\tremoveAll := false\n\t\tif syncedPod, ok := kl.podManager.GetPodByUID(podID); ok {\n\t\t\t// generate the api status using the cached runtime status to get up-to-date ContainerStatuses\n\t\t\tapiPodStatus := kl.generateAPIPodStatus(syncedPod, podStatus)\n\t\t\t// When an evicted or deleted pod has already synced, all containers can be removed.\n\t\t\tremoveAll = eviction.PodIsEvicted(syncedPod.Status) || (syncedPod.DeletionTimestamp != nil && notRunning(apiPodStatus.ContainerStatuses))\n\t\t}\n\t\tkl.containerDeletor.deleteContainersInPod(exitedContainerID, podStatus, removeAll)\n\t}\n}"}, {"instruction": "// CreateLocalEtcdStaticPodManifestFile will write local etcd static pod manifest file.\n// This function is used by init - when the etcd cluster is empty - or by kubeadm\n// upgrade - when the etcd cluster is already up and running (and the --initial-cluster flag have no impact)", "input": "go language", "output": "func CreateLocalEtcdStaticPodManifestFile(manifestDir string, nodeName string, cfg *kubeadmapi.ClusterConfiguration, endpoint *kubeadmapi.APIEndpoint) error {\n\tif cfg.Etcd.External != nil {\n\t\treturn errors.New(\"etcd static pod manifest cannot be generated for cluster using external etcd\")\n\t}\n\t// gets etcd StaticPodSpec\n\tspec := GetEtcdPodSpec(cfg, endpoint, nodeName, []etcdutil.Member{})\n\n\t// writes etcd StaticPod to disk\n\tif err := staticpodutil.WriteStaticPodToDisk(kubeadmconstants.Etcd, manifestDir, spec); err != nil {\n\t\treturn err\n\t}\n\n\tklog.V(1).Infof(\"[etcd] wrote Static Pod manifest for a local etcd member to %q\\n\", kubeadmconstants.GetStaticPodFilepath(kubeadmconstants.Etcd, manifestDir))\n\treturn nil\n}"}, {"instruction": "// monitorResizeEvents spawns a goroutine that periodically gets the terminal size and tries to send\n// it to the resizeEvents channel if the size has changed. The goroutine stops when the stop channel\n// is closed.", "input": "go language", "output": "func monitorResizeEvents(fd uintptr, resizeEvents chan<- remotecommand.TerminalSize, stop chan struct{}) {\n\tgo func() {\n\t\tdefer runtime.HandleCrash()\n\n\t\tsize := GetSize(fd)\n\t\tif size == nil {\n\t\t\treturn\n\t\t}\n\t\tlastSize := *size\n\n\t\tfor {\n\t\t\t// see if we need to stop running\n\t\t\tselect {\n\t\t\tcase <-stop:\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t}\n\n\t\t\tsize := GetSize(fd)\n\t\t\tif size == nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif size.Height != lastSize.Height || size.Width != lastSize.Width {\n\t\t\t\tlastSize.Height = size.Height\n\t\t\t\tlastSize.Width = size.Width\n\t\t\t\tresizeEvents <- *size\n\t\t\t}\n\n\t\t\t// sleep to avoid hot looping\n\t\t\ttime.Sleep(250 * time.Millisecond)\n\t\t}\n\t}()\n}"}, {"instruction": "// WARNING: If you're adding any return calls or defer any more work from this\n// function you have to make sure to update nodesInProcessing properly with the\n// disposition of the node when the work is done.", "input": "go language", "output": "func (r *rangeAllocator) AllocateOrOccupyCIDR(node *v1.Node) error {\n\tif node == nil {\n\t\treturn nil\n\t}\n\tif !r.insertNodeToProcessing(node.Name) {\n\t\tklog.V(2).Infof(\"Node %v is already in a process of CIDR assignment.\", node.Name)\n\t\treturn nil\n\t}\n\tif node.Spec.PodCIDR != \"\" {\n\t\treturn r.occupyCIDR(node)\n\t}\n\tpodCIDR, err := r.cidrs.AllocateNext()\n\tif err != nil {\n\t\tr.removeNodeFromProcessing(node.Name)\n\t\tnodeutil.RecordNodeStatusChange(r.recorder, node, \"CIDRNotAvailable\")\n\t\treturn fmt.Errorf(\"failed to allocate cidr: %v\", err)\n\t}\n\n\tklog.V(4).Infof(\"Putting node %s with CIDR %s into the work queue\", node.Name, podCIDR)\n\tr.nodeCIDRUpdateChannel <- nodeAndCIDR{\n\t\tnodeName: node.Name,\n\t\tcidr:     podCIDR,\n\t}\n\treturn nil\n}"}, {"instruction": "// getRelease uses `system_profiler SPSoftwareDataType` to get OSX kernel version", "input": "go language", "output": "func getRelease() (string, error) {\n\tcmd := exec.Command(\"system_profiler\", \"SPSoftwareDataType\")\n\tosName, err := cmd.Output()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tvar release string\n\tdata := strings.Split(string(osName), \"\\n\")\n\tfor _, line := range data {\n\t\tif strings.Contains(line, \"Kernel Version\") {\n\t\t\t// It has the format like '      Kernel Version: Darwin 14.5.0'\n\t\t\tcontent := strings.SplitN(line, \":\", 2)\n\t\t\tif len(content) != 2 {\n\t\t\t\treturn \"\", fmt.Errorf(\"Kernel Version is invalid\")\n\t\t\t}\n\n\t\t\tprettyNames, err := shellwords.Parse(content[1])\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", fmt.Errorf(\"Kernel Version is invalid: %s\", err.Error())\n\t\t\t}\n\n\t\t\tif len(prettyNames) != 2 {\n\t\t\t\treturn \"\", fmt.Errorf(\"Kernel Version needs to be 'Darwin x.x.x' \")\n\t\t\t}\n\t\t\trelease = prettyNames[1]\n\t\t}\n\t}\n\n\treturn release, nil\n}"}, {"instruction": "// newerObject checks the mutation cache for a newer object and returns one if found. If the\n// mutated object is older than the backing object, it is removed from the  Must be\n// called while the lock is held.", "input": "go language", "output": "func (c *mutationCache) newerObject(key string, backing runtime.Object) runtime.Object {\n\tmutatedObj, exists := c.mutationCache.Get(key)\n\tif !exists {\n\t\treturn backing\n\t}\n\tmutatedObjRuntime, ok := mutatedObj.(runtime.Object)\n\tif !ok {\n\t\treturn backing\n\t}\n\tif c.comparator.CompareResourceVersion(backing, mutatedObjRuntime) >= 0 {\n\t\tc.mutationCache.Remove(key)\n\t\treturn backing\n\t}\n\treturn mutatedObjRuntime\n}"}, {"instruction": "// MakeFileFunc constructs a function that takes a file path and returns the\n// contents of that file, either directly as a string (where valid UTF-8 is\n// required) or as a string containing base64 bytes.", "input": "go language", "output": "func MakeFileFunc(baseDir string, encBase64 bool) function.Function {\n\treturn function.New(&function.Spec{\n\t\tParams: []function.Parameter{\n\t\t\t{\n\t\t\t\tName: \"path\",\n\t\t\t\tType: cty.String,\n\t\t\t},\n\t\t},\n\t\tType: function.StaticReturnType(cty.String),\n\t\tImpl: func(args []cty.Value, retType cty.Type) (cty.Value, error) {\n\t\t\tpath := args[0].AsString()\n\t\t\tsrc, err := readFileBytes(baseDir, path)\n\t\t\tif err != nil {\n\t\t\t\treturn cty.UnknownVal(cty.String), err\n\t\t\t}\n\n\t\t\tswitch {\n\t\t\tcase encBase64:\n\t\t\t\tenc := base64.StdEncoding.EncodeToString(src)\n\t\t\t\treturn cty.StringVal(enc), nil\n\t\t\tdefault:\n\t\t\t\tif !utf8.Valid(src) {\n\t\t\t\t\treturn cty.UnknownVal(cty.String), fmt.Errorf(\"contents of %s are not valid UTF-8; use the filebase64 function to obtain the Base64 encoded contents or the other file functions (e.g. filemd5, filesha256) to obtain file hashing results instead\", path)\n\t\t\t\t}\n\t\t\t\treturn cty.StringVal(string(src)), nil\n\t\t\t}\n\t\t},\n\t})\n}"}, {"instruction": "// NewServer returns a new simulation API server", "input": "go language", "output": "func NewServer(network *Network) *Server {\n\ts := &Server{\n\t\trouter:  httprouter.New(),\n\t\tnetwork: network,\n\t}\n\n\ts.OPTIONS(\"/\", s.Options)\n\ts.GET(\"/\", s.GetNetwork)\n\ts.POST(\"/start\", s.StartNetwork)\n\ts.POST(\"/stop\", s.StopNetwork)\n\ts.POST(\"/mocker/start\", s.StartMocker)\n\ts.POST(\"/mocker/stop\", s.StopMocker)\n\ts.GET(\"/mocker\", s.GetMockers)\n\ts.POST(\"/reset\", s.ResetNetwork)\n\ts.GET(\"/events\", s.StreamNetworkEvents)\n\ts.GET(\"/snapshot\", s.CreateSnapshot)\n\ts.POST(\"/snapshot\", s.LoadSnapshot)\n\ts.POST(\"/nodes\", s.CreateNode)\n\ts.GET(\"/nodes\", s.GetNodes)\n\ts.GET(\"/nodes/:nodeid\", s.GetNode)\n\ts.POST(\"/nodes/:nodeid/start\", s.StartNode)\n\ts.POST(\"/nodes/:nodeid/stop\", s.StopNode)\n\ts.POST(\"/nodes/:nodeid/conn/:peerid\", s.ConnectNode)\n\ts.DELETE(\"/nodes/:nodeid/conn/:peerid\", s.DisconnectNode)\n\ts.GET(\"/nodes/:nodeid/rpc\", s.NodeRPC)\n\n\treturn s\n}"}, {"instruction": "// CompactRules combines rules that contain a single APIGroup/Resource, differ only by verb, and contain no other attributes.\n// this is a fast check, and works well with the decomposed \"missing rules\" list from a Covers check.", "input": "go language", "output": "func CompactRules(rules []rbacv1.PolicyRule) ([]rbacv1.PolicyRule, error) {\n\tcompacted := make([]rbacv1.PolicyRule, 0, len(rules))\n\n\tsimpleRules := map[simpleResource]*rbacv1.PolicyRule{}\n\tfor _, rule := range rules {\n\t\tif resource, isSimple := isSimpleResourceRule(&rule); isSimple {\n\t\t\tif existingRule, ok := simpleRules[resource]; ok {\n\t\t\t\t// Add the new verbs to the existing simple resource rule\n\t\t\t\tif existingRule.Verbs == nil {\n\t\t\t\t\texistingRule.Verbs = []string{}\n\t\t\t\t}\n\t\t\t\texistingRule.Verbs = append(existingRule.Verbs, rule.Verbs...)\n\t\t\t} else {\n\t\t\t\t// Copy the rule to accumulate matching simple resource rules into\n\t\t\t\tsimpleRules[resource] = rule.DeepCopy()\n\t\t\t}\n\t\t} else {\n\t\t\tcompacted = append(compacted, rule)\n\t\t}\n\t}\n\n\t// Once we've consolidated the simple resource rules, add them to the compacted list\n\tfor _, simpleRule := range simpleRules {\n\t\tcompacted = append(compacted, *simpleRule)\n\t}\n\n\treturn compacted, nil\n}"}, {"instruction": "// RunInContainer runs a command in a container, returns the combined stdout, stderr as an array of bytes", "input": "go language", "output": "func (kl *Kubelet) RunInContainer(podFullName string, podUID types.UID, containerName string, cmd []string) ([]byte, error) {\n\tcontainer, err := kl.findContainer(podFullName, podUID, containerName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif container == nil {\n\t\treturn nil, fmt.Errorf(\"container not found (%q)\", containerName)\n\t}\n\t// TODO(tallclair): Pass a proper timeout value.\n\treturn kl.runner.RunInContainer(container.ID, cmd, 0)\n}"}, {"instruction": "// NewSelectorSpreadPriority creates a SelectorSpread.", "input": "go language", "output": "func NewSelectorSpreadPriority(\n\tserviceLister algorithm.ServiceLister,\n\tcontrollerLister algorithm.ControllerLister,\n\treplicaSetLister algorithm.ReplicaSetLister,\n\tstatefulSetLister algorithm.StatefulSetLister) (PriorityMapFunction, PriorityReduceFunction) {\n\tselectorSpread := &SelectorSpread{\n\t\tserviceLister:     serviceLister,\n\t\tcontrollerLister:  controllerLister,\n\t\treplicaSetLister:  replicaSetLister,\n\t\tstatefulSetLister: statefulSetLister,\n\t}\n\treturn selectorSpread.CalculateSpreadPriorityMap, selectorSpread.CalculateSpreadPriorityReduce\n}"}, {"instruction": "// adaptSharedNamespaceContainer replaces container name with its ID in hostConfig.\n// To be more precisely, it modifies `container:name` to `container:ID` of PidMode, IpcMode\n// and NetworkMode.\n//\n// When a container shares its namespace with another container, use ID can keep the namespace\n// sharing connection between the two containers even the another container is renamed.", "input": "go language", "output": "func adaptSharedNamespaceContainer(daemon containerGetter, hostConfig *containertypes.HostConfig) {\n\tcontainerPrefix := \"container:\"\n\tif hostConfig.PidMode.IsContainer() {\n\t\tpidContainer := hostConfig.PidMode.Container()\n\t\t// if there is any error returned here, we just ignore it and leave it to be\n\t\t// handled in the following logic\n\t\tif c, err := daemon.GetContainer(pidContainer); err == nil {\n\t\t\thostConfig.PidMode = containertypes.PidMode(containerPrefix + c.ID)\n\t\t}\n\t}\n\tif hostConfig.IpcMode.IsContainer() {\n\t\tipcContainer := hostConfig.IpcMode.Container()\n\t\tif c, err := daemon.GetContainer(ipcContainer); err == nil {\n\t\t\thostConfig.IpcMode = containertypes.IpcMode(containerPrefix + c.ID)\n\t\t}\n\t}\n\tif hostConfig.NetworkMode.IsContainer() {\n\t\tnetContainer := hostConfig.NetworkMode.ConnectedContainer()\n\t\tif c, err := daemon.GetContainer(netContainer); err == nil {\n\t\t\thostConfig.NetworkMode = containertypes.NetworkMode(containerPrefix + c.ID)\n\t\t}\n\t}\n}"}, {"instruction": "// RecommendedDefaultVolumeConfiguration defaults a pointer to a VolumeConfiguration\n// struct. This will set the recommended default values, but they may be subject to\n// change between API versions. This function is intentionally not registered in the\n// scheme as a \"normal\" `SetDefaults_Foo` function to allow consumers of this type to\n// set whatever defaults for their embedded configs. Forcing consumers to use these\n// defaults would be problematic as defaulting in the scheme is done as part of the\n// conversion, and there would be no easy way to opt-out. Instead, if you want to use\n// this defaulting method run it in your wrapper struct of this type in its `SetDefaults_` method.", "input": "go language", "output": "func RecommendedDefaultVolumeConfiguration(obj *kubectrlmgrconfigv1alpha1.VolumeConfiguration) {\n\tif obj.EnableHostPathProvisioning == nil {\n\t\tobj.EnableHostPathProvisioning = utilpointer.BoolPtr(false)\n\t}\n\tif obj.EnableDynamicProvisioning == nil {\n\t\tobj.EnableDynamicProvisioning = utilpointer.BoolPtr(true)\n\t}\n\tif obj.FlexVolumePluginDir == \"\" {\n\t\tobj.FlexVolumePluginDir = \"/usr/libexec/kubernetes/kubelet-plugins/volume/exec/\"\n\t}\n\t// Use the default PersistentVolumeRecyclerConfiguration options.\n\tRecommendedDefaultPersistentVolumeRecyclerConfiguration(&obj.PersistentVolumeRecyclerConfiguration)\n}"}, {"instruction": "// CreateDisk creates a new Persistent Disk, with the specified name &\n// size, in the specified zone. It stores specified tags encoded in\n// JSON in Description field.", "input": "go language", "output": "func (g *Cloud) CreateDisk(\n\tname string, diskType string, zone string, sizeGb int64, tags map[string]string) error {\n\t// Do not allow creation of PDs in zones that are do not have nodes. Such PDs\n\t// are not currently usable.\n\tcurZones, err := g.GetAllCurrentZones()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !curZones.Has(zone) {\n\t\treturn fmt.Errorf(\"kubernetes does not have a node in zone %q\", zone)\n\t}\n\n\ttagsStr, err := g.encodeDiskTags(tags)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdiskType, err = getDiskType(diskType)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tmc := newDiskMetricContextZonal(\"create\", g.region, zone)\n\n\terr = g.manager.CreateDiskOnCloudProvider(\n\t\tname, sizeGb, tagsStr, diskType, zone)\n\n\tmc.Observe(err)\n\tif isGCEError(err, \"alreadyExists\") {\n\t\tklog.Warningf(\"GCE PD %q already exists, reusing\", name)\n\t\treturn nil\n\t}\n\treturn err\n}"}, {"instruction": "// NewCachingSecretManager creates a manager that keeps a cache of all secrets\n// necessary for registered pods.\n// It implements the following logic:\n// - whenever a pod is created or updated, the cached versions of all secrets\n//   are invalidated\n// - every GetObject() call tries to fetch the value from local cache; if it is\n//   not there, invalidated or too old, we fetch it from apiserver and refresh the\n//   value in cache; otherwise it is just fetched from cache", "input": "go language", "output": "func NewCachingSecretManager(kubeClient clientset.Interface, getTTL manager.GetObjectTTLFunc) Manager {\n\tgetSecret := func(namespace, name string, opts metav1.GetOptions) (runtime.Object, error) {\n\t\treturn kubeClient.CoreV1().Secrets(namespace).Get(name, opts)\n\t}\n\tsecretStore := manager.NewObjectStore(getSecret, clock.RealClock{}, getTTL, defaultTTL)\n\treturn &secretManager{\n\t\tmanager: manager.NewCacheBasedManager(secretStore, getSecretNames),\n\t}\n}"}, {"instruction": "// WaitInspectWithArgs waits for the specified expression to be equals to the specified expected string in the given time.\n// Deprecated: use cli.WaitCmd instead", "input": "go language", "output": "func WaitInspectWithArgs(dockerBinary, name, expr, expected string, timeout time.Duration, arg ...string) error {\n\tafter := time.After(timeout)\n\n\targs := append(arg, \"inspect\", \"-f\", expr, name)\n\tfor {\n\t\tresult := icmd.RunCommand(dockerBinary, args...)\n\t\tif result.Error != nil {\n\t\t\tif !strings.Contains(strings.ToLower(result.Stderr()), \"no such\") {\n\t\t\t\treturn errors.Errorf(\"error executing docker inspect: %v\\n%s\",\n\t\t\t\t\tresult.Stderr(), result.Stdout())\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-after:\n\t\t\t\treturn result.Error\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(10 * time.Millisecond)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tout := strings.TrimSpace(result.Stdout())\n\t\tif out == expected {\n\t\t\tbreak\n\t\t}\n\n\t\tselect {\n\t\tcase <-after:\n\t\t\treturn errors.Errorf(\"condition \\\"%q == %q\\\" not true in time (%v)\", out, expected, timeout)\n\t\tdefault:\n\t\t}\n\n\t\ttime.Sleep(100 * time.Millisecond)\n\t}\n\treturn nil\n}"}, {"instruction": "// GET /api/teams/:teamId/members", "input": "go language", "output": "func GetTeamMembers(c *m.ReqContext) Response {\n\tquery := m.GetTeamMembersQuery{OrgId: c.OrgId, TeamId: c.ParamsInt64(\":teamId\")}\n\n\tif err := bus.Dispatch(&query); err != nil {\n\t\treturn Error(500, \"Failed to get Team Members\", err)\n\t}\n\n\tfor _, member := range query.Result {\n\t\tmember.AvatarUrl = dtos.GetGravatarUrl(member.Email)\n\t\tmember.Labels = []string{}\n\n\t\tif setting.IsEnterprise && setting.LdapEnabled && member.External {\n\t\t\tmember.Labels = append(member.Labels, \"LDAP\")\n\t\t}\n\t}\n\n\treturn JSON(200, query.Result)\n}"}, {"instruction": "// Init callback representing the invocation of a chaincode\n// This chaincode will manage two accounts A and B and will transfer X units from A to B upon invoke", "input": "go language", "output": "func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response {\n\tvar err error\n\t_, args := stub.GetFunctionAndParameters()\n\tif len(args) != 4 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 4\")\n\t}\n\n\t// Initialize the chaincode\n\tA = args[0]\n\tAval, err = strconv.Atoi(args[1])\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for asset holding\")\n\t}\n\tB = args[2]\n\tBval, err = strconv.Atoi(args[3])\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for asset holding\")\n\t}\n\tfmt.Printf(\"Aval = %d, Bval = %d\\n\", Aval, Bval)\n\n\treturn shim.Success(nil)\n}"}, {"instruction": "// Get implements the Retriever interface.", "input": "go language", "output": "func (us *unionStore) Get(k Key) ([]byte, error) {\n\tv, err := us.MemBuffer.Get(k)\n\tif IsErrNotFound(err) {\n\t\tif _, ok := us.opts.Get(PresumeKeyNotExists); ok {\n\t\t\te, ok := us.opts.Get(PresumeKeyNotExistsError)\n\t\t\tif ok && e != nil {\n\t\t\t\tus.markLazyConditionPair(k, nil, e.(error))\n\t\t\t} else {\n\t\t\t\tus.markLazyConditionPair(k, nil, ErrKeyExists)\n\t\t\t}\n\t\t\treturn nil, ErrNotExist\n\t\t}\n\t}\n\tif IsErrNotFound(err) {\n\t\tv, err = us.BufferStore.r.Get(k)\n\t}\n\tif err != nil {\n\t\treturn v, err\n\t}\n\tif len(v) == 0 {\n\t\treturn nil, ErrNotExist\n\t}\n\treturn v, nil\n}"}, {"instruction": "// formatProgress formats the progress information for a specified action.", "input": "go language", "output": "func (sf *jsonProgressFormatter) formatProgress(id, action string, progress *jsonmessage.JSONProgress, aux interface{}) []byte {\n\tif progress == nil {\n\t\tprogress = &jsonmessage.JSONProgress{}\n\t}\n\tvar auxJSON *json.RawMessage\n\tif aux != nil {\n\t\tauxJSONBytes, err := json.Marshal(aux)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\tauxJSON = new(json.RawMessage)\n\t\t*auxJSON = auxJSONBytes\n\t}\n\tb, err := json.Marshal(&jsonmessage.JSONMessage{\n\t\tStatus:          action,\n\t\tProgressMessage: progress.String(),\n\t\tProgress:        progress,\n\t\tID:              id,\n\t\tAux:             auxJSON,\n\t})\n\tif err != nil {\n\t\treturn nil\n\t}\n\treturn appendNewline(b)\n}"}, {"instruction": "// ServeHTTP handles table related requests, such as table's region information, disk usage.", "input": "go language", "output": "func (h tableHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\t// parse params\n\tparams := mux.Vars(req)\n\tdbName := params[pDBName]\n\ttableName := params[pTableName]\n\tschema, err := h.schema()\n\tif err != nil {\n\t\twriteError(w, err)\n\t\treturn\n\t}\n\t// get table's schema.\n\ttableVal, err := schema.TableByName(model.NewCIStr(dbName), model.NewCIStr(tableName))\n\tif err != nil {\n\t\twriteError(w, err)\n\t\treturn\n\t}\n\n\tswitch h.op {\n\tcase opTableRegions:\n\t\th.handleRegionRequest(schema, tableVal, w, req)\n\tcase opTableDiskUsage:\n\t\th.handleDiskUsageRequest(schema, tableVal, w, req)\n\tcase opTableScatter:\n\t\th.handleScatterTableRequest(schema, tableVal, w, req)\n\tcase opStopTableScatter:\n\t\th.handleStopScatterTableRequest(schema, tableVal, w, req)\n\tdefault:\n\t\twriteError(w, errors.New(\"method not found\"))\n\t}\n}"}, {"instruction": "// Duration converts the given number to a time.Duration.\n// Unit is one of nanosecond/ns, microsecond/us/\u00b5s, millisecond/ms, second/s, minute/m or hour/h.", "input": "go language", "output": "func (ns *Namespace) Duration(unit interface{}, number interface{}) (_time.Duration, error) {\n\tunitStr, err := cast.ToStringE(unit)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tunitDuration, found := durationUnits[unitStr]\n\tif !found {\n\t\treturn 0, fmt.Errorf(\"%q is not a valid duration unit\", unit)\n\t}\n\tn, err := cast.ToInt64E(number)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn _time.Duration(n) * unitDuration, nil\n}"}, {"instruction": "// Run is the long-running method that handles state syncing. It should be run\n// in it's own goroutine and will continue until a fatal error is hit or Close\n// is called. Run will return an error if it is called more than once, or called\n// after Close.", "input": "go language", "output": "func (m *Manager) Run() error {\n\tm.mu.Lock()\n\talreadyStarted := m.started\n\tm.started = true\n\tstateCh := m.stateCh\n\tm.mu.Unlock()\n\n\t// Protect against multiple Run calls.\n\tif alreadyStarted {\n\t\treturn ErrStarted\n\t}\n\n\t// Protect against being run after Close.\n\tif stateCh == nil {\n\t\treturn ErrStopped\n\t}\n\n\t// Register for notifications about state changes\n\tm.State.Notify(stateCh)\n\tdefer m.State.StopNotify(stateCh)\n\n\tfor {\n\t\tm.syncState()\n\n\t\t// Wait for a state change\n\t\t_, ok := <-stateCh\n\t\tif !ok {\n\t\t\t// Stopped\n\t\t\treturn nil\n\t\t}\n\t}\n}"}, {"instruction": "// NodeSelectorRequirementsAsSelector converts the []NodeSelectorRequirement core type into a struct that implements\n// labels.Selector.", "input": "go language", "output": "func NodeSelectorRequirementsAsSelector(nsm []core.NodeSelectorRequirement) (labels.Selector, error) {\n\tif len(nsm) == 0 {\n\t\treturn labels.Nothing(), nil\n\t}\n\tselector := labels.NewSelector()\n\tfor _, expr := range nsm {\n\t\tvar op selection.Operator\n\t\tswitch expr.Operator {\n\t\tcase core.NodeSelectorOpIn:\n\t\t\top = selection.In\n\t\tcase core.NodeSelectorOpNotIn:\n\t\t\top = selection.NotIn\n\t\tcase core.NodeSelectorOpExists:\n\t\t\top = selection.Exists\n\t\tcase core.NodeSelectorOpDoesNotExist:\n\t\t\top = selection.DoesNotExist\n\t\tcase core.NodeSelectorOpGt:\n\t\t\top = selection.GreaterThan\n\t\tcase core.NodeSelectorOpLt:\n\t\t\top = selection.LessThan\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"%q is not a valid node selector operator\", expr.Operator)\n\t\t}\n\t\tr, err := labels.NewRequirement(expr.Key, op, expr.Values)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tselector = selector.Add(*r)\n\t}\n\treturn selector, nil\n}"}, {"instruction": "// GetSortedMapValues returns a sorted map previously filled with SetInMap.", "input": "go language", "output": "func (c *Scratch) GetSortedMapValues(key string) interface{} {\n\tc.mu.RLock()\n\n\tif c.values[key] == nil {\n\t\tc.mu.RUnlock()\n\t\treturn nil\n\t}\n\n\tunsortedMap := c.values[key].(map[string]interface{})\n\tc.mu.RUnlock()\n\tvar keys []string\n\tfor mapKey := range unsortedMap {\n\t\tkeys = append(keys, mapKey)\n\t}\n\n\tsort.Strings(keys)\n\n\tsortedArray := make([]interface{}, len(unsortedMap))\n\tfor i, mapKey := range keys {\n\t\tsortedArray[i] = unsortedMap[mapKey]\n\t}\n\n\treturn sortedArray\n}"}, {"instruction": "// ToPB implements PhysicalPlan ToPB interface.", "input": "go language", "output": "func (p *PhysicalIndexScan) ToPB(ctx sessionctx.Context) (*tipb.Executor, error) {\n\tcolumns := make([]*model.ColumnInfo, 0, p.schema.Len())\n\ttableColumns := p.Table.Cols()\n\tfor _, col := range p.schema.Columns {\n\t\tif col.ID == model.ExtraHandleID {\n\t\t\tcolumns = append(columns, model.NewExtraHandleColInfo())\n\t\t} else {\n\t\t\tcolumns = append(columns, model.FindColumnInfo(tableColumns, col.ColName.L))\n\t\t}\n\t}\n\tidxExec := &tipb.IndexScan{\n\t\tTableId: p.Table.ID,\n\t\tIndexId: p.Index.ID,\n\t\tColumns: model.ColumnsToProto(columns, p.Table.PKIsHandle),\n\t\tDesc:    p.Desc,\n\t}\n\tunique := checkCoverIndex(p.Index, p.Ranges)\n\tidxExec.Unique = &unique\n\treturn &tipb.Executor{Tp: tipb.ExecType_TypeIndexScan, IdxScan: idxExec}, nil\n}"}, {"instruction": "// Pack the given method name to conform the ABI. Method call's data\n// will consist of method_id, args0, arg1, ... argN. Method id consists\n// of 4 bytes and arguments are all 32 bytes.\n// Method ids are created from the first 4 bytes of the hash of the\n// methods string signature. (signature = baz(uint32,string32))", "input": "go language", "output": "func (abi ABI) Pack(name string, args ...interface{}) ([]byte, error) {\n\t// Fetch the ABI of the requested method\n\tif name == \"\" {\n\t\t// constructor\n\t\targuments, err := abi.Constructor.Inputs.Pack(args...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn arguments, nil\n\t}\n\tmethod, exist := abi.Methods[name]\n\tif !exist {\n\t\treturn nil, fmt.Errorf(\"method '%s' not found\", name)\n\t}\n\targuments, err := method.Inputs.Pack(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Pack up the method ID too if not a constructor and return\n\treturn append(method.Id(), arguments...), nil\n}"}, {"instruction": "// DeleteVolumes removes the ScaleIO volume", "input": "go language", "output": "func (m *sioMgr) DeleteVolume(volName string) error {\n\tclient, err := m.getClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvol, err := client.FindVolume(volName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := client.DeleteVolume(sioVolumeID(vol.ID)); err != nil {\n\t\tklog.Error(log(\"failed to delete volume %s: %v\", volName, err))\n\t\treturn err\n\t}\n\n\tklog.V(4).Info(log(\"deleted volume %s successfully\", volName))\n\treturn nil\n\n}"}, {"instruction": "// NewController constructs a new Controller object and returns it. The dynamicConfigDir\n// path must be absolute. transform applies an arbitrary transformation to config after loading, and before validation.\n// This can be used, for example, to include config from flags before the controller's validation step.\n// If transform returns an error, loadConfig will fail, and an InternalError will be reported.\n// Be wary if using this function as an extension point, in most cases the controller should\n// probably just be natively extended to do what you need. Injecting flag precedence transformations\n// is something of an exception because the caller of this controller (cmd/) is aware of flags, but this\n// controller's tree (pkg/) is not.", "input": "go language", "output": "func NewController(dynamicConfigDir string, transform TransformFunc) *Controller {\n\treturn &Controller{\n\t\ttransform: transform,\n\t\t// channels must have capacity at least 1, since we signal with non-blocking writes\n\t\tpendingConfigSource: make(chan bool, 1),\n\t\tconfigStatus:        status.NewNodeConfigStatus(),\n\t\tcheckpointStore:     store.NewFsStore(utilfs.DefaultFs{}, filepath.Join(dynamicConfigDir, storeDir)),\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *HorizontalPodAutoscalerStatus) DeepCopyInto(out *HorizontalPodAutoscalerStatus) {\n\t*out = *in\n\tif in.ObservedGeneration != nil {\n\t\tin, out := &in.ObservedGeneration, &out.ObservedGeneration\n\t\t*out = new(int64)\n\t\t**out = **in\n\t}\n\tif in.LastScaleTime != nil {\n\t\tin, out := &in.LastScaleTime, &out.LastScaleTime\n\t\t*out = (*in).DeepCopy()\n\t}\n\tif in.CurrentMetrics != nil {\n\t\tin, out := &in.CurrentMetrics, &out.CurrentMetrics\n\t\t*out = make([]MetricStatus, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.Conditions != nil {\n\t\tin, out := &in.Conditions, &out.Conditions\n\t\t*out = make([]HorizontalPodAutoscalerCondition, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// numericContextResultType returns types.EvalType for numeric function's parameters.\n// the returned types.EvalType should be one of: types.ETInt, types.ETDecimal, types.ETReal", "input": "go language", "output": "func numericContextResultType(ft *types.FieldType) types.EvalType {\n\tif types.IsTypeTemporal(ft.Tp) {\n\t\tif ft.Decimal > 0 {\n\t\t\treturn types.ETDecimal\n\t\t}\n\t\treturn types.ETInt\n\t}\n\tif types.IsBinaryStr(ft) {\n\t\treturn types.ETInt\n\t}\n\tevalTp4Ft := types.ETReal\n\tif !ft.Hybrid() {\n\t\tevalTp4Ft = ft.EvalType()\n\t\tif evalTp4Ft != types.ETDecimal && evalTp4Ft != types.ETInt {\n\t\t\tevalTp4Ft = types.ETReal\n\t\t}\n\t}\n\treturn evalTp4Ft\n}"}, {"instruction": "// ReadAtMost reads at most max bytes from the end of the file identified by path or\n// returns an error. It returns true if the file was longer than max. It will\n// allocate up to max bytes.", "input": "go language", "output": "func ReadAtMost(path string, max int64) ([]byte, bool, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tdefer f.Close()\n\tfi, err := f.Stat()\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tsize := fi.Size()\n\tif size == 0 {\n\t\treturn nil, false, nil\n\t}\n\tif size < max {\n\t\tmax = size\n\t}\n\toffset, err := f.Seek(-max, io.SeekEnd)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tdata, err := ioutil.ReadAll(f)\n\treturn data, offset > 0, err\n}"}, {"instruction": "// expireNodes iterates over the database and deletes all nodes that have not\n// been seen (i.e. received a pong from) for some allotted time.", "input": "go language", "output": "func (db *nodeDB) expireNodes() error {\n\tthreshold := time.Now().Add(-nodeDBNodeExpiration)\n\n\t// Find discovered nodes that are older than the allowance\n\tit := db.lvl.NewIterator(nil, nil)\n\tdefer it.Release()\n\n\tfor it.Next() {\n\t\t// Skip the item if not a discovery node\n\t\tid, field := splitKey(it.Key())\n\t\tif field != nodeDBDiscoverRoot {\n\t\t\tcontinue\n\t\t}\n\t\t// Skip the node if not expired yet (and not self)\n\t\tif !bytes.Equal(id[:], db.self[:]) {\n\t\t\tif seen := db.lastPong(id); seen.After(threshold) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// Otherwise delete all associated information\n\t\tdb.deleteNode(id)\n\t}\n\treturn nil\n}"}, {"instruction": "// RunAPIVersions does the work", "input": "go language", "output": "func (o *APIVersionsOptions) RunAPIVersions() error {\n\t// Always request fresh data from the server\n\to.discoveryClient.Invalidate()\n\n\tgroupList, err := o.discoveryClient.ServerGroups()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"couldn't get available api versions from server: %v\", err)\n\t}\n\tapiVersions := metav1.ExtractGroupVersions(groupList)\n\tsort.Strings(apiVersions)\n\tfor _, v := range apiVersions {\n\t\tfmt.Fprintln(o.Out, v)\n\t}\n\treturn nil\n}"}, {"instruction": "// autoDeposit starts a goroutine that periodically sends funds to the chequebook\n// contract caller holds the lock the go routine terminates if Chequebook.quit is closed.", "input": "go language", "output": "func (cb *Chequebook) autoDeposit(interval time.Duration) {\n\tif cb.quit != nil {\n\t\tclose(cb.quit)\n\t\tcb.quit = nil\n\t}\n\t// if threshold >= balance autodeposit after every cheque issued\n\tif interval == time.Duration(0) || cb.threshold != nil && cb.buffer != nil && cb.threshold.Cmp(cb.buffer) >= 0 {\n\t\treturn\n\t}\n\n\tticker := time.NewTicker(interval)\n\tcb.quit = make(chan bool)\n\tquit := cb.quit\n\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-quit:\n\t\t\t\treturn\n\t\t\tcase <-ticker.C:\n\t\t\t\tcb.lock.Lock()\n\t\t\t\tif cb.balance.Cmp(cb.buffer) < 0 {\n\t\t\t\t\tamount := new(big.Int).Sub(cb.buffer, cb.balance)\n\t\t\t\t\ttxhash, err := cb.deposit(amount)\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\tcb.txhash = txhash\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcb.lock.Unlock()\n\t\t\t}\n\t\t}\n\t}()\n}"}, {"instruction": "// convertToRuntimeSecurityContext converts v1.SecurityContext to runtimeapi.SecurityContext.", "input": "go language", "output": "func convertToRuntimeSecurityContext(securityContext *v1.SecurityContext) *runtimeapi.LinuxContainerSecurityContext {\n\tif securityContext == nil {\n\t\treturn nil\n\t}\n\n\tsc := &runtimeapi.LinuxContainerSecurityContext{\n\t\tCapabilities:   convertToRuntimeCapabilities(securityContext.Capabilities),\n\t\tSelinuxOptions: convertToRuntimeSELinuxOption(securityContext.SELinuxOptions),\n\t}\n\tif securityContext.RunAsUser != nil {\n\t\tsc.RunAsUser = &runtimeapi.Int64Value{Value: int64(*securityContext.RunAsUser)}\n\t}\n\tif securityContext.RunAsGroup != nil {\n\t\tsc.RunAsGroup = &runtimeapi.Int64Value{Value: int64(*securityContext.RunAsGroup)}\n\t}\n\tif securityContext.Privileged != nil {\n\t\tsc.Privileged = *securityContext.Privileged\n\t}\n\tif securityContext.ReadOnlyRootFilesystem != nil {\n\t\tsc.ReadonlyRootfs = *securityContext.ReadOnlyRootFilesystem\n\t}\n\n\treturn sc\n}"}, {"instruction": "// handleDivisionByZeroError reports error or warning depend on the context.", "input": "go language", "output": "func handleDivisionByZeroError(ctx sessionctx.Context) error {\n\tsc := ctx.GetSessionVars().StmtCtx\n\tif sc.InInsertStmt || sc.InUpdateStmt || sc.InDeleteStmt {\n\t\tif !ctx.GetSessionVars().SQLMode.HasErrorForDivisionByZeroMode() {\n\t\t\treturn nil\n\t\t}\n\t\tif ctx.GetSessionVars().StrictSQLMode && !sc.DividedByZeroAsWarning {\n\t\t\treturn ErrDivisionByZero\n\t\t}\n\t}\n\tsc.AppendWarning(ErrDivisionByZero)\n\treturn nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *NetworkPolicyEgressRule) DeepCopyInto(out *NetworkPolicyEgressRule) {\n\t*out = *in\n\tif in.Ports != nil {\n\t\tin, out := &in.Ports, &out.Ports\n\t\t*out = make([]NetworkPolicyPort, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.To != nil {\n\t\tin, out := &in.To, &out.To\n\t\t*out = make([]NetworkPolicyPeer, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// DefaultServiceIPRange takes a the serviceIPRange flag and returns the defaulted service ip range (if  needed),\n// api server service IP, and an error", "input": "go language", "output": "func DefaultServiceIPRange(passedServiceClusterIPRange net.IPNet) (net.IPNet, net.IP, error) {\n\tserviceClusterIPRange := passedServiceClusterIPRange\n\tif passedServiceClusterIPRange.IP == nil {\n\t\tklog.Infof(\"Network range for service cluster IPs is unspecified. Defaulting to %v.\", kubeoptions.DefaultServiceIPCIDR)\n\t\tserviceClusterIPRange = kubeoptions.DefaultServiceIPCIDR\n\t}\n\tif size := ipallocator.RangeSize(&serviceClusterIPRange); size < 8 {\n\t\treturn net.IPNet{}, net.IP{}, fmt.Errorf(\"The service cluster IP range must be at least %d IP addresses\", 8)\n\t}\n\n\t// Select the first valid IP from ServiceClusterIPRange to use as the GenericAPIServer service IP.\n\tapiServerServiceIP, err := ipallocator.GetIndexedIP(&serviceClusterIPRange, 1)\n\tif err != nil {\n\t\treturn net.IPNet{}, net.IP{}, err\n\t}\n\tklog.V(4).Infof(\"Setting service IP to %q (read-write).\", apiServerServiceIP)\n\n\treturn serviceClusterIPRange, apiServerServiceIP, nil\n}"}, {"instruction": "// Connect returns a handler for the pod exec proxy", "input": "go language", "output": "func (r *AttachREST) Connect(ctx context.Context, name string, opts runtime.Object, responder rest.Responder) (http.Handler, error) {\n\tattachOpts, ok := opts.(*api.PodAttachOptions)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"Invalid options object: %#v\", opts)\n\t}\n\tlocation, transport, err := pod.AttachLocation(r.Store, r.KubeletConn, ctx, name, attachOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newThrottledUpgradeAwareProxyHandler(location, transport, false, true, true, responder), nil\n}"}, {"instruction": "// Clone is used to return a new token cloned from an existing one\n//\n// Deprecated: Use TokenClone instead.", "input": "go language", "output": "func (a *ACL) Clone(id string, q *WriteOptions) (string, *WriteMeta, error) {\n\tr := a.c.newRequest(\"PUT\", \"/v1/acl/clone/\"+id)\n\tr.setWriteOptions(q)\n\trtt, resp, err := requireOK(a.c.doRequest(r))\n\tif err != nil {\n\t\treturn \"\", nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\twm := &WriteMeta{RequestTime: rtt}\n\tvar out struct{ ID string }\n\tif err := decodeBody(resp, &out); err != nil {\n\t\treturn \"\", nil, err\n\t}\n\treturn out.ID, wm, nil\n}"}, {"instruction": "// Tasks provides a mock function with given fields: application", "input": "go language", "output": "func (_m *Marathon) Tasks(application string) (*marathon.Tasks, error) {\n\tret := _m.Called(application)\n\n\tvar r0 *marathon.Tasks\n\tif rf, ok := ret.Get(0).(func(string) *marathon.Tasks); ok {\n\t\tr0 = rf(application)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*marathon.Tasks)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(string) error); ok {\n\t\tr1 = rf(application)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// Extract extracts compressed archives\n//\n// Implements Extractor.", "input": "go language", "output": "func (g *TarGzExtractor) Extract(buffer *bytes.Buffer, targetDir string) error {\n\tuncompressedStream, err := gzip.NewReader(buffer)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttarReader := tar.NewReader(uncompressedStream)\n\n\tos.MkdirAll(targetDir, 0755)\n\n\tfor true {\n\t\theader, err := tarReader.Next()\n\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpath, err := fp.SecureJoin(targetDir, header.Name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tswitch header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif err := os.Mkdir(path, 0755); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase tar.TypeReg:\n\t\t\toutFile, err := os.Create(path)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif _, err := io.Copy(outFile, tarReader); err != nil {\n\t\t\t\toutFile.Close()\n\t\t\t\treturn err\n\t\t\t}\n\t\t\toutFile.Close()\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"unknown type: %b in %s\", header.Typeflag, header.Name)\n\t\t}\n\t}\n\n\treturn nil\n\n}"}, {"instruction": "// deposit deposits amount to the chequebook account.\n// The caller must hold lock.", "input": "go language", "output": "func (cb *Chequebook) deposit(amount *big.Int) (string, error) {\n\t// since the amount is variable here, we do not use sessions\n\tdepositTransactor := bind.NewKeyedTransactor(cb.prvKey)\n\tdepositTransactor.Value = amount\n\tchbookRaw := &contract.ChequebookRaw{Contract: cb.contract}\n\ttx, err := chbookRaw.Transfer(depositTransactor)\n\tif err != nil {\n\t\tcb.log.Warn(\"Failed to fund chequebook\", \"amount\", amount, \"balance\", cb.balance, \"target\", cb.buffer, \"err\", err)\n\t\treturn \"\", err\n\t}\n\t// assume that transaction is actually successful, we add the amount to balance right away\n\tcb.balance.Add(cb.balance, amount)\n\tcb.log.Trace(\"Deposited funds to chequebook\", \"amount\", amount, \"balance\", cb.balance, \"target\", cb.buffer)\n\treturn tx.Hash().Hex(), nil\n}"}, {"instruction": "// Register registers a plugin", "input": "go language", "output": "func Register(plugins *admission.Plugins) {\n\tplugins.Register(PluginName, func(config io.Reader) (admission.Interface, error) {\n\t\t// the pods/status endpoint is ignored by this plugin since old kubelets\n\t\t// corrupt them.  the pod status strategy ensures status updates cannot mutate\n\t\t// ownerRef.\n\t\twhiteList := []whiteListItem{\n\t\t\t{\n\t\t\t\tgroupResource: schema.GroupResource{Resource: \"pods\"},\n\t\t\t\tsubresource:   \"status\",\n\t\t\t},\n\t\t}\n\t\treturn &gcPermissionsEnforcement{\n\t\t\tHandler:   admission.NewHandler(admission.Create, admission.Update),\n\t\t\twhiteList: whiteList,\n\t\t}, nil\n\t})\n}"}, {"instruction": "// Due to the way cgo works this has to be in a separate file, as devmapper.go has\n// definitions in the cgo block, which is incompatible with using \"//export\"\n// DevmapperLogCallback exports the devmapper log callback for cgo. Note that\n// because we are using callbacks, this function will be called for *every* log\n// in libdm (even debug ones because there's no way of setting the verbosity\n// level for an external logging callback).\n//export DevmapperLogCallback", "input": "go language", "output": "func DevmapperLogCallback(level C.int, file *C.char, line, dmErrnoOrClass C.int, message *C.char) {\n\tmsg := C.GoString(message)\n\n\t// Track what errno libdm saw, because the library only gives us 0 or 1.\n\tif level < LogLevelDebug {\n\t\tif strings.Contains(msg, \"busy\") {\n\t\t\tdmSawBusy = true\n\t\t}\n\n\t\tif strings.Contains(msg, \"File exists\") {\n\t\t\tdmSawExist = true\n\t\t}\n\n\t\tif strings.Contains(msg, \"No such device or address\") {\n\t\t\tdmSawEnxio = true\n\t\t}\n\t\tif strings.Contains(msg, \"No data available\") {\n\t\t\tdmSawEnoData = true\n\t\t}\n\t}\n\n\tif dmLogger != nil {\n\t\tdmLogger.DMLog(int(level), C.GoString(file), int(line), int(dmErrnoOrClass), msg)\n\t}\n}"}, {"instruction": "// ConfigCreate applies the given config entry update.", "input": "go language", "output": "func (s *HTTPServer) ConfigApply(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\targs := structs.ConfigEntryRequest{\n\t\tOp: structs.ConfigEntryUpsert,\n\t}\n\ts.parseDC(req, &args.Datacenter)\n\ts.parseToken(req, &args.Token)\n\n\tvar raw map[string]interface{}\n\tif err := decodeBody(req, &raw, nil); err != nil {\n\t\treturn nil, BadRequestError{Reason: fmt.Sprintf(\"Request decoding failed: %v\", err)}\n\t}\n\n\tif entry, err := structs.DecodeConfigEntry(raw); err == nil {\n\t\targs.Entry = entry\n\t} else {\n\t\treturn nil, BadRequestError{Reason: fmt.Sprintf(\"Request decoding failed: %v\", err)}\n\t}\n\n\t// Check for cas value\n\tif casStr := req.URL.Query().Get(\"cas\"); casStr != \"\" {\n\t\tcasVal, err := strconv.ParseUint(casStr, 10, 64)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\targs.Op = structs.ConfigEntryUpsertCAS\n\t\targs.Entry.GetRaftIndex().ModifyIndex = casVal\n\t}\n\n\tvar reply bool\n\tif err := s.agent.RPC(\"ConfigEntry.Apply\", &args, &reply); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn reply, nil\n}"}, {"instruction": "// getCgroupConfig returns a ResourceConfig object that can be used to create or update cgroups via CgroupManager interface.", "input": "go language", "output": "func getCgroupConfig(rl v1.ResourceList) *ResourceConfig {\n\t// TODO(vishh): Set CPU Quota if necessary.\n\tif rl == nil {\n\t\treturn nil\n\t}\n\tvar rc ResourceConfig\n\tif q, exists := rl[v1.ResourceMemory]; exists {\n\t\t// Memory is defined in bytes.\n\t\tval := q.Value()\n\t\trc.Memory = &val\n\t}\n\tif q, exists := rl[v1.ResourceCPU]; exists {\n\t\t// CPU is defined in milli-cores.\n\t\tval := MilliCPUToShares(q.MilliValue())\n\t\trc.CpuShares = &val\n\t}\n\tif q, exists := rl[pidlimit.PIDs]; exists {\n\t\tval := q.Value()\n\t\trc.PidsLimit = &val\n\t}\n\trc.HugePageLimit = HugePageLimits(rl)\n\n\treturn &rc\n}"}, {"instruction": "// initTableIndices initializes the indices of the tableCommon.", "input": "go language", "output": "func initTableIndices(t *tableCommon) error {\n\ttblInfo := t.meta\n\tfor _, idxInfo := range tblInfo.Indices {\n\t\tif idxInfo.State == model.StateNone {\n\t\t\treturn table.ErrIndexStateCantNone.GenWithStack(\"index %s can't be in none state\", idxInfo.Name)\n\t\t}\n\n\t\t// Use partition ID for index, because tableCommon may be table or partition.\n\t\tidx := NewIndex(t.physicalTableID, tblInfo, idxInfo)\n\t\tt.indices = append(t.indices, idx)\n\t}\n\treturn nil\n}"}, {"instruction": "// newResponseRecorder returns an initialized responseRecorder.", "input": "go language", "output": "func newResponseRecorder(rw http.ResponseWriter, logger logrus.FieldLogger) responseRecorder {\n\trecorder := &responseRecorderWithoutCloseNotify{\n\t\tHeaderMap:      make(http.Header),\n\t\tBody:           new(bytes.Buffer),\n\t\tCode:           http.StatusOK,\n\t\tresponseWriter: rw,\n\t\tlogger:         logger,\n\t}\n\tif _, ok := rw.(http.CloseNotifier); ok {\n\t\treturn &responseRecorderWithCloseNotify{recorder}\n\t}\n\treturn recorder\n}"}, {"instruction": "// ParseResponse parses the given response about the given channel", "input": "go language", "output": "func (parser *PeerResponseParser) ParseResponse(channel string, res ServiceResponse) error {\n\tvar listPeers peerLister\n\tif channel == \"\" {\n\t\tlistPeers = res.ForLocal()\n\t} else {\n\t\tlistPeers = &simpleChannelResponse{res.ForChannel(channel)}\n\t}\n\tpeers, err := listPeers.Peers()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tchannelState := channel != \"\"\n\tb, _ := json.MarshalIndent(assemblePeers(peers, channelState), \"\", \"\\t\")\n\tfmt.Fprintln(parser.Writer, string(b))\n\treturn nil\n}"}, {"instruction": "// Login is used to exchange auth method credentials for a newly-minted Consul Token.", "input": "go language", "output": "func (a *ACL) Login(auth *ACLLoginParams, q *WriteOptions) (*ACLToken, *WriteMeta, error) {\n\tr := a.c.newRequest(\"POST\", \"/v1/acl/login\")\n\tr.setWriteOptions(q)\n\tr.obj = auth\n\n\trtt, resp, err := requireOK(a.c.doRequest(r))\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\twm := &WriteMeta{RequestTime: rtt}\n\tvar out ACLToken\n\tif err := decodeBody(resp, &out); err != nil {\n\t\treturn nil, nil, err\n\t}\n\treturn &out, wm, nil\n}"}, {"instruction": "// NewFilteredJobInformer constructs a new informer for Job type.\n// Always prefer using an informer factory to get a shared informer instead of getting an independent\n// one. This reduces memory footprint and number of connections to the server.", "input": "go language", "output": "func NewFilteredJobInformer(client kubernetes.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\n\treturn cache.NewSharedIndexInformer(\n\t\t&cache.ListWatch{\n\t\t\tListFunc: func(options metav1.ListOptions) (runtime.Object, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.BatchV1().Jobs(namespace).List(options)\n\t\t\t},\n\t\t\tWatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.BatchV1().Jobs(namespace).Watch(options)\n\t\t\t},\n\t\t},\n\t\t&batchv1.Job{},\n\t\tresyncPeriod,\n\t\tindexers,\n\t)\n}"}, {"instruction": "// Register injects a new peer into the working set, or returns an error if the\n// peer is already known.\n//\n// The method also sets the starting throughput values of the new peer to the\n// average of all existing peers, to give it a realistic chance of being used\n// for data retrievals.", "input": "go language", "output": "func (ps *peerSet) Register(p *peerConnection) error {\n\t// Retrieve the current median RTT as a sane default\n\tp.rtt = ps.medianRTT()\n\n\t// Register the new peer with some meaningful defaults\n\tps.lock.Lock()\n\tif _, ok := ps.peers[p.id]; ok {\n\t\tps.lock.Unlock()\n\t\treturn errAlreadyRegistered\n\t}\n\tif len(ps.peers) > 0 {\n\t\tp.headerThroughput, p.blockThroughput, p.receiptThroughput, p.stateThroughput = 0, 0, 0, 0\n\n\t\tfor _, peer := range ps.peers {\n\t\t\tpeer.lock.RLock()\n\t\t\tp.headerThroughput += peer.headerThroughput\n\t\t\tp.blockThroughput += peer.blockThroughput\n\t\t\tp.receiptThroughput += peer.receiptThroughput\n\t\t\tp.stateThroughput += peer.stateThroughput\n\t\t\tpeer.lock.RUnlock()\n\t\t}\n\t\tp.headerThroughput /= float64(len(ps.peers))\n\t\tp.blockThroughput /= float64(len(ps.peers))\n\t\tp.receiptThroughput /= float64(len(ps.peers))\n\t\tp.stateThroughput /= float64(len(ps.peers))\n\t}\n\tps.peers[p.id] = p\n\tps.lock.Unlock()\n\n\tps.newPeerFeed.Send(p)\n\treturn nil\n}"}, {"instruction": "// New returns a new instance of the os-namespaced template functions.", "input": "go language", "output": "func New(deps *deps.Deps) *Namespace {\n\n\t// Since Hugo 0.38 we can have multiple content dirs. This can make it hard to\n\t// reason about where the file is placed relative to the project root.\n\t// To make the {{ readFile .Filename }} variant just work, we create a composite\n\t// filesystem that first checks the work dir fs and then the content fs.\n\tvar rfs afero.Fs\n\tif deps.Fs != nil {\n\t\trfs = deps.Fs.WorkingDir\n\t\tif deps.PathSpec != nil && deps.PathSpec.BaseFs != nil {\n\t\t\trfs = afero.NewReadOnlyFs(afero.NewCopyOnWriteFs(deps.PathSpec.BaseFs.Content.Fs, deps.Fs.WorkingDir))\n\t\t}\n\t}\n\n\treturn &Namespace{\n\t\treadFileFs: rfs,\n\t\tdeps:       deps,\n\t}\n}"}, {"instruction": "// scaleForResourceMappings attempts to fetch the scale for the\n// resource with the given name and namespace, trying each RESTMapping\n// in turn until a working one is found.  If none work, the first error\n// is returned.  It returns both the scale, as well as the group-resource from\n// the working mapping.", "input": "go language", "output": "func (a *HorizontalController) scaleForResourceMappings(namespace, name string, mappings []*apimeta.RESTMapping) (*autoscalingv1.Scale, schema.GroupResource, error) {\n\tvar firstErr error\n\tfor i, mapping := range mappings {\n\t\ttargetGR := mapping.Resource.GroupResource()\n\t\tscale, err := a.scaleNamespacer.Scales(namespace).Get(targetGR, name)\n\t\tif err == nil {\n\t\t\treturn scale, targetGR, nil\n\t\t}\n\n\t\t// if this is the first error, remember it,\n\t\t// then go on and try other mappings until we find a good one\n\t\tif i == 0 {\n\t\t\tfirstErr = err\n\t\t}\n\t}\n\n\t// make sure we handle an empty set of mappings\n\tif firstErr == nil {\n\t\tfirstErr = fmt.Errorf(\"unrecognized resource\")\n\t}\n\n\treturn nil, schema.GroupResource{}, firstErr\n}"}, {"instruction": "// InstanceID returns the cloud provider ID of the node with the specified nodeName.", "input": "go language", "output": "func (c *Cloud) InstanceID(ctx context.Context, nodeName types.NodeName) (string, error) {\n\t// In the future it is possible to also return an endpoint as:\n\t// <endpoint>/<zone>/<instanceid>\n\tif c.selfAWSInstance.nodeName == nodeName {\n\t\treturn \"/\" + c.selfAWSInstance.availabilityZone + \"/\" + c.selfAWSInstance.awsID, nil\n\t}\n\tinst, err := c.getInstanceByNodeName(nodeName)\n\tif err != nil {\n\t\tif err == cloudprovider.InstanceNotFound {\n\t\t\t// The Instances interface requires that we return InstanceNotFound (without wrapping)\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"getInstanceByNodeName failed for %q with %q\", nodeName, err)\n\t}\n\treturn \"/\" + aws.StringValue(inst.Placement.AvailabilityZone) + \"/\" + aws.StringValue(inst.InstanceId), nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *LimitedResource) DeepCopyInto(out *LimitedResource) {\n\t*out = *in\n\tif in.MatchContains != nil {\n\t\tin, out := &in.MatchContains, &out.MatchContains\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.MatchScopes != nil {\n\t\tin, out := &in.MatchScopes, &out.MatchScopes\n\t\t*out = make([]v1.ScopedResourceSelectorRequirement, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// Format the ExprNode into a Writer.", "input": "go language", "output": "func (n *ValueExpr) Format(w io.Writer) {\n\tvar s string\n\tswitch n.Kind() {\n\tcase types.KindNull:\n\t\ts = \"NULL\"\n\tcase types.KindInt64:\n\t\tif n.Type.Flag&mysql.IsBooleanFlag != 0 {\n\t\t\tif n.GetInt64() > 0 {\n\t\t\t\ts = \"TRUE\"\n\t\t\t} else {\n\t\t\t\ts = \"FALSE\"\n\t\t\t}\n\t\t} else {\n\t\t\ts = strconv.FormatInt(n.GetInt64(), 10)\n\t\t}\n\tcase types.KindUint64:\n\t\ts = strconv.FormatUint(n.GetUint64(), 10)\n\tcase types.KindFloat32:\n\t\ts = strconv.FormatFloat(n.GetFloat64(), 'e', -1, 32)\n\tcase types.KindFloat64:\n\t\ts = strconv.FormatFloat(n.GetFloat64(), 'e', -1, 64)\n\tcase types.KindString, types.KindBytes:\n\t\ts = strconv.Quote(n.GetString())\n\tcase types.KindMysqlDecimal:\n\t\ts = n.GetMysqlDecimal().String()\n\tcase types.KindBinaryLiteral:\n\t\tif n.Type.Flag&mysql.UnsignedFlag != 0 {\n\t\t\ts = fmt.Sprintf(\"x'%x'\", n.GetBytes())\n\t\t} else {\n\t\t\ts = n.GetBinaryLiteral().ToBitLiteralString(true)\n\t\t}\n\tdefault:\n\t\tpanic(\"Can't format to string\")\n\t}\n\tfmt.Fprint(w, s)\n}"}, {"instruction": "// SetClientRootCAs sets the list of authorities used to verify client\n// certificates based on a list of PEM-encoded X509 certificate authorities", "input": "go language", "output": "func (gServer *GRPCServer) SetClientRootCAs(clientRoots [][]byte) error {\n\tgServer.lock.Lock()\n\tdefer gServer.lock.Unlock()\n\n\terrMsg := \"Failed to set client root certificate(s): %s\"\n\n\t//create a new map and CertPool\n\tclientRootCAs := make(map[string]*x509.Certificate)\n\tfor _, clientRoot := range clientRoots {\n\t\tcerts, subjects, err := pemToX509Certs(clientRoot)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(errMsg, err.Error())\n\t\t}\n\t\tif len(certs) >= 1 {\n\t\t\tfor i, cert := range certs {\n\t\t\t\t//add it to our clientRootCAs map using subject as key\n\t\t\t\tclientRootCAs[subjects[i]] = cert\n\t\t\t}\n\t\t}\n\t}\n\n\t//create a new CertPool and populate with the new clientRootCAs\n\tcertPool := x509.NewCertPool()\n\tfor _, clientRoot := range clientRootCAs {\n\t\tcertPool.AddCert(clientRoot)\n\t}\n\t//replace the internal map\n\tgServer.clientRootCAs = clientRootCAs\n\t//replace the current ClientCAs pool\n\tgServer.tlsConfig.ClientCAs = certPool\n\treturn nil\n}"}, {"instruction": "// NewOnAddresses creates a new PortForwarder with custom listen addresses.", "input": "go language", "output": "func NewOnAddresses(dialer httpstream.Dialer, addresses []string, ports []string, stopChan <-chan struct{}, readyChan chan struct{}, out, errOut io.Writer) (*PortForwarder, error) {\n\tif len(addresses) == 0 {\n\t\treturn nil, errors.New(\"You must specify at least 1 address\")\n\t}\n\tparsedAddresses, err := parseAddresses(addresses)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(ports) == 0 {\n\t\treturn nil, errors.New(\"You must specify at least 1 port\")\n\t}\n\tparsedPorts, err := parsePorts(ports)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &PortForwarder{\n\t\tdialer:    dialer,\n\t\taddresses: parsedAddresses,\n\t\tports:     parsedPorts,\n\t\tstopChan:  stopChan,\n\t\tReady:     readyChan,\n\t\tout:       out,\n\t\terrOut:    errOut,\n\t}, nil\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *DeallocateExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\tvars := e.ctx.GetSessionVars()\n\tid, ok := vars.PreparedStmtNameToID[e.Name]\n\tif !ok {\n\t\treturn errors.Trace(plannercore.ErrStmtNotFound)\n\t}\n\tdelete(vars.PreparedStmtNameToID, e.Name)\n\tif plannercore.PreparedPlanCacheEnabled() {\n\t\te.ctx.PreparedPlanCache().Delete(plannercore.NewPSTMTPlanCacheKey(\n\t\t\tvars, id, vars.PreparedStmts[id].SchemaVersion,\n\t\t))\n\t}\n\tvars.RemovePreparedStmt(id)\n\treturn nil\n}"}, {"instruction": "// hashimotoLight aggregates data from the full dataset (using only a small\n// in-memory cache) in order to produce our final value for a particular header\n// hash and nonce.", "input": "go language", "output": "func hashimotoLight(size uint64, cache []uint32, hash []byte, nonce uint64) ([]byte, []byte) {\n\tkeccak512 := makeHasher(sha3.NewLegacyKeccak512())\n\n\tlookup := func(index uint32) []uint32 {\n\t\trawData := generateDatasetItem(cache, index, keccak512)\n\n\t\tdata := make([]uint32, len(rawData)/4)\n\t\tfor i := 0; i < len(data); i++ {\n\t\t\tdata[i] = binary.LittleEndian.Uint32(rawData[i*4:])\n\t\t}\n\t\treturn data\n\t}\n\treturn hashimoto(hash, nonce, size, lookup)\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *HPAControllerConfiguration) DeepCopyInto(out *HPAControllerConfiguration) {\n\t*out = *in\n\tout.HorizontalPodAutoscalerSyncPeriod = in.HorizontalPodAutoscalerSyncPeriod\n\tout.HorizontalPodAutoscalerUpscaleForbiddenWindow = in.HorizontalPodAutoscalerUpscaleForbiddenWindow\n\tout.HorizontalPodAutoscalerDownscaleForbiddenWindow = in.HorizontalPodAutoscalerDownscaleForbiddenWindow\n\tout.HorizontalPodAutoscalerDownscaleStabilizationWindow = in.HorizontalPodAutoscalerDownscaleStabilizationWindow\n\tout.HorizontalPodAutoscalerCPUInitializationPeriod = in.HorizontalPodAutoscalerCPUInitializationPeriod\n\tout.HorizontalPodAutoscalerInitialReadinessDelay = in.HorizontalPodAutoscalerInitialReadinessDelay\n\treturn\n}"}, {"instruction": "// GetDDLInfo returns DDL information.", "input": "go language", "output": "func GetDDLInfo(txn kv.Transaction) (*DDLInfo, error) {\n\tvar err error\n\tinfo := &DDLInfo{}\n\tt := meta.NewMeta(txn)\n\n\tinfo.Jobs = make([]*model.Job, 0, 2)\n\tjob, err := t.GetDDLJobByIdx(0)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\tif job != nil {\n\t\tinfo.Jobs = append(info.Jobs, job)\n\t}\n\taddIdxJob, err := t.GetDDLJobByIdx(0, meta.AddIndexJobListKey)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\tif addIdxJob != nil {\n\t\tinfo.Jobs = append(info.Jobs, addIdxJob)\n\t}\n\n\tinfo.SchemaVer, err = t.GetSchemaVersion()\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\tif addIdxJob == nil {\n\t\treturn info, nil\n\t}\n\n\tinfo.ReorgHandle, _, _, err = t.GetDDLReorgHandle(addIdxJob)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\n\treturn info, nil\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of StorageClasses that match those selectors.", "input": "go language", "output": "func (c *FakeStorageClasses) List(opts v1.ListOptions) (result *v1beta1.StorageClassList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootListAction(storageclassesResource, storageclassesKind, opts), &v1beta1.StorageClassList{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta1.StorageClassList{ListMeta: obj.(*v1beta1.StorageClassList).ListMeta}\n\tfor _, item := range obj.(*v1beta1.StorageClassList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// ConfirmUsable looks a particular context and determines if that particular part of the config is useable.  There might still be errors in the config,\n// but no errors in the sections requested or referenced.  It does not return early so that it can find as many errors as possible.", "input": "go language", "output": "func ConfirmUsable(config clientcmdapi.Config, passedContextName string) error {\n\tvalidationErrors := make([]error, 0)\n\n\tif clientcmdapi.IsConfigEmpty(&config) {\n\t\treturn newErrConfigurationInvalid([]error{ErrEmptyConfig})\n\t}\n\n\tvar contextName string\n\tif len(passedContextName) != 0 {\n\t\tcontextName = passedContextName\n\t} else {\n\t\tcontextName = config.CurrentContext\n\t}\n\n\tif len(contextName) == 0 {\n\t\treturn ErrNoContext\n\t}\n\n\tcontext, exists := config.Contexts[contextName]\n\tif !exists {\n\t\tvalidationErrors = append(validationErrors, &errContextNotFound{contextName})\n\t}\n\n\tif exists {\n\t\tvalidationErrors = append(validationErrors, validateContext(contextName, *context, config)...)\n\t\tvalidationErrors = append(validationErrors, validateAuthInfo(context.AuthInfo, *config.AuthInfos[context.AuthInfo])...)\n\t\tvalidationErrors = append(validationErrors, validateClusterInfo(context.Cluster, *config.Clusters[context.Cluster])...)\n\t}\n\n\treturn newErrConfigurationInvalid(validationErrors)\n}"}, {"instruction": "// modifyHostOptionsForSandbox applies NetworkMode/UTSMode to sandbox's dockercontainer.HostConfig.", "input": "go language", "output": "func modifyHostOptionsForSandbox(nsOpts *runtimeapi.NamespaceOption, network *knetwork.PluginManager, hc *dockercontainer.HostConfig) {\n\tif nsOpts.GetIpc() == runtimeapi.NamespaceMode_NODE {\n\t\thc.IpcMode = namespaceModeHost\n\t}\n\tif nsOpts.GetNetwork() == runtimeapi.NamespaceMode_NODE {\n\t\thc.NetworkMode = namespaceModeHost\n\t\treturn\n\t}\n\n\tif network == nil {\n\t\thc.NetworkMode = \"default\"\n\t\treturn\n\t}\n\n\tswitch network.PluginName() {\n\tcase \"cni\":\n\t\tfallthrough\n\tcase \"kubenet\":\n\t\thc.NetworkMode = \"none\"\n\tdefault:\n\t\thc.NetworkMode = \"default\"\n\t}\n}"}, {"instruction": "// executeKeyringOpMgr executes the appropriate keyring-related function based on\n// the type of keyring operation in the request. It takes the KeyManager as an\n// argument, so it can handle any operation for either LAN or WAN pools.", "input": "go language", "output": "func (m *Internal) executeKeyringOpMgr(\n\tmgr *serf.KeyManager,\n\targs *structs.KeyringRequest,\n\treply *structs.KeyringResponses,\n\twan bool,\n\tsegment string) {\n\tvar serfResp *serf.KeyResponse\n\tvar err error\n\n\topts := &serf.KeyRequestOptions{RelayFactor: args.RelayFactor}\n\tswitch args.Operation {\n\tcase structs.KeyringList:\n\t\tserfResp, err = mgr.ListKeysWithOptions(opts)\n\tcase structs.KeyringInstall:\n\t\tserfResp, err = mgr.InstallKeyWithOptions(args.Key, opts)\n\tcase structs.KeyringUse:\n\t\tserfResp, err = mgr.UseKeyWithOptions(args.Key, opts)\n\tcase structs.KeyringRemove:\n\t\tserfResp, err = mgr.RemoveKeyWithOptions(args.Key, opts)\n\t}\n\n\terrStr := \"\"\n\tif err != nil {\n\t\terrStr = err.Error()\n\t}\n\n\treply.Responses = append(reply.Responses, &structs.KeyringResponse{\n\t\tWAN:        wan,\n\t\tDatacenter: m.srv.config.Datacenter,\n\t\tSegment:    segment,\n\t\tMessages:   serfResp.Messages,\n\t\tKeys:       serfResp.Keys,\n\t\tNumNodes:   serfResp.NumNodes,\n\t\tError:      errStr,\n\t})\n}"}, {"instruction": "// elgEnabledCollNames returns the names of the collections for which the peer is not eligible as per 'existingPkg' and is eligible as per 'postCommitPkg'", "input": "go language", "output": "func (n *collElgNotifier) elgEnabledCollNames(ledgerID string,\n\texistingPkg, postCommitPkg *common.CollectionConfigPackage) ([]string, error) {\n\n\tcollectionNames := []string{}\n\texisingConfs := retrieveCollConfs(existingPkg)\n\tpostCommitConfs := retrieveCollConfs(postCommitPkg)\n\texistingConfMap := map[string]*common.StaticCollectionConfig{}\n\tfor _, existingConf := range exisingConfs {\n\t\texistingConfMap[existingConf.Name] = existingConf\n\t}\n\n\tfor _, postCommitConf := range postCommitConfs {\n\t\tcollName := postCommitConf.Name\n\t\texistingConf, ok := existingConfMap[collName]\n\t\tif !ok { // brand new collection\n\t\t\tcontinue\n\t\t}\n\t\tmembershipEnabled, err := n.elgEnabled(ledgerID, existingConf.MemberOrgsPolicy, postCommitConf.MemberOrgsPolicy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !membershipEnabled {\n\t\t\tcontinue\n\t\t}\n\t\t// not an existing member and added now\n\t\tcollectionNames = append(collectionNames, collName)\n\t}\n\treturn collectionNames, nil\n}"}, {"instruction": "// WaitForPodToDisappear blocks until it timeouts or gets a \"NotFound\" response from the API Server when getting the Static Pod in question", "input": "go language", "output": "func (w *KubeWaiter) WaitForPodToDisappear(podName string) error {\n\treturn wait.PollImmediate(constants.APICallRetryInterval, w.timeout, func() (bool, error) {\n\t\t_, err := w.client.CoreV1().Pods(metav1.NamespaceSystem).Get(podName, metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\tfmt.Printf(\"[apiclient] The old Pod %q is now removed (which is desired)\\n\", podName)\n\t\t\treturn true, nil\n\t\t}\n\t\treturn false, nil\n\t})\n}"}, {"instruction": "// GetSecrets returns all secrets of a managed swarm cluster.", "input": "go language", "output": "func (c *Cluster) GetSecrets(options apitypes.SecretListOptions) ([]types.Secret, error) {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\n\tstate := c.currentNodeState()\n\tif !state.IsActiveManager() {\n\t\treturn nil, c.errNoManager(state)\n\t}\n\n\tfilters, err := newListSecretsFilters(options.Filters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tctx, cancel := c.getRequestContext()\n\tdefer cancel()\n\n\tr, err := state.controlClient.ListSecrets(ctx,\n\t\t&swarmapi.ListSecretsRequest{Filters: filters})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsecrets := make([]types.Secret, 0, len(r.Secrets))\n\n\tfor _, secret := range r.Secrets {\n\t\tsecrets = append(secrets, convert.SecretFromGRPC(secret))\n\t}\n\n\treturn secrets, nil\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of ReplicationControllers that match those selectors.", "input": "go language", "output": "func (c *FakeReplicationControllers) List(opts v1.ListOptions) (result *corev1.ReplicationControllerList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(replicationcontrollersResource, replicationcontrollersKind, c.ns, opts), &corev1.ReplicationControllerList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &corev1.ReplicationControllerList{ListMeta: obj.(*corev1.ReplicationControllerList).ListMeta}\n\tfor _, item := range obj.(*corev1.ReplicationControllerList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// ToleratesTaint checks if the toleration tolerates the taint.\n// The matching follows the rules below:\n// (1) Empty toleration.effect means to match all taint effects,\n//     otherwise taint effect must equal to toleration.effect.\n// (2) If toleration.operator is 'Exists', it means to match all taint values.\n// (3) Empty toleration.key means to match all taint keys.\n//     If toleration.key is empty, toleration.operator must be 'Exists';\n//     this combination means to match all taint values and all taint keys.", "input": "go language", "output": "func (t *Toleration) ToleratesTaint(taint *Taint) bool {\n\tif len(t.Effect) > 0 && t.Effect != taint.Effect {\n\t\treturn false\n\t}\n\n\tif len(t.Key) > 0 && t.Key != taint.Key {\n\t\treturn false\n\t}\n\n\t// TODO: Use proper defaulting when Toleration becomes a field of PodSpec\n\tswitch t.Operator {\n\t// empty operator means Equal\n\tcase \"\", TolerationOpEqual:\n\t\treturn t.Value == taint.Value\n\tcase TolerationOpExists:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}"}, {"instruction": "// Patch applies the patch and returns the patched controllerRevision.", "input": "go language", "output": "func (c *FakeControllerRevisions) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *v1beta2.ControllerRevision, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewPatchSubresourceAction(controllerrevisionsResource, c.ns, name, pt, data, subresources...), &v1beta2.ControllerRevision{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*v1beta2.ControllerRevision), err\n}"}, {"instruction": "// Patch applies the patch and returns the patched persistentVolumeClaim.", "input": "go language", "output": "func (c *FakePersistentVolumeClaims) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *corev1.PersistentVolumeClaim, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewPatchSubresourceAction(persistentvolumeclaimsResource, c.ns, name, pt, data, subresources...), &corev1.PersistentVolumeClaim{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*corev1.PersistentVolumeClaim), err\n}"}, {"instruction": "// make push instruction function", "input": "go language", "output": "func makePush(size uint64, pushByteSize int) executionFunc {\n\treturn func(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {\n\t\tcodeLen := len(contract.Code)\n\n\t\tstartMin := codeLen\n\t\tif int(*pc+1) < startMin {\n\t\t\tstartMin = int(*pc + 1)\n\t\t}\n\n\t\tendMin := codeLen\n\t\tif startMin+pushByteSize < endMin {\n\t\t\tendMin = startMin + pushByteSize\n\t\t}\n\n\t\tinteger := interpreter.intPool.get()\n\t\tstack.push(integer.SetBytes(common.RightPadBytes(contract.Code[startMin:endMin], pushByteSize)))\n\n\t\t*pc += size\n\t\treturn nil, nil\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ISCSIPersistentVolumeSource) DeepCopyInto(out *ISCSIPersistentVolumeSource) {\n\t*out = *in\n\tif in.Portals != nil {\n\t\tin, out := &in.Portals, &out.Portals\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.SecretRef != nil {\n\t\tin, out := &in.SecretRef, &out.SecretRef\n\t\t*out = new(SecretReference)\n\t\t**out = **in\n\t}\n\tif in.InitiatorName != nil {\n\t\tin, out := &in.InitiatorName, &out.InitiatorName\n\t\t*out = new(string)\n\t\t**out = **in\n\t}\n\treturn\n}"}, {"instruction": "// Recv receives a message from a remote cluster member.", "input": "go language", "output": "func (stream *Stream) Recv() (*orderer.StepResponse, error) {\n\tstart := time.Now()\n\tdefer func() {\n\t\tif !stream.Logger.IsEnabledFor(zap.DebugLevel) {\n\t\t\treturn\n\t\t}\n\t\tstream.Logger.Debugf(\"Receive from %s(%s) took %v\", stream.NodeName, stream.Endpoint, time.Since(start))\n\t}()\n\n\tf := func() (*orderer.StepResponse, error) {\n\t\treturn stream.Cluster_StepClient.Recv()\n\t}\n\n\treturn stream.operateWithTimeout(f)\n}"}, {"instruction": "// Need to hold lock on m.fmut when calling this.", "input": "go language", "output": "func (m *model) tearDownFolderLocked(cfg config.FolderConfiguration, err error) {\n\t// Stop the services running for this folder and wait for them to finish\n\t// stopping to prevent races on restart.\n\ttokens := m.folderRunnerTokens[cfg.ID]\n\n\tm.fmut.Unlock()\n\n\t// Close connections to affected devices\n\t// Must happen before stopping the folder service to abort ongoing\n\t// transmissions and thus allow timely service termination.\n\tm.closeConns(cfg.DeviceIDs(), err)\n\n\tfor _, id := range tokens {\n\t\tm.RemoveAndWait(id, 0)\n\t}\n\n\tm.fmut.Lock()\n\n\t// Clean up our config maps\n\tdelete(m.folderCfgs, cfg.ID)\n\tdelete(m.folderFiles, cfg.ID)\n\tdelete(m.folderIgnores, cfg.ID)\n\tdelete(m.folderRunners, cfg.ID)\n\tdelete(m.folderRunnerTokens, cfg.ID)\n}"}, {"instruction": "// podMatchesScopeFunc is a function that knows how to evaluate if a pod matches a scope", "input": "go language", "output": "func podMatchesScopeFunc(selector corev1.ScopedResourceSelectorRequirement, object runtime.Object) (bool, error) {\n\tpod, err := toExternalPodOrError(object)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tswitch selector.ScopeName {\n\tcase corev1.ResourceQuotaScopeTerminating:\n\t\treturn isTerminating(pod), nil\n\tcase corev1.ResourceQuotaScopeNotTerminating:\n\t\treturn !isTerminating(pod), nil\n\tcase corev1.ResourceQuotaScopeBestEffort:\n\t\treturn isBestEffort(pod), nil\n\tcase corev1.ResourceQuotaScopeNotBestEffort:\n\t\treturn !isBestEffort(pod), nil\n\tcase corev1.ResourceQuotaScopePriorityClass:\n\t\treturn podMatchesSelector(pod, selector)\n\t}\n\treturn false, nil\n}"}, {"instruction": "// grantGlobalPriv manipulates mysql.user table.", "input": "go language", "output": "func (e *GrantExec) grantGlobalPriv(priv *ast.PrivElem, user *ast.UserSpec) error {\n\tif priv.Priv == 0 {\n\t\treturn nil\n\t}\n\tasgns, err := composeGlobalPrivUpdate(priv.Priv, \"Y\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tsql := fmt.Sprintf(`UPDATE %s.%s SET %s WHERE User='%s' AND Host='%s'`, mysql.SystemDB, mysql.UserTable, asgns, user.User.Username, user.User.Hostname)\n\t_, _, err = e.ctx.(sqlexec.RestrictedSQLExecutor).ExecRestrictedSQL(e.ctx, sql)\n\treturn err\n}"}, {"instruction": "// Read returns a full YAML document.", "input": "go language", "output": "func (r *YAMLReader) Read() ([]byte, error) {\n\tvar buffer bytes.Buffer\n\tfor {\n\t\tline, err := r.reader.Read()\n\t\tif err != nil && err != io.EOF {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tsep := len([]byte(separator))\n\t\tif i := bytes.Index(line, []byte(separator)); i == 0 {\n\t\t\t// We have a potential document terminator\n\t\t\ti += sep\n\t\t\tafter := line[i:]\n\t\t\tif len(strings.TrimRightFunc(string(after), unicode.IsSpace)) == 0 {\n\t\t\t\tif buffer.Len() != 0 {\n\t\t\t\t\treturn buffer.Bytes(), nil\n\t\t\t\t}\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif err == io.EOF {\n\t\t\tif buffer.Len() != 0 {\n\t\t\t\t// If we're at EOF, we have a final, non-terminated line. Return it.\n\t\t\t\treturn buffer.Bytes(), nil\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tbuffer.Write(line)\n\t}\n}"}, {"instruction": "// Detach checks with the GCE cloud provider if the specified volume is already\n// attached to the specified node. If the volume is not attached, it succeeds\n// (returns nil). If it is attached, Detach issues a call to the GCE cloud\n// provider to attach it.\n// Callers are responsible for retrying on failure.\n// Callers are responsible for thread safety between concurrent attach and detach\n// operations.", "input": "go language", "output": "func (detacher *gcePersistentDiskDetacher) Detach(volumeName string, nodeName types.NodeName) error {\n\tpdName := path.Base(volumeName)\n\n\tattached, err := detacher.gceDisks.DiskIsAttached(pdName, nodeName)\n\tif err != nil {\n\t\t// Log error and continue with detach\n\t\tklog.Errorf(\n\t\t\t\"Error checking if PD (%q) is already attached to current node (%q). Will continue and try detach anyway. err=%v\",\n\t\t\tpdName, nodeName, err)\n\t}\n\n\tif err == nil && !attached {\n\t\t// Volume is not attached to node. Success!\n\t\tklog.Infof(\"Detach operation is successful. PD %q was not attached to node %q.\", pdName, nodeName)\n\t\treturn nil\n\t}\n\n\tif err = detacher.gceDisks.DetachDisk(pdName, nodeName); err != nil {\n\t\tklog.Errorf(\"Error detaching PD %q from node %q: %v\", pdName, nodeName, err)\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// unpackAtomic unpacks ( hexdata -> go ) a single value", "input": "go language", "output": "func (arguments Arguments) unpackAtomic(v interface{}, marshalledValues interface{}) error {\n\tif arguments.LengthNonIndexed() == 0 {\n\t\treturn nil\n\t}\n\targument := arguments.NonIndexed()[0]\n\telem := reflect.ValueOf(v).Elem()\n\n\tif elem.Kind() == reflect.Struct {\n\t\tfieldmap, err := mapArgNamesToStructFields([]string{argument.Name}, elem)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfield := elem.FieldByName(fieldmap[argument.Name])\n\t\tif !field.IsValid() {\n\t\t\treturn fmt.Errorf(\"abi: field %s can't be found in the given value\", argument.Name)\n\t\t}\n\t\treturn unpack(&argument.Type, field.Addr().Interface(), marshalledValues)\n\t}\n\treturn unpack(&argument.Type, elem.Addr().Interface(), marshalledValues)\n}"}, {"instruction": "// RegisterEthService adds an Ethereum client to the stack.", "input": "go language", "output": "func RegisterEthService(stack *node.Node, cfg *eth.Config) {\n\tvar err error\n\tif cfg.SyncMode == downloader.LightSync {\n\t\terr = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {\n\t\t\treturn les.New(ctx, cfg)\n\t\t})\n\t} else {\n\t\terr = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {\n\t\t\tfullNode, err := eth.New(ctx, cfg)\n\t\t\tif fullNode != nil && cfg.LightServ > 0 {\n\t\t\t\tls, _ := les.NewLesServer(fullNode, cfg)\n\t\t\t\tfullNode.AddLesServer(ls)\n\t\t\t}\n\t\t\treturn fullNode, err\n\t\t})\n\t}\n\tif err != nil {\n\t\tFatalf(\"Failed to register the Ethereum service: %v\", err)\n\t}\n}"}, {"instruction": "// References returns a slice of references to the given ID. The slice\n// will be nil if there are no references to this ID.", "input": "go language", "output": "func (store *store) References(id digest.Digest) []reference.Named {\n\tstore.mu.RLock()\n\tdefer store.mu.RUnlock()\n\n\t// Convert the internal map to an array for two reasons:\n\t// 1) We must not return a mutable\n\t// 2) It would be ugly to expose the extraneous map keys to callers.\n\n\tvar references []reference.Named\n\tfor _, ref := range store.referencesByIDCache[id] {\n\t\treferences = append(references, ref)\n\t}\n\n\tsort.Sort(lexicalRefs(references))\n\n\treturn references\n}"}, {"instruction": "// ReadDataSource returns the data source's current state.", "input": "go language", "output": "func (p *Provider) ReadDataSource(req providers.ReadDataSourceRequest) providers.ReadDataSourceResponse {\n\t// call function\n\tvar res providers.ReadDataSourceResponse\n\n\t// This should not happen\n\tif req.TypeName != \"terraform_remote_state\" {\n\t\tres.Diagnostics.Append(fmt.Errorf(\"Error: unsupported data source %s\", req.TypeName))\n\t\treturn res\n\t}\n\n\tnewState, diags := dataSourceRemoteStateRead(&req.Config)\n\n\tres.State = newState\n\tres.Diagnostics = diags\n\n\treturn res\n}"}, {"instruction": "// SetIntermediate writes the incoming intermediate and root certificates to the\n// intermediate backend (as a chain).", "input": "go language", "output": "func (v *VaultProvider) SetIntermediate(intermediatePEM, rootPEM string) error {\n\tif v.isRoot {\n\t\treturn fmt.Errorf(\"cannot set an intermediate using another root in the primary datacenter\")\n\t}\n\n\t_, err := v.client.Logical().Write(v.config.IntermediatePKIPath+\"intermediate/set-signed\", map[string]interface{}{\n\t\t\"certificate\": fmt.Sprintf(\"%s\\n%s\", intermediatePEM, rootPEM),\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// ResolveIndices implements Plan interface.", "input": "go language", "output": "func (p *PhysicalIndexReader) ResolveIndices() (err error) {\n\terr = p.physicalSchemaProducer.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = p.indexPlan.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor i, col := range p.OutputColumns {\n\t\tnewCol, err := col.ResolveIndices(p.indexPlan.Schema())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tp.OutputColumns[i] = newCol.(*expression.Column)\n\t}\n\treturn\n}"}, {"instruction": "// parseInitVersion parses a Tini version string, and extracts the \"version\"\n// and \"git commit\" from the output.\n//\n// Output example from `docker-init --version`:\n//\n//     tini version 0.18.0 - git.fec3683", "input": "go language", "output": "func parseInitVersion(v string) (version string, commit string, err error) {\n\tparts := strings.Split(strings.TrimSpace(v), \" - \")\n\n\tif len(parts) >= 2 {\n\t\tgitParts := strings.Split(parts[1], \".\")\n\t\tif len(gitParts) == 2 && gitParts[0] == \"git\" {\n\t\t\tcommit = gitParts[1]\n\t\t}\n\t}\n\tif strings.HasPrefix(parts[0], \"tini version \") {\n\t\tversion = strings.TrimPrefix(parts[0], \"tini version \")\n\t}\n\tif version == \"\" && commit == \"\" {\n\t\terr = errors.Errorf(\"unknown output format: %s\", v)\n\t}\n\treturn version, commit, err\n}"}, {"instruction": "// Enables callback for keys received from a key exchange request", "input": "go language", "output": "func (ctl *HandshakeController) alertHandshake(pubkeyid string, symkeys []string) chan []string {\n\tctl.keyCMu.Lock()\n\tdefer ctl.keyCMu.Unlock()\n\tif len(symkeys) > 0 {\n\t\tif _, ok := ctl.keyC[pubkeyid]; ok {\n\t\t\tctl.keyC[pubkeyid] <- symkeys\n\t\t\tclose(ctl.keyC[pubkeyid])\n\t\t\tdelete(ctl.keyC, pubkeyid)\n\t\t}\n\t\treturn nil\n\t}\n\tif _, ok := ctl.keyC[pubkeyid]; !ok {\n\t\tctl.keyC[pubkeyid] = make(chan []string)\n\t}\n\treturn ctl.keyC[pubkeyid]\n}"}, {"instruction": "// NewREST returns a RESTStorage object that will work against pod disruption budgets.", "input": "go language", "output": "func NewREST(optsGetter generic.RESTOptionsGetter) *REST {\n\tstore := &genericregistry.Store{\n\t\tNewFunc:     func() runtime.Object { return &admissionregistration.ValidatingWebhookConfiguration{} },\n\t\tNewListFunc: func() runtime.Object { return &admissionregistration.ValidatingWebhookConfigurationList{} },\n\t\tObjectNameFunc: func(obj runtime.Object) (string, error) {\n\t\t\treturn obj.(*admissionregistration.ValidatingWebhookConfiguration).Name, nil\n\t\t},\n\t\tDefaultQualifiedResource: admissionregistration.Resource(\"validatingwebhookconfigurations\"),\n\n\t\tCreateStrategy: validatingwebhookconfiguration.Strategy,\n\t\tUpdateStrategy: validatingwebhookconfiguration.Strategy,\n\t\tDeleteStrategy: validatingwebhookconfiguration.Strategy,\n\t}\n\toptions := &generic.StoreOptions{RESTOptions: optsGetter}\n\tif err := store.CompleteWithOptions(options); err != nil {\n\t\tpanic(err) // TODO: Propagate error up\n\t}\n\treturn &REST{store}\n}"}, {"instruction": "// GetByKey is never guaranteed to return back the value set in Mutation.  It could be paged out, it could\n// be older than another copy, the backingCache may be more recent or, you might have written twice into the same key.\n// You get a value that was valid at some snapshot of time and will always return the newer of backingCache and mutationCache.", "input": "go language", "output": "func (c *mutationCache) GetByKey(key string) (interface{}, bool, error) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tobj, exists, err := c.backingCache.GetByKey(key)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tif !exists {\n\t\tif !c.includeAdds {\n\t\t\t// we can't distinguish between, \"didn't observe create\" and \"was deleted after create\", so\n\t\t\t// if the key is missing, we always return it as missing\n\t\t\treturn nil, false, nil\n\t\t}\n\t\tobj, exists = c.mutationCache.Get(key)\n\t\tif !exists {\n\t\t\treturn nil, false, nil\n\t\t}\n\t}\n\tobjRuntime, ok := obj.(runtime.Object)\n\tif !ok {\n\t\treturn obj, true, nil\n\t}\n\treturn c.newerObject(key, objRuntime), true, nil\n}"}, {"instruction": "// doCleanupMountPoint unmounts the given path and\n// deletes the remaining directory if successful.\n// if extensiveMountPointCheck is true\n// IsNotMountPoint will be called instead of IsLikelyNotMountPoint.\n// IsNotMountPoint is more expensive but properly handles bind mounts within the same fs.\n// if corruptedMnt is true, it means that the mountPath is a corrupted mountpoint, and the mount point check\n// will be skipped", "input": "go language", "output": "func doCleanupMountPoint(mountPath string, mounter Interface, extensiveMountPointCheck bool, corruptedMnt bool) error {\n\tif !corruptedMnt {\n\t\tvar notMnt bool\n\t\tvar err error\n\t\tif extensiveMountPointCheck {\n\t\t\tnotMnt, err = IsNotMountPoint(mounter, mountPath)\n\t\t} else {\n\t\t\tnotMnt, err = mounter.IsLikelyNotMountPoint(mountPath)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif notMnt {\n\t\t\tklog.Warningf(\"Warning: %q is not a mountpoint, deleting\", mountPath)\n\t\t\treturn os.Remove(mountPath)\n\t\t}\n\t}\n\n\t// Unmount the mount path\n\tklog.V(4).Infof(\"%q is a mountpoint, unmounting\", mountPath)\n\tif err := mounter.Unmount(mountPath); err != nil {\n\t\treturn err\n\t}\n\n\tnotMnt, mntErr := mounter.IsLikelyNotMountPoint(mountPath)\n\tif mntErr != nil {\n\t\treturn mntErr\n\t}\n\tif notMnt {\n\t\tklog.V(4).Infof(\"%q is unmounted, deleting the directory\", mountPath)\n\t\treturn os.Remove(mountPath)\n\t}\n\treturn fmt.Errorf(\"Failed to unmount path %v\", mountPath)\n}"}, {"instruction": "// ObjectValueID takes a value that is assumed to be an object representation\n// of some resource instance object and attempts to heuristically find an\n// attribute of it that is likely to be a unique identifier in the remote\n// system that it belongs to which will be useful to the user.\n//\n// If such an attribute is found, its name and string value intended for\n// display are returned. Both returned strings are empty if no such attribute\n// exists, in which case the caller should assume that the resource instance\n// address within the Terraform configuration is the best available identifier.\n//\n// This is only a best-effort sort of thing, relying on naming conventions in\n// our resource type schemas. The result is not guaranteed to be unique, but\n// should generally be suitable for display to an end-user anyway.\n//\n// This function will panic if the given value is not of an object type.", "input": "go language", "output": "func ObjectValueID(obj cty.Value) (k, v string) {\n\tif obj.IsNull() || !obj.IsKnown() {\n\t\treturn \"\", \"\"\n\t}\n\n\tatys := obj.Type().AttributeTypes()\n\n\tswitch {\n\n\tcase atys[\"id\"] == cty.String:\n\t\tv := obj.GetAttr(\"id\")\n\t\tif v.IsKnown() && !v.IsNull() {\n\t\t\treturn \"id\", v.AsString()\n\t\t}\n\n\tcase atys[\"name\"] == cty.String:\n\t\t// \"name\" isn't always globally unique, but if there isn't also an\n\t\t// \"id\" then it _often_ is, in practice.\n\t\tv := obj.GetAttr(\"name\")\n\t\tif v.IsKnown() && !v.IsNull() {\n\t\t\treturn \"name\", v.AsString()\n\t\t}\n\t}\n\n\treturn \"\", \"\"\n}"}, {"instruction": "// ClientIP implements a best effort algorithm to return the real client IP, it parses\n// X-Real-IP and X-Forwarded-For in order to work properly with reverse-proxies such us: nginx or haproxy.\n// Use X-Forwarded-For before X-Real-Ip as nginx uses X-Real-Ip with the proxy's IP.", "input": "go language", "output": "func (c *Context) ClientIP() string {\n\tif c.engine.ForwardedByClientIP {\n\t\tclientIP := c.requestHeader(\"X-Forwarded-For\")\n\t\tclientIP = strings.TrimSpace(strings.Split(clientIP, \",\")[0])\n\t\tif clientIP == \"\" {\n\t\t\tclientIP = strings.TrimSpace(c.requestHeader(\"X-Real-Ip\"))\n\t\t}\n\t\tif clientIP != \"\" {\n\t\t\treturn clientIP\n\t\t}\n\t}\n\n\tif c.engine.AppEngine {\n\t\tif addr := c.requestHeader(\"X-Appengine-Remote-Addr\"); addr != \"\" {\n\t\t\treturn addr\n\t\t}\n\t}\n\n\tif ip, _, err := net.SplitHostPort(strings.TrimSpace(c.Request.RemoteAddr)); err == nil {\n\t\treturn ip\n\t}\n\n\treturn \"\"\n}"}, {"instruction": "// PruneCache removes all cached build sources", "input": "go language", "output": "func (b *Backend) PruneCache(ctx context.Context, opts types.BuildCachePruneOptions) (*types.BuildCachePruneReport, error) {\n\teg, ctx := errgroup.WithContext(ctx)\n\n\tvar fsCacheSize uint64\n\teg.Go(func() error {\n\t\tvar err error\n\t\tfsCacheSize, err = b.fsCache.Prune(ctx)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to prune fscache\")\n\t\t}\n\t\treturn nil\n\t})\n\n\tvar buildCacheSize int64\n\tvar cacheIDs []string\n\teg.Go(func() error {\n\t\tvar err error\n\t\tbuildCacheSize, cacheIDs, err = b.buildkit.Prune(ctx, opts)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to prune build cache\")\n\t\t}\n\t\treturn nil\n\t})\n\n\tif err := eg.Wait(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &types.BuildCachePruneReport{SpaceReclaimed: fsCacheSize + uint64(buildCacheSize), CachesDeleted: cacheIDs}, nil\n}"}, {"instruction": "// InWritableDir calls fn(path), while making sure that the directory\n// containing `path` is writable for the duration of the call.", "input": "go language", "output": "func InWritableDir(fn func(string) error, fs fs.Filesystem, path string) error {\n\tdir := filepath.Dir(path)\n\tinfo, err := fs.Stat(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !info.IsDir() {\n\t\treturn errors.New(\"Not a directory: \" + path)\n\t}\n\tif info.Mode()&0200 == 0 {\n\t\t// A non-writeable directory (for this user; we assume that's the\n\t\t// relevant part). Temporarily change the mode so we can delete the\n\t\t// file or directory inside it.\n\t\terr = fs.Chmod(dir, 0755)\n\t\tif err == nil {\n\t\t\tdefer func() {\n\t\t\t\terr = fs.Chmod(dir, info.Mode())\n\t\t\t\tif err != nil {\n\t\t\t\t\t// We managed to change the permission bits like a\n\t\t\t\t\t// millisecond ago, so it'd be bizarre if we couldn't\n\t\t\t\t\t// change it back.\n\t\t\t\t\tpanic(err)\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\treturn fn(path)\n}"}, {"instruction": "// InstallRelease creates a release using kubeClient.Create", "input": "go language", "output": "func (r *ReleaseModuleServiceServer) InstallRelease(ctx context.Context, in *rudderAPI.InstallReleaseRequest) (*rudderAPI.InstallReleaseResponse, error) {\n\tgrpclog.Print(\"install\")\n\tb := bytes.NewBufferString(in.Release.Manifest)\n\terr := kubeClient.Create(in.Release.Namespace, b, 500, false)\n\tif err != nil {\n\t\tgrpclog.Printf(\"error when creating release: %v\", err)\n\t}\n\treturn &rudderAPI.InstallReleaseResponse{}, err\n}"}, {"instruction": "// Manifest hack for supporting Swarm feeds from the bzz: scheme\n// see swarm/api/api.go:API.Get() for more information", "input": "go language", "output": "func (a *API) NewFeedManifest(ctx context.Context, feed *feed.Feed) (storage.Address, error) {\n\tvar manifest Manifest\n\tentry := ManifestEntry{\n\t\tFeed:        feed,\n\t\tContentType: FeedContentType,\n\t}\n\tmanifest.Entries = append(manifest.Entries, entry)\n\tdata, err := json.Marshal(&manifest)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\taddr, wait, err := a.Store(ctx, bytes.NewReader(data), int64(len(data)), false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = wait(ctx)\n\treturn addr, err\n}"}, {"instruction": "// ACLTokenListExpires lists tokens that are expired as of the provided time.\n// The returned set will be no larger than the max value provided.", "input": "go language", "output": "func (s *Store) ACLTokenListExpired(local bool, asOf time.Time, max int) (structs.ACLTokens, <-chan struct{}, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\titer, err := tx.Get(\"acl-tokens\", s.expiresIndexName(local))\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed acl token listing: %v\", err)\n\t}\n\n\tvar (\n\t\ttokens structs.ACLTokens\n\t\ti      int\n\t)\n\tfor raw := iter.Next(); raw != nil; raw = iter.Next() {\n\t\ttoken := raw.(*structs.ACLToken)\n\t\tif token.ExpirationTime != nil && !token.ExpirationTime.Before(asOf) {\n\t\t\treturn tokens, nil, nil\n\t\t}\n\n\t\ttokens = append(tokens, token)\n\t\ti += 1\n\t\tif i >= max {\n\t\t\treturn tokens, nil, nil\n\t\t}\n\t}\n\n\treturn tokens, iter.WatchCh(), nil\n}"}, {"instruction": "// DefaultVersionedAPIPathFor constructs the default path for the given group version, assuming the given\n// API path, following the standard conventions of the Kubernetes API.", "input": "go language", "output": "func DefaultVersionedAPIPath(apiPath string, groupVersion schema.GroupVersion) string {\n\tversionedAPIPath := path.Join(\"/\", apiPath)\n\n\t// Add the version to the end of the path\n\tif len(groupVersion.Group) > 0 {\n\t\tversionedAPIPath = path.Join(versionedAPIPath, groupVersion.Group, groupVersion.Version)\n\n\t} else {\n\t\tversionedAPIPath = path.Join(versionedAPIPath, groupVersion.Version)\n\t}\n\n\treturn versionedAPIPath\n}"}, {"instruction": "// ResolveIndices implements Plan interface.", "input": "go language", "output": "func (p *PhysicalProjection) ResolveIndices() (err error) {\n\terr = p.physicalSchemaProducer.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor i, expr := range p.Exprs {\n\t\tp.Exprs[i], err = expr.ResolveIndices(p.children[0].Schema())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tchildProj, isProj := p.children[0].(*PhysicalProjection)\n\tif !isProj {\n\t\treturn\n\t}\n\trefine4NeighbourProj(p, childProj)\n\treturn\n}"}, {"instruction": "// Implementation of EC2.Instances", "input": "go language", "output": "func (s *awsSdkEC2) DescribeInstances(request *ec2.DescribeInstancesInput) ([]*ec2.Instance, error) {\n\t// Instances are paged\n\tresults := []*ec2.Instance{}\n\tvar nextToken *string\n\trequestTime := time.Now()\n\tfor {\n\t\tresponse, err := s.ec2.DescribeInstances(request)\n\t\tif err != nil {\n\t\t\trecordAWSMetric(\"describe_instance\", 0, err)\n\t\t\treturn nil, fmt.Errorf(\"error listing AWS instances: %q\", err)\n\t\t}\n\n\t\tfor _, reservation := range response.Reservations {\n\t\t\tresults = append(results, reservation.Instances...)\n\t\t}\n\n\t\tnextToken = response.NextToken\n\t\tif aws.StringValue(nextToken) == \"\" {\n\t\t\tbreak\n\t\t}\n\t\trequest.NextToken = nextToken\n\t}\n\ttimeTaken := time.Since(requestTime).Seconds()\n\trecordAWSMetric(\"describe_instance\", timeTaken, nil)\n\treturn results, nil\n}"}, {"instruction": "// Get pods which should be resynchronized. Currently, the following pod should be resynchronized:\n//   * pod whose work is ready.\n//   * internal modules that request sync of a pod.", "input": "go language", "output": "func (kl *Kubelet) getPodsToSync() []*v1.Pod {\n\tallPods := kl.podManager.GetPods()\n\tpodUIDs := kl.workQueue.GetWork()\n\tpodUIDSet := sets.NewString()\n\tfor _, podUID := range podUIDs {\n\t\tpodUIDSet.Insert(string(podUID))\n\t}\n\tvar podsToSync []*v1.Pod\n\tfor _, pod := range allPods {\n\t\tif podUIDSet.Has(string(pod.UID)) {\n\t\t\t// The work of the pod is ready\n\t\t\tpodsToSync = append(podsToSync, pod)\n\t\t\tcontinue\n\t\t}\n\t\tfor _, podSyncLoopHandler := range kl.PodSyncLoopHandlers {\n\t\t\tif podSyncLoopHandler.ShouldSync(pod) {\n\t\t\t\tpodsToSync = append(podsToSync, pod)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn podsToSync\n}"}, {"instruction": "// Run will not return until stopCh is closed. workers determines how many\n// endpoints will be handled in parallel.", "input": "go language", "output": "func (e *EndpointController) Run(workers int, stopCh <-chan struct{}) {\n\tdefer utilruntime.HandleCrash()\n\tdefer e.queue.ShutDown()\n\n\tklog.Infof(\"Starting endpoint controller\")\n\tdefer klog.Infof(\"Shutting down endpoint controller\")\n\n\tif !controller.WaitForCacheSync(\"endpoint\", stopCh, e.podsSynced, e.servicesSynced, e.endpointsSynced) {\n\t\treturn\n\t}\n\n\tfor i := 0; i < workers; i++ {\n\t\tgo wait.Until(e.worker, e.workerLoopPeriod, stopCh)\n\t}\n\n\tgo func() {\n\t\tdefer utilruntime.HandleCrash()\n\t\te.checkLeftoverEndpoints()\n\t}()\n\n\t<-stopCh\n}"}, {"instruction": "// This implementation is shared between Linux and NsEnter", "input": "go language", "output": "func safeOpenSubPath(mounter mount.Interface, subpath Subpath) (int, error) {\n\tif !mount.PathWithinBase(subpath.Path, subpath.VolumePath) {\n\t\treturn -1, fmt.Errorf(\"subpath %q not within volume path %q\", subpath.Path, subpath.VolumePath)\n\t}\n\tfd, err := doSafeOpen(subpath.Path, subpath.VolumePath)\n\tif err != nil {\n\t\treturn -1, fmt.Errorf(\"error opening subpath %v: %v\", subpath.Path, err)\n\t}\n\treturn fd, nil\n}"}, {"instruction": "// TODO: test", "input": "go language", "output": "func (n *EvalDeposeState) Eval(ctx EvalContext) (interface{}, error) {\n\tabsAddr := n.Addr.Absolute(ctx.Path())\n\tstate := ctx.State()\n\n\tvar key states.DeposedKey\n\tif n.ForceKey == states.NotDeposed {\n\t\tkey = state.DeposeResourceInstanceObject(absAddr)\n\t} else {\n\t\tkey = n.ForceKey\n\t\tstate.DeposeResourceInstanceObjectForceKey(absAddr, key)\n\t}\n\tlog.Printf(\"[TRACE] EvalDeposeState: prior object for %s now deposed with key %s\", absAddr, key)\n\n\tif n.OutputKey != nil {\n\t\t*n.OutputKey = key\n\t}\n\n\treturn nil, nil\n}"}, {"instruction": "// DiskIsAttached returns if disk is attached to the VM using controllers supported by the plugin.", "input": "go language", "output": "func (pc *PCCloud) DiskIsAttached(ctx context.Context, pdID string, nodeName k8stypes.NodeName) (bool, error) {\n\tphotonClient, err := getPhotonClient(pc)\n\tif err != nil {\n\t\tklog.Errorf(\"Photon Cloud Provider: Failed to get photon client for DiskIsAttached, error: [%v]\", err)\n\t\treturn false, err\n\t}\n\n\tdisk, err := photonClient.Disks.Get(pdID)\n\tif err != nil {\n\t\tklog.Errorf(\"Photon Cloud Provider: Failed to Get disk with pdID %s. Error[%v]\", pdID, err)\n\t\treturn false, err\n\t}\n\n\tvmID, err := pc.InstanceID(ctx, nodeName)\n\tif err == cloudprovider.InstanceNotFound {\n\t\tklog.Infof(\"Instance %q does not exist, disk %s will be detached automatically.\", nodeName, pdID)\n\t\treturn false, nil\n\t}\n\tif err != nil {\n\t\tklog.Errorf(\"Photon Cloud Provider: pc.InstanceID failed for DiskIsAttached. Error[%v]\", err)\n\t\treturn false, err\n\t}\n\n\tfor _, vm := range disk.VMs {\n\t\tif vm == vmID {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}"}, {"instruction": "// checkWhereMap handles the where-matching logic when the seqv value is a Map.", "input": "go language", "output": "func (ns *Namespace) checkWhereMap(seqv, kv, mv reflect.Value, path []string, op string) (interface{}, error) {\n\trv := reflect.MakeMap(seqv.Type())\n\tkeys := seqv.MapKeys()\n\tfor _, k := range keys {\n\t\telemv := seqv.MapIndex(k)\n\t\tswitch elemv.Kind() {\n\t\tcase reflect.Array, reflect.Slice:\n\t\t\tr, err := ns.checkWhereArray(elemv, kv, mv, path, op)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tswitch rr := reflect.ValueOf(r); rr.Kind() {\n\t\t\tcase reflect.Slice:\n\t\t\t\tif rr.Len() > 0 {\n\t\t\t\t\trv.SetMapIndex(k, elemv)\n\t\t\t\t}\n\t\t\t}\n\t\tcase reflect.Interface:\n\t\t\telemvv, isNil := indirect(elemv)\n\t\t\tif isNil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tswitch elemvv.Kind() {\n\t\t\tcase reflect.Array, reflect.Slice:\n\t\t\t\tr, err := ns.checkWhereArray(elemvv, kv, mv, path, op)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\tswitch rr := reflect.ValueOf(r); rr.Kind() {\n\t\t\t\tcase reflect.Slice:\n\t\t\t\t\tif rr.Len() > 0 {\n\t\t\t\t\t\trv.SetMapIndex(k, elemv)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn rv.Interface(), nil\n}"}, {"instruction": "// Dereference removes an existing reference from a root node.", "input": "go language", "output": "func (db *Database) Dereference(root common.Hash) {\n\t// Sanity check to ensure that the meta-root is not removed\n\tif root == (common.Hash{}) {\n\t\tlog.Error(\"Attempted to dereference the trie cache meta root\")\n\t\treturn\n\t}\n\tdb.lock.Lock()\n\tdefer db.lock.Unlock()\n\n\tnodes, storage, start := len(db.dirties), db.dirtiesSize, time.Now()\n\tdb.dereference(root, common.Hash{})\n\n\tdb.gcnodes += uint64(nodes - len(db.dirties))\n\tdb.gcsize += storage - db.dirtiesSize\n\tdb.gctime += time.Since(start)\n\n\tmemcacheGCTimeTimer.Update(time.Since(start))\n\tmemcacheGCSizeMeter.Mark(int64(storage - db.dirtiesSize))\n\tmemcacheGCNodesMeter.Mark(int64(nodes - len(db.dirties)))\n\n\tlog.Debug(\"Dereferenced trie from memory database\", \"nodes\", nodes-len(db.dirties), \"size\", storage-db.dirtiesSize, \"time\", time.Since(start),\n\t\t\"gcnodes\", db.gcnodes, \"gcsize\", db.gcsize, \"gctime\", db.gctime, \"livenodes\", len(db.dirties), \"livesize\", db.dirtiesSize)\n}"}, {"instruction": "// ConvertJSONToFloat casts JSON into float64.", "input": "go language", "output": "func ConvertJSONToFloat(sc *stmtctx.StatementContext, j json.BinaryJSON) (float64, error) {\n\tswitch j.TypeCode {\n\tcase json.TypeCodeObject, json.TypeCodeArray:\n\t\treturn 0, nil\n\tcase json.TypeCodeLiteral:\n\t\tswitch j.Value[0] {\n\t\tcase json.LiteralNil, json.LiteralFalse:\n\t\t\treturn 0, nil\n\t\tdefault:\n\t\t\treturn 1, nil\n\t\t}\n\tcase json.TypeCodeInt64:\n\t\treturn float64(j.GetInt64()), nil\n\tcase json.TypeCodeUint64:\n\t\tu, err := ConvertIntToUint(sc, j.GetInt64(), IntergerUnsignedUpperBound(mysql.TypeLonglong), mysql.TypeLonglong)\n\t\treturn float64(u), errors.Trace(err)\n\tcase json.TypeCodeFloat64:\n\t\treturn j.GetFloat64(), nil\n\tcase json.TypeCodeString:\n\t\tstr := string(hack.String(j.GetString()))\n\t\treturn StrToFloat(sc, str)\n\t}\n\treturn 0, errors.New(\"Unknown type code in JSON\")\n}"}, {"instruction": "// query callback representing the query of a chaincode", "input": "go language", "output": "func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n\tvar A string // Entities\n\tvar err error\n\n\tif len(args) != 1 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting name of the person to query\")\n\t}\n\n\tA = args[0]\n\n\t// Get the state from the ledger\n\tAvalbytes, err := stub.GetState(A)\n\tif err != nil {\n\t\tjsonResp := \"{\\\"Error\\\":\\\"Failed to get state for \" + A + \"\\\"}\"\n\t\treturn shim.Error(jsonResp)\n\t}\n\n\tif Avalbytes == nil {\n\t\tjsonResp := \"{\\\"Error\\\":\\\"Nil amount for \" + A + \"\\\"}\"\n\t\treturn shim.Error(jsonResp)\n\t}\n\n\tjsonResp := \"{\\\"Name\\\":\\\"\" + A + \"\\\",\\\"Amount\\\":\\\"\" + string(Avalbytes) + \"\\\"}\"\n\tfmt.Printf(\"Query Response:%s\\n\", jsonResp)\n\treturn shim.Success(Avalbytes)\n}"}, {"instruction": "// SetShhConfig applies shh-related command line flags to the config.", "input": "go language", "output": "func SetShhConfig(ctx *cli.Context, stack *node.Node, cfg *whisper.Config) {\n\tif ctx.GlobalIsSet(WhisperMaxMessageSizeFlag.Name) {\n\t\tcfg.MaxMessageSize = uint32(ctx.GlobalUint(WhisperMaxMessageSizeFlag.Name))\n\t}\n\tif ctx.GlobalIsSet(WhisperMinPOWFlag.Name) {\n\t\tcfg.MinimumAcceptedPOW = ctx.GlobalFloat64(WhisperMinPOWFlag.Name)\n\t}\n\tif ctx.GlobalIsSet(WhisperRestrictConnectionBetweenLightClientsFlag.Name) {\n\t\tcfg.RestrictConnectionBetweenLightClients = true\n\t}\n}"}, {"instruction": "// NewKubeConfigFilePhase creates a kubeadm workflow phase that creates a kubeconfig file.", "input": "go language", "output": "func NewKubeConfigFilePhase(kubeConfigFileName string) workflow.Phase {\n\treturn workflow.Phase{\n\t\tName:         kubeconfigFilePhaseProperties[kubeConfigFileName].name,\n\t\tShort:        kubeconfigFilePhaseProperties[kubeConfigFileName].short,\n\t\tLong:         fmt.Sprintf(kubeconfigFilePhaseProperties[kubeConfigFileName].long, kubeConfigFileName),\n\t\tRun:          runKubeConfigFile(kubeConfigFileName),\n\t\tInheritFlags: getKubeConfigPhaseFlags(kubeConfigFileName),\n\t}\n}"}, {"instruction": "// NewDefaultOptions builds a \"normal\" set of options.  You wouldn't normally expose this, but hyperkube isn't cobra compatible", "input": "go language", "output": "func NewDefaultOptions(out, err io.Writer) *AggregatorOptions {\n\to := &AggregatorOptions{\n\t\tRecommendedOptions: genericoptions.NewRecommendedOptions(\n\t\t\tdefaultEtcdPathPrefix,\n\t\t\taggregatorscheme.Codecs.LegacyCodec(v1beta1.SchemeGroupVersion),\n\t\t\tgenericoptions.NewProcessInfo(\"kube-aggregator\", \"kube-system\"),\n\t\t),\n\t\tAPIEnablement: genericoptions.NewAPIEnablementOptions(),\n\n\t\tStdOut: out,\n\t\tStdErr: err,\n\t}\n\n\treturn o\n}"}, {"instruction": "// TryLoadCertFromDisk tries to load the cert from the disk and validates that it is valid", "input": "go language", "output": "func TryLoadCertFromDisk(pkiPath, name string) (*x509.Certificate, error) {\n\tcertificatePath := pathForCert(pkiPath, name)\n\n\tcerts, err := certutil.CertsFromFile(certificatePath)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"couldn't load the certificate file %s\", certificatePath)\n\t}\n\n\t// We are only putting one certificate in the certificate pem file, so it's safe to just pick the first one\n\t// TODO: Support multiple certs here in order to be able to rotate certs\n\tcert := certs[0]\n\n\t// Check so that the certificate is valid now\n\tnow := time.Now()\n\tif now.Before(cert.NotBefore) {\n\t\treturn nil, errors.New(\"the certificate is not valid yet\")\n\t}\n\tif now.After(cert.NotAfter) {\n\t\treturn nil, errors.New(\"the certificate has expired\")\n\t}\n\n\treturn cert, nil\n}"}, {"instruction": "// RecommendedContextOverrideFlags is a convenience method to return recommended flag names prefixed with a string of your choosing", "input": "go language", "output": "func RecommendedContextOverrideFlags(prefix string) ContextOverrideFlags {\n\treturn ContextOverrideFlags{\n\t\tClusterName:  FlagInfo{prefix + FlagClusterName, \"\", \"\", \"The name of the kubeconfig cluster to use\"},\n\t\tAuthInfoName: FlagInfo{prefix + FlagAuthInfoName, \"\", \"\", \"The name of the kubeconfig user to use\"},\n\t\tNamespace:    FlagInfo{prefix + FlagNamespace, \"n\", \"\", \"If present, the namespace scope for this CLI request\"},\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *KubeProxyConntrackConfiguration) DeepCopyInto(out *KubeProxyConntrackConfiguration) {\n\t*out = *in\n\tif in.Max != nil {\n\t\tin, out := &in.Max, &out.Max\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.MaxPerCore != nil {\n\t\tin, out := &in.MaxPerCore, &out.MaxPerCore\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.Min != nil {\n\t\tin, out := &in.Min, &out.Min\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.TCPEstablishedTimeout != nil {\n\t\tin, out := &in.TCPEstablishedTimeout, &out.TCPEstablishedTimeout\n\t\t*out = new(v1.Duration)\n\t\t**out = **in\n\t}\n\tif in.TCPCloseWaitTimeout != nil {\n\t\tin, out := &in.TCPCloseWaitTimeout, &out.TCPCloseWaitTimeout\n\t\t*out = new(v1.Duration)\n\t\t**out = **in\n\t}\n\treturn\n}"}, {"instruction": "// GetCSIAttachLimitKey returns limit key used for CSI volumes", "input": "go language", "output": "func GetCSIAttachLimitKey(driverName string) string {\n\tcsiPrefixLength := len(CSIAttachLimitPrefix)\n\ttotalkeyLength := csiPrefixLength + len(driverName)\n\tif totalkeyLength >= ResourceNameLengthLimit {\n\t\tcharsFromDriverName := driverName[:23]\n\t\thash := sha1.New()\n\t\thash.Write([]byte(driverName))\n\t\thashed := hex.EncodeToString(hash.Sum(nil))\n\t\thashed = hashed[:16]\n\t\treturn CSIAttachLimitPrefix + charsFromDriverName + hashed\n\t}\n\treturn CSIAttachLimitPrefix + driverName\n}"}, {"instruction": "// evalInt evals a builtinInetAtonSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/miscellaneous-functions.html#function_inet-aton", "input": "go language", "output": "func (b *builtinInetAtonSig) evalInt(row chunk.Row) (int64, bool, error) {\n\tval, isNull, err := b.args[0].EvalString(b.ctx, row)\n\tif err != nil || isNull {\n\t\treturn 0, true, err\n\t}\n\t// ip address should not end with '.'.\n\tif len(val) == 0 || val[len(val)-1] == '.' {\n\t\treturn 0, true, nil\n\t}\n\n\tvar (\n\t\tbyteResult, result uint64\n\t\tdotCount           int\n\t)\n\tfor _, c := range val {\n\t\tif c >= '0' && c <= '9' {\n\t\t\tdigit := uint64(c - '0')\n\t\t\tbyteResult = byteResult*10 + digit\n\t\t\tif byteResult > 255 {\n\t\t\t\treturn 0, true, nil\n\t\t\t}\n\t\t} else if c == '.' {\n\t\t\tdotCount++\n\t\t\tif dotCount > 3 {\n\t\t\t\treturn 0, true, nil\n\t\t\t}\n\t\t\tresult = (result << 8) + byteResult\n\t\t\tbyteResult = 0\n\t\t} else {\n\t\t\treturn 0, true, nil\n\t\t}\n\t}\n\t// 127 \t\t-> 0.0.0.127\n\t// 127.255 \t-> 127.0.0.255\n\t// 127.256\t-> NULL\n\t// 127.2.1\t-> 127.2.0.1\n\tswitch dotCount {\n\tcase 1:\n\t\tresult <<= 8\n\t\tfallthrough\n\tcase 2:\n\t\tresult <<= 8\n\t}\n\treturn int64((result << 8) + byteResult), false, nil\n}"}, {"instruction": "// UserEvents is used to return a slice of the most recent\n// user events.", "input": "go language", "output": "func (a *Agent) UserEvents() []*UserEvent {\n\tn := len(a.eventBuf)\n\tout := make([]*UserEvent, n)\n\ta.eventLock.RLock()\n\tdefer a.eventLock.RUnlock()\n\n\t// Check if the buffer is full\n\tif a.eventBuf[a.eventIndex] != nil {\n\t\tif a.eventIndex == 0 {\n\t\t\tcopy(out, a.eventBuf)\n\t\t} else {\n\t\t\tcopy(out, a.eventBuf[a.eventIndex:])\n\t\t\tcopy(out[n-a.eventIndex:], a.eventBuf[:a.eventIndex])\n\t\t}\n\t} else {\n\t\t// We haven't filled the buffer yet\n\t\tcopy(out, a.eventBuf[:a.eventIndex])\n\t\tout = out[:a.eventIndex]\n\t}\n\treturn out\n}"}, {"instruction": "// setWS creates the WebSocket RPC listener interface string from the set\n// command line flags, returning empty if the HTTP endpoint is disabled.", "input": "go language", "output": "func setWS(ctx *cli.Context, cfg *node.Config) {\n\tif ctx.GlobalBool(WSEnabledFlag.Name) && cfg.WSHost == \"\" {\n\t\tcfg.WSHost = \"127.0.0.1\"\n\t\tif ctx.GlobalIsSet(WSListenAddrFlag.Name) {\n\t\t\tcfg.WSHost = ctx.GlobalString(WSListenAddrFlag.Name)\n\t\t}\n\t}\n\n\tif ctx.GlobalIsSet(WSPortFlag.Name) {\n\t\tcfg.WSPort = ctx.GlobalInt(WSPortFlag.Name)\n\t}\n\tif ctx.GlobalIsSet(WSAllowedOriginsFlag.Name) {\n\t\tcfg.WSOrigins = splitAndTrim(ctx.GlobalString(WSAllowedOriginsFlag.Name))\n\t}\n\tif ctx.GlobalIsSet(WSApiFlag.Name) {\n\t\tcfg.WSModules = splitAndTrim(ctx.GlobalString(WSApiFlag.Name))\n\t}\n}"}, {"instruction": "// MountVolume mounts a Portworx Volume on the specified mountPath", "input": "go language", "output": "func (util *portworxVolumeUtil) MountVolume(m *portworxVolumeMounter, mountPath string) error {\n\tdriver, err := util.getLocalPortworxDriver(m.plugin.host)\n\tif err != nil || driver == nil {\n\t\tklog.Errorf(\"Failed to get portworx driver. Err: %v\", err)\n\t\treturn err\n\t}\n\n\terr = driver.Mount(m.volName, mountPath)\n\tif err != nil {\n\t\tklog.Errorf(\"Error mounting Portworx Volume (%v) on Path (%v): %v\", m.volName, mountPath, err)\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// Returns the list of component status. Note that the label and field are both ignored.\n// Note that this call doesn't support labels or selectors.", "input": "go language", "output": "func (rs *REST) List(ctx context.Context, options *metainternalversion.ListOptions) (runtime.Object, error) {\n\tservers := rs.GetServersToValidate()\n\n\twait := sync.WaitGroup{}\n\twait.Add(len(servers))\n\tstatuses := make(chan api.ComponentStatus, len(servers))\n\tfor k, v := range servers {\n\t\tgo func(name string, server *Server) {\n\t\t\tdefer wait.Done()\n\t\t\tstatus := rs.getComponentStatus(name, server)\n\t\t\tstatuses <- *status\n\t\t}(k, v)\n\t}\n\twait.Wait()\n\tclose(statuses)\n\n\treply := []api.ComponentStatus{}\n\tfor status := range statuses {\n\t\treply = append(reply, status)\n\t}\n\treturn &api.ComponentStatusList{Items: reply}, nil\n}"}, {"instruction": "// Function to call on webhook failure; behavior determined by defaultAllow flag", "input": "go language", "output": "func (a *Plugin) webhookError(pod *api.Pod, attributes admission.Attributes, err error) error {\n\tif err != nil {\n\t\tklog.V(2).Infof(\"error contacting webhook backend: %s\", err)\n\t\tif a.defaultAllow {\n\t\t\tattributes.AddAnnotation(AuditKeyPrefix+ImagePolicyFailedOpenKeySuffix, \"true\")\n\t\t\t// TODO(wteiken): Remove the annotation code for the 1.13 release\n\t\t\tannotations := pod.GetAnnotations()\n\t\t\tif annotations == nil {\n\t\t\t\tannotations = make(map[string]string)\n\t\t\t}\n\t\t\tannotations[api.ImagePolicyFailedOpenKey] = \"true\"\n\t\t\tpod.ObjectMeta.SetAnnotations(annotations)\n\n\t\t\tklog.V(2).Infof(\"resource allowed in spite of webhook backend failure\")\n\t\t\treturn nil\n\t\t}\n\t\tklog.V(2).Infof(\"resource not allowed due to webhook backend failure \")\n\t\treturn admission.NewForbidden(attributes, err)\n\t}\n\treturn nil\n}"}, {"instruction": "// Check checks schema validity, returns true if use schemaVer and related tables at txnTS is legal.", "input": "go language", "output": "func (s *schemaValidator) Check(txnTS uint64, schemaVer int64, relatedTableIDs []int64) checkResult {\n\ts.mux.RLock()\n\tdefer s.mux.RUnlock()\n\tif !s.isStarted {\n\t\tlogutil.Logger(context.Background()).Info(\"the schema validator stopped before checking\")\n\t\treturn ResultUnknown\n\t}\n\tif s.lease == 0 {\n\t\treturn ResultSucc\n\t}\n\n\t// Schema changed, result decided by whether related tables change.\n\tif schemaVer < s.latestSchemaVer {\n\t\t// The DDL relatedTableIDs is empty.\n\t\tif len(relatedTableIDs) == 0 {\n\t\t\tlogutil.Logger(context.Background()).Info(\"the related table ID is empty\", zap.Int64(\"schemaVer\", schemaVer),\n\t\t\t\tzap.Int64(\"latestSchemaVer\", s.latestSchemaVer))\n\t\t\treturn ResultFail\n\t\t}\n\n\t\tif s.isRelatedTablesChanged(schemaVer, relatedTableIDs) {\n\t\t\treturn ResultFail\n\t\t}\n\t\treturn ResultSucc\n\t}\n\n\t// Schema unchanged, maybe success or the schema validator is unavailable.\n\tt := oracle.GetTimeFromTS(txnTS)\n\tif t.After(s.latestSchemaExpire) {\n\t\treturn ResultUnknown\n\t}\n\treturn ResultSucc\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *ShowDDLJobQueriesExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\treq.GrowAndReset(e.maxChunkSize)\n\tif e.cursor >= len(e.jobs) {\n\t\treturn nil\n\t}\n\tif len(e.jobIDs) >= len(e.jobs) {\n\t\treturn nil\n\t}\n\tnumCurBatch := mathutil.Min(req.Capacity(), len(e.jobs)-e.cursor)\n\tfor _, id := range e.jobIDs {\n\t\tfor i := e.cursor; i < e.cursor+numCurBatch; i++ {\n\t\t\tif id == e.jobs[i].ID {\n\t\t\t\treq.AppendString(0, e.jobs[i].Query)\n\t\t\t}\n\t\t}\n\t}\n\te.cursor += numCurBatch\n\treturn nil\n}"}, {"instruction": "// handleEvents is used to process incoming user events", "input": "go language", "output": "func (a *Agent) handleEvents() {\n\tfor {\n\t\tselect {\n\t\tcase e := <-a.eventCh:\n\t\t\t// Decode the event\n\t\t\tmsg := new(UserEvent)\n\t\t\tif err := decodeMsgPack(e.Payload, msg); err != nil {\n\t\t\t\ta.logger.Printf(\"[ERR] agent: Failed to decode event: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tmsg.LTime = uint64(e.LTime)\n\n\t\t\t// Skip if we don't pass filtering\n\t\t\tif !a.shouldProcessUserEvent(msg) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Ingest the event\n\t\t\ta.ingestUserEvent(msg)\n\n\t\tcase <-a.shutdownCh:\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// doExecMount calls exec(mount <what> <where>) using given exec interface.", "input": "go language", "output": "func (m *execMounter) doExecMount(source, target, fstype string, options []string) error {\n\tklog.V(5).Infof(\"Exec Mounting %s %s %s %v\", source, target, fstype, options)\n\tmountArgs := mount.MakeMountArgs(source, target, fstype, options)\n\toutput, err := m.exec.Run(\"mount\", mountArgs...)\n\tklog.V(5).Infof(\"Exec mounted %v: %v: %s\", mountArgs, err, string(output))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"mount failed: %v\\nMounting command: %s\\nMounting arguments: %s %s %s %v\\nOutput: %s\",\n\t\t\terr, \"mount\", source, target, fstype, options, string(output))\n\t}\n\n\treturn err\n}"}, {"instruction": "// GetNetworks returns a list of all networks", "input": "go language", "output": "func (daemon *Daemon) GetNetworks(filter filters.Args, config types.NetworkListConfig) ([]types.NetworkResource, error) {\n\tnetworks := daemon.getAllNetworks()\n\n\tlist := make([]types.NetworkResource, 0, len(networks))\n\tvar idx map[string]libnetwork.Network\n\tif config.Detailed {\n\t\tidx = make(map[string]libnetwork.Network)\n\t}\n\n\tfor _, n := range networks {\n\t\tnr := buildNetworkResource(n)\n\t\tlist = append(list, nr)\n\t\tif config.Detailed {\n\t\t\tidx[nr.ID] = n\n\t\t}\n\t}\n\n\tvar err error\n\tlist, err = internalnetwork.FilterNetworks(list, filter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif config.Detailed {\n\t\tfor i, n := range list {\n\t\t\tnp := &n\n\t\t\tbuildDetailedNetworkResources(np, idx[n.ID], config.Verbose)\n\t\t\tlist[i] = *np\n\t\t}\n\t}\n\n\treturn list, nil\n}"}, {"instruction": "// printPodsMultilineWithIndent prints multiple pods with a user-defined alignment.", "input": "go language", "output": "func printPodsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, pods []corev1.Pod) {\n\tw.Write(LEVEL_0, \"%s%s:%s\", initialIndent, title, innerIndent)\n\n\tif pods == nil || len(pods) == 0 {\n\t\tw.WriteLine(\"<none>\")\n\t\treturn\n\t}\n\n\t// to print pods in the sorted order\n\tsort.Slice(pods, func(i, j int) bool {\n\t\tcmpKey := func(pod corev1.Pod) string {\n\t\t\treturn pod.Name\n\t\t}\n\t\treturn cmpKey(pods[i]) < cmpKey(pods[j])\n\t})\n\n\tfor i, pod := range pods {\n\t\tif i != 0 {\n\t\t\tw.Write(LEVEL_0, \"%s\", initialIndent)\n\t\t\tw.Write(LEVEL_0, \"%s\", innerIndent)\n\t\t}\n\t\tw.Write(LEVEL_0, \"%s\\n\", pod.Name)\n\t}\n}"}, {"instruction": "// NewKubeletStartPhase creates a kubeadm workflow phase that start kubelet on a node.", "input": "go language", "output": "func NewKubeletStartPhase() workflow.Phase {\n\treturn workflow.Phase{\n\t\tName:  \"kubelet-start [api-server-endpoint]\",\n\t\tShort: \"Write kubelet settings, certificates and (re)start the kubelet\",\n\t\tLong:  \"Write a file with KubeletConfiguration and an environment file with node specific kubelet settings, and then (re)start kubelet.\",\n\t\tRun:   runKubeletStartJoinPhase,\n\t\tInheritFlags: []string{\n\t\t\toptions.CfgPath,\n\t\t\toptions.NodeCRISocket,\n\t\t\toptions.NodeName,\n\t\t\toptions.FileDiscovery,\n\t\t\toptions.TokenDiscovery,\n\t\t\toptions.TokenDiscoveryCAHash,\n\t\t\toptions.TokenDiscoverySkipCAHash,\n\t\t\toptions.TLSBootstrapToken,\n\t\t\toptions.TokenStr,\n\t\t},\n\t}\n}"}, {"instruction": "// defaultProxyCommand returns the default Connect managed proxy command.", "input": "go language", "output": "func defaultProxyCommand(agentCfg *config.RuntimeConfig) ([]string, error) {\n\t// Get the path to the current executable. This is cached once by the\n\t// library so this is effectively just a variable read.\n\texecPath, err := os.Executable()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// \"consul connect proxy\" default value for managed daemon proxy\n\tcmd := []string{execPath, \"connect\", \"proxy\"}\n\n\tif agentCfg != nil && agentCfg.LogLevel != \"INFO\" {\n\t\tcmd = append(cmd, \"-log-level\", agentCfg.LogLevel)\n\t}\n\treturn cmd, nil\n}"}, {"instruction": "// Collect implements prometheus.Collector\n// Since new containers are frequently created and removed, using the prometheus.Gauge Collector would\n// leak metric collectors for containers or pods that no longer exist.  Instead, implement\n// prometheus.Collector in a way that only collects metrics for active containers.", "input": "go language", "output": "func (rc *resourceMetricCollector) Collect(ch chan<- prometheus.Metric) {\n\trc.errors.Set(0)\n\tdefer rc.errors.Collect(ch)\n\tsummary, err := rc.provider.GetCPUAndMemoryStats()\n\tif err != nil {\n\t\trc.errors.Set(1)\n\t\tklog.Warningf(\"Error getting summary for resourceMetric prometheus endpoint: %v\", err)\n\t\treturn\n\t}\n\n\tfor _, metric := range rc.config.NodeMetrics {\n\t\tif value, timestamp := metric.ValueFn(summary.Node); value != nil {\n\t\t\tch <- prometheus.NewMetricWithTimestamp(timestamp,\n\t\t\t\tprometheus.MustNewConstMetric(metric.desc(), prometheus.GaugeValue, *value))\n\t\t}\n\t}\n\n\tfor _, pod := range summary.Pods {\n\t\tfor _, container := range pod.Containers {\n\t\t\tfor _, metric := range rc.config.ContainerMetrics {\n\t\t\t\tif value, timestamp := metric.ValueFn(container); value != nil {\n\t\t\t\t\tch <- prometheus.NewMetricWithTimestamp(timestamp,\n\t\t\t\t\t\tprometheus.MustNewConstMetric(metric.desc(), prometheus.GaugeValue, *value, container.Name, pod.PodRef.Name, pod.PodRef.Namespace))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// CommonAccessor returns a Common interface for the provided object or an error if the object does\n// not provide List.", "input": "go language", "output": "func CommonAccessor(obj interface{}) (metav1.Common, error) {\n\tswitch t := obj.(type) {\n\tcase List:\n\t\treturn t, nil\n\tcase metav1.ListInterface:\n\t\treturn t, nil\n\tcase ListMetaAccessor:\n\t\tif m := t.GetListMeta(); m != nil {\n\t\t\treturn m, nil\n\t\t}\n\t\treturn nil, errNotCommon\n\tcase metav1.ListMetaAccessor:\n\t\tif m := t.GetListMeta(); m != nil {\n\t\t\treturn m, nil\n\t\t}\n\t\treturn nil, errNotCommon\n\tcase metav1.Object:\n\t\treturn t, nil\n\tcase metav1.ObjectMetaAccessor:\n\t\tif m := t.GetObjectMeta(); m != nil {\n\t\t\treturn m, nil\n\t\t}\n\t\treturn nil, errNotCommon\n\tdefault:\n\t\treturn nil, errNotCommon\n\t}\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *ShowExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\treq.GrowAndReset(e.maxChunkSize)\n\tif e.result == nil {\n\t\te.result = e.newFirstChunk()\n\t\terr := e.fetchAll()\n\t\tif err != nil {\n\t\t\treturn errors.Trace(err)\n\t\t}\n\t\titer := chunk.NewIterator4Chunk(e.result)\n\t\tfor colIdx := 0; colIdx < e.Schema().Len(); colIdx++ {\n\t\t\tretType := e.Schema().Columns[colIdx].RetType\n\t\t\tif !types.IsTypeVarchar(retType.Tp) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor row := iter.Begin(); row != iter.End(); row = iter.Next() {\n\t\t\t\tif valLen := len(row.GetString(colIdx)); retType.Flen < valLen {\n\t\t\t\t\tretType.Flen = valLen\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif e.cursor >= e.result.NumRows() {\n\t\treturn nil\n\t}\n\tnumCurBatch := mathutil.Min(req.Capacity(), e.result.NumRows()-e.cursor)\n\treq.Append(e.result, e.cursor, e.cursor+numCurBatch)\n\te.cursor += numCurBatch\n\treturn nil\n}"}, {"instruction": "// IPRange returns a SchemaValidateFunc which tests if the provided value\n// is of type string, and in valid IP range notation", "input": "go language", "output": "func IPRange() schema.SchemaValidateFunc {\n\treturn func(i interface{}, k string) (s []string, es []error) {\n\t\tv, ok := i.(string)\n\t\tif !ok {\n\t\t\tes = append(es, fmt.Errorf(\"expected type of %s to be string\", k))\n\t\t\treturn\n\t\t}\n\n\t\tips := strings.Split(v, \"-\")\n\t\tif len(ips) != 2 {\n\t\t\tes = append(es, fmt.Errorf(\n\t\t\t\t\"expected %s to contain a valid IP range, got: %s\", k, v))\n\t\t\treturn\n\t\t}\n\t\tip1 := net.ParseIP(ips[0])\n\t\tip2 := net.ParseIP(ips[1])\n\t\tif ip1 == nil || ip2 == nil || bytes.Compare(ip1, ip2) > 0 {\n\t\t\tes = append(es, fmt.Errorf(\n\t\t\t\t\"expected %s to contain a valid IP range, got: %s\", k, v))\n\t\t}\n\t\treturn\n\t}\n}"}, {"instruction": "// deleteDupKeys picks primary/unique key-value pairs from rows and remove them from the dupKVs", "input": "go language", "output": "func (b *batchChecker) deleteDupKeys(ctx sessionctx.Context, t table.Table, rows [][]types.Datum) error {\n\tcleanupRows, err := b.getKeysNeedCheck(ctx, t, rows)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, row := range cleanupRows {\n\t\tif row.handleKey != nil {\n\t\t\tdelete(b.dupKVs, string(row.handleKey.newKV.key))\n\t\t}\n\t\tfor _, uk := range row.uniqueKeys {\n\t\t\tdelete(b.dupKVs, string(uk.newKV.key))\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// tar2ext4Actual is the implementation of tar2ext to write a layer from a tar file.\n// It can be called through re-exec (default), or inline for debugging.", "input": "go language", "output": "func tar2ext4Actual(dest string, diff io.Reader) (int64, error) {\n\t// maxDiskSize is not relating to the sandbox size - this is the\n\t// maximum possible size a layer VHD generated can be from an EXT4\n\t// layout perspective.\n\tconst maxDiskSize = 128 * 1024 * 1024 * 1024 // 128GB\n\tout, err := os.Create(dest)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tdefer out.Close()\n\tif err := tar2ext4.Convert(\n\t\tdiff,\n\t\tout,\n\t\ttar2ext4.AppendVhdFooter,\n\t\ttar2ext4.ConvertWhiteout,\n\t\ttar2ext4.MaximumDiskSize(maxDiskSize)); err != nil {\n\t\treturn 0, err\n\t}\n\tfi, err := os.Stat(dest)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn fi.Size(), nil\n}"}, {"instruction": "// check if message is in the cache", "input": "go language", "output": "func (p *Pss) checkFwdCache(msg *PssMsg) bool {\n\tp.fwdCacheMu.Lock()\n\tdefer p.fwdCacheMu.Unlock()\n\n\tdigest := p.digest(msg)\n\tentry, ok := p.fwdCache[digest]\n\tif ok {\n\t\tif entry.expiresAt.After(time.Now()) {\n\t\t\tlog.Trace(\"unexpired cache\", \"digest\", fmt.Sprintf(\"%x\", digest))\n\t\t\tmetrics.GetOrRegisterCounter(\"pss.checkfwdcache.unexpired\", nil).Inc(1)\n\t\t\treturn true\n\t\t}\n\t\tmetrics.GetOrRegisterCounter(\"pss.checkfwdcache.expired\", nil).Inc(1)\n\t}\n\treturn false\n}"}, {"instruction": "// NotSupported returns a *Error indicating \"unsupported value\".\n// This is used to report unknown values for enumerated fields (e.g. a list of\n// valid values).", "input": "go language", "output": "func NotSupported(field *Path, value interface{}, validValues []string) *Error {\n\tdetail := \"\"\n\tif validValues != nil && len(validValues) > 0 {\n\t\tquotedValues := make([]string, len(validValues))\n\t\tfor i, v := range validValues {\n\t\t\tquotedValues[i] = strconv.Quote(v)\n\t\t}\n\t\tdetail = \"supported values: \" + strings.Join(quotedValues, \", \")\n\t}\n\treturn &Error{ErrorTypeNotSupported, field.String(), value, detail}\n}"}, {"instruction": "// NewTransaction creates a new transaction with the given properties. Contracts\n// can be created by transacting with a nil recipient.", "input": "go language", "output": "func NewTransaction(nonce int64, to *Address, amount *BigInt, gasLimit int64, gasPrice *BigInt, data []byte) *Transaction {\n\tif to == nil {\n\t\treturn &Transaction{types.NewContractCreation(uint64(nonce), amount.bigint, uint64(gasLimit), gasPrice.bigint, common.CopyBytes(data))}\n\t}\n\treturn &Transaction{types.NewTransaction(uint64(nonce), to.address, amount.bigint, uint64(gasLimit), gasPrice.bigint, common.CopyBytes(data))}\n}"}, {"instruction": "// NewV1Endpoint parses the given address to return a registry endpoint.", "input": "go language", "output": "func NewV1Endpoint(index *registrytypes.IndexInfo, userAgent string, metaHeaders http.Header) (*V1Endpoint, error) {\n\ttlsConfig, err := newTLSConfig(index.Name, index.Secure)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tendpoint, err := newV1EndpointFromStr(GetAuthConfigKey(index), tlsConfig, userAgent, metaHeaders)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := validateEndpoint(endpoint); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn endpoint, nil\n}"}, {"instruction": "// ParseHost and set defaults for a Daemon host string.\n// defaultToTLS is preferred over defaultToUnixXDG.", "input": "go language", "output": "func ParseHost(defaultToTLS, defaultToUnixXDG bool, val string) (string, error) {\n\thost := strings.TrimSpace(val)\n\tif host == \"\" {\n\t\tif defaultToTLS {\n\t\t\thost = DefaultTLSHost\n\t\t} else if defaultToUnixXDG {\n\t\t\truntimeDir, err := homedir.GetRuntimeDir()\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\t\t\tsocket := filepath.Join(runtimeDir, \"docker.sock\")\n\t\t\thost = \"unix://\" + socket\n\t\t} else {\n\t\t\thost = DefaultHost\n\t\t}\n\t} else {\n\t\tvar err error\n\t\thost, err = parseDaemonHost(host)\n\t\tif err != nil {\n\t\t\treturn val, err\n\t\t}\n\t}\n\treturn host, nil\n}"}, {"instruction": "// New creates a function that can be used\n// to inject a script tag for the livereload JavaScript in a HTML document.", "input": "go language", "output": "func New(port int) transform.Transformer {\n\treturn func(ft transform.FromTo) error {\n\t\tb := ft.From().Bytes()\n\t\tendBodyTag := \"</body>\"\n\t\tmatch := []byte(endBodyTag)\n\t\treplaceTemplate := `<script data-no-instant>document.write('<script src=\"/livereload.js?port=%d&mindelay=10\"></' + 'script>')</script>%s`\n\t\treplace := []byte(fmt.Sprintf(replaceTemplate, port, endBodyTag))\n\n\t\tnewcontent := bytes.Replace(b, match, replace, 1)\n\t\tif len(newcontent) == len(b) {\n\t\t\tendBodyTag = \"</BODY>\"\n\t\t\treplace := []byte(fmt.Sprintf(replaceTemplate, port, endBodyTag))\n\t\t\tmatch := []byte(endBodyTag)\n\t\t\tnewcontent = bytes.Replace(b, match, replace, 1)\n\t\t}\n\n\t\tif _, err := ft.To().Write(newcontent); err != nil {\n\t\t\thelpers.DistinctWarnLog.Println(\"Failed to inject LiveReload script:\", err)\n\t\t}\n\t\treturn nil\n\t}\n}"}, {"instruction": "// cleanupAssumedPods exists for making test deterministic by taking time as input argument.", "input": "go language", "output": "func (cache *schedulerCache) cleanupAssumedPods(now time.Time) {\n\tcache.mu.Lock()\n\tdefer cache.mu.Unlock()\n\n\t// The size of assumedPods should be small\n\tfor key := range cache.assumedPods {\n\t\tps, ok := cache.podStates[key]\n\t\tif !ok {\n\t\t\tpanic(\"Key found in assumed set but not in podStates. Potentially a logical error.\")\n\t\t}\n\t\tif !ps.bindingFinished {\n\t\t\tklog.V(3).Infof(\"Couldn't expire cache for pod %v/%v. Binding is still in progress.\",\n\t\t\t\tps.pod.Namespace, ps.pod.Name)\n\t\t\tcontinue\n\t\t}\n\t\tif now.After(*ps.deadline) {\n\t\t\tklog.Warningf(\"Pod %s/%s expired\", ps.pod.Namespace, ps.pod.Name)\n\t\t\tif err := cache.expirePod(key, ps); err != nil {\n\t\t\t\tklog.Errorf(\"ExpirePod failed for %s: %v\", key, err)\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ObjectMetricStatus) DeepCopyInto(out *ObjectMetricStatus) {\n\t*out = *in\n\tout.Target = in.Target\n\tout.CurrentValue = in.CurrentValue.DeepCopy()\n\tif in.Selector != nil {\n\t\tin, out := &in.Selector, &out.Selector\n\t\t*out = new(v1.LabelSelector)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.AverageValue != nil {\n\t\tin, out := &in.AverageValue, &out.AverageValue\n\t\tx := (*in).DeepCopy()\n\t\t*out = &x\n\t}\n\treturn\n}"}, {"instruction": "// UnlockAccount will unlock the account associated with the given address with\n// the given password for duration seconds. If duration is nil it will use a\n// default of 300 seconds. It returns an indication if the account was unlocked.", "input": "go language", "output": "func (s *PrivateAccountAPI) UnlockAccount(ctx context.Context, addr common.Address, password string, duration *uint64) (bool, error) {\n\t// When the API is exposed by external RPC(http, ws etc), unless the user\n\t// explicitly specifies to allow the insecure account unlocking, otherwise\n\t// it is disabled.\n\tif s.b.ExtRPCEnabled() && !s.b.AccountManager().Config().InsecureUnlockAllowed {\n\t\treturn false, errors.New(\"account unlock with HTTP access is forbidden\")\n\t}\n\n\tconst max = uint64(time.Duration(math.MaxInt64) / time.Second)\n\tvar d time.Duration\n\tif duration == nil {\n\t\td = 300 * time.Second\n\t} else if *duration > max {\n\t\treturn false, errors.New(\"unlock duration too large\")\n\t} else {\n\t\td = time.Duration(*duration) * time.Second\n\t}\n\terr := fetchKeystore(s.am).TimedUnlock(accounts.Account{Address: addr}, password, d)\n\tif err != nil {\n\t\tlog.Warn(\"Failed account unlock attempt\", \"address\", addr, \"err\", err)\n\t}\n\treturn err == nil, err\n}"}, {"instruction": "// Next moves the cursor to next block and returns true iff the iterator is not exhausted", "input": "go language", "output": "func (itr *blocksItr) Next() (ledger.QueryResult, error) {\n\tif itr.maxBlockNumAvailable < itr.blockNumToRetrieve {\n\t\titr.maxBlockNumAvailable = itr.waitForBlock(itr.blockNumToRetrieve)\n\t}\n\titr.closeMarkerLock.Lock()\n\tdefer itr.closeMarkerLock.Unlock()\n\tif itr.closeMarker {\n\t\treturn nil, nil\n\t}\n\tif itr.stream == nil {\n\t\tlogger.Debugf(\"Initializing block stream for iterator. itr.maxBlockNumAvailable=%d\", itr.maxBlockNumAvailable)\n\t\tif err := itr.initStream(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tnextBlockBytes, err := itr.stream.nextBlockBytes()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\titr.blockNumToRetrieve++\n\treturn deserializeBlock(nextBlockBytes)\n}"}, {"instruction": "// newTerminalPrompter creates a liner based user input prompter working off the\n// standard input and output streams.", "input": "go language", "output": "func newTerminalPrompter() *terminalPrompter {\n\tp := new(terminalPrompter)\n\t// Get the original mode before calling NewLiner.\n\t// This is usually regular \"cooked\" mode where characters echo.\n\tnormalMode, _ := liner.TerminalMode()\n\t// Turn on liner. It switches to raw mode.\n\tp.State = liner.NewLiner()\n\trawMode, err := liner.TerminalMode()\n\tif err != nil || !liner.TerminalSupported() {\n\t\tp.supported = false\n\t} else {\n\t\tp.supported = true\n\t\tp.normalMode = normalMode\n\t\tp.rawMode = rawMode\n\t\t// Switch back to normal mode while we're not prompting.\n\t\tnormalMode.ApplyMode()\n\t}\n\tp.SetCtrlCAborts(true)\n\tp.SetTabCompletionStyle(liner.TabPrints)\n\tp.SetMultiLineMode(true)\n\treturn p\n}"}, {"instruction": "// podKiller launches a goroutine to kill a pod received from the channel if\n// another goroutine isn't already in action.", "input": "go language", "output": "func (kl *Kubelet) podKiller() {\n\tkilling := sets.NewString()\n\t// guard for the killing set\n\tlock := sync.Mutex{}\n\tfor podPair := range kl.podKillingCh {\n\t\trunningPod := podPair.RunningPod\n\t\tapiPod := podPair.APIPod\n\n\t\tlock.Lock()\n\t\texists := killing.Has(string(runningPod.ID))\n\t\tif !exists {\n\t\t\tkilling.Insert(string(runningPod.ID))\n\t\t}\n\t\tlock.Unlock()\n\n\t\tif !exists {\n\t\t\tgo func(apiPod *v1.Pod, runningPod *kubecontainer.Pod) {\n\t\t\t\tklog.V(2).Infof(\"Killing unwanted pod %q\", runningPod.Name)\n\t\t\t\terr := kl.killPod(apiPod, runningPod, nil, nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\tklog.Errorf(\"Failed killing the pod %q: %v\", runningPod.Name, err)\n\t\t\t\t}\n\t\t\t\tlock.Lock()\n\t\t\t\tkilling.Delete(string(runningPod.ID))\n\t\t\t\tlock.Unlock()\n\t\t\t}(apiPod, runningPod)\n\t\t}\n\t}\n}"}, {"instruction": "// MergeSchema will merge two schema into one schema. We shouldn't need to consider unique keys.\n// That will be processed in build_key_info.go.", "input": "go language", "output": "func MergeSchema(lSchema, rSchema *Schema) *Schema {\n\tif lSchema == nil && rSchema == nil {\n\t\treturn nil\n\t}\n\tif lSchema == nil {\n\t\treturn rSchema.Clone()\n\t}\n\tif rSchema == nil {\n\t\treturn lSchema.Clone()\n\t}\n\ttmpL := lSchema.Clone()\n\ttmpR := rSchema.Clone()\n\tret := NewSchema(append(tmpL.Columns, tmpR.Columns...)...)\n\tret.TblID2Handle = tmpL.TblID2Handle\n\tfor id, cols := range tmpR.TblID2Handle {\n\t\tif _, ok := ret.TblID2Handle[id]; ok {\n\t\t\tret.TblID2Handle[id] = append(ret.TblID2Handle[id], cols...)\n\t\t} else {\n\t\t\tret.TblID2Handle[id] = cols\n\t\t}\n\t}\n\treturn ret\n}"}, {"instruction": "// Get performs an HTTP GET and returns the bytes and/or an error. Any non-200\n// return code is returned as an error.", "input": "go language", "output": "func (p *Process) Get(path string) ([]byte, error) {\n\tclient := &http.Client{\n\t\tTimeout: 30 * time.Second,\n\t\tTransport: &http.Transport{\n\t\t\tDial:              dialer.Dial,\n\t\t\tProxy:             http.ProxyFromEnvironment,\n\t\t\tDisableKeepAlives: true,\n\t\t},\n\t}\n\n\turl := fmt.Sprintf(\"http://%s%s\", p.addr, path)\n\treq, err := http.NewRequest(\"GET\", url, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq.Header.Add(\"X-API-Key\", APIKey)\n\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn p.readResponse(resp)\n}"}, {"instruction": "// StrategicMergeMapPatch applies a strategic merge patch. The original and patch documents\n// must be JSONMap. A patch can be created from an original and modified document by\n// calling CreateTwoWayMergeMapPatch.\n// Warning: the original and patch JSONMap objects are mutated by this function and should not be reused.", "input": "go language", "output": "func StrategicMergeMapPatch(original, patch JSONMap, dataStruct interface{}) (JSONMap, error) {\n\tschema, err := NewPatchMetaFromStruct(dataStruct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We need the go struct tags `patchMergeKey` and `patchStrategy` for fields that support a strategic merge patch.\n\t// For native resources, we can easily figure out these tags since we know the fields.\n\n\t// Because custom resources are decoded as Unstructured and because we're missing the metadata about how to handle\n\t// each field in a strategic merge patch, we can't find the go struct tags. Hence, we can't easily  do a strategic merge\n\t// for custom resources. So we should fail fast and return an error.\n\tif _, ok := dataStruct.(*unstructured.Unstructured); ok {\n\t\treturn nil, mergepatch.ErrUnsupportedStrategicMergePatchFormat\n\t}\n\n\treturn StrategicMergeMapPatchUsingLookupPatchMeta(original, patch, schema)\n}"}, {"instruction": "// Insert the given request into the cache and returns the token used for fetching it out.", "input": "go language", "output": "func (c *requestCache) Insert(req request) (token string, err error) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\t// Remove expired entries.\n\tc.gc()\n\t// If the cache is full, reject the request.\n\tif c.ll.Len() == maxInFlight {\n\t\treturn \"\", NewErrorTooManyInFlight()\n\t}\n\ttoken, err = c.uniqueToken()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tele := c.ll.PushFront(&cacheEntry{token, req, c.clock.Now().Add(cacheTTL)})\n\n\tc.tokens[token] = ele\n\treturn token, nil\n}"}, {"instruction": "// incGCSizeInBatch changes gcSize field value\n// by change which can be negative. This function\n// must be called under batchMu lock.", "input": "go language", "output": "func (db *DB) incGCSizeInBatch(batch *leveldb.Batch, change int64) (err error) {\n\tif change == 0 {\n\t\treturn nil\n\t}\n\tgcSize, err := db.gcSize.Get()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar new uint64\n\tif change > 0 {\n\t\tnew = gcSize + uint64(change)\n\t} else {\n\t\t// 'change' is an int64 and is negative\n\t\t// a conversion is needed with correct sign\n\t\tc := uint64(-change)\n\t\tif c > gcSize {\n\t\t\t// protect uint64 undeflow\n\t\t\treturn nil\n\t\t}\n\t\tnew = gcSize - c\n\t}\n\tdb.gcSize.PutInBatch(batch, new)\n\n\t// trigger garbage collection if we reached the capacity\n\tif new >= db.capacity {\n\t\tdb.triggerGarbageCollection()\n\t}\n\treturn nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *CustomResourceDefinitionVersion) DeepCopyInto(out *CustomResourceDefinitionVersion) {\n\t*out = *in\n\tif in.Schema != nil {\n\t\tin, out := &in.Schema, &out.Schema\n\t\t*out = new(CustomResourceValidation)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.Subresources != nil {\n\t\tin, out := &in.Subresources, &out.Subresources\n\t\t*out = new(CustomResourceSubresources)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.AdditionalPrinterColumns != nil {\n\t\tin, out := &in.AdditionalPrinterColumns, &out.AdditionalPrinterColumns\n\t\t*out = make([]CustomResourceColumnDefinition, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\treturn\n}"}, {"instruction": "// IntrinsicGas computes the 'intrinsic gas' for a message with the given data.", "input": "go language", "output": "func IntrinsicGas(data []byte, contractCreation, homestead bool) (uint64, error) {\n\t// Set the starting gas for the raw transaction\n\tvar gas uint64\n\tif contractCreation && homestead {\n\t\tgas = params.TxGasContractCreation\n\t} else {\n\t\tgas = params.TxGas\n\t}\n\t// Bump the required gas by the amount of transactional data\n\tif len(data) > 0 {\n\t\t// Zero and non-zero bytes are priced differently\n\t\tvar nz uint64\n\t\tfor _, byt := range data {\n\t\t\tif byt != 0 {\n\t\t\t\tnz++\n\t\t\t}\n\t\t}\n\t\t// Make sure we don't exceed uint64 for all data combinations\n\t\tif (math.MaxUint64-gas)/params.TxDataNonZeroGas < nz {\n\t\t\treturn 0, vm.ErrOutOfGas\n\t\t}\n\t\tgas += nz * params.TxDataNonZeroGas\n\n\t\tz := uint64(len(data)) - nz\n\t\tif (math.MaxUint64-gas)/params.TxDataZeroGas < z {\n\t\t\treturn 0, vm.ErrOutOfGas\n\t\t}\n\t\tgas += z * params.TxDataZeroGas\n\t}\n\treturn gas, nil\n}"}, {"instruction": "// StartWSEndpoint starts a websocket endpoint", "input": "go language", "output": "func StartWSEndpoint(endpoint string, apis []API, modules []string, wsOrigins []string, exposeAll bool) (net.Listener, *Server, error) {\n\n\t// Generate the whitelist based on the allowed modules\n\twhitelist := make(map[string]bool)\n\tfor _, module := range modules {\n\t\twhitelist[module] = true\n\t}\n\t// Register all the APIs exposed by the services\n\thandler := NewServer()\n\tfor _, api := range apis {\n\t\tif exposeAll || whitelist[api.Namespace] || (len(whitelist) == 0 && api.Public) {\n\t\t\tif err := handler.RegisterName(api.Namespace, api.Service); err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tlog.Debug(\"WebSocket registered\", \"service\", api.Service, \"namespace\", api.Namespace)\n\t\t}\n\t}\n\t// All APIs registered, start the HTTP listener\n\tvar (\n\t\tlistener net.Listener\n\t\terr      error\n\t)\n\tif listener, err = net.Listen(\"tcp\", endpoint); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tgo NewWSServer(wsOrigins, handler).Serve(listener)\n\treturn listener, handler, err\n\n}"}, {"instruction": "// NewECDSASignerEntity returns a signer entity that is capable of signing using ECDSA", "input": "go language", "output": "func NewECDSASignerEntity(ID string, b bccsp.BCCSP, signKeyBytes []byte) (*BCCSPSignerEntity, error) {\n\tif b == nil {\n\t\treturn nil, errors.New(\"nil BCCSP\")\n\t}\n\n\tbl, _ := pem.Decode(signKeyBytes)\n\tif bl == nil {\n\t\treturn nil, errors.New(\"pem.Decode returns nil\")\n\t}\n\n\tsignKey, err := b.KeyImport(bl.Bytes, &bccsp.ECDSAPrivateKeyImportOpts{Temporary: true})\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, \"bccspInst.KeyImport failed\")\n\t}\n\n\treturn NewSignerEntity(ID, b, signKey, nil, &bccsp.SHA256Opts{})\n}"}, {"instruction": "// convertFakeContainer converts the fake container to real container", "input": "go language", "output": "func convertFakeContainer(f *FakeContainer) *dockertypes.ContainerJSON {\n\tif f.Config == nil {\n\t\tf.Config = &dockercontainer.Config{}\n\t}\n\tif f.HostConfig == nil {\n\t\tf.HostConfig = &dockercontainer.HostConfig{}\n\t}\n\treturn &dockertypes.ContainerJSON{\n\t\tContainerJSONBase: &dockertypes.ContainerJSONBase{\n\t\t\tID:    f.ID,\n\t\t\tName:  f.Name,\n\t\t\tImage: f.Config.Image,\n\t\t\tState: &dockertypes.ContainerState{\n\t\t\t\tRunning:    f.Running,\n\t\t\t\tExitCode:   f.ExitCode,\n\t\t\t\tPid:        f.Pid,\n\t\t\t\tStartedAt:  dockerTimestampToString(f.StartedAt),\n\t\t\t\tFinishedAt: dockerTimestampToString(f.FinishedAt),\n\t\t\t},\n\t\t\tCreated:    dockerTimestampToString(f.CreatedAt),\n\t\t\tHostConfig: f.HostConfig,\n\t\t},\n\t\tConfig:          f.Config,\n\t\tNetworkSettings: &dockertypes.NetworkSettings{},\n\t}\n}"}, {"instruction": "// GetFilterMessages returns the messages that match the filter criteria and\n// are received between the last poll and now.", "input": "go language", "output": "func (api *PublicWhisperAPI) GetFilterMessages(id string) ([]*Message, error) {\n\tapi.mu.Lock()\n\tf := api.w.GetFilter(id)\n\tif f == nil {\n\t\tapi.mu.Unlock()\n\t\treturn nil, fmt.Errorf(\"filter not found\")\n\t}\n\tapi.lastUsed[id] = time.Now()\n\tapi.mu.Unlock()\n\n\treceivedMessages := f.Retrieve()\n\tmessages := make([]*Message, 0, len(receivedMessages))\n\tfor _, msg := range receivedMessages {\n\t\tmessages = append(messages, ToWhisperMessage(msg))\n\t}\n\n\treturn messages, nil\n}"}, {"instruction": "// Validate makes sure provided values for EnvOptions are valid", "input": "go language", "output": "func (o *EnvOptions) Validate() error {\n\tif len(o.Filenames) == 0 && len(o.resources) < 1 {\n\t\treturn fmt.Errorf(\"one or more resources must be specified as <resource> <name> or <resource>/<name>\")\n\t}\n\tif o.List && len(o.output) > 0 {\n\t\treturn fmt.Errorf(\"--list and --output may not be specified together\")\n\t}\n\tif len(o.Keys) > 0 && len(o.From) == 0 {\n\t\treturn fmt.Errorf(\"when specifying --keys, a configmap or secret must be provided with --from\")\n\t}\n\treturn nil\n}"}, {"instruction": "// DeepCopy returns a new resource state that contains equivalent data to the\n// receiver but shares no backing memory in common.\n//\n// As with all methods on Resource, this method is not safe to use concurrently\n// with writing to any portion of the recieving data structure. It is the\n// caller's responsibility to ensure mutual exclusion for the duration of the\n// operation, but may then freely modify the receiver and the returned copy\n// independently once this method returns.", "input": "go language", "output": "func (rs *Resource) DeepCopy() *Resource {\n\tif rs == nil {\n\t\treturn nil\n\t}\n\n\tinstances := make(map[addrs.InstanceKey]*ResourceInstance, len(rs.Instances))\n\tfor k, i := range rs.Instances {\n\t\tinstances[k] = i.DeepCopy()\n\t}\n\n\treturn &Resource{\n\t\tAddr:           rs.Addr,\n\t\tEachMode:       rs.EachMode,\n\t\tInstances:      instances,\n\t\tProviderConfig: rs.ProviderConfig, // technically mutable, but immutable by convention\n\t}\n}"}, {"instruction": "// evalDecimal evals a builtinCaseWhenDecimalSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/case.html", "input": "go language", "output": "func (b *builtinCaseWhenDecimalSig) evalDecimal(row chunk.Row) (ret *types.MyDecimal, isNull bool, err error) {\n\tvar condition int64\n\targs, l := b.getArgs(), len(b.getArgs())\n\tfor i := 0; i < l-1; i += 2 {\n\t\tcondition, isNull, err = args[i].EvalInt(b.ctx, row)\n\t\tif err != nil {\n\t\t\treturn nil, isNull, err\n\t\t}\n\t\tif isNull || condition == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tret, isNull, err = args[i+1].EvalDecimal(b.ctx, row)\n\t\treturn ret, isNull, err\n\t}\n\t// when clause(condition, result) -> args[i], args[i+1]; (i >= 0 && i+1 < l-1)\n\t// else clause -> args[l-1]\n\t// If case clause has else clause, l%2 == 1.\n\tif l%2 == 1 {\n\t\tret, isNull, err = args[l-1].EvalDecimal(b.ctx, row)\n\t\treturn ret, isNull, err\n\t}\n\treturn ret, true, nil\n}"}, {"instruction": "// evalTime evals DATE(expr).\n// See https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_date", "input": "go language", "output": "func (b *builtinDateSig) evalTime(row chunk.Row) (types.Time, bool, error) {\n\texpr, isNull, err := b.args[0].EvalTime(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn types.Time{}, true, handleInvalidTimeError(b.ctx, err)\n\t}\n\n\tif expr.IsZero() {\n\t\treturn types.Time{}, true, handleInvalidTimeError(b.ctx, types.ErrIncorrectDatetimeValue.GenWithStackByArgs(expr.String()))\n\t}\n\n\texpr.Time = types.FromDate(expr.Time.Year(), expr.Time.Month(), expr.Time.Day(), 0, 0, 0, 0)\n\texpr.Type = mysql.TypeDate\n\treturn expr, false, nil\n}"}, {"instruction": "// StartRecordingToSink starts sending events received from the specified eventBroadcaster to the given sink.\n// The return value can be ignored or used to stop recording, if desired.\n// TODO: make me an object with parameterizable queue length and retry interval", "input": "go language", "output": "func (eventBroadcaster *eventBroadcasterImpl) StartRecordingToSink(sink EventSink) watch.Interface {\n\t// The default math/rand package functions aren't thread safe, so create a\n\t// new Rand object for each StartRecording call.\n\trandGen := rand.New(rand.NewSource(time.Now().UnixNano()))\n\teventCorrelator := NewEventCorrelatorWithOptions(eventBroadcaster.options)\n\treturn eventBroadcaster.StartEventWatcher(\n\t\tfunc(event *v1.Event) {\n\t\t\trecordToSink(sink, event, eventCorrelator, randGen, eventBroadcaster.sleepDuration)\n\t\t})\n}"}, {"instruction": "// Filter iterates over the list of transactions and removes all of them for which\n// the specified function evaluates to true.", "input": "go language", "output": "func (m *txSortedMap) Filter(filter func(*types.Transaction) bool) types.Transactions {\n\tvar removed types.Transactions\n\n\t// Collect all the transactions to filter out\n\tfor nonce, tx := range m.items {\n\t\tif filter(tx) {\n\t\t\tremoved = append(removed, tx)\n\t\t\tdelete(m.items, nonce)\n\t\t}\n\t}\n\t// If transactions were removed, the heap and cache are ruined\n\tif len(removed) > 0 {\n\t\t*m.index = make([]uint64, 0, len(m.items))\n\t\tfor nonce := range m.items {\n\t\t\t*m.index = append(*m.index, nonce)\n\t\t}\n\t\theap.Init(m.index)\n\n\t\tm.cache = nil\n\t}\n\treturn removed\n}"}, {"instruction": "// createLogGroup creates a log group for the instance of the awslogs logging driver", "input": "go language", "output": "func (l *logStream) createLogGroup() error {\n\tif _, err := l.client.CreateLogGroup(&cloudwatchlogs.CreateLogGroupInput{\n\t\tLogGroupName: aws.String(l.logGroupName),\n\t}); err != nil {\n\t\tif awsErr, ok := err.(awserr.Error); ok {\n\t\t\tfields := logrus.Fields{\n\t\t\t\t\"errorCode\":      awsErr.Code(),\n\t\t\t\t\"message\":        awsErr.Message(),\n\t\t\t\t\"origError\":      awsErr.OrigErr(),\n\t\t\t\t\"logGroupName\":   l.logGroupName,\n\t\t\t\t\"logCreateGroup\": l.logCreateGroup,\n\t\t\t}\n\t\t\tif awsErr.Code() == resourceAlreadyExistsCode {\n\t\t\t\t// Allow creation to succeed\n\t\t\t\tlogrus.WithFields(fields).Info(\"Log group already exists\")\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tlogrus.WithFields(fields).Error(\"Failed to create log group\")\n\t\t}\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// GetCgroupCPUAndMemoryStats returns the CPU and memory stats of the cgroup with the cgroupName. Note that\n// this function doesn't generate filesystem stats.", "input": "go language", "output": "func (p *StatsProvider) GetCgroupCPUAndMemoryStats(cgroupName string, updateStats bool) (*statsapi.ContainerStats, error) {\n\tinfo, err := getCgroupInfo(p.cadvisor, cgroupName, updateStats)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get cgroup stats for %q: %v\", cgroupName, err)\n\t}\n\t// Rootfs and imagefs doesn't make sense for raw cgroup.\n\ts := cadvisorInfoToContainerCPUAndMemoryStats(cgroupName, info)\n\treturn s, nil\n}"}, {"instruction": "// Update implements Aggregation interface.", "input": "go language", "output": "func (mmf *maxMinFunction) Update(evalCtx *AggEvaluateContext, sc *stmtctx.StatementContext, row chunk.Row) error {\n\ta := mmf.Args[0]\n\tvalue, err := a.Eval(row)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif evalCtx.Value.IsNull() {\n\t\tevalCtx.Value = *(&value).Copy()\n\t}\n\tif value.IsNull() {\n\t\treturn nil\n\t}\n\tvar c int\n\tc, err = evalCtx.Value.CompareDatum(sc, &value)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif (mmf.isMax && c == -1) || (!mmf.isMax && c == 1) {\n\t\tevalCtx.Value = *(&value).Copy()\n\t}\n\treturn nil\n}"}, {"instruction": "// handleMultiplexV2 is used to multiplex a single incoming connection\n// using the Yamux multiplexer", "input": "go language", "output": "func (s *Server) handleMultiplexV2(conn net.Conn) {\n\tdefer conn.Close()\n\tconf := yamux.DefaultConfig()\n\tconf.LogOutput = s.config.LogOutput\n\tserver, _ := yamux.Server(conn, conf)\n\tfor {\n\t\tsub, err := server.Accept()\n\t\tif err != nil {\n\t\t\tif err != io.EOF {\n\t\t\t\ts.logger.Printf(\"[ERR] consul.rpc: multiplex conn accept failed: %v %s\", err, logConn(conn))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tgo s.handleConsulConn(sub)\n\t}\n}"}, {"instruction": "// ReadReceipt retrieves a specific transaction receipt from the database, along with\n// its added positional metadata.", "input": "go language", "output": "func ReadReceipt(db ethdb.Reader, hash common.Hash, config *params.ChainConfig) (*types.Receipt, common.Hash, uint64, uint64) {\n\t// Retrieve the context of the receipt based on the transaction hash\n\tblockNumber := ReadTxLookupEntry(db, hash)\n\tif blockNumber == nil {\n\t\treturn nil, common.Hash{}, 0, 0\n\t}\n\tblockHash := ReadCanonicalHash(db, *blockNumber)\n\tif blockHash == (common.Hash{}) {\n\t\treturn nil, common.Hash{}, 0, 0\n\t}\n\t// Read all the receipts from the block and return the one with the matching hash\n\treceipts := ReadReceipts(db, blockHash, *blockNumber, config)\n\tfor receiptIndex, receipt := range receipts {\n\t\tif receipt.TxHash == hash {\n\t\t\treturn receipt, blockHash, *blockNumber, uint64(receiptIndex)\n\t\t}\n\t}\n\tlog.Error(\"Receipt not found\", \"number\", blockNumber, \"hash\", blockHash, \"txhash\", hash)\n\treturn nil, common.Hash{}, 0, 0\n}"}, {"instruction": "// eachListChunk fetches runtimeObject list chunks using this ListPager and invokes fn on each list\n// chunk. If fn returns an error, processing stops and that error is returned. If fn does not return\n// an error, any error encountered while retrieving the list from the server is returned. If the\n// context cancels or times out, the context error is returned. Since the list is retrieved in\n// paginated chunks, an \"Expired\" error (metav1.StatusReasonExpired) may be returned if the\n// pagination list requests exceed the expiration limit of the apiserver being called.", "input": "go language", "output": "func (p *ListPager) eachListChunk(ctx context.Context, options metav1.ListOptions, fn func(obj runtime.Object) error) error {\n\tif options.Limit == 0 {\n\t\toptions.Limit = p.PageSize\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tobj, err := p.PageFn(ctx, options)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm, err := meta.ListAccessor(obj)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"returned object must be a list: %v\", err)\n\t\t}\n\t\tif err := fn(obj); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// if we have no more items, return.\n\t\tif len(m.GetContinue()) == 0 {\n\t\t\treturn nil\n\t\t}\n\t\t// set the next loop up\n\t\toptions.Continue = m.GetContinue()\n\t}\n}"}, {"instruction": "// CompileExecutePreparedStmt compiles a session Execute command to a stmt.Statement.", "input": "go language", "output": "func CompileExecutePreparedStmt(ctx sessionctx.Context, ID uint32, args ...interface{}) (sqlexec.Statement, error) {\n\texecStmt := &ast.ExecuteStmt{ExecID: ID}\n\tif err := ResetContextOfStmt(ctx, execStmt); err != nil {\n\t\treturn nil, err\n\t}\n\texecStmt.UsingVars = make([]ast.ExprNode, len(args))\n\tfor i, val := range args {\n\t\texecStmt.UsingVars[i] = ast.NewValueExpr(val)\n\t}\n\tis := GetInfoSchema(ctx)\n\texecPlan, err := planner.Optimize(ctx, execStmt, is)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tstmt := &ExecStmt{\n\t\tInfoSchema: is,\n\t\tPlan:       execPlan,\n\t\tStmtNode:   execStmt,\n\t\tCtx:        ctx,\n\t}\n\tif prepared, ok := ctx.GetSessionVars().PreparedStmts[ID]; ok {\n\t\tstmt.Text = prepared.Stmt.Text()\n\t\tctx.GetSessionVars().StmtCtx.OriginalSQL = stmt.Text\n\t}\n\treturn stmt, nil\n}"}, {"instruction": "// peek creates the next state of the iterator.", "input": "go language", "output": "func (it *nodeIterator) peek(descend bool) (*nodeIteratorState, *int, []byte, error) {\n\tif len(it.stack) == 0 {\n\t\t// Initialize the iterator if we've just started.\n\t\troot := it.trie.Hash()\n\t\tstate := &nodeIteratorState{node: it.trie.root, index: -1}\n\t\tif root != emptyRoot {\n\t\t\tstate.hash = root\n\t\t}\n\t\terr := state.resolve(it.trie, nil)\n\t\treturn state, nil, nil, err\n\t}\n\tif !descend {\n\t\t// If we're skipping children, pop the current node first\n\t\tit.pop()\n\t}\n\n\t// Continue iteration to the next child\n\tfor len(it.stack) > 0 {\n\t\tparent := it.stack[len(it.stack)-1]\n\t\tancestor := parent.hash\n\t\tif (ancestor == common.Hash{}) {\n\t\t\tancestor = parent.parent\n\t\t}\n\t\tstate, path, ok := it.nextChild(parent, ancestor)\n\t\tif ok {\n\t\t\tif err := state.resolve(it.trie, path); err != nil {\n\t\t\t\treturn parent, &parent.index, path, err\n\t\t\t}\n\t\t\treturn state, &parent.index, path, nil\n\t\t}\n\t\t// No more child nodes, move back up.\n\t\tit.pop()\n\t}\n\treturn nil, nil, nil, errIteratorEnd\n}"}, {"instruction": "// create creates log group and log stream for the instance of the awslogs logging driver", "input": "go language", "output": "func (l *logStream) create() error {\n\tif err := l.createLogStream(); err != nil {\n\t\tif l.logCreateGroup {\n\t\t\tif awsErr, ok := err.(awserr.Error); ok && awsErr.Code() == resourceNotFoundCode {\n\t\t\t\tif err := l.createLogGroup(); err != nil {\n\t\t\t\t\treturn errors.Wrap(err, \"failed to create Cloudwatch log group\")\n\t\t\t\t}\n\t\t\t\terr := l.createLogStream()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn errors.Wrap(err, \"failed to create Cloudwatch log stream\")\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to create Cloudwatch log stream\")\n\t\t}\n\t}\n\n\treturn nil\n}"}, {"instruction": "// create is a helper function to create a mock apply that uses the configured\n// working directory to find the logfile.", "input": "go language", "output": "func (m *mockApplies) create(cvID, workspaceID string) (*tfe.Apply, error) {\n\tc, ok := m.client.ConfigurationVersions.configVersions[cvID]\n\tif !ok {\n\t\treturn nil, tfe.ErrResourceNotFound\n\t}\n\tif c.Speculative {\n\t\t// Speculative means its plan-only so we don't create a Apply.\n\t\treturn nil, nil\n\t}\n\n\tid := generateID(\"apply-\")\n\turl := fmt.Sprintf(\"https://app.terraform.io/_archivist/%s\", id)\n\n\ta := &tfe.Apply{\n\t\tID:         id,\n\t\tLogReadURL: url,\n\t\tStatus:     tfe.ApplyPending,\n\t}\n\n\tw, ok := m.client.Workspaces.workspaceIDs[workspaceID]\n\tif !ok {\n\t\treturn nil, tfe.ErrResourceNotFound\n\t}\n\n\tif w.AutoApply {\n\t\ta.Status = tfe.ApplyRunning\n\t}\n\n\tm.logs[url] = filepath.Join(\n\t\tm.client.ConfigurationVersions.uploadPaths[cvID],\n\t\tw.WorkingDirectory,\n\t\t\"apply.log\",\n\t)\n\tm.applies[a.ID] = a\n\n\treturn a, nil\n}"}, {"instruction": "// AddFlags adds flags for the insecure serving options.", "input": "go language", "output": "func (o *CombinedInsecureServingOptions) AddFlags(fs *pflag.FlagSet) {\n\tif o == nil {\n\t\treturn\n\t}\n\n\tfs.StringVar(&o.BindAddress, \"address\", o.BindAddress, \"DEPRECATED: the IP address on which to listen for the --port port (set to 0.0.0.0 for all IPv4 interfaces and :: for all IPv6 interfaces). See --bind-address instead.\")\n\t// MarkDeprecated hides the flag from the help. We don't want that:\n\t// fs.MarkDeprecated(\"address\", \"see --bind-address instead.\")\n\tfs.IntVar(&o.BindPort, \"port\", o.BindPort, \"DEPRECATED: the port on which to serve HTTP insecurely without authentication and authorization. If 0, don't serve HTTPS at all. See --secure-port instead.\")\n\t// MarkDeprecated hides the flag from the help. We don't want that:\n\t// fs.MarkDeprecated(\"port\", \"see --secure-port instead.\")\n}"}, {"instruction": "// StatusViewerFor returns a StatusViewer for the resource specified by kind.", "input": "go language", "output": "func StatusViewerFor(kind schema.GroupKind) (StatusViewer, error) {\n\tswitch kind {\n\tcase extensionsv1beta1.SchemeGroupVersion.WithKind(\"Deployment\").GroupKind(),\n\t\tappsv1.SchemeGroupVersion.WithKind(\"Deployment\").GroupKind():\n\t\treturn &DeploymentStatusViewer{}, nil\n\tcase extensionsv1beta1.SchemeGroupVersion.WithKind(\"DaemonSet\").GroupKind(),\n\t\tappsv1.SchemeGroupVersion.WithKind(\"DaemonSet\").GroupKind():\n\t\treturn &DaemonSetStatusViewer{}, nil\n\tcase appsv1.SchemeGroupVersion.WithKind(\"StatefulSet\").GroupKind():\n\t\treturn &StatefulSetStatusViewer{}, nil\n\t}\n\treturn nil, fmt.Errorf(\"no status viewer has been implemented for %v\", kind)\n}"}, {"instruction": "// Cleanup stops active swarm node. This is run before daemon shutdown.", "input": "go language", "output": "func (c *Cluster) Cleanup() {\n\tc.controlMutex.Lock()\n\tdefer c.controlMutex.Unlock()\n\n\tc.mu.Lock()\n\tnode := c.nr\n\tif node == nil {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\tstate := c.currentNodeState()\n\tc.mu.Unlock()\n\n\tif state.IsActiveManager() {\n\t\tactive, reachable, unreachable, err := managerStats(state.controlClient, state.NodeID())\n\t\tif err == nil {\n\t\t\tsinglenode := active && isLastManager(reachable, unreachable)\n\t\t\tif active && !singlenode && removingManagerCausesLossOfQuorum(reachable, unreachable) {\n\t\t\t\tlogrus.Errorf(\"Leaving cluster with %v managers left out of %v. Raft quorum will be lost.\", reachable-1, reachable+unreachable)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := node.Stop(); err != nil {\n\t\tlogrus.Errorf(\"failed to shut down cluster node: %v\", err)\n\t\tsignal.DumpStacks(\"\")\n\t}\n\n\tc.mu.Lock()\n\tc.nr = nil\n\tc.mu.Unlock()\n}"}, {"instruction": "// expandLocations replaces the variables in the locations map with actual\n// directory locations.", "input": "go language", "output": "func expandLocations() error {\n\tnewLocations := make(map[LocationEnum]string)\n\tfor key, dir := range locationTemplates {\n\t\tfor varName, value := range baseDirs {\n\t\t\tdir = strings.Replace(dir, \"${\"+string(varName)+\"}\", value, -1)\n\t\t}\n\t\tvar err error\n\t\tdir, err = fs.ExpandTilde(dir)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tnewLocations[key] = filepath.Clean(dir)\n\t}\n\tlocations = newLocations\n\treturn nil\n}"}, {"instruction": "// Init returns a new VFS driver.\n// This sets the home directory for the driver and returns NaiveDiffDriver.", "input": "go language", "output": "func Init(home string, options []string, uidMaps, gidMaps []idtools.IDMap) (graphdriver.Driver, error) {\n\td := &Driver{\n\t\thome:      home,\n\t\tidMapping: idtools.NewIDMappingsFromMaps(uidMaps, gidMaps),\n\t}\n\n\tif err := d.parseOptions(options); err != nil {\n\t\treturn nil, err\n\t}\n\n\trootIDs := d.idMapping.RootPair()\n\tif err := idtools.MkdirAllAndChown(home, 0700, rootIDs); err != nil {\n\t\treturn nil, err\n\t}\n\n\tsetupDriverQuota(d)\n\n\tif size := d.getQuotaOpt(); !d.quotaSupported() && size > 0 {\n\t\treturn nil, quota.ErrQuotaNotSupported\n\t}\n\n\treturn graphdriver.NewNaiveDiffDriver(d, uidMaps, gidMaps), nil\n}"}, {"instruction": "// DoMakeRShared is common implementation of MakeRShared on Linux. It checks if\n// path is shared and bind-mounts it as rshared if needed. mountCmd and\n// mountArgs are expected to contain mount-like command, DoMakeRShared will add\n// '--bind <path> <path>' and '--make-rshared <path>' to mountArgs.", "input": "go language", "output": "func DoMakeRShared(path string, mountInfoFilename string) error {\n\tshared, err := isShared(path, mountInfoFilename)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif shared {\n\t\tklog.V(4).Infof(\"Directory %s is already on a shared mount\", path)\n\t\treturn nil\n\t}\n\n\tklog.V(2).Infof(\"Bind-mounting %q with shared mount propagation\", path)\n\t// mount --bind /var/lib/kubelet /var/lib/kubelet\n\tif err := syscall.Mount(path, path, \"\" /*fstype*/, syscall.MS_BIND, \"\" /*data*/); err != nil {\n\t\treturn fmt.Errorf(\"failed to bind-mount %s: %v\", path, err)\n\t}\n\n\t// mount --make-rshared /var/lib/kubelet\n\tif err := syscall.Mount(path, path, \"\" /*fstype*/, syscall.MS_SHARED|syscall.MS_REC, \"\" /*data*/); err != nil {\n\t\treturn fmt.Errorf(\"failed to make %s rshared: %v\", path, err)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// resolveControllerRef returns the controller referenced by a ControllerRef,\n// or nil if the ControllerRef could not be resolved to a matching controller\n// of the correct Kind.", "input": "go language", "output": "func (rsc *ReplicaSetController) resolveControllerRef(namespace string, controllerRef *metav1.OwnerReference) *apps.ReplicaSet {\n\t// We can't look up by UID, so look up by Name and then verify UID.\n\t// Don't even try to look up by Name if it's the wrong Kind.\n\tif controllerRef.Kind != rsc.Kind {\n\t\treturn nil\n\t}\n\trs, err := rsc.rsLister.ReplicaSets(namespace).Get(controllerRef.Name)\n\tif err != nil {\n\t\treturn nil\n\t}\n\tif rs.UID != controllerRef.UID {\n\t\t// The controller we found with this Name is not the same one that the\n\t\t// ControllerRef points to.\n\t\treturn nil\n\t}\n\treturn rs\n}"}, {"instruction": "// AddImagesCommonConfigFlags adds the flags that configure kubeadm (and affect the images kubeadm will use)", "input": "go language", "output": "func AddImagesCommonConfigFlags(flagSet *flag.FlagSet, cfg *kubeadmapiv1beta2.InitConfiguration, cfgPath *string, featureGatesString *string) {\n\toptions.AddKubernetesVersionFlag(flagSet, &cfg.ClusterConfiguration.KubernetesVersion)\n\toptions.AddFeatureGatesStringFlag(flagSet, featureGatesString)\n\toptions.AddImageMetaFlags(flagSet, &cfg.ImageRepository)\n\tflagSet.StringVar(cfgPath, \"config\", *cfgPath, \"Path to kubeadm config file.\")\n}"}, {"instruction": "// getRun handles requests to run a command inside a container.", "input": "go language", "output": "func (s *Server) getRun(request *restful.Request, response *restful.Response) {\n\tparams := getExecRequestParams(request)\n\tpod, ok := s.host.GetPodByName(params.podNamespace, params.podName)\n\tif !ok {\n\t\tresponse.WriteError(http.StatusNotFound, fmt.Errorf(\"pod does not exist\"))\n\t\treturn\n\t}\n\n\t// For legacy reasons, run uses different query param than exec.\n\tparams.cmd = strings.Split(request.QueryParameter(\"cmd\"), \" \")\n\tdata, err := s.host.RunInContainer(kubecontainer.GetPodFullName(pod), params.podUID, params.containerName, params.cmd)\n\tif err != nil {\n\t\tresponse.WriteError(http.StatusInternalServerError, err)\n\t\treturn\n\t}\n\twriteJSONResponse(response, data)\n}"}, {"instruction": "// FindCWD returns the current working directory from where the Hugo\n// executable is run.", "input": "go language", "output": "func FindCWD() (string, error) {\n\tserverFile, err := filepath.Abs(os.Args[0])\n\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"can't get absolute path for executable: %v\", err)\n\t}\n\n\tpath := filepath.Dir(serverFile)\n\trealFile, err := filepath.EvalSymlinks(serverFile)\n\n\tif err != nil {\n\t\tif _, err = os.Stat(serverFile + \".exe\"); err == nil {\n\t\t\trealFile = filepath.Clean(serverFile + \".exe\")\n\t\t}\n\t}\n\n\tif err == nil && realFile != serverFile {\n\t\tpath = filepath.Dir(realFile)\n\t}\n\n\treturn path, nil\n}"}, {"instruction": "// Hash returns a hash of either a ConfigMap or a Secret", "input": "go language", "output": "func (h *KustHash) Hash(m map[string]interface{}) (string, error) {\n\tu := unstructured.Unstructured{\n\t\tObject: m,\n\t}\n\tkind := u.GetKind()\n\tswitch kind {\n\tcase \"ConfigMap\":\n\t\tcm, err := unstructuredToConfigmap(u)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn ConfigMapHash(cm)\n\tcase \"Secret\":\n\t\tsec, err := unstructuredToSecret(u)\n\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn SecretHash(sec)\n\tdefault:\n\t\treturn \"\", fmt.Errorf(\"type %s is supported for hashing in %v\", kind, m)\n\t}\n}"}, {"instruction": "// modifiableCharsetAndCollation returns error when the charset or collation is not modifiable.", "input": "go language", "output": "func modifiableCharsetAndCollation(toCharset, toCollate, origCharset, origCollate string) error {\n\tif !charset.ValidCharsetAndCollation(toCharset, toCollate) {\n\t\treturn ErrUnknownCharacterSet.GenWithStack(\"Unknown character set: '%s', collation: '%s'\", toCharset, toCollate)\n\t}\n\tif toCharset == charset.CharsetUTF8MB4 && origCharset == charset.CharsetUTF8 {\n\t\t// TiDB only allow utf8 to be changed to utf8mb4.\n\t\treturn nil\n\t}\n\n\tif toCharset != origCharset {\n\t\tmsg := fmt.Sprintf(\"charset from %s to %s\", origCharset, toCharset)\n\t\treturn errUnsupportedModifyCharset.GenWithStackByArgs(msg)\n\t}\n\tif toCollate != origCollate {\n\t\tmsg := fmt.Sprintf(\"collate from %s to %s\", origCollate, toCollate)\n\t\treturn errUnsupportedModifyCharset.GenWithStackByArgs(msg)\n\t}\n\treturn nil\n}"}, {"instruction": "// resolveGeneratedColumns resolves generated columns with their generation\n// expressions respectively. onDups indicates which columns are in on-duplicate list.", "input": "go language", "output": "func (b *PlanBuilder) resolveGeneratedColumns(columns []*table.Column, onDups map[string]struct{}, mockPlan LogicalPlan) (igc InsertGeneratedColumns, err error) {\n\tfor _, column := range columns {\n\t\tif !column.IsGenerated() {\n\t\t\tcontinue\n\t\t}\n\t\tcolumnName := &ast.ColumnName{Name: column.Name}\n\t\tcolumnName.SetText(column.Name.O)\n\n\t\tcolExpr, _, err := mockPlan.findColumn(columnName)\n\t\tif err != nil {\n\t\t\treturn igc, err\n\t\t}\n\n\t\texpr, _, err := b.rewrite(column.GeneratedExpr, mockPlan, nil, true)\n\t\tif err != nil {\n\t\t\treturn igc, err\n\t\t}\n\t\texpr = expression.BuildCastFunction(b.ctx, expr, colExpr.GetType())\n\n\t\tigc.Columns = append(igc.Columns, columnName)\n\t\tigc.Exprs = append(igc.Exprs, expr)\n\t\tif onDups == nil {\n\t\t\tcontinue\n\t\t}\n\t\tfor dep := range column.Dependences {\n\t\t\tif _, ok := onDups[dep]; ok {\n\t\t\t\tassign := &expression.Assignment{Col: colExpr, Expr: expr}\n\t\t\t\tigc.OnDuplicates = append(igc.OnDuplicates, assign)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn igc, nil\n}"}, {"instruction": "// writeActionSymbol writes a symbol to represent the given action, followed\n// by a space.\n//\n// It only supports the actions that can be represented with a single character:\n// Create, Delete, Update and NoAction.", "input": "go language", "output": "func (p *blockBodyDiffPrinter) writeActionSymbol(action plans.Action) {\n\tswitch action {\n\tcase plans.Create:\n\t\tp.buf.WriteString(p.color.Color(\"[green]+[reset] \"))\n\tcase plans.Delete:\n\t\tp.buf.WriteString(p.color.Color(\"[red]-[reset] \"))\n\tcase plans.Update:\n\t\tp.buf.WriteString(p.color.Color(\"[yellow]~[reset] \"))\n\tcase plans.NoOp:\n\t\tp.buf.WriteString(\"  \")\n\tdefault:\n\t\t// Should never happen\n\t\tp.buf.WriteString(p.color.Color(\"? \"))\n\t}\n}"}, {"instruction": "// GetUncleByBlockHashAndIndex returns the uncle block for the given block hash and index. When fullTx is true\n// all transactions in the block are returned in full detail, otherwise only the transaction hash is returned.", "input": "go language", "output": "func (s *PublicBlockChainAPI) GetUncleByBlockHashAndIndex(ctx context.Context, blockHash common.Hash, index hexutil.Uint) (map[string]interface{}, error) {\n\tblock, err := s.b.GetBlock(ctx, blockHash)\n\tif block != nil {\n\t\tuncles := block.Uncles()\n\t\tif index >= hexutil.Uint(len(uncles)) {\n\t\t\tlog.Debug(\"Requested uncle not found\", \"number\", block.Number(), \"hash\", blockHash, \"index\", index)\n\t\t\treturn nil, nil\n\t\t}\n\t\tblock = types.NewBlockWithHeader(uncles[index])\n\t\treturn s.rpcOutputBlock(block, false, false)\n\t}\n\treturn nil, err\n}"}, {"instruction": "// UpdateDashboardModel updates an existing model from command into model for update", "input": "go language", "output": "func (cmd *UpdateFolderCommand) UpdateDashboardModel(dashFolder *Dashboard, orgId int64, userId int64) {\n\tdashFolder.OrgId = orgId\n\tdashFolder.Title = strings.TrimSpace(cmd.Title)\n\tdashFolder.Data.Set(\"title\", dashFolder.Title)\n\n\tif cmd.Uid != \"\" {\n\t\tdashFolder.SetUid(cmd.Uid)\n\t}\n\n\tdashFolder.SetVersion(cmd.Version)\n\tdashFolder.IsFolder = true\n\n\tif userId == 0 {\n\t\tuserId = -1\n\t}\n\n\tdashFolder.UpdatedBy = userId\n\tdashFolder.UpdateSlug()\n}"}, {"instruction": "// BeforeSign is added to the Sign chain; called before each request", "input": "go language", "output": "func (c *CrossRequestRetryDelay) BeforeSign(r *request.Request) {\n\tnow := time.Now()\n\tdelay := c.backoff.ComputeDelayForRequest(now)\n\tif delay > 0 {\n\t\tklog.Warningf(\"Inserting delay before AWS request (%s) to avoid RequestLimitExceeded: %s\",\n\t\t\tdescribeRequest(r), delay.String())\n\n\t\tif sleepFn := r.Config.SleepDelay; sleepFn != nil {\n\t\t\t// Support SleepDelay for backwards compatibility\n\t\t\tsleepFn(delay)\n\t\t} else if err := aws.SleepWithContext(r.Context(), delay); err != nil {\n\t\t\tr.Error = awserr.New(request.CanceledErrorCode, \"request context canceled\", err)\n\t\t\tr.Retryable = aws.Bool(false)\n\t\t\treturn\n\t\t}\n\n\t\t// Avoid clock skew problems\n\t\tr.Time = now\n\t}\n}"}, {"instruction": "// numCPU queries the system for the count of threads available\n// for use to this process.\n//\n// Issues two syscalls.\n// Returns 0 on errors. Use |runtime.NumCPU| in that case.", "input": "go language", "output": "func numCPU() int {\n\t// Gets the affinity mask for a process: The very one invoking this function.\n\tpid, _, _ := unix.RawSyscall(unix.SYS_GETPID, 0, 0, 0)\n\n\tvar mask [1024 / 64]uintptr\n\t_, _, err := unix.RawSyscall(unix.SYS_SCHED_GETAFFINITY, pid, uintptr(len(mask)*8), uintptr(unsafe.Pointer(&mask[0])))\n\tif err != 0 {\n\t\treturn 0\n\t}\n\n\t// For every available thread a bit is set in the mask.\n\tncpu := 0\n\tfor _, e := range mask {\n\t\tif e == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tncpu += int(popcnt(uint64(e)))\n\t}\n\treturn ncpu\n}"}, {"instruction": "// setGraphQL creates the GraphQL listener interface string from the set\n// command line flags, returning empty if the GraphQL endpoint is disabled.", "input": "go language", "output": "func setGraphQL(ctx *cli.Context, cfg *node.Config) {\n\tif ctx.GlobalBool(GraphQLEnabledFlag.Name) && cfg.GraphQLHost == \"\" {\n\t\tcfg.GraphQLHost = \"127.0.0.1\"\n\t\tif ctx.GlobalIsSet(GraphQLListenAddrFlag.Name) {\n\t\t\tcfg.GraphQLHost = ctx.GlobalString(GraphQLListenAddrFlag.Name)\n\t\t}\n\t}\n\tcfg.GraphQLPort = ctx.GlobalInt(GraphQLPortFlag.Name)\n\tif ctx.GlobalIsSet(GraphQLCORSDomainFlag.Name) {\n\t\tcfg.GraphQLCors = splitAndTrim(ctx.GlobalString(GraphQLCORSDomainFlag.Name))\n\t}\n\tif ctx.GlobalIsSet(GraphQLVirtualHostsFlag.Name) {\n\t\tcfg.GraphQLVirtualHosts = splitAndTrim(ctx.GlobalString(GraphQLVirtualHostsFlag.Name))\n\t}\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *CheckIndexExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\tif e.done {\n\t\treturn nil\n\t}\n\tdefer func() { e.done = true }()\n\n\terr := admin.CheckIndicesCount(e.ctx, e.dbName, e.tableName, []string{e.idxName})\n\tif err != nil {\n\t\treturn err\n\t}\n\tchk := e.src.newFirstChunk()\n\tfor {\n\t\terr := e.src.Next(ctx, chunk.NewRecordBatch(chk))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif chk.NumRows() == 0 {\n\t\t\tbreak\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// IgnoreFile returns whether a given file should be ignored.", "input": "go language", "output": "func (s *SourceSpec) IgnoreFile(filename string) bool {\n\tif filename == \"\" {\n\t\tif _, ok := s.SourceFs.(*afero.OsFs); ok {\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n\n\tbase := filepath.Base(filename)\n\n\tif len(base) > 0 {\n\t\tfirst := base[0]\n\t\tlast := base[len(base)-1]\n\t\tif first == '.' ||\n\t\t\tfirst == '#' ||\n\t\t\tlast == '~' {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif len(s.ignoreFilesRe) == 0 {\n\t\treturn false\n\t}\n\n\tfor _, re := range s.ignoreFilesRe {\n\t\tif re.MatchString(filename) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}"}, {"instruction": "// PlannedDataResourceObject is similar to ProposedNewObject but tailored for\n// planning data resources in particular. Specifically, it replaces the values\n// of any Computed attributes not set in the configuration with an unknown\n// value, which serves as a placeholder for a value to be filled in by the\n// provider when the data resource is finally read.\n//\n// Data resources are different because the planning of them is handled\n// entirely within Terraform Core and not subject to customization by the\n// provider. This function is, in effect, producing an equivalent result to\n// passing the ProposedNewObject result into a provider's PlanResourceChange\n// function, assuming a fixed implementation of PlanResourceChange that just\n// fills in unknown values as needed.", "input": "go language", "output": "func PlannedDataResourceObject(schema *configschema.Block, config cty.Value) cty.Value {\n\t// Our trick here is to run the ProposedNewObject logic with an\n\t// entirely-unknown prior value. Because of cty's unknown short-circuit\n\t// behavior, any operation on prior returns another unknown, and so\n\t// unknown values propagate into all of the parts of the resulting value\n\t// that would normally be filled in by preserving the prior state.\n\tprior := cty.UnknownVal(schema.ImpliedType())\n\treturn proposedNewObject(schema, prior, config)\n}"}, {"instruction": "// MetadataFromConfigValue reads and translates configuration updates from config value into raft metadata", "input": "go language", "output": "func MetadataFromConfigValue(configValue *common.ConfigValue) (*etcdraft.ConfigMetadata, error) {\n\tconsensusTypeValue := &orderer.ConsensusType{}\n\tif err := proto.Unmarshal(configValue.Value, consensusTypeValue); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to unmarshal consensusType config update\")\n\t}\n\n\tupdatedMetadata := &etcdraft.ConfigMetadata{}\n\tif err := proto.Unmarshal(consensusTypeValue.Metadata, updatedMetadata); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to unmarshal updated (new) etcdraft metadata configuration\")\n\t}\n\n\treturn updatedMetadata, nil\n}"}, {"instruction": "// ipcListen will create a Unix socket on the given endpoint.", "input": "go language", "output": "func ipcListen(endpoint string) (net.Listener, error) {\n\tif len(endpoint) > int(C.max_socket_path_size()) {\n\t\tlog.Warn(fmt.Sprintf(\"The ipc endpoint is longer than %d characters. \", C.max_socket_path_size()),\n\t\t\t\"endpoint\", endpoint)\n\t}\n\n\t// Ensure the IPC path exists and remove any previous leftover\n\tif err := os.MkdirAll(filepath.Dir(endpoint), 0751); err != nil {\n\t\treturn nil, err\n\t}\n\tos.Remove(endpoint)\n\tl, err := net.Listen(\"unix\", endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tos.Chmod(endpoint, 0600)\n\treturn l, nil\n}"}, {"instruction": "// Injectable for testing", "input": "go language", "output": "func processRoutes(routeTable network.RouteTable, exists bool, err error) ([]*cloudprovider.Route, error) {\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !exists {\n\t\treturn []*cloudprovider.Route{}, nil\n\t}\n\n\tvar kubeRoutes []*cloudprovider.Route\n\tif routeTable.RouteTablePropertiesFormat != nil && routeTable.Routes != nil {\n\t\tkubeRoutes = make([]*cloudprovider.Route, len(*routeTable.Routes))\n\t\tfor i, route := range *routeTable.Routes {\n\t\t\tinstance := mapRouteNameToNodeName(*route.Name)\n\t\t\tcidr := *route.AddressPrefix\n\t\t\tklog.V(10).Infof(\"ListRoutes: * instance=%q, cidr=%q\", instance, cidr)\n\n\t\t\tkubeRoutes[i] = &cloudprovider.Route{\n\t\t\t\tName:            *route.Name,\n\t\t\t\tTargetNode:      instance,\n\t\t\t\tDestinationCIDR: cidr,\n\t\t\t}\n\t\t}\n\t}\n\n\tklog.V(10).Info(\"ListRoutes: FINISH\")\n\treturn kubeRoutes, nil\n}"}, {"instruction": "// evalString evals a builtinCurrentUserSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/information-functions.html#function_current-user", "input": "go language", "output": "func (b *builtinCurrentRoleSig) evalString(row chunk.Row) (string, bool, error) {\n\tdata := b.ctx.GetSessionVars()\n\tif data == nil || data.ActiveRoles == nil {\n\t\treturn \"\", true, errors.Errorf(\"Missing session variable when eval builtin\")\n\t}\n\tif len(data.ActiveRoles) == 0 {\n\t\treturn \"\", false, nil\n\t}\n\tres := \"\"\n\tfor i, r := range data.ActiveRoles {\n\t\tres += r.String()\n\t\tif i != len(data.ActiveRoles)-1 {\n\t\t\tres += \",\"\n\t\t}\n\t}\n\treturn res, false, nil\n}"}, {"instruction": "// Get returns the previously stored value, or the empty string if it does not exist or key is of 0-length", "input": "go language", "output": "func (s *AESEncryptedStorage) Get(key string) string {\n\tif len(key) == 0 {\n\t\treturn \"\"\n\t}\n\tdata, err := s.readEncryptedStorage()\n\tif err != nil {\n\t\tlog.Warn(\"Failed to read encrypted storage\", \"err\", err, \"file\", s.filename)\n\t\treturn \"\"\n\t}\n\tencrypted, exist := data[key]\n\tif !exist {\n\t\tlog.Warn(\"Key does not exist\", \"key\", key)\n\t\treturn \"\"\n\t}\n\tentry, err := decrypt(s.key, encrypted.Iv, encrypted.CipherText, []byte(key))\n\tif err != nil {\n\t\tlog.Warn(\"Failed to decrypt key\", \"key\", key)\n\t\treturn \"\"\n\t}\n\treturn string(entry)\n}"}, {"instruction": "// getOpenAPIModels is a private method for getting the OpenAPI models", "input": "go language", "output": "func (s *GenericAPIServer) getOpenAPIModels(apiPrefix string, apiGroupInfos ...*APIGroupInfo) (openapiproto.Models, error) {\n\tif s.openAPIConfig == nil {\n\t\treturn nil, nil\n\t}\n\tpathsToIgnore := openapiutil.NewTrie(s.openAPIConfig.IgnorePrefixes)\n\tresourceNames := make([]string, 0)\n\tfor _, apiGroupInfo := range apiGroupInfos {\n\t\tgroupResources, err := getResourceNamesForGroup(apiPrefix, apiGroupInfo, pathsToIgnore)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresourceNames = append(resourceNames, groupResources...)\n\t}\n\n\t// Build the openapi definitions for those resources and convert it to proto models\n\topenAPISpec, err := openapibuilder.BuildOpenAPIDefinitionsForResources(s.openAPIConfig, resourceNames...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn utilopenapi.ToProtoModels(openAPISpec)\n}"}, {"instruction": "// ChannelCreationBlockToGenesisBlock converts a channel creation block to a genesis block", "input": "go language", "output": "func ChannelCreationBlockToGenesisBlock(block *common.Block) (*common.Block, error) {\n\tif block == nil {\n\t\treturn nil, errors.New(\"nil block\")\n\t}\n\tenv, err := utils.ExtractEnvelope(block, 0)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpayload, err := utils.ExtractPayload(env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tblock.Data.Data = [][]byte{payload.Data}\n\tblock.Header.DataHash = block.Data.Hash()\n\tblock.Header.Number = 0\n\tblock.Header.PreviousHash = nil\n\tmetadata := &common.BlockMetadata{\n\t\tMetadata: make([][]byte, 4),\n\t}\n\tblock.Metadata = metadata\n\tmetadata.Metadata[common.BlockMetadataIndex_LAST_CONFIG] = utils.MarshalOrPanic(&common.Metadata{\n\t\tValue: utils.MarshalOrPanic(&common.LastConfig{Index: 0}),\n\t\t// This is a genesis block, peer never verify this signature because we can't bootstrap\n\t\t// trust from an earlier block, hence there are no signatures here.\n\t})\n\treturn block, nil\n}"}, {"instruction": "// buildTargetGroupName will build unique name for targetGroup of service & port.\n// the name is in format k8s-{namespace:8}-{name:8}-{uuid:10} (chosen to benefit most common use cases).\n// Note: targetProtocol & targetType are included since they cannot be modified on existing targetGroup.", "input": "go language", "output": "func (c *Cloud) buildTargetGroupName(serviceName types.NamespacedName, servicePort int64, targetProtocol string, targetType string) string {\n\thasher := sha1.New()\n\t_, _ = hasher.Write([]byte(c.tagging.clusterID()))\n\t_, _ = hasher.Write([]byte(serviceName.Namespace))\n\t_, _ = hasher.Write([]byte(serviceName.Name))\n\t_, _ = hasher.Write([]byte(strconv.FormatInt(servicePort, 10)))\n\t_, _ = hasher.Write([]byte(targetProtocol))\n\t_, _ = hasher.Write([]byte(targetType))\n\ttgUUID := hex.EncodeToString(hasher.Sum(nil))\n\n\tsanitizedNamespace := invalidELBV2NameRegex.ReplaceAllString(serviceName.Namespace, \"\")\n\tsanitizedServiceName := invalidELBV2NameRegex.ReplaceAllString(serviceName.Name, \"\")\n\treturn fmt.Sprintf(\"k8s-%.8s-%.8s-%.10s\", sanitizedNamespace, sanitizedServiceName, tgUUID)\n}"}, {"instruction": "// SetUnstructuredContent obeys the conventions of List and keeps Items and the items\n// array in sync. If items is not an array of objects in the incoming map, then any\n// mismatched item will be removed.", "input": "go language", "output": "func (obj *UnstructuredList) SetUnstructuredContent(content map[string]interface{}) {\n\tobj.Object = content\n\tif content == nil {\n\t\tobj.Items = nil\n\t\treturn\n\t}\n\titems, ok := obj.Object[\"items\"].([]interface{})\n\tif !ok || items == nil {\n\t\titems = []interface{}{}\n\t}\n\tunstructuredItems := make([]Unstructured, 0, len(items))\n\tnewItems := make([]interface{}, 0, len(items))\n\tfor _, item := range items {\n\t\to, ok := item.(map[string]interface{})\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tunstructuredItems = append(unstructuredItems, Unstructured{Object: o})\n\t\tnewItems = append(newItems, o)\n\t}\n\tobj.Items = unstructuredItems\n\tobj.Object[\"items\"] = newItems\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *PolicyRule) DeepCopyInto(out *PolicyRule) {\n\t*out = *in\n\tif in.Verbs != nil {\n\t\tin, out := &in.Verbs, &out.Verbs\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.APIGroups != nil {\n\t\tin, out := &in.APIGroups, &out.APIGroups\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.Resources != nil {\n\t\tin, out := &in.Resources, &out.Resources\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.ResourceNames != nil {\n\t\tin, out := &in.ResourceNames, &out.ResourceNames\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.NonResourceURLs != nil {\n\t\tin, out := &in.NonResourceURLs, &out.NonResourceURLs\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\treturn\n}"}, {"instruction": "// applyPackageSpecOverride applies the package spec overrides for the given\n// osDistro to the packageSpecs and returns the applied result.", "input": "go language", "output": "func applyPackageSpecOverride(packageSpecs []PackageSpec, overrides []PackageSpecOverride, osDistro string) []PackageSpec {\n\tvar override *PackageSpecOverride\n\tfor _, o := range overrides {\n\t\tif o.OSDistro == osDistro {\n\t\t\toverride = &o\n\t\t\tbreak\n\t\t}\n\t}\n\tif override == nil {\n\t\treturn packageSpecs\n\t}\n\n\t// Remove packages in the spec that matches the overrides in\n\t// Subtractions.\n\tvar out []PackageSpec\n\tsubtractions := make(map[string]bool)\n\tfor _, spec := range override.Subtractions {\n\t\tsubtractions[spec.Name] = true\n\t}\n\tfor _, spec := range packageSpecs {\n\t\tif _, ok := subtractions[spec.Name]; !ok {\n\t\t\tout = append(out, spec)\n\t\t}\n\t}\n\n\t// Add packages in the spec that matches the overrides in Additions.\n\treturn append(out, override.Additions...)\n}"}, {"instruction": "// neighbourhoodRadiusForPot returns the neighbourhood radius of the kademlia\n// neighbourhood radius encloses the nearest neighbour set with size >= neighbourhoodSize\n// i.e., neighbourhood radius is the deepest PO such that all bins not shallower altogether\n// contain at least neighbourhoodSize connected peers\n// if there is altogether less than neighbourhoodSize peers connected, it returns 0\n// caller must hold the lock", "input": "go language", "output": "func neighbourhoodRadiusForPot(p *pot.Pot, neighbourhoodSize int, pivotAddr []byte) (depth int) {\n\tif p.Size() <= neighbourhoodSize {\n\t\treturn 0\n\t}\n\t// total number of peers in iteration\n\tvar size int\n\tf := func(v pot.Val, i int) bool {\n\t\t// po == 256 means that addr is the pivot address(self)\n\t\tif i == 256 {\n\t\t\treturn true\n\t\t}\n\t\tsize++\n\n\t\t// this means we have all nn-peers.\n\t\t// depth is by default set to the bin of the farthest nn-peer\n\t\tif size == neighbourhoodSize {\n\t\t\tdepth = i\n\t\t\treturn false\n\t\t}\n\n\t\treturn true\n\t}\n\tp.EachNeighbour(pivotAddr, Pof, f)\n\treturn depth\n}"}, {"instruction": "// ParseAbsProviderConfigStr is a helper wrapper around ParseAbsProviderConfig\n// that takes a string and parses it with the HCL native syntax traversal parser\n// before interpreting it.\n//\n// This should be used only in specialized situations since it will cause the\n// created references to not have any meaningful source location information.\n// If a reference string is coming from a source that should be identified in\n// error messages then the caller should instead parse it directly using a\n// suitable function from the HCL API and pass the traversal itself to\n// ParseAbsProviderConfig.\n//\n// Error diagnostics are returned if either the parsing fails or the analysis\n// of the traversal fails. There is no way for the caller to distinguish the\n// two kinds of diagnostics programmatically. If error diagnostics are returned\n// the returned address is invalid.", "input": "go language", "output": "func ParseAbsProviderConfigStr(str string) (AbsProviderConfig, tfdiags.Diagnostics) {\n\tvar diags tfdiags.Diagnostics\n\n\ttraversal, parseDiags := hclsyntax.ParseTraversalAbs([]byte(str), \"\", hcl.Pos{Line: 1, Column: 1})\n\tdiags = diags.Append(parseDiags)\n\tif parseDiags.HasErrors() {\n\t\treturn AbsProviderConfig{}, diags\n\t}\n\n\taddr, addrDiags := ParseAbsProviderConfig(traversal)\n\tdiags = diags.Append(addrDiags)\n\treturn addr, diags\n}"}, {"instruction": "// UpdateStatus was generated because the type contains a Status member.\n// Add a +genclient:noStatus comment above the type to avoid generating UpdateStatus().", "input": "go language", "output": "func (c *FakeReplicationControllers) UpdateStatus(replicationController *corev1.ReplicationController) (*corev1.ReplicationController, error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewUpdateSubresourceAction(replicationcontrollersResource, \"status\", c.ns, replicationController), &corev1.ReplicationController{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*corev1.ReplicationController), err\n}"}, {"instruction": "// getCgroupProcs takes a cgroup directory name as an argument\n// reads through the cgroup's procs file and returns a list of tgid's.\n// It returns an empty list if a procs file doesn't exists", "input": "go language", "output": "func getCgroupProcs(dir string) ([]int, error) {\n\tprocsFile := filepath.Join(dir, \"cgroup.procs\")\n\tf, err := os.Open(procsFile)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\t// The procsFile does not exist, So no pids attached to this directory\n\t\t\treturn []int{}, nil\n\t\t}\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\n\ts := bufio.NewScanner(f)\n\tout := []int{}\n\tfor s.Scan() {\n\t\tif t := s.Text(); t != \"\" {\n\t\t\tpid, err := strconv.Atoi(t)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected line in %v; could not convert to pid: %v\", procsFile, err)\n\t\t\t}\n\t\t\tout = append(out, pid)\n\t\t}\n\t}\n\treturn out, nil\n}"}, {"instruction": "// Update updates internal state of what has been downloaded into the temporary\n// files by the remote device for this specific folder.", "input": "go language", "output": "func (t *deviceDownloadState) Update(folder string, updates []protocol.FileDownloadProgressUpdate) {\n\tif t == nil {\n\t\treturn\n\t}\n\tt.mut.RLock()\n\tf, ok := t.folders[folder]\n\tt.mut.RUnlock()\n\n\tif !ok {\n\t\tf = &deviceFolderDownloadState{\n\t\t\tmut:   sync.NewRWMutex(),\n\t\t\tfiles: make(map[string]deviceFolderFileDownloadState),\n\t\t}\n\t\tt.mut.Lock()\n\t\tt.folders[folder] = f\n\t\tt.mut.Unlock()\n\t}\n\n\tf.Update(updates)\n}"}, {"instruction": "// Backup creates a backup of an etcd2 data directory at the given backupDir.", "input": "go language", "output": "func (e *CombinedEtcdClient) Backup(version *EtcdVersion, backupDir string) error {\n\t// We cannot use etcd/client (v2) to make this call. It is implemented in the etcdctl client code.\n\tif version.Major != 2 {\n\t\treturn fmt.Errorf(\"etcd 2.x required but got version '%s'\", version)\n\t}\n\treturn e.runEtcdctlCommand(version,\n\t\t\"--debug\",\n\t\t\"backup\",\n\t\t\"--data-dir\", e.cfg.dataDirectory,\n\t\t\"--backup-dir\", backupDir,\n\t)\n}"}, {"instruction": "// RunCompletion checks given arguments and executes command", "input": "go language", "output": "func RunCompletion(out io.Writer, boilerPlate string, cmd *cobra.Command, args []string) error {\n\tif length := len(args); length == 0 {\n\t\treturn errors.New(\"shell not specified\")\n\t} else if length > 1 {\n\t\treturn errors.New(\"too many arguments. expected only the shell type\")\n\t}\n\trun, found := completionShells[args[0]]\n\tif !found {\n\t\treturn errors.Errorf(\"unsupported shell type %q\", args[0])\n\t}\n\n\tif len(boilerPlate) == 0 {\n\t\tboilerPlate = defaultBoilerPlate\n\t}\n\tif _, err := out.Write([]byte(boilerPlate)); err != nil {\n\t\treturn err\n\t}\n\treturn run(out, cmd.Parent())\n}"}, {"instruction": "// sweepList will loop over the list, merge each session's local stats into handle\n// and remove closed session's collector.", "input": "go language", "output": "func (h *Handle) sweepList() {\n\tprev := h.listHead\n\tprev.Lock()\n\terrorRateMap := make(errorRateDeltaMap)\n\tfor curr := prev.next; curr != nil; curr = curr.next {\n\t\tcurr.Lock()\n\t\t// Merge the session stats into handle and error rate map.\n\t\th.merge(curr, errorRateMap)\n\t\tif curr.deleted {\n\t\t\tprev.next = curr.next\n\t\t\t// Since the session is already closed, we can safely unlock it here.\n\t\t\tcurr.Unlock()\n\t\t} else {\n\t\t\t// Unlock the previous lock, so we only holds at most two session's lock at the same time.\n\t\t\tprev.Unlock()\n\t\t\tprev = curr\n\t\t}\n\t}\n\tprev.Unlock()\n\th.mu.Lock()\n\th.mu.rateMap.merge(errorRateMap)\n\th.mu.Unlock()\n}"}, {"instruction": "// newCallback turns fn (a function) into a callback object. It returns nil if the function\n// is unsuitable as an RPC callback.", "input": "go language", "output": "func newCallback(receiver, fn reflect.Value) *callback {\n\tfntype := fn.Type()\n\tc := &callback{fn: fn, rcvr: receiver, errPos: -1, isSubscribe: isPubSub(fntype)}\n\t// Determine parameter types. They must all be exported or builtin types.\n\tc.makeArgTypes()\n\tif !allExportedOrBuiltin(c.argTypes) {\n\t\treturn nil\n\t}\n\t// Verify return types. The function must return at most one error\n\t// and/or one other non-error value.\n\touts := make([]reflect.Type, fntype.NumOut())\n\tfor i := 0; i < fntype.NumOut(); i++ {\n\t\touts[i] = fntype.Out(i)\n\t}\n\tif len(outs) > 2 || !allExportedOrBuiltin(outs) {\n\t\treturn nil\n\t}\n\t// If an error is returned, it must be the last returned value.\n\tswitch {\n\tcase len(outs) == 1 && isErrorType(outs[0]):\n\t\tc.errPos = 0\n\tcase len(outs) == 2:\n\t\tif isErrorType(outs[0]) || !isErrorType(outs[1]) {\n\t\t\treturn nil\n\t\t}\n\t\tc.errPos = 1\n\t}\n\treturn c\n}"}, {"instruction": "// TODO: Remove this when extensions/v1beta1 and apps/v1beta1 Deployment are dropped.", "input": "go language", "output": "func getRollbackTo(d *apps.Deployment) *extensions.RollbackConfig {\n\t// Extract the annotation used for round-tripping the deprecated RollbackTo field.\n\trevision := d.Annotations[apps.DeprecatedRollbackTo]\n\tif revision == \"\" {\n\t\treturn nil\n\t}\n\trevision64, err := strconv.ParseInt(revision, 10, 64)\n\tif err != nil {\n\t\t// If it's invalid, ignore it.\n\t\treturn nil\n\t}\n\treturn &extensions.RollbackConfig{\n\t\tRevision: revision64,\n\t}\n}"}, {"instruction": "// NewAccessEntryACT creates a manifest AccessEntry in order to create an ACT protected by a combination of EC keys and passwords", "input": "go language", "output": "func NewAccessEntryACT(publisher string, salt []byte, act string) (*AccessEntry, error) {\n\tif len(salt) != 32 {\n\t\treturn nil, fmt.Errorf(\"salt should be 32 bytes long\")\n\t}\n\tif len(publisher) != 66 {\n\t\treturn nil, fmt.Errorf(\"publisher should be 66 characters long\")\n\t}\n\n\treturn &AccessEntry{\n\t\tType:      AccessTypeACT,\n\t\tPublisher: publisher,\n\t\tSalt:      salt,\n\t\tAct:       act,\n\t\tKdfParams: DefaultKdfParams,\n\t}, nil\n}"}, {"instruction": "// RequestVerificationWithUser implements the Manager interface.", "input": "go language", "output": "func (p *UserPrivileges) RequestVerificationWithUser(db, table, column string, priv mysql.PrivilegeType, user *auth.UserIdentity) bool {\n\tif SkipWithGrant {\n\t\treturn true\n\t}\n\n\tif user == nil {\n\t\treturn false\n\t}\n\n\t// Skip check for INFORMATION_SCHEMA database.\n\t// See https://dev.mysql.com/doc/refman/5.7/en/information-schema.html\n\tif strings.EqualFold(db, \"INFORMATION_SCHEMA\") {\n\t\treturn true\n\t}\n\n\tmysqlPriv := p.Handle.Get()\n\treturn mysqlPriv.RequestVerification(nil, user.Username, user.Hostname, db, table, column, priv)\n}"}, {"instruction": "// Start is used to start an HTTP check.\n// The check runs until stop is called", "input": "go language", "output": "func (c *CheckHTTP) Start() {\n\tc.stopLock.Lock()\n\tdefer c.stopLock.Unlock()\n\n\tif c.httpClient == nil {\n\t\t// Create the transport. We disable HTTP Keep-Alive's to prevent\n\t\t// failing checks due to the keepalive interval.\n\t\ttrans := cleanhttp.DefaultTransport()\n\t\ttrans.DisableKeepAlives = true\n\n\t\t// Take on the supplied TLS client config.\n\t\ttrans.TLSClientConfig = c.TLSClientConfig\n\n\t\t// Create the HTTP client.\n\t\tc.httpClient = &http.Client{\n\t\t\tTimeout:   10 * time.Second,\n\t\t\tTransport: trans,\n\t\t}\n\n\t\t// For long (>10s) interval checks the http timeout is 10s, otherwise the\n\t\t// timeout is the interval. This means that a check *should* return\n\t\t// before the next check begins.\n\t\tif c.Timeout > 0 && c.Timeout < c.Interval {\n\t\t\tc.httpClient.Timeout = c.Timeout\n\t\t} else if c.Interval < 10*time.Second {\n\t\t\tc.httpClient.Timeout = c.Interval\n\t\t}\n\t}\n\n\tc.stop = false\n\tc.stopCh = make(chan struct{})\n\tgo c.run()\n}"}, {"instruction": "// GetDDLJobs get all DDL jobs and sorts jobs by job.ID.", "input": "go language", "output": "func GetDDLJobs(txn kv.Transaction) ([]*model.Job, error) {\n\tt := meta.NewMeta(txn)\n\tgeneralJobs, err := getDDLJobsInQueue(t, meta.DefaultJobListKey)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\taddIdxJobs, err := getDDLJobsInQueue(t, meta.AddIndexJobListKey)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\tjobs := append(generalJobs, addIdxJobs...)\n\tsort.Sort(jobArray(jobs))\n\treturn jobs, nil\n}"}, {"instruction": "// GetSnapshot retrieves the state snapshot at a given block.", "input": "go language", "output": "func (api *API) GetSnapshot(number *rpc.BlockNumber) (*Snapshot, error) {\n\t// Retrieve the requested block number (or current if none requested)\n\tvar header *types.Header\n\tif number == nil || *number == rpc.LatestBlockNumber {\n\t\theader = api.chain.CurrentHeader()\n\t} else {\n\t\theader = api.chain.GetHeaderByNumber(uint64(number.Int64()))\n\t}\n\t// Ensure we have an actually valid block and return its snapshot\n\tif header == nil {\n\t\treturn nil, errUnknownBlock\n\t}\n\treturn api.clique.snapshot(api.chain, header.Number.Uint64(), header.Hash(), nil)\n}"}, {"instruction": "// GetTxSimulationResults implements method in interface `ledger.TxSimulator`", "input": "go language", "output": "func (s *lockBasedTxSimulator) GetTxSimulationResults() (*ledger.TxSimulationResults, error) {\n\tif s.simulationResultsComputed {\n\t\treturn nil, errors.New(\"this function should only be called once on a transaction simulator instance\")\n\t}\n\tdefer func() { s.simulationResultsComputed = true }()\n\tlogger.Debugf(\"Simulation completed, getting simulation results\")\n\tif s.helper.err != nil {\n\t\treturn nil, s.helper.err\n\t}\n\ts.helper.addRangeQueryInfo()\n\treturn s.rwsetBuilder.GetTxSimulationResults()\n}"}, {"instruction": "// PendingTransactions returns the transactions that are in the transaction pool\n// and have a from address that is one of the accounts this node manages.", "input": "go language", "output": "func (s *PublicTransactionPoolAPI) PendingTransactions() ([]*RPCTransaction, error) {\n\tpending, err := s.b.GetPoolTransactions()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\taccounts := make(map[common.Address]struct{})\n\tfor _, wallet := range s.b.AccountManager().Wallets() {\n\t\tfor _, account := range wallet.Accounts() {\n\t\t\taccounts[account.Address] = struct{}{}\n\t\t}\n\t}\n\ttransactions := make([]*RPCTransaction, 0, len(pending))\n\tfor _, tx := range pending {\n\t\tvar signer types.Signer = types.HomesteadSigner{}\n\t\tif tx.Protected() {\n\t\t\tsigner = types.NewEIP155Signer(tx.ChainId())\n\t\t}\n\t\tfrom, _ := types.Sender(signer, tx)\n\t\tif _, exists := accounts[from]; exists {\n\t\t\ttransactions = append(transactions, newRPCPendingTransaction(tx))\n\t\t}\n\t}\n\treturn transactions, nil\n}"}, {"instruction": "// validateArgs is a checker to ensure tests are not running commands which are\n// not supported on platforms. Specifically on Windows this is 'busybox top'.", "input": "go language", "output": "func validateArgs(args ...string) error {\n\tif testEnv.OSType != \"windows\" {\n\t\treturn nil\n\t}\n\tfoundBusybox := -1\n\tfor key, value := range args {\n\t\tif strings.ToLower(value) == \"busybox\" {\n\t\t\tfoundBusybox = key\n\t\t}\n\t\tif (foundBusybox != -1) && (key == foundBusybox+1) && (strings.ToLower(value) == \"top\") {\n\t\t\treturn errors.New(\"cannot use 'busybox top' in tests on Windows. Use runSleepingContainer()\")\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// DeployENS deploys a new Ethereum contract, binding an instance of ENS to it.", "input": "go language", "output": "func DeployENS(auth *bind.TransactOpts, backend bind.ContractBackend) (common.Address, *types.Transaction, *ENS, error) {\n\tparsed, err := abi.JSON(strings.NewReader(ENSABI))\n\tif err != nil {\n\t\treturn common.Address{}, nil, nil, err\n\t}\n\taddress, tx, contract, err := bind.DeployContract(auth, parsed, common.FromHex(ENSBin), backend)\n\tif err != nil {\n\t\treturn common.Address{}, nil, nil, err\n\t}\n\treturn address, tx, &ENS{ENSCaller: ENSCaller{contract: contract}, ENSTransactor: ENSTransactor{contract: contract}, ENSFilterer: ENSFilterer{contract: contract}}, nil\n}"}, {"instruction": "// LocalChangedFiles returns a paginated list of currently needed files in\n// progress, queued, and to be queued on next puller iteration, as well as the\n// total number of files currently needed.", "input": "go language", "output": "func (m *model) LocalChangedFiles(folder string, page, perpage int) []db.FileInfoTruncated {\n\tm.fmut.RLock()\n\trf, ok := m.folderFiles[folder]\n\tfcfg := m.folderCfgs[folder]\n\tm.fmut.RUnlock()\n\n\tif !ok {\n\t\treturn nil\n\t}\n\tif fcfg.Type != config.FolderTypeReceiveOnly {\n\t\treturn nil\n\t}\n\tif rf.ReceiveOnlyChangedSize().TotalItems() == 0 {\n\t\treturn nil\n\t}\n\n\tfiles := make([]db.FileInfoTruncated, 0, perpage)\n\n\tskip := (page - 1) * perpage\n\tget := perpage\n\n\trf.WithHaveTruncated(protocol.LocalDeviceID, func(f db.FileIntf) bool {\n\t\tif !f.IsReceiveOnlyChanged() {\n\t\t\treturn true\n\t\t}\n\t\tif skip > 0 {\n\t\t\tskip--\n\t\t\treturn true\n\t\t}\n\t\tft := f.(db.FileInfoTruncated)\n\t\tfiles = append(files, ft)\n\t\tget--\n\t\treturn get > 0\n\t})\n\n\treturn files\n}"}, {"instruction": "// processTTL checks whether a given Job's TTL has expired, and add it to the queue after the TTL is expected to expire\n// if the TTL will expire later.", "input": "go language", "output": "func (tc *Controller) processTTL(job *batch.Job) (expired bool, err error) {\n\t// We don't care about the Jobs that are going to be deleted, or the ones that don't need clean up.\n\tif job.DeletionTimestamp != nil || !needsCleanup(job) {\n\t\treturn false, nil\n\t}\n\n\tnow := tc.clock.Now()\n\tt, err := timeLeft(job, &now)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t// TTL has expired\n\tif *t <= 0 {\n\t\treturn true, nil\n\t}\n\n\ttc.enqueueAfter(job, *t)\n\treturn false, nil\n}"}, {"instruction": "// makeListenerFromUserConfig returns the listener config decoded from an\n// arbitrary proto3 json format string or an error if it's invalid.\n//\n// For now we only support embedding in JSON strings because of the hcl parsing\n// pain (see config.go comment above call to patchSliceOfMaps). Until we\n// refactor config parser a _lot_ user's opaque config that contains arrays will\n// be mangled. We could actually fix that up in mapstructure which knows the\n// type of the target so could resolve the slices to singletons unambiguously\n// and it would work for us here... but we still have the problem that the\n// config would render incorrectly in general in our HTTP API responses so we\n// really need to fix it \"properly\".\n//\n// When we do that we can support just nesting the config directly into the\n// JSON/hcl naturally but this is a stop-gap that gets us an escape hatch\n// immediately. It's also probably not a bad thing to support long-term since\n// any config generated by other systems will likely be in canonical protobuf\n// from rather than our slight variant in JSON/hcl.", "input": "go language", "output": "func makeListenerFromUserConfig(configJSON string) (*envoy.Listener, error) {\n\t// Figure out if there is an @type field. We don't require is since we know\n\t// this will be a listener but unmarshalling into types.Any fails if it's not\n\t// there and unmarshalling into listener directly fails if it is...\n\tvar jsonFields map[string]*json.RawMessage\n\tif err := json.Unmarshal([]byte(configJSON), &jsonFields); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar l envoy.Listener\n\n\tif _, ok := jsonFields[\"@type\"]; ok {\n\t\t// Type field is present so decode it as a types.Any\n\t\tvar any types.Any\n\t\terr := jsonpb.UnmarshalString(configJSON, &any)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// And then unmarshal the listener again...\n\t\terr = proto.Unmarshal(any.Value, &l)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &l, err\n\t}\n\n\t// No @type so try decoding as a straight listener.\n\terr := jsonpb.UnmarshalString(configJSON, &l)\n\treturn &l, err\n}"}, {"instruction": "// Endorsers provides a mock function with given fields: invocationChain, f", "input": "go language", "output": "func (_m *ChannelResponse) Endorsers(invocationChain client.InvocationChain, f client.Filter) (client.Endorsers, error) {\n\tret := _m.Called(invocationChain, f)\n\n\tvar r0 client.Endorsers\n\tif rf, ok := ret.Get(0).(func(client.InvocationChain, client.Filter) client.Endorsers); ok {\n\t\tr0 = rf(invocationChain, f)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(client.Endorsers)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(client.InvocationChain, client.Filter) error); ok {\n\t\tr1 = rf(invocationChain, f)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *RevokeExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\tif e.done {\n\t\treturn nil\n\t}\n\te.done = true\n\n\t// Revoke for each user.\n\tfor _, user := range e.Users {\n\t\t// Check if user exists.\n\t\texists, err := userExists(e.ctx, user.User.Username, user.User.Hostname)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !exists {\n\t\t\treturn errors.Errorf(\"Unknown user: %s\", user.User)\n\t\t}\n\n\t\terr = e.revokeOneUser(user.User.Username, user.User.Hostname)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tdomain.GetDomain(e.ctx).NotifyUpdatePrivilege(e.ctx)\n\treturn nil\n}"}, {"instruction": "// <endpointsMap> is updated by this function (based on the given changes).\n// <changes> map is cleared after applying them.", "input": "go language", "output": "func (proxier *Proxier) updateEndpointsMap() (result updateEndpointMapResult) {\n\tresult.staleEndpoints = make(map[endpointServicePair]bool)\n\tresult.staleServiceNames = make(map[proxy.ServicePortName]bool)\n\n\tvar endpointsMap proxyEndpointsMap = proxier.endpointsMap\n\tvar changes *endpointsChangeMap = &proxier.endpointsChanges\n\n\tfunc() {\n\t\tchanges.lock.Lock()\n\t\tdefer changes.lock.Unlock()\n\t\tfor _, change := range changes.items {\n\t\t\tendpointsMap.unmerge(change.previous, proxier.serviceMap)\n\t\t\tendpointsMap.merge(change.current, proxier.serviceMap)\n\t\t}\n\t\tchanges.items = make(map[types.NamespacedName]*endpointsChange)\n\t}()\n\n\t// TODO: If this will appear to be computationally expensive, consider\n\t// computing this incrementally similarly to endpointsMap.\n\tresult.hcEndpoints = make(map[types.NamespacedName]int)\n\tlocalIPs := getLocalIPs(endpointsMap)\n\tfor nsn, ips := range localIPs {\n\t\tresult.hcEndpoints[nsn] = len(ips)\n\t}\n\n\treturn result\n}"}, {"instruction": "// Set adds or updates the given entry in the record. It panics if the value can't be\n// encoded. If the record is signed, Set increments the sequence number and invalidates\n// the sequence number.", "input": "go language", "output": "func (r *Record) Set(e Entry) {\n\tblob, err := rlp.EncodeToBytes(e)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"enr: can't encode %s: %v\", e.ENRKey(), err))\n\t}\n\tr.invalidate()\n\n\tpairs := make([]pair, len(r.pairs))\n\tcopy(pairs, r.pairs)\n\ti := sort.Search(len(pairs), func(i int) bool { return pairs[i].k >= e.ENRKey() })\n\tswitch {\n\tcase i < len(pairs) && pairs[i].k == e.ENRKey():\n\t\t// element is present at r.pairs[i]\n\t\tpairs[i].v = blob\n\tcase i < len(r.pairs):\n\t\t// insert pair before i-th elem\n\t\tel := pair{e.ENRKey(), blob}\n\t\tpairs = append(pairs, pair{})\n\t\tcopy(pairs[i+1:], pairs[i:])\n\t\tpairs[i] = el\n\tdefault:\n\t\t// element should be placed at the end of r.pairs\n\t\tpairs = append(pairs, pair{e.ENRKey(), blob})\n\t}\n\tr.pairs = pairs\n}"}, {"instruction": "// Build is used to build a specific AggFunc implementation according to the\n// input aggFuncDesc.", "input": "go language", "output": "func Build(ctx sessionctx.Context, aggFuncDesc *aggregation.AggFuncDesc, ordinal int) AggFunc {\n\tswitch aggFuncDesc.Name {\n\tcase ast.AggFuncCount:\n\t\treturn buildCount(aggFuncDesc, ordinal)\n\tcase ast.AggFuncSum:\n\t\treturn buildSum(aggFuncDesc, ordinal)\n\tcase ast.AggFuncAvg:\n\t\treturn buildAvg(aggFuncDesc, ordinal)\n\tcase ast.AggFuncFirstRow:\n\t\treturn buildFirstRow(aggFuncDesc, ordinal)\n\tcase ast.AggFuncMax:\n\t\treturn buildMaxMin(aggFuncDesc, ordinal, true)\n\tcase ast.AggFuncMin:\n\t\treturn buildMaxMin(aggFuncDesc, ordinal, false)\n\tcase ast.AggFuncGroupConcat:\n\t\treturn buildGroupConcat(ctx, aggFuncDesc, ordinal)\n\tcase ast.AggFuncBitOr:\n\t\treturn buildBitOr(aggFuncDesc, ordinal)\n\tcase ast.AggFuncBitXor:\n\t\treturn buildBitXor(aggFuncDesc, ordinal)\n\tcase ast.AggFuncBitAnd:\n\t\treturn buildBitAnd(aggFuncDesc, ordinal)\n\t}\n\treturn nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *HorizontalPodAutoscalerSpec) DeepCopyInto(out *HorizontalPodAutoscalerSpec) {\n\t*out = *in\n\tout.ScaleTargetRef = in.ScaleTargetRef\n\tif in.MinReplicas != nil {\n\t\tin, out := &in.MinReplicas, &out.MinReplicas\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.Metrics != nil {\n\t\tin, out := &in.Metrics, &out.Metrics\n\t\t*out = make([]MetricSpec, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// pushRepository pushes layers that do not already exist on the registry.", "input": "go language", "output": "func (p *v1Pusher) pushRepository(ctx context.Context) error {\n\timgList, tags, referencedLayers, err := p.getImageList()\n\tdefer func() {\n\t\tfor _, l := range referencedLayers {\n\t\t\tl.Release()\n\t\t}\n\t}()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\timageIndex := createImageIndex(imgList, tags)\n\tfor _, data := range imageIndex {\n\t\tlogrus.Debugf(\"Pushing ID: %s with Tag: %s\", data.ID, data.Tag)\n\t}\n\n\t// Register all the images in a repository with the registry\n\t// If an image is not in this list it will not be associated with the repository\n\trepoData, err := p.session.PushImageJSONIndex(p.repoInfo.Name, imageIndex, false, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// push the repository to each of the endpoints only if it does not exist.\n\tfor _, endpoint := range repoData.Endpoints {\n\t\tif err := p.pushImageToEndpoint(ctx, endpoint, imgList, tags, repoData); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t_, err = p.session.PushImageJSONIndex(p.repoInfo.Name, imageIndex, true, repoData.Endpoints)\n\treturn err\n}"}, {"instruction": "// New creates a new custom error pages middleware.", "input": "go language", "output": "func New(ctx context.Context, next http.Handler, config config.ErrorPage, serviceBuilder serviceBuilder, name string) (http.Handler, error) {\n\tmiddlewares.GetLogger(ctx, name, typeName).Debug(\"Creating middleware\")\n\n\thttpCodeRanges, err := types.NewHTTPCodeRanges(config.Status)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tbackend, err := serviceBuilder.BuildHTTP(ctx, config.Service, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &customErrors{\n\t\tname:           name,\n\t\tnext:           next,\n\t\tbackendHandler: backend,\n\t\thttpCodeRanges: httpCodeRanges,\n\t\tbackendQuery:   config.Query,\n\t}, nil\n}"}, {"instruction": "// Update updates internal state of what has been downloaded into the temporary\n// files by the remote device for this specific folder.", "input": "go language", "output": "func (p *deviceFolderDownloadState) Update(updates []protocol.FileDownloadProgressUpdate) {\n\tp.mut.Lock()\n\tdefer p.mut.Unlock()\n\n\tfor _, update := range updates {\n\t\tlocal, ok := p.files[update.Name]\n\t\tif update.UpdateType == protocol.UpdateTypeForget && ok && local.version.Equal(update.Version) {\n\t\t\tdelete(p.files, update.Name)\n\t\t} else if update.UpdateType == protocol.UpdateTypeAppend {\n\t\t\tif !ok {\n\t\t\t\tlocal = deviceFolderFileDownloadState{\n\t\t\t\t\tblockIndexes: update.BlockIndexes,\n\t\t\t\t\tversion:      update.Version,\n\t\t\t\t}\n\t\t\t} else if !local.version.Equal(update.Version) {\n\t\t\t\tlocal.blockIndexes = append(local.blockIndexes[:0], update.BlockIndexes...)\n\t\t\t\tlocal.version = update.Version\n\t\t\t} else {\n\t\t\t\tlocal.blockIndexes = append(local.blockIndexes, update.BlockIndexes...)\n\t\t\t}\n\t\t\tp.files[update.Name] = local\n\t\t}\n\t}\n}"}, {"instruction": "// NewIdentityMapper method, all we need is a reference to a MessageCryptoService", "input": "go language", "output": "func NewIdentityMapper(mcs api.MessageCryptoService, selfIdentity api.PeerIdentityType, onPurge purgeTrigger, sa api.SecurityAdvisor) Mapper {\n\tselfPKIID := mcs.GetPKIidOfCert(selfIdentity)\n\tidMapper := &identityMapperImpl{\n\t\tonPurge:    onPurge,\n\t\tmcs:        mcs,\n\t\tpkiID2Cert: make(map[string]*storedIdentity),\n\t\tstopChan:   make(chan struct{}),\n\t\tselfPKIID:  string(selfPKIID),\n\t\tsa:         sa,\n\t}\n\tif err := idMapper.Put(selfPKIID, selfIdentity); err != nil {\n\t\tpanic(errors.Wrap(err, \"Failed putting our own identity into the identity mapper\"))\n\t}\n\tgo idMapper.periodicalPurgeUnusedIdentities()\n\treturn idMapper\n}"}, {"instruction": "// providerRequiresNetworkingConfiguration returns whether the cloud provider\n// requires special networking configuration.", "input": "go language", "output": "func (kl *Kubelet) providerRequiresNetworkingConfiguration() bool {\n\t// TODO: We should have a mechanism to say whether native cloud provider\n\t// is used or whether we are using overlay networking. We should return\n\t// true for cloud providers if they implement Routes() interface and\n\t// we are not using overlay networking.\n\tif kl.cloud == nil || kl.cloud.ProviderName() != \"gce\" {\n\t\treturn false\n\t}\n\t_, supported := kl.cloud.Routes()\n\treturn supported\n}"}, {"instruction": "// milliCPUToShares converts milliCPU to CPU shares", "input": "go language", "output": "func milliCPUToShares(milliCPU int64, hyperv bool) int64 {\n\tvar minShares int64 = minSharesProcess\n\tif hyperv {\n\t\tminShares = minSharesHyperV\n\t}\n\n\tif milliCPU == 0 {\n\t\t// Return here to really match kernel default for zero milliCPU.\n\t\treturn minShares\n\t}\n\n\t// Conceptually (milliCPU / milliCPUToCPU) * sharesPerCPU, but factored to improve rounding.\n\ttotalCPU := sysinfo.NumCPU()\n\tshares := (milliCPU * (maxShares - minShares)) / int64(totalCPU) / milliCPUToCPU\n\tif shares < minShares {\n\t\treturn minShares\n\t}\n\tif shares > maxShares {\n\t\treturn maxShares\n\t}\n\treturn shares\n}"}, {"instruction": "// syncNamespaceFromKey looks for a namespace with the specified key in its store and synchronizes it", "input": "go language", "output": "func (nm *NamespaceController) syncNamespaceFromKey(key string) (err error) {\n\tstartTime := time.Now()\n\tdefer func() {\n\t\tklog.V(4).Infof(\"Finished syncing namespace %q (%v)\", key, time.Since(startTime))\n\t}()\n\n\tnamespace, err := nm.lister.Get(key)\n\tif errors.IsNotFound(err) {\n\t\tklog.Infof(\"Namespace has been deleted %v\", key)\n\t\treturn nil\n\t}\n\tif err != nil {\n\t\tutilruntime.HandleError(fmt.Errorf(\"Unable to retrieve namespace %v from store: %v\", key, err))\n\t\treturn err\n\t}\n\treturn nm.namespacedResourcesDeleter.Delete(namespace.Name)\n}"}, {"instruction": "// Receive is called to deposit the latest cheque to the incoming Inbox.\n// The given promise must be a *Cheque.", "input": "go language", "output": "func (i *Inbox) Receive(promise swap.Promise) (*big.Int, error) {\n\tch := promise.(*Cheque)\n\n\tdefer i.lock.Unlock()\n\ti.lock.Lock()\n\n\tvar sum *big.Int\n\tif i.cheque == nil {\n\t\t// the sum is checked against the blockchain once a cheque is received\n\t\ttally, err := i.session.Sent(i.beneficiary)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"inbox: error calling backend to set amount: %v\", err)\n\t\t}\n\t\tsum = tally\n\t} else {\n\t\tsum = i.cheque.Amount\n\t}\n\n\tamount, err := ch.Verify(i.signer, i.contract, i.beneficiary, sum)\n\tvar uncashed *big.Int\n\tif err == nil {\n\t\ti.cheque = ch\n\n\t\tif i.maxUncashed != nil {\n\t\t\tuncashed = new(big.Int).Sub(ch.Amount, i.cashed)\n\t\t\tif i.maxUncashed.Cmp(uncashed) < 0 {\n\t\t\t\ti.Cash()\n\t\t\t}\n\t\t}\n\t\ti.log.Trace(\"Received cheque in chequebook inbox\", \"amount\", amount, \"uncashed\", uncashed)\n\t}\n\n\treturn amount, err\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *LocalEtcd) DeepCopyInto(out *LocalEtcd) {\n\t*out = *in\n\tout.ImageMeta = in.ImageMeta\n\tif in.ExtraArgs != nil {\n\t\tin, out := &in.ExtraArgs, &out.ExtraArgs\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.ServerCertSANs != nil {\n\t\tin, out := &in.ServerCertSANs, &out.ServerCertSANs\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.PeerCertSANs != nil {\n\t\tin, out := &in.PeerCertSANs, &out.PeerCertSANs\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\treturn\n}"}, {"instruction": "// Read reads bytes from BytesPipe.\n// Data could be read only once.", "input": "go language", "output": "func (bp *BytesPipe) Read(p []byte) (n int, err error) {\n\tbp.mu.Lock()\n\tif bp.bufLen == 0 {\n\t\tif bp.closeErr != nil {\n\t\t\tbp.mu.Unlock()\n\t\t\treturn 0, bp.closeErr\n\t\t}\n\t\tbp.wait.Wait()\n\t\tif bp.bufLen == 0 && bp.closeErr != nil {\n\t\t\terr := bp.closeErr\n\t\t\tbp.mu.Unlock()\n\t\t\treturn 0, err\n\t\t}\n\t}\n\n\tfor bp.bufLen > 0 {\n\t\tb := bp.buf[0]\n\t\tread, _ := b.Read(p) // ignore error since fixedBuffer doesn't really return an error\n\t\tn += read\n\t\tbp.bufLen -= read\n\n\t\tif b.Len() == 0 {\n\t\t\t// it's empty so return it to the pool and move to the next one\n\t\t\treturnBuffer(b)\n\t\t\tbp.buf[0] = nil\n\t\t\tbp.buf = bp.buf[1:]\n\t\t}\n\n\t\tif len(p) == read {\n\t\t\tbreak\n\t\t}\n\n\t\tp = p[read:]\n\t}\n\n\tbp.wait.Broadcast()\n\tbp.mu.Unlock()\n\treturn\n}"}, {"instruction": "// WaitForClusterAvailable returns true if all endpoints in the cluster are available after retry attempts, an error is returned otherwise", "input": "go language", "output": "func (c *Client) WaitForClusterAvailable(retries int, retryInterval time.Duration) (bool, error) {\n\tfor i := 0; i < retries; i++ {\n\t\tif i > 0 {\n\t\t\tklog.V(1).Infof(\"[etcd] Waiting %v until next retry\\n\", retryInterval)\n\t\t\ttime.Sleep(retryInterval)\n\t\t}\n\t\tklog.V(2).Infof(\"[etcd] attempting to see if all cluster endpoints (%s) are available %d/%d\", c.Endpoints, i+1, retries)\n\t\tresp, err := c.ClusterAvailable()\n\t\tif err != nil {\n\t\t\tswitch err {\n\t\t\tcase context.DeadlineExceeded:\n\t\t\t\tklog.V(1).Infof(\"[etcd] Attempt timed out\")\n\t\t\tdefault:\n\t\t\t\tklog.V(1).Infof(\"[etcd] Attempt failed with error: %v\\n\", err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn resp, nil\n\t}\n\treturn false, errors.New(\"timeout waiting for etcd cluster to be available\")\n}"}, {"instruction": "// validatePathNoBacksteps makes sure the targetPath does not have any `..` path elements when split\n//\n// This assumes the OS of the apiserver and the nodes are the same. The same check should be done\n// on the node to ensure there are no backsteps.", "input": "go language", "output": "func validatePathNoBacksteps(targetPath string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tparts := strings.Split(filepath.ToSlash(targetPath), \"/\")\n\tfor _, item := range parts {\n\t\tif item == \"..\" {\n\t\t\tallErrs = append(allErrs, field.Invalid(fldPath, targetPath, \"must not contain '..'\"))\n\t\t\tbreak // even for `../../..`, one error is sufficient to make the point\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// Shutdown blocks until stopCh passed to the Run method is closed and all\n// events added prior to that moment are batched and sent to the delegate backend.", "input": "go language", "output": "func (b *bufferedBackend) Shutdown() {\n\t// Wait until the routine spawned in Run method exits.\n\t<-b.shutdownCh\n\n\t// Wait until all sending routines exit.\n\t//\n\t// - When b.shutdownCh is closed, we know that the goroutine in Run has terminated.\n\t// - This means that processIncomingEvents has terminated.\n\t// - Which means that b.buffer is closed and cannot accept any new events anymore.\n\t// - Because processEvents is called synchronously from the Run goroutine, the waitgroup has its final value.\n\t// Hence wg.Wait will not miss any more outgoing batches.\n\tb.wg.Wait()\n\n\tb.delegateBackend.Shutdown()\n}"}, {"instruction": "// Error returns detailed information of why the pod failed to fit on each node", "input": "go language", "output": "func (f *FitError) Error() string {\n\treasons := make(map[string]int)\n\tfor _, predicates := range f.FailedPredicates {\n\t\tfor _, pred := range predicates {\n\t\t\treasons[pred.GetReason()]++\n\t\t}\n\t}\n\n\tsortReasonsHistogram := func() []string {\n\t\treasonStrings := []string{}\n\t\tfor k, v := range reasons {\n\t\t\treasonStrings = append(reasonStrings, fmt.Sprintf(\"%v %v\", v, k))\n\t\t}\n\t\tsort.Strings(reasonStrings)\n\t\treturn reasonStrings\n\t}\n\treasonMsg := fmt.Sprintf(NoNodeAvailableMsg+\": %v.\", f.NumAllNodes, strings.Join(sortReasonsHistogram(), \", \"))\n\treturn reasonMsg\n}"}, {"instruction": "// JWTTokenGenerator returns a TokenGenerator that generates signed JWT tokens, using the given privateKey.\n// privateKey is a PEM-encoded byte array of a private RSA key.\n// JWTTokenAuthenticator()", "input": "go language", "output": "func JWTTokenGenerator(iss string, privateKey interface{}) (TokenGenerator, error) {\n\tvar alg jose.SignatureAlgorithm\n\tswitch pk := privateKey.(type) {\n\tcase *rsa.PrivateKey:\n\t\talg = jose.RS256\n\tcase *ecdsa.PrivateKey:\n\t\tswitch pk.Curve {\n\t\tcase elliptic.P256():\n\t\t\talg = jose.ES256\n\t\tcase elliptic.P384():\n\t\t\talg = jose.ES384\n\t\tcase elliptic.P521():\n\t\t\talg = jose.ES512\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unknown private key curve, must be 256, 384, or 521\")\n\t\t}\n\tcase jose.OpaqueSigner:\n\t\talg = jose.SignatureAlgorithm(pk.Public().Algorithm)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unknown private key type %T, must be *rsa.PrivateKey, *ecdsa.PrivateKey, or jose.OpaqueSigner\", privateKey)\n\t}\n\n\tsigner, err := jose.NewSigner(\n\t\tjose.SigningKey{\n\t\t\tAlgorithm: alg,\n\t\t\tKey:       privateKey,\n\t\t},\n\t\tnil,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &jwtTokenGenerator{\n\t\tiss:    iss,\n\t\tsigner: signer,\n\t}, nil\n}"}, {"instruction": "// Stop stops the node with the given ID", "input": "go language", "output": "func (net *Network) Stop(id enode.ID) error {\n\t// IMPORTANT: node.Stop() must NOT be called under net.lock as\n\t// node.Reachable() closure has a reference to the network and\n\t// calls net.InitConn() what also locks the network. => DEADLOCK\n\t// That holds until the following ticket is not resolved:\n\n\tvar err error\n\n\tnode, err := func() (*Node, error) {\n\t\tnet.lock.Lock()\n\t\tdefer net.lock.Unlock()\n\n\t\tnode := net.getNode(id)\n\t\tif node == nil {\n\t\t\treturn nil, fmt.Errorf(\"node %v does not exist\", id)\n\t\t}\n\t\tif !node.Up() {\n\t\t\treturn nil, fmt.Errorf(\"node %v already down\", id)\n\t\t}\n\t\tnode.SetUp(false)\n\t\treturn node, nil\n\t}()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = node.Stop() // must be called without net.lock\n\n\tnet.lock.Lock()\n\tdefer net.lock.Unlock()\n\n\tif err != nil {\n\t\tnode.SetUp(true)\n\t\treturn err\n\t}\n\tlog.Info(\"Stopped node\", \"id\", id, \"err\", err)\n\tev := ControlEvent(node)\n\tnet.events.Send(ev)\n\treturn nil\n}"}, {"instruction": "// Parses awslogs-multiline-pattern and awslogs-datetime-format options\n// If awslogs-datetime-format is present, convert the format from strftime\n// to regexp and return.\n// If awslogs-multiline-pattern is present, compile regexp and return", "input": "go language", "output": "func parseMultilineOptions(info logger.Info) (*regexp.Regexp, error) {\n\tdateTimeFormat := info.Config[datetimeFormatKey]\n\tmultilinePatternKey := info.Config[multilinePatternKey]\n\t// strftime input is parsed into a regular expression\n\tif dateTimeFormat != \"\" {\n\t\t// %. matches each strftime format sequence and ReplaceAllStringFunc\n\t\t// looks up each format sequence in the conversion table strftimeToRegex\n\t\t// to replace with a defined regular expression\n\t\tr := regexp.MustCompile(\"%.\")\n\t\tmultilinePatternKey = r.ReplaceAllStringFunc(dateTimeFormat, func(s string) string {\n\t\t\treturn strftimeToRegex[s]\n\t\t})\n\t}\n\tif multilinePatternKey != \"\" {\n\t\tmultilinePattern, err := regexp.Compile(multilinePatternKey)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"awslogs could not parse multiline pattern key %q\", multilinePatternKey)\n\t\t}\n\t\treturn multilinePattern, nil\n\t}\n\treturn nil, nil\n}"}, {"instruction": "// ShutdownTimeout returns the timeout (in seconds) before containers are forcibly\n// killed during shutdown. The default timeout can be configured both on the daemon\n// and per container, and the longest timeout will be used. A grace-period of\n// 5 seconds is added to the configured timeout.\n//\n// A negative (-1) timeout means \"indefinitely\", which means that containers\n// are not forcibly killed, and the daemon shuts down after all containers exit.", "input": "go language", "output": "func (daemon *Daemon) ShutdownTimeout() int {\n\tshutdownTimeout := daemon.configStore.ShutdownTimeout\n\tif shutdownTimeout < 0 {\n\t\treturn -1\n\t}\n\tif daemon.containers == nil {\n\t\treturn shutdownTimeout\n\t}\n\n\tgraceTimeout := 5\n\tfor _, c := range daemon.containers.List() {\n\t\tstopTimeout := c.StopTimeout()\n\t\tif stopTimeout < 0 {\n\t\t\treturn -1\n\t\t}\n\t\tif stopTimeout+graceTimeout > shutdownTimeout {\n\t\t\tshutdownTimeout = stopTimeout + graceTimeout\n\t\t}\n\t}\n\treturn shutdownTimeout\n}"}, {"instruction": "// Commit writes the block and state of a genesis specification to the database.\n// The block is committed as the canonical head block.", "input": "go language", "output": "func (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) {\n\tblock := g.ToBlock(db)\n\tif block.Number().Sign() != 0 {\n\t\treturn nil, fmt.Errorf(\"can't commit genesis block with number > 0\")\n\t}\n\trawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty)\n\trawdb.WriteBlock(db, block)\n\trawdb.WriteReceipts(db, block.Hash(), block.NumberU64(), nil)\n\trawdb.WriteCanonicalHash(db, block.Hash(), block.NumberU64())\n\trawdb.WriteHeadBlockHash(db, block.Hash())\n\trawdb.WriteHeadHeaderHash(db, block.Hash())\n\n\tconfig := g.Config\n\tif config == nil {\n\t\tconfig = params.AllEthashProtocolChanges\n\t}\n\trawdb.WriteChainConfig(db, block.Hash(), config)\n\treturn block, nil\n}"}, {"instruction": "// AddFlags adds flags related to GarbageCollectorController for controller manager to the specified FlagSet.", "input": "go language", "output": "func (o *GarbageCollectorControllerOptions) AddFlags(fs *pflag.FlagSet) {\n\tif o == nil {\n\t\treturn\n\t}\n\n\tfs.Int32Var(&o.ConcurrentGCSyncs, \"concurrent-gc-syncs\", o.ConcurrentGCSyncs, \"The number of garbage collector workers that are allowed to sync concurrently.\")\n\tfs.BoolVar(&o.EnableGarbageCollector, \"enable-garbage-collector\", o.EnableGarbageCollector, \"Enables the generic garbage collector. MUST be synced with the corresponding flag of the kube-apiserver.\")\n}"}, {"instruction": "// HistoryViewerFor returns an implementation of HistoryViewer interface for the given schema kind", "input": "go language", "output": "func HistoryViewerFor(kind schema.GroupKind, c kubernetes.Interface) (HistoryViewer, error) {\n\telem := kapps.GroupKindElement(kind)\n\tvisitor := &HistoryVisitor{\n\t\tclientset: c,\n\t}\n\n\t// Determine which HistoryViewer we need here\n\terr := elem.Accept(visitor)\n\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error retrieving history for %q, %v\", kind.String(), err)\n\t}\n\n\tif visitor.result == nil {\n\t\treturn nil, fmt.Errorf(\"no history viewer has been implemented for %q\", kind.String())\n\t}\n\n\treturn visitor.result, nil\n}"}, {"instruction": "// removeTicket removes a ticket from the ticket store", "input": "go language", "output": "func (s *ticketStore) removeTicketRef(ref ticketRef) {\n\tlog.Trace(\"Removing discovery ticket reference\", \"node\", ref.t.node.ID, \"serial\", ref.t.serial)\n\n\t// Make nextRegisterableTicket return the next available ticket.\n\ts.nextTicketCached = nil\n\n\ttopic := ref.topic()\n\ttickets := s.tickets[topic]\n\n\tif tickets == nil {\n\t\tlog.Trace(\"Removing tickets from unknown topic\", \"topic\", topic)\n\t\treturn\n\t}\n\tbucket := timeBucket(ref.t.regTime[ref.idx] / mclock.AbsTime(ticketTimeBucketLen))\n\tlist := tickets.buckets[bucket]\n\tidx := -1\n\tfor i, bt := range list {\n\t\tif bt.t == ref.t {\n\t\t\tidx = i\n\t\t\tbreak\n\t\t}\n\t}\n\tif idx == -1 {\n\t\tpanic(nil)\n\t}\n\tlist = append(list[:idx], list[idx+1:]...)\n\tif len(list) != 0 {\n\t\ttickets.buckets[bucket] = list\n\t} else {\n\t\tdelete(tickets.buckets, bucket)\n\t}\n\tref.t.refCnt--\n\tif ref.t.refCnt == 0 {\n\t\tdelete(s.nodes, ref.t.node)\n\t\tdelete(s.nodeLastReq, ref.t.node)\n\t}\n}"}, {"instruction": "// Returns a set of targeted nodes. A targeted node is either addressed\n// directly, address indirectly via its container, or it's a dependency of a\n// targeted node. Destroy mode keeps dependents instead of dependencies.", "input": "go language", "output": "func (t *TargetsTransformer) selectTargetedNodes(g *Graph, addrs []addrs.Targetable) (*dag.Set, error) {\n\ttargetedNodes := new(dag.Set)\n\n\tvertices := g.Vertices()\n\n\tfor _, v := range vertices {\n\t\tif t.nodeIsTarget(v, addrs) {\n\t\t\ttargetedNodes.Add(v)\n\n\t\t\t// We inform nodes that ask about the list of targets - helps for nodes\n\t\t\t// that need to dynamically expand. Note that this only occurs for nodes\n\t\t\t// that are already directly targeted.\n\t\t\tif tn, ok := v.(GraphNodeTargetable); ok {\n\t\t\t\ttn.SetTargets(addrs)\n\t\t\t}\n\n\t\t\tvar deps *dag.Set\n\t\t\tvar err error\n\t\t\tif t.Destroy {\n\t\t\t\tdeps, err = g.Descendents(v)\n\t\t\t} else {\n\t\t\t\tdeps, err = g.Ancestors(v)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tfor _, d := range deps.List() {\n\t\t\t\ttargetedNodes.Add(d)\n\t\t\t}\n\t\t}\n\t}\n\treturn t.addDependencies(targetedNodes, g)\n}"}, {"instruction": "// Provide implements DockerConfigProvider", "input": "go language", "output": "func (g *containerRegistryProvider) Provide(image string) credentialprovider.DockerConfig {\n\tcfg := credentialprovider.DockerConfig{}\n\n\ttokenJsonBlob, err := credentialprovider.ReadUrl(metadataToken, g.Client, metadataHeader)\n\tif err != nil {\n\t\tklog.Errorf(\"while reading access token endpoint: %v\", err)\n\t\treturn cfg\n\t}\n\n\temail, err := credentialprovider.ReadUrl(metadataEmail, g.Client, metadataHeader)\n\tif err != nil {\n\t\tklog.Errorf(\"while reading email endpoint: %v\", err)\n\t\treturn cfg\n\t}\n\n\tvar parsedBlob tokenBlob\n\tif err := json.Unmarshal([]byte(tokenJsonBlob), &parsedBlob); err != nil {\n\t\tklog.Errorf(\"while parsing json blob %s: %v\", tokenJsonBlob, err)\n\t\treturn cfg\n\t}\n\n\tentry := credentialprovider.DockerConfigEntry{\n\t\tUsername: \"_token\",\n\t\tPassword: parsedBlob.AccessToken,\n\t\tEmail:    string(email),\n\t}\n\n\t// Add our entry for each of the supported container registry URLs\n\tfor _, k := range containerRegistryUrls {\n\t\tcfg[k] = entry\n\t}\n\treturn cfg\n}"}, {"instruction": "// CreateConfiguration creates a provider configuration from content using templating.", "input": "go language", "output": "func (p *Provider) CreateConfiguration(tmplContent string, funcMap template.FuncMap, templateObjects interface{}) (*config.Configuration, error) {\n\tvar defaultFuncMap = sprig.TxtFuncMap()\n\tdefaultFuncMap[\"normalize\"] = provider.Normalize\n\tdefaultFuncMap[\"split\"] = strings.Split\n\tfor funcID, funcElement := range funcMap {\n\t\tdefaultFuncMap[funcID] = funcElement\n\t}\n\n\ttmpl := template.New(p.Filename).Funcs(defaultFuncMap)\n\n\t_, err := tmpl.Parse(tmplContent)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar buffer bytes.Buffer\n\terr = tmpl.Execute(&buffer, templateObjects)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar renderedTemplate = buffer.String()\n\tif p.DebugLogGeneratedTemplate {\n\t\tlog.Debugf(\"Template content: %s\", tmplContent)\n\t\tlog.Debugf(\"Rendering results: %s\", renderedTemplate)\n\t}\n\treturn p.DecodeConfiguration(renderedTemplate)\n}"}, {"instruction": "// GetAllDDLJobsInQueue gets all DDL Jobs in the current queue.\n// The length of jobListKeys can only be 1 or 0.\n// If its length is 1, we need to replace m.jobListKey with jobListKeys[0].\n// Otherwise, we use m.jobListKey directly.", "input": "go language", "output": "func (m *Meta) GetAllDDLJobsInQueue(jobListKeys ...JobListKeyType) ([]*model.Job, error) {\n\tlistKey := m.jobListKey\n\tif len(jobListKeys) != 0 {\n\t\tlistKey = jobListKeys[0]\n\t}\n\n\tvalues, err := m.txn.LGetAll(listKey)\n\tif err != nil || values == nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\n\tjobs := make([]*model.Job, 0, len(values))\n\tfor _, val := range values {\n\t\tjob := &model.Job{}\n\t\terr = job.Decode(val)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tjobs = append(jobs, job)\n\t}\n\n\treturn jobs, nil\n}"}, {"instruction": "// DidDisconnect tracks the fact that the \"one\" node disconnected from the\n// \"other\" node", "input": "go language", "output": "func (net *Network) DidDisconnect(one, other enode.ID) error {\n\tnet.lock.Lock()\n\tdefer net.lock.Unlock()\n\tconn := net.getConn(one, other)\n\tif conn == nil {\n\t\treturn fmt.Errorf(\"connection between %v and %v does not exist\", one, other)\n\t}\n\tif !conn.Up {\n\t\treturn fmt.Errorf(\"%v and %v already disconnected\", one, other)\n\t}\n\tconn.Up = false\n\tconn.initiated = time.Now().Add(-DialBanTimeout)\n\tnet.events.Send(NewEvent(conn))\n\treturn nil\n}"}, {"instruction": "// parseRSAPrivateKey parses a single RSA private key from the provided data", "input": "go language", "output": "func parseRSAPrivateKey(data []byte) (*rsa.PrivateKey, error) {\n\tvar err error\n\n\t// Parse the key\n\tvar parsedKey interface{}\n\tif parsedKey, err = x509.ParsePKCS1PrivateKey(data); err != nil {\n\t\tif parsedKey, err = x509.ParsePKCS8PrivateKey(data); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Test if parsed key is an RSA Private Key\n\tvar privKey *rsa.PrivateKey\n\tvar ok bool\n\tif privKey, ok = parsedKey.(*rsa.PrivateKey); !ok {\n\t\treturn nil, fmt.Errorf(\"data doesn't contain valid RSA Private Key\")\n\t}\n\n\treturn privKey, nil\n}"}, {"instruction": "// The LB needs to be configured with instance addresses on the same\n// subnet as the LB (aka opts.SubnetID).  Currently we're just\n// guessing that the node's InternalIP is the right address.\n// In case no InternalIP can be found, ExternalIP is tried.\n// If neither InternalIP nor ExternalIP can be found an error is\n// returned.", "input": "go language", "output": "func nodeAddressForLB(node *v1.Node) (string, error) {\n\taddrs := node.Status.Addresses\n\tif len(addrs) == 0 {\n\t\treturn \"\", ErrNoAddressFound\n\t}\n\n\tallowedAddrTypes := []v1.NodeAddressType{v1.NodeInternalIP, v1.NodeExternalIP}\n\n\tfor _, allowedAddrType := range allowedAddrTypes {\n\t\tfor _, addr := range addrs {\n\t\t\tif addr.Type == allowedAddrType {\n\t\t\t\treturn addr.Address, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn \"\", ErrNoAddressFound\n}"}, {"instruction": "// getContext returns the clientcmdapi.Context, or an error if a required context is not found.", "input": "go language", "output": "func (config *DirectClientConfig) getContext() (clientcmdapi.Context, error) {\n\tcontexts := config.config.Contexts\n\tcontextName, required := config.getContextName()\n\n\tmergedContext := clientcmdapi.NewContext()\n\tif configContext, exists := contexts[contextName]; exists {\n\t\tmergo.MergeWithOverwrite(mergedContext, configContext)\n\t} else if required {\n\t\treturn clientcmdapi.Context{}, fmt.Errorf(\"context %q does not exist\", contextName)\n\t}\n\tmergo.MergeWithOverwrite(mergedContext, config.overrides.Context)\n\n\treturn *mergedContext, nil\n}"}, {"instruction": "// MarshalJSON marshals type Criteria to a json string", "input": "go language", "output": "func (c Criteria) MarshalJSON() ([]byte, error) {\n\ttype Criteria struct {\n\t\tSymKeyID     string        `json:\"symKeyID\"`\n\t\tPrivateKeyID string        `json:\"privateKeyID\"`\n\t\tSig          hexutil.Bytes `json:\"sig\"`\n\t\tMinPow       float64       `json:\"minPow\"`\n\t\tTopics       []TopicType   `json:\"topics\"`\n\t\tAllowP2P     bool          `json:\"allowP2P\"`\n\t}\n\tvar enc Criteria\n\tenc.SymKeyID = c.SymKeyID\n\tenc.PrivateKeyID = c.PrivateKeyID\n\tenc.Sig = c.Sig\n\tenc.MinPow = c.MinPow\n\tenc.Topics = c.Topics\n\tenc.AllowP2P = c.AllowP2P\n\treturn json.Marshal(&enc)\n}"}, {"instruction": "// CAProviderState is used to get the Consul CA provider state for the given ID.", "input": "go language", "output": "func (s *Store) CAProviderState(id string) (uint64, *structs.CAConsulProviderState, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the index\n\tidx := maxIndexTxn(tx, caBuiltinProviderTableName)\n\n\t// Get the provider config\n\tc, err := tx.First(caBuiltinProviderTableName, \"id\", id)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed built-in CA state lookup: %s\", err)\n\t}\n\n\tstate, ok := c.(*structs.CAConsulProviderState)\n\tif !ok {\n\t\treturn 0, nil, nil\n\t}\n\n\treturn idx, state, nil\n}"}, {"instruction": "// serveChunkExplorer starts an http server in background with chunk explorer handler\n// using the provided global store. Server is started if the returned shutdown function\n// is not nil.", "input": "go language", "output": "func serveChunkExplorer(ctx *cli.Context, globalStore mock.GlobalStorer) (shutdown func(), err error) {\n\tif !ctx.IsSet(\"explorer-address\") {\n\t\treturn nil, nil\n\t}\n\n\tcorsOrigins := ctx.StringSlice(\"explorer-cors-origin\")\n\tserver := &http.Server{\n\t\tHandler:      explorer.NewHandler(globalStore, corsOrigins),\n\t\tIdleTimeout:  30 * time.Minute,\n\t\tReadTimeout:  2 * time.Minute,\n\t\tWriteTimeout: 2 * time.Minute,\n\t}\n\tlistener, err := net.Listen(\"tcp\", ctx.String(\"explorer-address\"))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"explorer: %v\", err)\n\t}\n\tlog.Info(\"chunk explorer http\", \"address\", listener.Addr().String(), \"origins\", corsOrigins)\n\n\tgo func() {\n\t\tif err := server.Serve(listener); err != nil {\n\t\t\tlog.Error(\"chunk explorer\", \"err\", err)\n\t\t}\n\t}()\n\n\treturn func() {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tdefer cancel()\n\t\tif err := server.Shutdown(ctx); err != nil {\n\t\t\tlog.Error(\"chunk explorer: shutdown\", \"err\", err)\n\t\t}\n\t}, nil\n}"}, {"instruction": "// updateAllocatedDevices gets a list of active pods and then frees any Devices that are bound to\n// terminated pods. Returns error on failure.", "input": "go language", "output": "func (m *ManagerImpl) updateAllocatedDevices(activePods []*v1.Pod) {\n\tif !m.sourcesReady.AllReady() {\n\t\treturn\n\t}\n\tm.mutex.Lock()\n\tdefer m.mutex.Unlock()\n\tactivePodUids := sets.NewString()\n\tfor _, pod := range activePods {\n\t\tactivePodUids.Insert(string(pod.UID))\n\t}\n\tallocatedPodUids := m.podDevices.pods()\n\tpodsToBeRemoved := allocatedPodUids.Difference(activePodUids)\n\tif len(podsToBeRemoved) <= 0 {\n\t\treturn\n\t}\n\tklog.V(3).Infof(\"pods to be removed: %v\", podsToBeRemoved.List())\n\tm.podDevices.delete(podsToBeRemoved.List())\n\t// Regenerated allocatedDevices after we update pod allocation information.\n\tm.allocatedDevices = m.podDevices.devices()\n}"}, {"instruction": "// Matches matches path against all the patterns. Matches is not safe to be\n// called concurrently", "input": "go language", "output": "func (pm *PatternMatcher) Matches(file string) (bool, error) {\n\tmatched := false\n\tfile = filepath.FromSlash(file)\n\tparentPath := filepath.Dir(file)\n\tparentPathDirs := strings.Split(parentPath, string(os.PathSeparator))\n\n\tfor _, pattern := range pm.patterns {\n\t\tnegative := false\n\n\t\tif pattern.exclusion {\n\t\t\tnegative = true\n\t\t}\n\n\t\tmatch, err := pattern.match(file)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif !match && parentPath != \".\" {\n\t\t\t// Check to see if the pattern matches one of our parent dirs.\n\t\t\tif len(pattern.dirs) <= len(parentPathDirs) {\n\t\t\t\tmatch, _ = pattern.match(strings.Join(parentPathDirs[:len(pattern.dirs)], string(os.PathSeparator)))\n\t\t\t}\n\t\t}\n\n\t\tif match {\n\t\t\tmatched = !negative\n\t\t}\n\t}\n\n\tif matched {\n\t\tlogrus.Debugf(\"Skipping excluded path: %s\", file)\n\t}\n\n\treturn matched, nil\n}"}, {"instruction": "// Less compares two values in a byTimestamp slice by Timestamp.  Less is\n// required by the sort.Interface interface.", "input": "go language", "output": "func (slice byTimestamp) Less(i, j int) bool {\n\tiTimestamp, jTimestamp := int64(0), int64(0)\n\tif slice != nil && slice[i].inputLogEvent.Timestamp != nil {\n\t\tiTimestamp = *slice[i].inputLogEvent.Timestamp\n\t}\n\tif slice != nil && slice[j].inputLogEvent.Timestamp != nil {\n\t\tjTimestamp = *slice[j].inputLogEvent.Timestamp\n\t}\n\tif iTimestamp == jTimestamp {\n\t\treturn slice[i].insertOrder < slice[j].insertOrder\n\t}\n\treturn iTimestamp < jTimestamp\n}"}, {"instruction": "// Status returns the status of the runtime.", "input": "go language", "output": "func (r *RemoteRuntimeService) Status() (*runtimeapi.RuntimeStatus, error) {\n\tctx, cancel := getContextWithTimeout(r.timeout)\n\tdefer cancel()\n\n\tresp, err := r.runtimeClient.Status(ctx, &runtimeapi.StatusRequest{})\n\tif err != nil {\n\t\tklog.Errorf(\"Status from runtime service failed: %v\", err)\n\t\treturn nil, err\n\t}\n\n\tif resp.Status == nil || len(resp.Status.Conditions) < 2 {\n\t\terrorMessage := \"RuntimeReady or NetworkReady condition are not set\"\n\t\tklog.Errorf(\"Status failed: %s\", errorMessage)\n\t\treturn nil, errors.New(errorMessage)\n\t}\n\n\treturn resp.Status, nil\n}"}, {"instruction": "// ensureHomeIfIAmStatic ensure $HOME to be set if dockerversion.IAmStatic is \"true\".\n// See issue #29344: gcplogs segfaults (static binary)\n// If HOME is not set, logging.NewClient() will call os/user.Current() via oauth2/google.\n// However, in static binary, os/user.Current() leads to segfault due to a glibc issue that won't be fixed\n// in a short term. (golang/go#13470, https://sourceware.org/bugzilla/show_bug.cgi?id=19341)\n// So we forcibly set HOME so as to avoid call to os/user/Current()", "input": "go language", "output": "func ensureHomeIfIAmStatic() error {\n\t// Note: dockerversion.IAmStatic and homedir.GetStatic() is only available for linux.\n\t// So we need to use them in this gcplogging_linux.go rather than in gcplogging.go\n\tif dockerversion.IAmStatic == \"true\" && os.Getenv(\"HOME\") == \"\" {\n\t\thome, err := homedir.GetStatic()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogrus.Warnf(\"gcplogs requires HOME to be set for static daemon binary. Forcibly setting HOME to %s.\", home)\n\t\tos.Setenv(\"HOME\", home)\n\t}\n\treturn nil\n}"}, {"instruction": "// getGroupVersionKind returns the GroupVersionKind of the object", "input": "go language", "output": "func getGroupVersionKind(config map[string]interface{}) (schema.GroupVersionKind, error) {\n\tgvk := schema.GroupVersionKind{}\n\tif gv, found := config[\"apiVersion\"]; found {\n\t\tcasted, ok := gv.(string)\n\t\tif !ok {\n\t\t\treturn gvk, fmt.Errorf(\"Expected string for apiVersion, found %T\", gv)\n\t\t}\n\t\ts := strings.Split(casted, \"/\")\n\t\tif len(s) != 1 {\n\t\t\tgvk.Group = s[0]\n\t\t}\n\t\tgvk.Version = s[len(s)-1]\n\t} else {\n\t\treturn gvk, fmt.Errorf(\"Missing apiVersion in Kind %v\", config)\n\t}\n\tif k, found := config[\"kind\"]; found {\n\t\tcasted, ok := k.(string)\n\t\tif !ok {\n\t\t\treturn gvk, fmt.Errorf(\"Expected string for kind, found %T\", k)\n\t\t}\n\t\tgvk.Kind = casted\n\t} else {\n\t\treturn gvk, fmt.Errorf(\"Missing kind in Kind %v\", config)\n\t}\n\treturn gvk, nil\n}"}, {"instruction": "// UpdateAttachment notifies the attacher about the attachment config.", "input": "go language", "output": "func (daemon *Daemon) UpdateAttachment(networkName, networkID, containerID string, config *network.NetworkingConfig) error {\n\tif daemon.clusterProvider == nil {\n\t\treturn fmt.Errorf(\"cluster provider is not initialized\")\n\t}\n\n\tif err := daemon.clusterProvider.UpdateAttachment(networkName, containerID, config); err != nil {\n\t\treturn daemon.clusterProvider.UpdateAttachment(networkID, containerID, config)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// DecodeObjectManagedFields extracts and converts the objects ManagedFields into a fieldpath.ManagedFields.", "input": "go language", "output": "func DecodeObjectManagedFields(from runtime.Object) (fieldpath.ManagedFields, error) {\n\tif from == nil {\n\t\treturn make(map[string]*fieldpath.VersionedSet), nil\n\t}\n\taccessor, err := meta.Accessor(from)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"couldn't get accessor: %v\", err))\n\t}\n\n\tmanaged, err := decodeManagedFields(accessor.GetManagedFields())\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to convert managed fields from API: %v\", err)\n\t}\n\treturn managed, err\n}"}, {"instruction": "// AddInstancesToTargetPool adds instances by link to the TargetPool", "input": "go language", "output": "func (g *Cloud) AddInstancesToTargetPool(name, region string, instanceRefs []*compute.InstanceReference) error {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\treq := &compute.TargetPoolsAddInstanceRequest{\n\t\tInstances: instanceRefs,\n\t}\n\tmc := newTargetPoolMetricContext(\"add_instances\", region)\n\treturn mc.Observe(g.c.TargetPools().AddInstance(ctx, meta.RegionalKey(name, region), req))\n}"}, {"instruction": "// getAllReplicaSetsAndSyncRevision returns all the replica sets for the provided deployment (new and all old), with new RS's and deployment's revision updated.\n//\n// rsList should come from getReplicaSetsForDeployment(d).\n//\n// 1. Get all old RSes this deployment targets, and calculate the max revision number among them (maxOldV).\n// 2. Get new RS this deployment targets (whose pod template matches deployment's), and update new RS's revision number to (maxOldV + 1),\n//    only if its revision number is smaller than (maxOldV + 1). If this step failed, we'll update it in the next deployment sync loop.\n// 3. Copy new RS's revision number to deployment (update deployment's revision). If this step failed, we'll update it in the next deployment sync loop.\n//\n// Note that currently the deployment controller is using caches to avoid querying the server for reads.\n// This may lead to stale reads of replica sets, thus incorrect deployment status.", "input": "go language", "output": "func (dc *DeploymentController) getAllReplicaSetsAndSyncRevision(d *apps.Deployment, rsList []*apps.ReplicaSet, createIfNotExisted bool) (*apps.ReplicaSet, []*apps.ReplicaSet, error) {\n\t_, allOldRSs := deploymentutil.FindOldReplicaSets(d, rsList)\n\n\t// Get new replica set with the updated revision number\n\tnewRS, err := dc.getNewReplicaSet(d, rsList, allOldRSs, createIfNotExisted)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn newRS, allOldRSs, nil\n}"}, {"instruction": "// GraphNodeEvalable", "input": "go language", "output": "func (n *NodePlannableResourceInstance) EvalTree() EvalNode {\n\taddr := n.ResourceInstanceAddr()\n\n\t// State still uses legacy-style internal ids, so we need to shim to get\n\t// a suitable key to use.\n\tstateId := NewLegacyResourceInstanceAddress(addr).stateId()\n\n\t// Determine the dependencies for the state.\n\tstateDeps := n.StateReferences()\n\n\t// Eval info is different depending on what kind of resource this is\n\tswitch addr.Resource.Resource.Mode {\n\tcase addrs.ManagedResourceMode:\n\t\treturn n.evalTreeManagedResource(addr, stateId, stateDeps)\n\tcase addrs.DataResourceMode:\n\t\treturn n.evalTreeDataResource(addr, stateId, stateDeps)\n\tdefault:\n\t\tpanic(fmt.Errorf(\"unsupported resource mode %s\", n.Config.Mode))\n\t}\n}"}, {"instruction": "// itemChanged returns true if the given disk file differs from the information\n// in the database and schedules that file for scanning", "input": "go language", "output": "func (f *sendReceiveFolder) itemChanged(stat fs.FileInfo, item protocol.FileInfo, hasItem bool, scanChan chan<- string) (changed bool, err error) {\n\tdefer func() {\n\t\tif changed {\n\t\t\tscanChan <- item.Name\n\t\t}\n\t}()\n\n\tif !hasItem || item.Deleted {\n\t\t// The item appeared from nowhere\n\t\treturn true, nil\n\t}\n\n\t// Check that the item on disk is what we expect it to be according\n\t// to the database. If there's a mismatch here, there might be local\n\t// changes that we don't know about yet and we should scan before\n\t// touching the item.\n\tstatItem, err := scanner.CreateFileInfo(stat, item.Name, f.fs)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"comparing item on disk to db\")\n\t}\n\n\treturn !statItem.IsEquivalentOptional(item, f.IgnorePerms, true, protocol.LocalAllFlags), nil\n}"}, {"instruction": "// getIPv4DefaultRoutes obtains the IPv4 routes, and filters out non-default routes.", "input": "go language", "output": "func getIPv4DefaultRoutes(input io.Reader) ([]Route, error) {\n\troutes := []Route{}\n\tscanner := bufio.NewReader(input)\n\tfor {\n\t\tline, err := scanner.ReadString('\\n')\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t\t//ignore the headers in the route info\n\t\tif strings.HasPrefix(line, \"Iface\") {\n\t\t\tcontinue\n\t\t}\n\t\tfields := strings.Fields(line)\n\t\t// Interested in fields:\n\t\t//  0 - interface name\n\t\t//  1 - destination address\n\t\t//  2 - gateway\n\t\tdest, err := parseIP(fields[1], familyIPv4)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tgw, err := parseIP(fields[2], familyIPv4)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !dest.Equal(net.IPv4zero) {\n\t\t\tcontinue\n\t\t}\n\t\troutes = append(routes, Route{\n\t\t\tInterface:   fields[0],\n\t\t\tDestination: dest,\n\t\t\tGateway:     gw,\n\t\t\tFamily:      familyIPv4,\n\t\t})\n\t}\n\treturn routes, nil\n}"}, {"instruction": "// ExportChain exports a blockchain into the specified file, truncating any data\n// already present in the file.", "input": "go language", "output": "func ExportChain(blockchain *core.BlockChain, fn string) error {\n\tlog.Info(\"Exporting blockchain\", \"file\", fn)\n\n\t// Open the file handle and potentially wrap with a gzip stream\n\tfh, err := os.OpenFile(fn, os.O_CREATE|os.O_WRONLY|os.O_TRUNC, os.ModePerm)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer fh.Close()\n\n\tvar writer io.Writer = fh\n\tif strings.HasSuffix(fn, \".gz\") {\n\t\twriter = gzip.NewWriter(writer)\n\t\tdefer writer.(*gzip.Writer).Close()\n\t}\n\t// Iterate over the blocks and export them\n\tif err := blockchain.Export(writer); err != nil {\n\t\treturn err\n\t}\n\tlog.Info(\"Exported blockchain\", \"file\", fn)\n\n\treturn nil\n}"}, {"instruction": "// Gets Disk counts per storage account", "input": "go language", "output": "func (c *BlobDiskController) getDiskCount(SAName string) (int, error) {\n\t// if we have it in cache\n\tif c.accounts[SAName].diskCount != -1 {\n\t\treturn int(c.accounts[SAName].diskCount), nil\n\t}\n\n\tvar err error\n\tvar blobSvc azstorage.BlobStorageClient\n\n\tif err = c.ensureDefaultContainer(SAName); err != nil {\n\t\treturn 0, err\n\t}\n\n\tif blobSvc, err = c.getBlobSvcClient(SAName); err != nil {\n\t\treturn 0, err\n\t}\n\tparams := azstorage.ListBlobsParameters{}\n\n\tcontainer := blobSvc.GetContainerReference(vhdContainerName)\n\tresponse, err := container.ListBlobs(params)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tklog.V(4).Infof(\"azure-Disk -  refreshed data count for account %s and found %v\", SAName, len(response.Blobs))\n\tc.accounts[SAName].diskCount = int32(len(response.Blobs))\n\n\treturn int(c.accounts[SAName].diskCount), nil\n}"}, {"instruction": "// setClaimProvisioner saves\n// claim.Annotations[annStorageProvisioner] = class.Provisioner", "input": "go language", "output": "func (ctrl *PersistentVolumeController) setClaimProvisioner(claim *v1.PersistentVolumeClaim, provisionerName string) (*v1.PersistentVolumeClaim, error) {\n\tif val, ok := claim.Annotations[annStorageProvisioner]; ok && val == provisionerName {\n\t\t// annotation is already set, nothing to do\n\t\treturn claim, nil\n\t}\n\n\t// The volume from method args can be pointing to watcher cache. We must not\n\t// modify these, therefore create a copy.\n\tclaimClone := claim.DeepCopy()\n\tmetav1.SetMetaDataAnnotation(&claimClone.ObjectMeta, annStorageProvisioner, provisionerName)\n\tnewClaim, err := ctrl.kubeClient.CoreV1().PersistentVolumeClaims(claim.Namespace).Update(claimClone)\n\tif err != nil {\n\t\treturn newClaim, err\n\t}\n\t_, err = ctrl.storeClaimUpdate(newClaim)\n\tif err != nil {\n\t\treturn newClaim, err\n\t}\n\treturn newClaim, nil\n}"}, {"instruction": "// mergeDNSOptions merges DNS options. If duplicated, entries given by PodDNSConfigOption will\n// overwrite the existing ones.", "input": "go language", "output": "func mergeDNSOptions(existingDNSConfigOptions []string, dnsConfigOptions []v1.PodDNSConfigOption) []string {\n\toptionsMap := make(map[string]string)\n\tfor _, op := range existingDNSConfigOptions {\n\t\tif index := strings.Index(op, \":\"); index != -1 {\n\t\t\toptionsMap[op[:index]] = op[index+1:]\n\t\t} else {\n\t\t\toptionsMap[op] = \"\"\n\t\t}\n\t}\n\tfor _, op := range dnsConfigOptions {\n\t\tif op.Value != nil {\n\t\t\toptionsMap[op.Name] = *op.Value\n\t\t} else {\n\t\t\toptionsMap[op.Name] = \"\"\n\t\t}\n\t}\n\t// Reconvert DNS options into a string array.\n\toptions := []string{}\n\tfor opName, opValue := range optionsMap {\n\t\top := opName\n\t\tif opValue != \"\" {\n\t\t\top = op + \":\" + opValue\n\t\t}\n\t\toptions = append(options, op)\n\t}\n\treturn options\n}"}, {"instruction": "// NodeAddressesByProviderID will not be called from the node that is requesting this ID.\n// i.e. metadata service and other local methods cannot be used here", "input": "go language", "output": "func (g *Cloud) NodeAddressesByProviderID(ctx context.Context, providerID string) ([]v1.NodeAddress, error) {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\t_, zone, name, err := splitProviderID(providerID)\n\tif err != nil {\n\t\treturn []v1.NodeAddress{}, err\n\t}\n\n\tinstance, err := g.c.Instances().Get(ctx, meta.ZonalKey(canonicalizeInstanceName(name), zone))\n\tif err != nil {\n\t\treturn []v1.NodeAddress{}, fmt.Errorf(\"error while querying for providerID %q: %v\", providerID, err)\n\t}\n\n\tif len(instance.NetworkInterfaces) < 1 {\n\t\treturn []v1.NodeAddress{}, fmt.Errorf(\"could not find network interfaces for providerID %q\", providerID)\n\t}\n\tnetworkInterface := instance.NetworkInterfaces[0]\n\n\tnodeAddresses := []v1.NodeAddress{{Type: v1.NodeInternalIP, Address: networkInterface.NetworkIP}}\n\tfor _, config := range networkInterface.AccessConfigs {\n\t\tnodeAddresses = append(nodeAddresses, v1.NodeAddress{Type: v1.NodeExternalIP, Address: config.NatIP})\n\t}\n\n\treturn nodeAddresses, nil\n}"}, {"instruction": "// Stream opens a protocol streamer to the server and streams until a client closes\n// the connection or the server disconnects.", "input": "go language", "output": "func (e *streamExecutor) Stream(options StreamOptions) error {\n\treq, err := http.NewRequest(e.method, e.url.String(), nil)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error creating request: %v\", err)\n\t}\n\n\tconn, protocol, err := spdy.Negotiate(\n\t\te.upgrader,\n\t\t&http.Client{Transport: e.transport},\n\t\treq,\n\t\te.protocols...,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer conn.Close()\n\n\tvar streamer streamProtocolHandler\n\n\tswitch protocol {\n\tcase remotecommand.StreamProtocolV4Name:\n\t\tstreamer = newStreamProtocolV4(options)\n\tcase remotecommand.StreamProtocolV3Name:\n\t\tstreamer = newStreamProtocolV3(options)\n\tcase remotecommand.StreamProtocolV2Name:\n\t\tstreamer = newStreamProtocolV2(options)\n\tcase \"\":\n\t\tklog.V(4).Infof(\"The server did not negotiate a streaming protocol version. Falling back to %s\", remotecommand.StreamProtocolV1Name)\n\t\tfallthrough\n\tcase remotecommand.StreamProtocolV1Name:\n\t\tstreamer = newStreamProtocolV1(options)\n\t}\n\n\treturn streamer.stream(conn)\n}"}, {"instruction": "// Run is used to run a watch plan", "input": "go language", "output": "func (p *Plan) RunWithConfig(address string, conf *consulapi.Config) error {\n\t// Setup the client\n\tp.address = address\n\tif conf == nil {\n\t\tconf = consulapi.DefaultConfig()\n\t}\n\tconf.Address = address\n\tconf.Datacenter = p.Datacenter\n\tconf.Token = p.Token\n\tclient, err := consulapi.NewClient(conf)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed to connect to agent: %v\", err)\n\t}\n\n\t// Create the logger\n\toutput := p.LogOutput\n\tif output == nil {\n\t\toutput = os.Stderr\n\t}\n\tlogger := log.New(output, \"\", log.LstdFlags)\n\n\treturn p.RunWithClientAndLogger(client, logger)\n}"}, {"instruction": "// TranslatePullError is used to convert an error from a registry pull\n// operation to an error representing the entire pull operation. Any error\n// information which is not used by the returned error gets output to\n// log at info level.", "input": "go language", "output": "func TranslatePullError(err error, ref reference.Named) error {\n\tswitch v := err.(type) {\n\tcase errcode.Errors:\n\t\tif len(v) != 0 {\n\t\t\tfor _, extra := range v[1:] {\n\t\t\t\tlogrus.Infof(\"Ignoring extra error returned from registry: %v\", extra)\n\t\t\t}\n\t\t\treturn TranslatePullError(v[0], ref)\n\t\t}\n\tcase errcode.Error:\n\t\tswitch v.Code {\n\t\tcase errcode.ErrorCodeDenied, v2.ErrorCodeManifestUnknown, v2.ErrorCodeNameUnknown:\n\t\t\treturn notFoundError{v, ref}\n\t\t}\n\tcase xfer.DoNotRetry:\n\t\treturn TranslatePullError(v.Err, ref)\n\t}\n\n\treturn errdefs.Unknown(err)\n}"}, {"instruction": "// RunCompletion checks given arguments and executes command", "input": "go language", "output": "func RunCompletion(out io.Writer, boilerPlate string, cmd *cobra.Command, args []string) error {\n\tif len(args) == 0 {\n\t\treturn cmdutil.UsageErrorf(cmd, \"Shell not specified.\")\n\t}\n\tif len(args) > 1 {\n\t\treturn cmdutil.UsageErrorf(cmd, \"Too many arguments. Expected only the shell type.\")\n\t}\n\trun, found := completionShells[args[0]]\n\tif !found {\n\t\treturn cmdutil.UsageErrorf(cmd, \"Unsupported shell type %q.\", args[0])\n\t}\n\n\treturn run(out, boilerPlate, cmd.Parent())\n}"}, {"instruction": "// StmtCommit implements the sessionctx.Context interface.", "input": "go language", "output": "func (s *session) StmtCommit() error {\n\tdefer s.txn.cleanup()\n\tst := &s.txn\n\tvar count int\n\terr := kv.WalkMemBuffer(st.buf, func(k kv.Key, v []byte) error {\n\t\tfailpoint.Inject(\"mockStmtCommitError\", func(val failpoint.Value) {\n\t\t\tif val.(bool) {\n\t\t\t\tcount++\n\t\t\t}\n\t\t})\n\n\t\tif count > 3 {\n\t\t\treturn errors.New(\"mock stmt commit error\")\n\t\t}\n\n\t\tif len(v) == 0 {\n\t\t\treturn st.Transaction.Delete(k)\n\t\t}\n\t\treturn st.Transaction.Set(k, v)\n\t})\n\tif err != nil {\n\t\tst.doNotCommit = err\n\t\treturn err\n\t}\n\n\t// Need to flush binlog.\n\tfor tableID, delta := range st.mutations {\n\t\tmutation := getBinlogMutation(s, tableID)\n\t\tmergeToMutation(mutation, delta)\n\t}\n\n\tif len(st.dirtyTableOP) > 0 {\n\t\tdirtyDB := executor.GetDirtyDB(s)\n\t\tfor _, op := range st.dirtyTableOP {\n\t\t\tmergeToDirtyDB(dirtyDB, op)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// ResolveCharsetCollation will resolve the charset by the order: table charset > database charset > server default charset.", "input": "go language", "output": "func ResolveCharsetCollation(tblCharset, dbCharset string) (string, string, error) {\n\tif len(tblCharset) != 0 {\n\t\tdefCollate, err := charset.GetDefaultCollation(tblCharset)\n\t\tif err != nil {\n\t\t\t// return terror is better.\n\t\t\treturn \"\", \"\", ErrUnknownCharacterSet.GenWithStackByArgs(tblCharset)\n\t\t}\n\t\treturn tblCharset, defCollate, nil\n\t}\n\n\tif len(dbCharset) != 0 {\n\t\tdefCollate, err := charset.GetDefaultCollation(dbCharset)\n\t\tif err != nil {\n\t\t\treturn \"\", \"\", ErrUnknownCharacterSet.GenWithStackByArgs(dbCharset)\n\t\t}\n\t\treturn dbCharset, defCollate, errors.Trace(err)\n\t}\n\n\tcharset, collate := charset.GetDefaultCharsetAndCollate()\n\treturn charset, collate, nil\n}"}, {"instruction": "// DumpFeedbackToKV dumps the given feedback to physical kv layer.", "input": "go language", "output": "func (h *Handle) DumpFeedbackToKV(fb *statistics.QueryFeedback) error {\n\tvals, err := statistics.EncodeFeedback(fb)\n\tif err != nil {\n\t\tlogutil.Logger(context.Background()).Debug(\"error occurred when encoding feedback\", zap.Error(err))\n\t\treturn nil\n\t}\n\tvar isIndex int64\n\tif fb.Tp == statistics.IndexType {\n\t\tisIndex = 1\n\t}\n\tsql := fmt.Sprintf(\"insert into mysql.stats_feedback (table_id, hist_id, is_index, feedback) values \"+\n\t\t\"(%d, %d, %d, X'%X')\", fb.PhysicalID, fb.Hist.ID, isIndex, vals)\n\th.mu.Lock()\n\t_, err = h.mu.ctx.(sqlexec.SQLExecutor).Execute(context.TODO(), sql)\n\th.mu.Unlock()\n\tif err != nil {\n\t\tmetrics.DumpFeedbackCounter.WithLabelValues(metrics.LblError).Inc()\n\t} else {\n\t\tmetrics.DumpFeedbackCounter.WithLabelValues(metrics.LblOK).Inc()\n\t}\n\treturn errors.Trace(err)\n}"}, {"instruction": "// ensureLease creates the lease if it does not exist. Returns the lease and\n// a bool (true if this call created the lease), or any error that occurs.", "input": "go language", "output": "func (c *controller) ensureLease() (*coordv1beta1.Lease, bool, error) {\n\tlease, err := c.leaseClient.Get(c.holderIdentity, metav1.GetOptions{})\n\tif apierrors.IsNotFound(err) {\n\t\t// lease does not exist, create it\n\t\tlease, err := c.leaseClient.Create(c.newLease(nil))\n\t\tif err != nil {\n\t\t\treturn nil, false, err\n\t\t}\n\t\treturn lease, true, nil\n\t} else if err != nil {\n\t\t// unexpected error getting lease\n\t\treturn nil, false, err\n\t}\n\t// lease already existed\n\treturn lease, false, nil\n}"}, {"instruction": "// String implements the fmt.Stringer interface.", "input": "go language", "output": "func (c *ChainConfig) String() string {\n\tvar engine interface{}\n\tswitch {\n\tcase c.Ethash != nil:\n\t\tengine = c.Ethash\n\tcase c.Clique != nil:\n\t\tengine = c.Clique\n\tdefault:\n\t\tengine = \"unknown\"\n\t}\n\treturn fmt.Sprintf(\"{ChainID: %v Homestead: %v DAO: %v DAOSupport: %v EIP150: %v EIP155: %v EIP158: %v Byzantium: %v Constantinople: %v  ConstantinopleFix: %v Engine: %v}\",\n\t\tc.ChainID,\n\t\tc.HomesteadBlock,\n\t\tc.DAOForkBlock,\n\t\tc.DAOForkSupport,\n\t\tc.EIP150Block,\n\t\tc.EIP155Block,\n\t\tc.EIP158Block,\n\t\tc.ByzantiumBlock,\n\t\tc.ConstantinopleBlock,\n\t\tc.PetersburgBlock,\n\t\tengine,\n\t)\n}"}, {"instruction": "// clearAttachableNetworks removes the attachable networks\n// after disconnecting any connected container", "input": "go language", "output": "func (daemon *Daemon) clearAttachableNetworks() {\n\tfor _, n := range daemon.getAllNetworks() {\n\t\tif !n.Info().Attachable() {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, ep := range n.Endpoints() {\n\t\t\tepInfo := ep.Info()\n\t\t\tif epInfo == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tsb := epInfo.Sandbox()\n\t\t\tif sb == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcontainerID := sb.ContainerID()\n\t\t\tif err := daemon.DisconnectContainerFromNetwork(containerID, n.ID(), true); err != nil {\n\t\t\t\tlogrus.Warnf(\"Failed to disconnect container %s from swarm network %s on cluster leave: %v\",\n\t\t\t\t\tcontainerID, n.Name(), err)\n\t\t\t}\n\t\t}\n\t\tif err := daemon.DeleteManagedNetwork(n.ID()); err != nil {\n\t\t\tlogrus.Warnf(\"Failed to remove swarm network %s on cluster leave: %v\", n.Name(), err)\n\t\t}\n\t}\n}"}, {"instruction": "// getAffinityTermProperties receives a Pod and affinity terms and returns the namespaces and\n// selectors of the terms.", "input": "go language", "output": "func getAffinityTermProperties(pod *v1.Pod, terms []v1.PodAffinityTerm) (properties []*affinityTermProperties, err error) {\n\tif terms == nil {\n\t\treturn properties, nil\n\t}\n\n\tfor _, term := range terms {\n\t\tnamespaces := priorityutil.GetNamespacesFromPodAffinityTerm(pod, &term)\n\t\tselector, err := metav1.LabelSelectorAsSelector(term.LabelSelector)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tproperties = append(properties, &affinityTermProperties{namespaces: namespaces, selector: selector})\n\t}\n\treturn properties, nil\n}"}, {"instruction": "// getFsInfo writes metrics.Capacity, metrics.Used and metrics.Available from the filesystem info", "input": "go language", "output": "func (md *metricsStatFS) getFsInfo(metrics *Metrics) error {\n\tavailable, capacity, usage, inodes, inodesFree, inodesUsed, err := fs.FsInfo(md.path)\n\tif err != nil {\n\t\treturn NewFsInfoFailedError(err)\n\t}\n\tmetrics.Available = resource.NewQuantity(available, resource.BinarySI)\n\tmetrics.Capacity = resource.NewQuantity(capacity, resource.BinarySI)\n\tmetrics.Used = resource.NewQuantity(usage, resource.BinarySI)\n\tmetrics.Inodes = resource.NewQuantity(inodes, resource.BinarySI)\n\tmetrics.InodesFree = resource.NewQuantity(inodesFree, resource.BinarySI)\n\tmetrics.InodesUsed = resource.NewQuantity(inodesUsed, resource.BinarySI)\n\treturn nil\n}"}, {"instruction": "// Validate checks to the AnnotateOptions to see if there is sufficient information run the command.", "input": "go language", "output": "func (o AnnotateOptions) Validate() error {\n\tif o.all && len(o.selector) > 0 {\n\t\treturn fmt.Errorf(\"cannot set --all and --selector at the same time\")\n\t}\n\tif o.all && len(o.fieldSelector) > 0 {\n\t\treturn fmt.Errorf(\"cannot set --all and --field-selector at the same time\")\n\t}\n\tif len(o.resources) < 1 && cmdutil.IsFilenameSliceEmpty(o.Filenames, o.Kustomize) {\n\t\treturn fmt.Errorf(\"one or more resources must be specified as <resource> <name> or <resource>/<name>\")\n\t}\n\tif len(o.newAnnotations) < 1 && len(o.removeAnnotations) < 1 {\n\t\treturn fmt.Errorf(\"at least one annotation update is required\")\n\t}\n\treturn validateAnnotations(o.removeAnnotations, o.newAnnotations)\n}"}, {"instruction": "// GetOrganizationalUnits returns the OU for this instance", "input": "go language", "output": "func (id *identity) GetOrganizationalUnits() []*OUIdentifier {\n\tif id.cert == nil {\n\t\treturn nil\n\t}\n\n\tcid, err := id.msp.getCertificationChainIdentifier(id)\n\tif err != nil {\n\t\tmspIdentityLogger.Errorf(\"Failed getting certification chain identifier for [%v]: [%+v]\", id, err)\n\n\t\treturn nil\n\t}\n\n\tres := []*OUIdentifier{}\n\tfor _, unit := range id.cert.Subject.OrganizationalUnit {\n\t\tres = append(res, &OUIdentifier{\n\t\t\tOrganizationalUnitIdentifier: unit,\n\t\t\tCertifiersIdentifier:         cid,\n\t\t})\n\t}\n\n\treturn res\n}"}, {"instruction": "// getOrInitialize either grabs the configmaps current value or defines the value\n// and sets the configmap. This is for the case of the user calling GetClusterID()\n// before the watch has begun.", "input": "go language", "output": "func (ci *ClusterID) getOrInitialize() error {\n\tif ci.store == nil {\n\t\treturn errors.New(\"Cloud.ClusterID is not ready. Call Initialize() before using\")\n\t}\n\n\tif ci.clusterID != nil {\n\t\treturn nil\n\t}\n\n\texists, err := ci.getConfigMap()\n\tif err != nil {\n\t\treturn err\n\t} else if exists {\n\t\treturn nil\n\t}\n\n\t// The configmap does not exist - let's try creating one.\n\tnewID, err := makeUID()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tklog.V(4).Infof(\"Creating clusteriD: %v\", newID)\n\tcfg := &v1.ConfigMap{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      UIDConfigMapName,\n\t\t\tNamespace: UIDNamespace,\n\t\t},\n\t}\n\tcfg.Data = map[string]string{\n\t\tUIDCluster:  newID,\n\t\tUIDProvider: newID,\n\t}\n\n\tif _, err := ci.client.CoreV1().ConfigMaps(UIDNamespace).Create(cfg); err != nil {\n\t\tklog.Errorf(\"GCE cloud provider failed to create %v config map to store cluster id: %v\", ci.cfgMapKey, err)\n\t\treturn err\n\t}\n\n\tklog.V(2).Infof(\"Created a config map containing clusteriD: %v\", newID)\n\tci.update(cfg)\n\treturn nil\n}"}, {"instruction": "// NamespaceToSelectableFields returns a field set that represents the object", "input": "go language", "output": "func NamespaceToSelectableFields(namespace *api.Namespace) fields.Set {\n\tobjectMetaFieldsSet := generic.ObjectMetaFieldsSet(&namespace.ObjectMeta, false)\n\tspecificFieldsSet := fields.Set{\n\t\t\"status.phase\": string(namespace.Status.Phase),\n\t\t// This is a bug, but we need to support it for backward compatibility.\n\t\t\"name\": namespace.Name,\n\t}\n\treturn generic.MergeFieldsSets(objectMetaFieldsSet, specificFieldsSet)\n}"}, {"instruction": "// getNewConn is used to return a new connection", "input": "go language", "output": "func (p *ConnPool) getNewConn(dc string, addr net.Addr, version int, useTLS bool) (*Conn, error) {\n\t// Get a new, raw connection.\n\tconn, _, err := p.DialTimeout(dc, addr, defaultDialTimeout, useTLS)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Switch the multiplexing based on version\n\tvar session muxSession\n\tif version < 2 {\n\t\tconn.Close()\n\t\treturn nil, fmt.Errorf(\"cannot make client connection, unsupported protocol version %d\", version)\n\t}\n\n\t// Write the Consul multiplex byte to set the mode\n\tif _, err := conn.Write([]byte{byte(RPCMultiplexV2)}); err != nil {\n\t\tconn.Close()\n\t\treturn nil, err\n\t}\n\n\t// Setup the logger\n\tconf := yamux.DefaultConfig()\n\tconf.LogOutput = p.LogOutput\n\n\t// Create a multiplexed session\n\tsession, _ = yamux.Client(conn, conf)\n\n\t// Wrap the connection\n\tc := &Conn{\n\t\trefCount: 1,\n\t\taddr:     addr,\n\t\tsession:  session,\n\t\tclients:  list.New(),\n\t\tlastUsed: time.Now(),\n\t\tversion:  version,\n\t\tpool:     p,\n\t}\n\treturn c, nil\n}"}, {"instruction": "// NewHandle creates a Handle for update stats.", "input": "go language", "output": "func NewHandle(ctx sessionctx.Context, lease time.Duration) *Handle {\n\thandle := &Handle{\n\t\tddlEventCh: make(chan *util.Event, 100),\n\t\tlistHead:   &SessionStatsCollector{mapper: make(tableDeltaMap), rateMap: make(errorRateDeltaMap)},\n\t\tglobalMap:  make(tableDeltaMap),\n\t\tLease:      lease,\n\t\tfeedback:   make([]*statistics.QueryFeedback, 0, MaxQueryFeedbackCount.Load()),\n\t}\n\t// It is safe to use it concurrently because the exec won't touch the ctx.\n\tif exec, ok := ctx.(sqlexec.RestrictedSQLExecutor); ok {\n\t\thandle.restrictedExec = exec\n\t}\n\thandle.mu.ctx = ctx\n\thandle.mu.rateMap = make(errorRateDeltaMap)\n\thandle.StatsCache.Store(StatsCache{})\n\treturn handle\n}"}, {"instruction": "// AddWrapper binds the passed type to the passed wrapper.\n// Notice that that wrapper must be an instance of one of the following interfaces:\n// KeyGenerator, KeyDeriver, KeyImporter, Encryptor, Decryptor, Signer, Verifier, Hasher.", "input": "go language", "output": "func (csp *CSP) AddWrapper(t reflect.Type, w interface{}) error {\n\tif t == nil {\n\t\treturn errors.Errorf(\"type cannot be nil\")\n\t}\n\tif w == nil {\n\t\treturn errors.Errorf(\"wrapper cannot be nil\")\n\t}\n\tswitch dt := w.(type) {\n\tcase KeyGenerator:\n\t\tcsp.KeyGenerators[t] = dt\n\tcase KeyImporter:\n\t\tcsp.KeyImporters[t] = dt\n\tcase KeyDeriver:\n\t\tcsp.KeyDerivers[t] = dt\n\tcase Encryptor:\n\t\tcsp.Encryptors[t] = dt\n\tcase Decryptor:\n\t\tcsp.Decryptors[t] = dt\n\tcase Signer:\n\t\tcsp.Signers[t] = dt\n\tcase Verifier:\n\t\tcsp.Verifiers[t] = dt\n\tcase Hasher:\n\t\tcsp.Hashers[t] = dt\n\tdefault:\n\t\treturn errors.Errorf(\"wrapper type not valid, must be on of: KeyGenerator, KeyDeriver, KeyImporter, Encryptor, Decryptor, Signer, Verifier, Hasher\")\n\t}\n\treturn nil\n}"}, {"instruction": "// Validate checks to the LabelOptions to see if there is sufficient information run the command.", "input": "go language", "output": "func (o *LabelOptions) Validate() error {\n\tif o.all && len(o.selector) > 0 {\n\t\treturn fmt.Errorf(\"cannot set --all and --selector at the same time\")\n\t}\n\tif o.all && len(o.fieldSelector) > 0 {\n\t\treturn fmt.Errorf(\"cannot set --all and --field-selector at the same time\")\n\t}\n\tif len(o.resources) < 1 && cmdutil.IsFilenameSliceEmpty(o.FilenameOptions.Filenames, o.FilenameOptions.Kustomize) {\n\t\treturn fmt.Errorf(\"one or more resources must be specified as <resource> <name> or <resource>/<name>\")\n\t}\n\tif len(o.newLabels) < 1 && len(o.removeLabels) < 1 && !o.list {\n\t\treturn fmt.Errorf(\"at least one label update is required\")\n\t}\n\treturn nil\n}"}, {"instruction": "// CryptBlocks implements BlockMode.CryptBlocks interface.", "input": "go language", "output": "func (x *ecbDecrypter) CryptBlocks(dst, src []byte) {\n\tif len(src)%x.blockSize != 0 {\n\t\tpanic(\"ECBDecrypter: input not full blocks\")\n\t}\n\tif len(dst) < len(src) {\n\t\tpanic(\"ECBDecrypter: output smaller than input\")\n\t}\n\t// See https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Electronic_Codebook_.28ECB.29\n\tfor len(src) > 0 {\n\t\tx.b.Decrypt(dst, src[:x.blockSize])\n\t\tsrc = src[x.blockSize:]\n\t\tdst = dst[x.blockSize:]\n\t}\n}"}, {"instruction": "// DecrypterVerify exposes how to get state to the ledger after having received keys for\n// decrypting (AES 256 bit key) and verifying (X9.62/SECG curve over a 256 bit prime field) that has been provided to the chaincode through the\n// transient field", "input": "go language", "output": "func (t *EncCC) DecrypterVerify(stub shim.ChaincodeStubInterface, args []string, decKey, verKey []byte) pb.Response {\n\t// create the decrypter/verify entity - we give it an ID, the bccsp instance and the keys\n\tent, err := entities.NewAES256EncrypterECDSASignerEntity(\"ID\", t.bccspInst, decKey, verKey)\n\tif err != nil {\n\t\treturn shim.Error(fmt.Sprintf(\"entities.NewAES256DecrypterEntity failed, err %s\", err))\n\t}\n\n\tif len(args) != 1 {\n\t\treturn shim.Error(\"Expected 1 parameters to function DecrypterVerify\")\n\t}\n\tkey := args[0]\n\n\t// here we decrypt the state associated to key and verify it\n\tcleartextValue, err := getStateDecryptAndVerify(stub, ent, key)\n\tif err != nil {\n\t\treturn shim.Error(fmt.Sprintf(\"getStateDecryptAndVerify failed, err %+v\", err))\n\t}\n\n\t// here we return the decrypted and verified value as a result\n\treturn shim.Success(cleartextValue)\n}"}, {"instruction": "// StopContainer stops a running container with a grace period (i.e., timeout).", "input": "go language", "output": "func (r *RemoteRuntimeService) StopContainer(containerID string, timeout int64) error {\n\t// Use timeout + default timeout (2 minutes) as timeout to leave extra time\n\t// for SIGKILL container and request latency.\n\tt := r.timeout + time.Duration(timeout)*time.Second\n\tctx, cancel := getContextWithTimeout(t)\n\tdefer cancel()\n\n\tr.logReduction.ClearID(containerID)\n\t_, err := r.runtimeClient.StopContainer(ctx, &runtimeapi.StopContainerRequest{\n\t\tContainerId: containerID,\n\t\tTimeout:     timeout,\n\t})\n\tif err != nil {\n\t\tklog.Errorf(\"StopContainer %q from runtime service failed: %v\", containerID, err)\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// ForResource gives generic access to a shared informer of the matching type\n// TODO extend this to unknown resources with a client pool", "input": "go language", "output": "func (f *sharedInformerFactory) ForResource(resource schema.GroupVersionResource) (GenericInformer, error) {\n\tswitch resource {\n\t// Group=apiregistration.k8s.io, Version=internalVersion\n\tcase apiregistration.SchemeGroupVersion.WithResource(\"apiservices\"):\n\t\treturn &genericInformer{resource: resource.GroupResource(), informer: f.Apiregistration().InternalVersion().APIServices().Informer()}, nil\n\n\t}\n\n\treturn nil, fmt.Errorf(\"no informer found for %v\", resource)\n}"}, {"instruction": "// Send sends the request, and receives a response", "input": "go language", "output": "func (stub *ClientStub) Send(server string, conf common.Config, req *discovery.Request) (ServiceResponse, error) {\n\tcomm, err := comm.NewClient(conf.TLSConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsigner, err := signer.NewSigner(conf.SignerConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttimeout, cancel := context.WithTimeout(context.Background(), defaultTimeout)\n\tdefer cancel()\n\n\tdisc := discovery.NewClient(comm.NewDialer(server), signer.Sign, 0)\n\n\tresp, err := disc.Send(timeout, req, &AuthInfo{\n\t\tClientIdentity:    signer.Creator,\n\t\tClientTlsCertHash: comm.TLSCertHash,\n\t})\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed connecting to %s: %v\", server, err)\n\t}\n\treturn &response{\n\t\tResponse: resp,\n\t}, nil\n}"}, {"instruction": "// evalDuration evals a builtinTimeTimeTimeDiffSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_timediff", "input": "go language", "output": "func (b *builtinTimeTimeTimeDiffSig) evalDuration(row chunk.Row) (d types.Duration, isNull bool, err error) {\n\tlhs, isNull, err := b.args[0].EvalTime(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn d, isNull, err\n\t}\n\n\trhs, isNull, err := b.args[1].EvalTime(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn d, isNull, err\n\t}\n\n\tsc := b.ctx.GetSessionVars().StmtCtx\n\td, isNull, err = calculateTimeDiff(sc, lhs, rhs)\n\treturn d, isNull, err\n}"}, {"instruction": "// parseWhereArgs parses the end arguments to the where function.  Return a\n// match value and an operator, if one is defined.", "input": "go language", "output": "func parseWhereArgs(args ...interface{}) (mv reflect.Value, op string, err error) {\n\tswitch len(args) {\n\tcase 1:\n\t\tmv = reflect.ValueOf(args[0])\n\tcase 2:\n\t\tvar ok bool\n\t\tif op, ok = args[0].(string); !ok {\n\t\t\terr = errors.New(\"operator argument must be string type\")\n\t\t\treturn\n\t\t}\n\t\top = strings.TrimSpace(strings.ToLower(op))\n\t\tmv = reflect.ValueOf(args[1])\n\tdefault:\n\t\terr = errors.New(\"can't evaluate the array by no match argument or more than or equal to two arguments\")\n\t}\n\treturn\n}"}, {"instruction": "// compare two variables of the same type, i.e. non complex one, such as TypeList or TypeMap", "input": "go language", "output": "func compareSimpleVariables(a, b ast.Variable) (bool, error) {\n\tif a.Type != b.Type {\n\t\treturn false, fmt.Errorf(\n\t\t\t\"won't compare items of different types %s and %s\",\n\t\t\ta.Type.Printable(), b.Type.Printable())\n\t}\n\tswitch a.Type {\n\tcase ast.TypeString:\n\t\treturn a.Value.(string) == b.Value.(string), nil\n\tdefault:\n\t\treturn false, fmt.Errorf(\n\t\t\t\"can't compare items of type %s\",\n\t\t\ta.Type.Printable())\n\t}\n}"}, {"instruction": "// setupMounts configures the mount points for a container by appending each\n// of the configured mounts on the container to the OCI mount structure\n// which will ultimately be passed into the oci runtime during container creation.\n// It also ensures each of the mounts are lexicographically sorted.\n// BUGBUG TODO Windows containerd. This would be much better if it returned\n// an array of runtime spec mounts, not container mounts. Then no need to\n// do multiple transitions.", "input": "go language", "output": "func (daemon *Daemon) setupMounts(c *container.Container) ([]container.Mount, error) {\n\tvar mnts []container.Mount\n\tfor _, mount := range c.MountPoints { // type is volumemounts.MountPoint\n\t\tif err := daemon.lazyInitializeVolume(c.ID, mount); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ts, err := mount.Setup(c.MountLabel, idtools.Identity{}, nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tmnts = append(mnts, container.Mount{\n\t\t\tSource:      s,\n\t\t\tDestination: mount.Destination,\n\t\t\tWritable:    mount.RW,\n\t\t})\n\t}\n\n\tsort.Sort(mounts(mnts))\n\treturn mnts, nil\n}"}, {"instruction": "// VerifyByChannel checks that signature is a valid signature of message\n// under a peer's verification key, but also in the context of a specific channel.\n// If the verification succeeded, Verify returns nil meaning no error occurred.\n// If peerIdentity is nil, then the verification fails.", "input": "go language", "output": "func (s *MSPMessageCryptoService) VerifyByChannel(chainID common.ChainID, peerIdentity api.PeerIdentityType, signature, message []byte) error {\n\t// Validate arguments\n\tif len(peerIdentity) == 0 {\n\t\treturn errors.New(\"Invalid Peer Identity. It must be different from nil.\")\n\t}\n\n\t// Get the policy manager for channel chainID\n\tcpm, flag := s.channelPolicyManagerGetter.Manager(string(chainID))\n\tif cpm == nil {\n\t\treturn fmt.Errorf(\"Could not acquire policy manager for channel %s\", string(chainID))\n\t}\n\tmcsLogger.Debugf(\"Got policy manager for channel [%s] with flag [%t]\", string(chainID), flag)\n\n\t// Get channel reader policy\n\tpolicy, flag := cpm.GetPolicy(policies.ChannelApplicationReaders)\n\tmcsLogger.Debugf(\"Got reader policy for channel [%s] with flag [%t]\", string(chainID), flag)\n\n\treturn policy.Evaluate(\n\t\t[]*pcommon.SignedData{{\n\t\t\tData:      message,\n\t\t\tIdentity:  []byte(peerIdentity),\n\t\t\tSignature: signature,\n\t\t}},\n\t)\n}"}, {"instruction": "// IsComputed returns whether the given key is computed or not.", "input": "go language", "output": "func (c *ResourceConfig) IsComputed(k string) bool {\n\t// The next thing we do is check the config if we get a computed\n\t// value out of it.\n\tv, ok := c.get(k, c.Config)\n\tif !ok {\n\t\treturn false\n\t}\n\n\t// If value is nil, then it isn't computed\n\tif v == nil {\n\t\treturn false\n\t}\n\n\t// Test if the value contains an unknown value\n\tvar w unknownCheckWalker\n\tif err := reflectwalk.Walk(v, &w); err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn w.Unknown\n}"}, {"instruction": "// DeepCopy creates a copy of the receiver where any pointers to nested mutable\n// values are also copied, thus ensuring that future mutations of the receiver\n// will not affect the copy.\n//\n// Some types used within a resource change are immutable by convention even\n// though the Go language allows them to be mutated, such as the types from\n// the addrs package. These are _not_ copied by this method, under the\n// assumption that callers will behave themselves.", "input": "go language", "output": "func (rcs *ResourceInstanceChangeSrc) DeepCopy() *ResourceInstanceChangeSrc {\n\tif rcs == nil {\n\t\treturn nil\n\t}\n\tret := *rcs\n\n\tret.RequiredReplace = cty.NewPathSet(ret.RequiredReplace.List()...)\n\n\tif len(ret.Private) != 0 {\n\t\tprivate := make([]byte, len(ret.Private))\n\t\tcopy(private, ret.Private)\n\t\tret.Private = private\n\t}\n\n\tret.ChangeSrc.Before = ret.ChangeSrc.Before.Copy()\n\tret.ChangeSrc.After = ret.ChangeSrc.After.Copy()\n\n\treturn &ret\n}"}, {"instruction": "// UnmarshalClusterStatus takes raw ConfigMap.Data and converts it to a ClusterStatus object", "input": "go language", "output": "func UnmarshalClusterStatus(data map[string]string) (*kubeadmapi.ClusterStatus, error) {\n\tclusterStatusData, ok := data[constants.ClusterStatusConfigMapKey]\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"unexpected error when reading kubeadm-config ConfigMap: %s key value pair missing\", constants.ClusterStatusConfigMapKey)\n\t}\n\tclusterStatus := &kubeadmapi.ClusterStatus{}\n\tif err := runtime.DecodeInto(kubeadmscheme.Codecs.UniversalDecoder(), []byte(clusterStatusData), clusterStatus); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn clusterStatus, nil\n}"}, {"instruction": "// LookupUser uses traditional local system files lookup (from libcontainer/user) on a username,\n// followed by a call to `getent` for supporting host configured non-files passwd and group dbs", "input": "go language", "output": "func LookupUser(username string) (user.User, error) {\n\t// first try a local system files lookup using existing capabilities\n\tusr, err := user.LookupUser(username)\n\tif err == nil {\n\t\treturn usr, nil\n\t}\n\t// local files lookup failed; attempt to call `getent` to query configured passwd dbs\n\tusr, err = getentUser(fmt.Sprintf(\"%s %s\", \"passwd\", username))\n\tif err != nil {\n\t\treturn user.User{}, err\n\t}\n\treturn usr, nil\n}"}, {"instruction": "// ObjectKinds returns a slice of one element with the group,version,kind of the\n// provided object, or an error if the object is not runtime.Unstructured or\n// has no group,version,kind information. unversionedType will always be false\n// because runtime.Unstructured object should always have group,version,kind\n// information set.", "input": "go language", "output": "func (d *UnstructuredObjectTyper) ObjectKinds(obj runtime.Object) (gvks []schema.GroupVersionKind, unversionedType bool, err error) {\n\tif _, ok := obj.(runtime.Unstructured); ok {\n\t\tgvk := obj.GetObjectKind().GroupVersionKind()\n\t\tif len(gvk.Kind) == 0 {\n\t\t\treturn nil, false, runtime.NewMissingKindErr(\"object has no kind field \")\n\t\t}\n\t\tif len(gvk.Version) == 0 {\n\t\t\treturn nil, false, runtime.NewMissingVersionErr(\"object has no apiVersion field\")\n\t\t}\n\t\treturn []schema.GroupVersionKind{gvk}, false, nil\n\t}\n\n\treturn nil, false, runtime.NewNotRegisteredErrForType(\"crdserverscheme.UnstructuredObjectTyper\", reflect.TypeOf(obj))\n}"}, {"instruction": "// ComputeV2MetadataHMACKey returns a key for the given \"authConfig\" that can be used to hash v2 metadata\n// entries.", "input": "go language", "output": "func ComputeV2MetadataHMACKey(authConfig *types.AuthConfig) ([]byte, error) {\n\tif authConfig == nil {\n\t\treturn nil, nil\n\t}\n\tkey := authConfigKeyInput{\n\t\tUsername:      authConfig.Username,\n\t\tPassword:      authConfig.Password,\n\t\tAuth:          authConfig.Auth,\n\t\tIdentityToken: authConfig.IdentityToken,\n\t\tRegistryToken: authConfig.RegistryToken,\n\t}\n\tbuf, err := json.Marshal(&key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn []byte(digest.FromBytes(buf)), nil\n}"}, {"instruction": "// Kill implements the SessionManager interface.", "input": "go language", "output": "func (s *Server) Kill(connectionID uint64, query bool) {\n\ts.rwlock.Lock()\n\tdefer s.rwlock.Unlock()\n\tlogutil.Logger(context.Background()).Info(\"kill\", zap.Uint64(\"connID\", connectionID), zap.Bool(\"query\", query))\n\tmetrics.ServerEventCounter.WithLabelValues(metrics.EventKill).Inc()\n\n\tconn, ok := s.clients[uint32(connectionID)]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif !query {\n\t\t// Mark the client connection status as WaitShutdown, when the goroutine detect\n\t\t// this, it will end the dispatch loop and exit.\n\t\tatomic.StoreInt32(&conn.status, connStatusWaitShutdown)\n\t}\n\tkillConn(conn)\n}"}, {"instruction": "// NewClientBackedDryRunGetterFromKubeconfig creates a new ClientBackedDryRunGetter instance from the given KubeConfig file", "input": "go language", "output": "func NewClientBackedDryRunGetterFromKubeconfig(file string) (*ClientBackedDryRunGetter, error) {\n\tconfig, err := clientcmd.LoadFromFile(file)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to load kubeconfig\")\n\t}\n\tclientConfig, err := clientcmd.NewDefaultClientConfig(*config, &clientcmd.ConfigOverrides{}).ClientConfig()\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to create API client configuration from kubeconfig\")\n\t}\n\treturn NewClientBackedDryRunGetter(clientConfig)\n}"}, {"instruction": "//----------------------------------------------------------------------------------\n// InitViper()\n//----------------------------------------------------------------------------------\n// Performs basic initialization of our viper-based configuration layer.\n// Primary thrust is to establish the paths that should be consulted to find\n// the configuration we need.  If v == nil, we will initialize the global\n// Viper instance\n//----------------------------------------------------------------------------------", "input": "go language", "output": "func InitViper(v *viper.Viper, configName string) error {\n\tvar altPath = os.Getenv(\"FABRIC_CFG_PATH\")\n\tif altPath != \"\" {\n\t\t// If the user has overridden the path with an envvar, its the only path\n\t\t// we will consider\n\n\t\tif !dirExists(altPath) {\n\t\t\treturn fmt.Errorf(\"FABRIC_CFG_PATH %s does not exist\", altPath)\n\t\t}\n\n\t\tAddConfigPath(v, altPath)\n\t} else {\n\t\t// If we get here, we should use the default paths in priority order:\n\t\t//\n\t\t// *) CWD\n\t\t// *) /etc/hyperledger/fabric\n\n\t\t// CWD\n\t\tAddConfigPath(v, \"./\")\n\n\t\t// And finally, the official path\n\t\tif dirExists(OfficialPath) {\n\t\t\tAddConfigPath(v, OfficialPath)\n\t\t}\n\t}\n\n\t// Now set the configuration file.\n\tif v != nil {\n\t\tv.SetConfigName(configName)\n\t} else {\n\t\tviper.SetConfigName(configName)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// LstatIfPossible returns the os.FileInfo structure describing a given file.\n// It attempts to use Lstat if supported or defers to the os.  In addition to\n// the FileInfo, a boolean is returned telling whether Lstat was called.", "input": "go language", "output": "func (fs *LanguageFs) LstatIfPossible(name string) (os.FileInfo, bool, error) {\n\tname, err := fs.realName(name)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\n\tvar fi os.FileInfo\n\tvar b bool\n\n\tif lif, ok := fs.Fs.(afero.Lstater); ok {\n\t\tfi, b, err = lif.LstatIfPossible(name)\n\t} else {\n\t\tfi, err = fs.Fs.Stat(name)\n\t}\n\n\tif err != nil {\n\t\treturn nil, b, err\n\t}\n\n\tlfi, err := fs.newLanguageFileInfo(name, fi)\n\n\treturn lfi, b, err\n}"}, {"instruction": "// Snapshots creates snapshots of the services by calling the\n// simulation_snapshot RPC method", "input": "go language", "output": "func (sn *SimNode) Snapshots() (map[string][]byte, error) {\n\tsn.lock.RLock()\n\tservices := make(map[string]node.Service, len(sn.running))\n\tfor name, service := range sn.running {\n\t\tservices[name] = service\n\t}\n\tsn.lock.RUnlock()\n\tif len(services) == 0 {\n\t\treturn nil, errors.New(\"no running services\")\n\t}\n\tsnapshots := make(map[string][]byte)\n\tfor name, service := range services {\n\t\tif s, ok := service.(interface {\n\t\t\tSnapshot() ([]byte, error)\n\t\t}); ok {\n\t\t\tsnap, err := s.Snapshot()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tsnapshots[name] = snap\n\t\t}\n\t}\n\treturn snapshots, nil\n}"}, {"instruction": "// NegotiateFormat returns an acceptable Accept format.", "input": "go language", "output": "func (c *Context) NegotiateFormat(offered ...string) string {\n\tassert1(len(offered) > 0, \"you must provide at least one offer\")\n\n\tif c.Accepted == nil {\n\t\tc.Accepted = parseAccept(c.requestHeader(\"Accept\"))\n\t}\n\tif len(c.Accepted) == 0 {\n\t\treturn offered[0]\n\t}\n\tfor _, accepted := range c.Accepted {\n\t\tfor _, offert := range offered {\n\t\t\t// According to RFC 2616 and RFC 2396, non-ASCII characters are not allowed in headers,\n\t\t\t// therefore we can just iterate over the string without casting it into []rune\n\t\t\ti := 0\n\t\t\tfor ; i < len(accepted); i++ {\n\t\t\t\tif accepted[i] == '*' || offert[i] == '*' {\n\t\t\t\t\treturn offert\n\t\t\t\t}\n\t\t\t\tif accepted[i] != offert[i] {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif i == len(accepted) {\n\t\t\t\treturn offert\n\t\t\t}\n\t\t}\n\t}\n\treturn \"\"\n}"}, {"instruction": "// Handle filesystem notify event.\n// Files names:\n// - MUST NOT start with a '.'", "input": "go language", "output": "func (w *Watcher) handleCreateEvent(event fsnotify.Event) error {\n\tklog.V(6).Infof(\"Handling create event: %v\", event)\n\n\tif w.containsBlacklistedDir(event.Name) {\n\t\treturn nil\n\t}\n\n\tfi, err := os.Stat(event.Name)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"stat file %s failed: %v\", event.Name, err)\n\t}\n\n\tif strings.HasPrefix(fi.Name(), \".\") {\n\t\tklog.V(5).Infof(\"Ignoring file (starts with '.'): %s\", fi.Name())\n\t\treturn nil\n\t}\n\n\tif !fi.IsDir() {\n\t\tif fi.Mode()&os.ModeSocket == 0 {\n\t\t\tklog.V(5).Infof(\"Ignoring non socket file %s\", fi.Name())\n\t\t\treturn nil\n\t\t}\n\n\t\treturn w.handlePluginRegistration(event.Name)\n\t}\n\n\treturn w.traversePluginDir(event.Name)\n}"}, {"instruction": "// CanUpgradeKubelets returns whether an upgrade of any kubelet in the cluster is possible", "input": "go language", "output": "func (u *Upgrade) CanUpgradeKubelets() bool {\n\t// If there are multiple different versions now, an upgrade is possible (even if only for a subset of the nodes)\n\tif len(u.Before.KubeletVersions) > 1 {\n\t\treturn true\n\t}\n\t// Don't report something available for upgrade if we don't know the current state\n\tif len(u.Before.KubeletVersions) == 0 {\n\t\treturn false\n\t}\n\n\t// if the same version number existed both before and after, we don't have to upgrade it\n\t_, sameVersionFound := u.Before.KubeletVersions[u.After.KubeVersion]\n\treturn !sameVersionFound\n}"}, {"instruction": "// compareHost compares two host string using some special rules, return value 1, 0, -1 means > = <.\n// TODO: Check how MySQL do it exactly, instead of guess its rules.", "input": "go language", "output": "func compareHost(x, y string) int {\n\t// The more-specific, the smaller it is.\n\t// The pattern '%' means \u201cany host\u201d and is least specific.\n\tif y == `%` {\n\t\tif x == `%` {\n\t\t\treturn 0\n\t\t}\n\t\treturn -1\n\t}\n\n\t// The empty string '' also means \u201cany host\u201d but sorts after '%'.\n\tif y == \"\" {\n\t\tif x == \"\" {\n\t\t\treturn 0\n\t\t}\n\t\treturn -1\n\t}\n\n\t// One of them end with `%`.\n\txEnd := strings.HasSuffix(x, `%`)\n\tyEnd := strings.HasSuffix(y, `%`)\n\tif xEnd || yEnd {\n\t\tswitch {\n\t\tcase !xEnd && yEnd:\n\t\t\treturn -1\n\t\tcase xEnd && !yEnd:\n\t\t\treturn 1\n\t\tcase xEnd && yEnd:\n\t\t\t// 192.168.199.% smaller than 192.168.%\n\t\t\t// A not very accurate comparison, compare them by length.\n\t\t\tif len(x) > len(y) {\n\t\t\t\treturn -1\n\t\t\t}\n\t\t}\n\t\treturn 0\n\t}\n\n\t// For other case, the order is nondeterministic.\n\tswitch x < y {\n\tcase true:\n\t\treturn -1\n\tcase false:\n\t\treturn 1\n\t}\n\treturn 0\n}"}, {"instruction": "// GEt /v1/connect/ca/configuration", "input": "go language", "output": "func (s *HTTPServer) ConnectCAConfigurationGet(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\t// Method is tested in ConnectCAConfiguration\n\tvar args structs.DCSpecificRequest\n\tif done := s.parse(resp, req, &args.Datacenter, &args.QueryOptions); done {\n\t\treturn nil, nil\n\t}\n\n\tvar reply structs.CAConfiguration\n\terr := s.agent.RPC(\"ConnectCA.ConfigurationGet\", &args, &reply)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfixupConfig(&reply)\n\treturn reply, nil\n}"}, {"instruction": "// UpdateVmssVMWithRetry invokes az.VirtualMachineScaleSetVMsClient.Update with exponential backoff retry", "input": "go language", "output": "func (az *Cloud) UpdateVmssVMWithRetry(resourceGroupName string, VMScaleSetName string, instanceID string, parameters compute.VirtualMachineScaleSetVM) error {\n\treturn wait.ExponentialBackoff(az.requestBackoff(), func() (bool, error) {\n\t\tctx, cancel := getContextWithCancel()\n\t\tdefer cancel()\n\n\t\tresp, err := az.VirtualMachineScaleSetVMsClient.Update(ctx, resourceGroupName, VMScaleSetName, instanceID, parameters)\n\t\tklog.V(10).Infof(\"VirtualMachinesClient.CreateOrUpdate(%s,%s): end\", VMScaleSetName, instanceID)\n\t\treturn az.processHTTPRetryResponse(nil, \"\", resp, err)\n\t})\n}"}, {"instruction": "// receive reads the result from a watcher, restarting it if necessary.", "input": "go language", "output": "func (rw *RetryWatcher) receive() {\n\tdefer close(rw.doneChan)\n\tdefer close(rw.resultChan)\n\n\tklog.V(4).Info(\"Starting RetryWatcher.\")\n\tdefer klog.V(4).Info(\"Stopping RetryWatcher.\")\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tgo func() {\n\t\tselect {\n\t\tcase <-rw.stopChan:\n\t\t\tcancel()\n\t\t\treturn\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\t}\n\t}()\n\n\t// We use non sliding until so we don't introduce delays on happy path when WATCH call\n\t// timeouts or gets closed and we need to reestablish it while also avoiding hot loops.\n\twait.NonSlidingUntilWithContext(ctx, func(ctx context.Context) {\n\t\tdone, retryAfter := rw.doReceive()\n\t\tif done {\n\t\t\tcancel()\n\t\t\treturn\n\t\t}\n\n\t\ttime.Sleep(retryAfter)\n\n\t\tklog.V(4).Infof(\"Restarting RetryWatcher at RV=%q\", rw.lastResourceVersion)\n\t}, rw.minRestartDelay)\n}"}, {"instruction": "// WaitForCacheSync waits for caches to populate.  It returns true if it was successful, false\n// if the controller should shutdown", "input": "go language", "output": "func WaitForCacheSync(stopCh <-chan struct{}, cacheSyncs ...InformerSynced) bool {\n\terr := wait.PollUntil(syncedPollPeriod,\n\t\tfunc() (bool, error) {\n\t\t\tfor _, syncFunc := range cacheSyncs {\n\t\t\t\tif !syncFunc() {\n\t\t\t\t\treturn false, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true, nil\n\t\t},\n\t\tstopCh)\n\tif err != nil {\n\t\tklog.V(2).Infof(\"stop requested\")\n\t\treturn false\n\t}\n\n\tklog.V(4).Infof(\"caches populated\")\n\treturn true\n}"}, {"instruction": "// CheckpointList returns the checkpoints of the given container in the docker host", "input": "go language", "output": "func (cli *Client) CheckpointList(ctx context.Context, container string, options types.CheckpointListOptions) ([]types.Checkpoint, error) {\n\tvar checkpoints []types.Checkpoint\n\n\tquery := url.Values{}\n\tif options.CheckpointDir != \"\" {\n\t\tquery.Set(\"dir\", options.CheckpointDir)\n\t}\n\n\tresp, err := cli.get(ctx, \"/containers/\"+container+\"/checkpoints\", query, nil)\n\tdefer ensureReaderClosed(resp)\n\tif err != nil {\n\t\treturn checkpoints, wrapResponseError(err, resp, \"container\", container)\n\t}\n\n\terr = json.NewDecoder(resp.body).Decode(&checkpoints)\n\treturn checkpoints, err\n}"}, {"instruction": "// TableHandlesToKVRanges converts sorted handle to kv ranges.\n// For continuous handles, we should merge them to a single key range.", "input": "go language", "output": "func TableHandlesToKVRanges(tid int64, handles []int64) []kv.KeyRange {\n\tkrs := make([]kv.KeyRange, 0, len(handles))\n\ti := 0\n\tfor i < len(handles) {\n\t\tj := i + 1\n\t\tfor ; j < len(handles) && handles[j-1] != math.MaxInt64; j++ {\n\t\t\tif handles[j] != handles[j-1]+1 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tlow := codec.EncodeInt(nil, handles[i])\n\t\thigh := codec.EncodeInt(nil, handles[j-1])\n\t\thigh = []byte(kv.Key(high).PrefixNext())\n\t\tstartKey := tablecodec.EncodeRowKey(tid, low)\n\t\tendKey := tablecodec.EncodeRowKey(tid, high)\n\t\tkrs = append(krs, kv.KeyRange{StartKey: startKey, EndKey: endKey})\n\t\ti = j\n\t}\n\treturn krs\n}"}, {"instruction": "// getDeploymentsForReplicaSet returns a list of Deployments that potentially\n// match a ReplicaSet.", "input": "go language", "output": "func (dc *DeploymentController) getDeploymentsForReplicaSet(rs *apps.ReplicaSet) []*apps.Deployment {\n\tdeployments, err := dc.dLister.GetDeploymentsForReplicaSet(rs)\n\tif err != nil || len(deployments) == 0 {\n\t\treturn nil\n\t}\n\t// Because all ReplicaSet's belonging to a deployment should have a unique label key,\n\t// there should never be more than one deployment returned by the above method.\n\t// If that happens we should probably dynamically repair the situation by ultimately\n\t// trying to clean up one of the controllers, for now we just return the older one\n\tif len(deployments) > 1 {\n\t\t// ControllerRef will ensure we don't do anything crazy, but more than one\n\t\t// item in this list nevertheless constitutes user error.\n\t\tklog.V(4).Infof(\"user error! more than one deployment is selecting replica set %s/%s with labels: %#v, returning %s/%s\",\n\t\t\trs.Namespace, rs.Name, rs.Labels, deployments[0].Namespace, deployments[0].Name)\n\t}\n\treturn deployments\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ExternalMetricValue) DeepCopyInto(out *ExternalMetricValue) {\n\t*out = *in\n\tout.TypeMeta = in.TypeMeta\n\tif in.MetricLabels != nil {\n\t\tin, out := &in.MetricLabels, &out.MetricLabels\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tin.Timestamp.DeepCopyInto(&out.Timestamp)\n\tif in.WindowSeconds != nil {\n\t\tin, out := &in.WindowSeconds, &out.WindowSeconds\n\t\t*out = new(int64)\n\t\t**out = **in\n\t}\n\tout.Value = in.Value.DeepCopy()\n\treturn\n}"}, {"instruction": "//setIPSetDefaults sets some IPSet fields if not present to their default values.", "input": "go language", "output": "func (set *IPSet) setIPSetDefaults() {\n\t// Setting default values if not present\n\tif set.HashSize == 0 {\n\t\tset.HashSize = 1024\n\t}\n\tif set.MaxElem == 0 {\n\t\tset.MaxElem = 65536\n\t}\n\t// Default protocol is IPv4\n\tif set.HashFamily == \"\" {\n\t\tset.HashFamily = ProtocolFamilyIPV4\n\t}\n\t// Default ipset type is \"hash:ip,port\"\n\tif len(set.SetType) == 0 {\n\t\tset.SetType = HashIPPort\n\t}\n\tif len(set.PortRange) == 0 {\n\t\tset.PortRange = DefaultPortRange\n\t}\n}"}, {"instruction": "// GetGlobalSysVar implements GlobalVarAccessor.GetGlobalSysVar interface.", "input": "go language", "output": "func (s *session) GetGlobalSysVar(name string) (string, error) {\n\tif s.Value(sessionctx.Initing) != nil {\n\t\t// When running bootstrap or upgrade, we should not access global storage.\n\t\treturn \"\", nil\n\t}\n\tsql := fmt.Sprintf(`SELECT VARIABLE_VALUE FROM %s.%s WHERE VARIABLE_NAME=\"%s\";`,\n\t\tmysql.SystemDB, mysql.GlobalVariablesTable, name)\n\tsysVar, err := s.getExecRet(s, sql)\n\tif err != nil {\n\t\tif executor.ErrResultIsEmpty.Equal(err) {\n\t\t\tif sv, ok := variable.SysVars[name]; ok {\n\t\t\t\treturn sv.Value, nil\n\t\t\t}\n\t\t\treturn \"\", variable.UnknownSystemVar.GenWithStackByArgs(name)\n\t\t}\n\t\treturn \"\", err\n\t}\n\treturn sysVar, nil\n}"}, {"instruction": "// Query fetches all releases that match the provided map of labels.\n// An error is returned if the secret fails to retrieve the releases.", "input": "go language", "output": "func (secrets *Secrets) Query(labels map[string]string) ([]*rspb.Release, error) {\n\tls := kblabels.Set{}\n\tfor k, v := range labels {\n\t\tif errs := validation.IsValidLabelValue(v); len(errs) != 0 {\n\t\t\treturn nil, fmt.Errorf(\"invalid label value: %q: %s\", v, strings.Join(errs, \"; \"))\n\t\t}\n\t\tls[k] = v\n\t}\n\n\topts := metav1.ListOptions{LabelSelector: ls.AsSelector().String()}\n\n\tlist, err := secrets.impl.List(opts)\n\tif err != nil {\n\t\tsecrets.Log(\"query: failed to query with labels: %s\", err)\n\t\treturn nil, err\n\t}\n\n\tif len(list.Items) == 0 {\n\t\treturn nil, storageerrors.ErrReleaseNotFound(labels[\"NAME\"])\n\t}\n\n\tvar results []*rspb.Release\n\tfor _, item := range list.Items {\n\t\trls, err := decodeRelease(string(item.Data[\"release\"]))\n\t\tif err != nil {\n\t\t\tsecrets.Log(\"query: failed to decode release: %s\", err)\n\t\t\tcontinue\n\t\t}\n\t\tresults = append(results, rls)\n\t}\n\treturn results, nil\n}"}, {"instruction": "// getResourceHandler is an HTTP handler function for get requests. It delegates to the\n// passed-in getterFunc to perform the actual get.", "input": "go language", "output": "func getResourceHandler(scope *RequestScope, getter getterFunc) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, req *http.Request) {\n\t\ttrace := utiltrace.New(\"Get \" + req.URL.Path)\n\t\tdefer trace.LogIfLong(500 * time.Millisecond)\n\n\t\tnamespace, name, err := scope.Namer.Name(req)\n\t\tif err != nil {\n\t\t\tscope.err(err, w, req)\n\t\t\treturn\n\t\t}\n\t\tctx := req.Context()\n\t\tctx = request.WithNamespace(ctx, namespace)\n\n\t\toutputMediaType, _, err := negotiation.NegotiateOutputMediaType(req, scope.Serializer, scope)\n\t\tif err != nil {\n\t\t\tscope.err(err, w, req)\n\t\t\treturn\n\t\t}\n\n\t\tresult, err := getter(ctx, name, req, trace)\n\t\tif err != nil {\n\t\t\tscope.err(err, w, req)\n\t\t\treturn\n\t\t}\n\n\t\ttrace.Step(\"About to write a response\")\n\t\ttransformResponseObject(ctx, scope, trace, req, w, http.StatusOK, outputMediaType, result)\n\t\ttrace.Step(\"Transformed response object\")\n\t}\n}"}, {"instruction": "// Validate makes sure there is no discrepency in provided option values", "input": "go language", "output": "func (o *CreateRoleOptions) Validate() error {\n\tif o.Name == \"\" {\n\t\treturn fmt.Errorf(\"name must be specified\")\n\t}\n\n\t// validate verbs.\n\tif len(o.Verbs) == 0 {\n\t\treturn fmt.Errorf(\"at least one verb must be specified\")\n\t}\n\n\tfor _, v := range o.Verbs {\n\t\tif !arrayContains(validResourceVerbs, v) {\n\t\t\treturn fmt.Errorf(\"invalid verb: '%s'\", v)\n\t\t}\n\t}\n\n\t// validate resources.\n\tif len(o.Resources) == 0 {\n\t\treturn fmt.Errorf(\"at least one resource must be specified\")\n\t}\n\n\treturn o.validateResource()\n}"}, {"instruction": "// ValidateIPBlock validates a cidr and the except fields of an IpBlock NetworkPolicyPeer", "input": "go language", "output": "func ValidateIPBlock(ipb *networking.IPBlock, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tif len(ipb.CIDR) == 0 || ipb.CIDR == \"\" {\n\t\tallErrs = append(allErrs, field.Required(fldPath.Child(\"cidr\"), \"\"))\n\t\treturn allErrs\n\t}\n\tcidrIPNet, err := apivalidation.ValidateCIDR(ipb.CIDR)\n\tif err != nil {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath.Child(\"cidr\"), ipb.CIDR, \"not a valid CIDR\"))\n\t\treturn allErrs\n\t}\n\texceptCIDR := ipb.Except\n\tfor i, exceptIP := range exceptCIDR {\n\t\texceptPath := fldPath.Child(\"except\").Index(i)\n\t\texceptCIDR, err := apivalidation.ValidateCIDR(exceptIP)\n\t\tif err != nil {\n\t\t\tallErrs = append(allErrs, field.Invalid(exceptPath, exceptIP, \"not a valid CIDR\"))\n\t\t\treturn allErrs\n\t\t}\n\t\tif !cidrIPNet.Contains(exceptCIDR.IP) {\n\t\t\tallErrs = append(allErrs, field.Invalid(exceptPath, exceptCIDR.IP, \"not within CIDR range\"))\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// Get retrieves the object from the Namespace and Name fields", "input": "go language", "output": "func (i *Info) Get() (err error) {\n\tobj, err := NewHelper(i.Client, i.Mapping).Get(i.Namespace, i.Name, i.Export)\n\tif err != nil {\n\t\tif errors.IsNotFound(err) && len(i.Namespace) > 0 && i.Namespace != metav1.NamespaceDefault && i.Namespace != metav1.NamespaceAll {\n\t\t\terr2 := i.Client.Get().AbsPath(\"api\", \"v1\", \"namespaces\", i.Namespace).Do().Error()\n\t\t\tif err2 != nil && errors.IsNotFound(err2) {\n\t\t\t\treturn err2\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\ti.Object = obj\n\ti.ResourceVersion, _ = metadataAccessor.ResourceVersion(obj)\n\treturn nil\n}"}, {"instruction": "// AccumulateRewards credits the coinbase of the given block with the mining\n// reward. The total reward consists of the static block reward and rewards for\n// included uncles. The coinbase of each uncle block is also rewarded.", "input": "go language", "output": "func accumulateRewards(config *params.ChainConfig, state *state.StateDB, header *types.Header, uncles []*types.Header) {\n\t// Select the correct block reward based on chain progression\n\tblockReward := FrontierBlockReward\n\tif config.IsByzantium(header.Number) {\n\t\tblockReward = ByzantiumBlockReward\n\t}\n\tif config.IsConstantinople(header.Number) {\n\t\tblockReward = ConstantinopleBlockReward\n\t}\n\t// Accumulate the rewards for the miner and any included uncles\n\treward := new(big.Int).Set(blockReward)\n\tr := new(big.Int)\n\tfor _, uncle := range uncles {\n\t\tr.Add(uncle.Number, big8)\n\t\tr.Sub(r, header.Number)\n\t\tr.Mul(r, blockReward)\n\t\tr.Div(r, big8)\n\t\tstate.AddBalance(uncle.Coinbase, r)\n\n\t\tr.Div(blockReward, big32)\n\t\treward.Add(reward, r)\n\t}\n\tstate.AddBalance(header.Coinbase, reward)\n}"}, {"instruction": "// resolve retrieves the hostname a service is running on either by returning the\n// actual server name and port, or preferably an nginx virtual host if available.", "input": "go language", "output": "func resolve(client *sshClient, network string, service string, port int) (string, error) {\n\t// Inspect the service to get various configurations from it\n\tinfos, err := inspectContainer(client, fmt.Sprintf(\"%s_%s_1\", network, service))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif !infos.running {\n\t\treturn \"\", ErrServiceOffline\n\t}\n\t// Container online, extract any environmental variables\n\tif vhost := infos.envvars[\"VIRTUAL_HOST\"]; vhost != \"\" {\n\t\treturn vhost, nil\n\t}\n\treturn fmt.Sprintf(\"%s:%d\", client.server, port), nil\n}"}, {"instruction": "// nodes returns a paginated list of node addresses. If key is not nil,\n// only nodes that contain that key will be returned.", "input": "go language", "output": "func (s *GlobalStore) nodes(key []byte, startAddr *common.Address, limit int) (nodes mock.Nodes, err error) {\n\titer := s.db.NewIterator(nil, nil)\n\tdefer iter.Release()\n\n\tif limit <= 0 {\n\t\tlimit = mock.DefaultLimit\n\t}\n\n\tprefix := []byte{indexForNodesPrefix}\n\tif key != nil {\n\t\tprefix = indexForNodesWithHashPrefix(key)\n\t}\n\tstartKey := prefix\n\tif startAddr != nil {\n\t\tif key != nil {\n\t\t\tstartKey = indexForNodesWithHash(key, *startAddr)\n\t\t} else {\n\t\t\tstartKey = indexForNodes(*startAddr)\n\t\t}\n\t}\n\n\tok := iter.Seek(startKey)\n\tif !ok {\n\t\treturn nodes, iter.Error()\n\t}\n\tfor ; ok; ok = iter.Next() {\n\t\tk := iter.Key()\n\t\tif !bytes.HasPrefix(k, prefix) {\n\t\t\tbreak\n\t\t}\n\t\taddr := common.BytesToAddress(append([]byte(nil), bytes.TrimPrefix(k, prefix)...))\n\n\t\tif len(nodes.Addrs) >= limit {\n\t\t\tnodes.Next = &addr\n\t\t\tbreak\n\t\t}\n\n\t\tnodes.Addrs = append(nodes.Addrs, addr)\n\t}\n\treturn nodes, iter.Error()\n}"}, {"instruction": "// Get returns a single intention by ID.", "input": "go language", "output": "func (s *Intention) Get(\n\targs *structs.IntentionQueryRequest,\n\treply *structs.IndexedIntentions) error {\n\t// Forward if necessary\n\tif done, err := s.srv.forward(\"Intention.Get\", args, args, reply); done {\n\t\treturn err\n\t}\n\n\treturn s.srv.blockingQuery(\n\t\t&args.QueryOptions,\n\t\t&reply.QueryMeta,\n\t\tfunc(ws memdb.WatchSet, state *state.Store) error {\n\t\t\tindex, ixn, err := state.IntentionGet(ws, args.IntentionID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif ixn == nil {\n\t\t\t\treturn ErrIntentionNotFound\n\t\t\t}\n\n\t\t\treply.Index = index\n\t\t\treply.Intentions = structs.Intentions{ixn}\n\n\t\t\t// Filter\n\t\t\tif err := s.srv.filterACL(args.Token, reply); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// If ACLs prevented any responses, error\n\t\t\tif len(reply.Intentions) == 0 {\n\t\t\t\ts.srv.logger.Printf(\"[WARN] consul.intention: Request to get intention '%s' denied due to ACLs\", args.IntentionID)\n\t\t\t\treturn acl.ErrPermissionDenied\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t)\n}"}, {"instruction": "// GetCCPackage tries each known package implementation one by one\n// till the right package is found", "input": "go language", "output": "func GetCCPackage(buf []byte) (CCPackage, error) {\n\t// try raw CDS\n\tcds := &CDSPackage{}\n\tif ccdata, err := cds.InitFromBuffer(buf); err != nil {\n\t\tcds = nil\n\t} else {\n\t\terr = cds.ValidateCC(ccdata)\n\t\tif err != nil {\n\t\t\tcds = nil\n\t\t}\n\t}\n\n\t// try signed CDS\n\tscds := &SignedCDSPackage{}\n\tif ccdata, err := scds.InitFromBuffer(buf); err != nil {\n\t\tscds = nil\n\t} else {\n\t\terr = scds.ValidateCC(ccdata)\n\t\tif err != nil {\n\t\t\tscds = nil\n\t\t}\n\t}\n\n\tif cds != nil && scds != nil {\n\t\t// Both were unmarshaled successfully, this is exactly why the approach of\n\t\t// hoping proto fails for bad inputs is fatally flawed.\n\t\tccproviderLogger.Errorf(\"Could not determine chaincode package type, guessing SignedCDS\")\n\t\treturn scds, nil\n\t}\n\n\tif cds != nil {\n\t\treturn cds, nil\n\t}\n\n\tif scds != nil {\n\t\treturn scds, nil\n\t}\n\n\treturn nil, errors.New(\"could not unmarshal chaincode package to CDS or SignedCDS\")\n}"}, {"instruction": "// GetUnlockKey returns the unlock key for the swarm.", "input": "go language", "output": "func (c *Cluster) GetUnlockKey() (string, error) {\n\tvar resp *swarmapi.GetUnlockKeyResponse\n\tif err := c.lockedManagerAction(func(ctx context.Context, state nodeState) error {\n\t\tclient := swarmapi.NewCAClient(state.grpcConn)\n\n\t\tr, err := client.GetUnlockKey(ctx, &swarmapi.GetUnlockKeyRequest{})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tresp = r\n\t\treturn nil\n\t}); err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(resp.UnlockKey) == 0 {\n\t\t// no key\n\t\treturn \"\", nil\n\t}\n\treturn encryption.HumanReadableKey(resp.UnlockKey), nil\n}"}, {"instruction": "// NewPodInformer creates a shared index informer that returns only non-terminal pods.", "input": "go language", "output": "func NewPodInformer(client clientset.Interface, resyncPeriod time.Duration) coreinformers.PodInformer {\n\tselector := fields.ParseSelectorOrDie(\n\t\t\"status.phase!=\" + string(v1.PodSucceeded) +\n\t\t\t\",status.phase!=\" + string(v1.PodFailed))\n\tlw := cache.NewListWatchFromClient(client.CoreV1().RESTClient(), string(v1.ResourcePods), metav1.NamespaceAll, selector)\n\treturn &podInformer{\n\t\tinformer: cache.NewSharedIndexInformer(lw, &v1.Pod{}, resyncPeriod, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc}),\n\t}\n}"}, {"instruction": "// AddMethodMapping adds a method to a template function namespace.", "input": "go language", "output": "func (t *TemplateFuncsNamespace) AddMethodMapping(m interface{}, aliases []string, examples [][2]string) {\n\tif t.MethodMappings == nil {\n\t\tt.MethodMappings = make(map[string]TemplateFuncMethodMapping)\n\t}\n\n\tname := methodToName(m)\n\n\t// sanity check\n\tfor _, e := range examples {\n\t\tif e[0] == \"\" {\n\t\t\tpanic(t.Name + \": Empty example for \" + name)\n\t\t}\n\t}\n\tfor _, a := range aliases {\n\t\tif a == \"\" {\n\t\t\tpanic(t.Name + \": Empty alias for \" + name)\n\t\t}\n\t}\n\n\tt.MethodMappings[name] = TemplateFuncMethodMapping{\n\t\tMethod:   m,\n\t\tAliases:  aliases,\n\t\tExamples: examples,\n\t}\n\n}"}, {"instruction": "// TLSConfig is used to generate a TLSClientConfig that's useful for talking to\n// Consul using TLS.", "input": "go language", "output": "func SetupTLSConfig(tlsConfig *TLSConfig) (*tls.Config, error) {\n\ttlsClientConfig := &tls.Config{\n\t\tInsecureSkipVerify: tlsConfig.InsecureSkipVerify,\n\t}\n\n\tif tlsConfig.Address != \"\" {\n\t\tserver := tlsConfig.Address\n\t\thasPort := strings.LastIndex(server, \":\") > strings.LastIndex(server, \"]\")\n\t\tif hasPort {\n\t\t\tvar err error\n\t\t\tserver, _, err = net.SplitHostPort(server)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\ttlsClientConfig.ServerName = server\n\t}\n\n\tif tlsConfig.CertFile != \"\" && tlsConfig.KeyFile != \"\" {\n\t\ttlsCert, err := tls.LoadX509KeyPair(tlsConfig.CertFile, tlsConfig.KeyFile)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ttlsClientConfig.Certificates = []tls.Certificate{tlsCert}\n\t}\n\n\tif tlsConfig.CAFile != \"\" || tlsConfig.CAPath != \"\" {\n\t\trootConfig := &rootcerts.Config{\n\t\t\tCAFile: tlsConfig.CAFile,\n\t\t\tCAPath: tlsConfig.CAPath,\n\t\t}\n\t\tif err := rootcerts.ConfigureTLS(tlsClientConfig, rootConfig); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn tlsClientConfig, nil\n}"}, {"instruction": "// statementContextToFlags converts StatementContext to tipb.SelectRequest.Flags.", "input": "go language", "output": "func statementContextToFlags(sc *stmtctx.StatementContext) uint64 {\n\tvar flags uint64\n\tif sc.InInsertStmt {\n\t\tflags |= model.FlagInInsertStmt\n\t} else if sc.InUpdateStmt || sc.InDeleteStmt {\n\t\tflags |= model.FlagInUpdateOrDeleteStmt\n\t} else if sc.InSelectStmt {\n\t\tflags |= model.FlagInSelectStmt\n\t}\n\tif sc.IgnoreTruncate {\n\t\tflags |= model.FlagIgnoreTruncate\n\t} else if sc.TruncateAsWarning {\n\t\tflags |= model.FlagTruncateAsWarning\n\t}\n\tif sc.OverflowAsWarning {\n\t\tflags |= model.FlagOverflowAsWarning\n\t}\n\tif sc.IgnoreZeroInDate {\n\t\tflags |= model.FlagIgnoreZeroInDate\n\t}\n\tif sc.DividedByZeroAsWarning {\n\t\tflags |= model.FlagDividedByZeroAsWarning\n\t}\n\tif sc.PadCharToFullLength {\n\t\tflags |= model.FlagPadCharToFullLength\n\t}\n\treturn flags\n}"}, {"instruction": "// parsePersistentNodes parses a list of discovery node URLs loaded from a .json\n// file from within the data directory.", "input": "go language", "output": "func (c *Config) parsePersistentNodes(w *bool, path string) []*enode.Node {\n\t// Short circuit if no node config is present\n\tif c.DataDir == \"\" {\n\t\treturn nil\n\t}\n\tif _, err := os.Stat(path); err != nil {\n\t\treturn nil\n\t}\n\tc.warnOnce(w, \"Found deprecated node list file %s, please use the TOML config file instead.\", path)\n\n\t// Load the nodes from the config file.\n\tvar nodelist []string\n\tif err := common.LoadJSON(path, &nodelist); err != nil {\n\t\tlog.Error(fmt.Sprintf(\"Can't load node list file: %v\", err))\n\t\treturn nil\n\t}\n\t// Interpret the list as a discovery node array\n\tvar nodes []*enode.Node\n\tfor _, url := range nodelist {\n\t\tif url == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tnode, err := enode.ParseV4(url)\n\t\tif err != nil {\n\t\t\tlog.Error(fmt.Sprintf(\"Node URL %s: %v\\n\", url, err))\n\t\t\tcontinue\n\t\t}\n\t\tnodes = append(nodes, node)\n\t}\n\treturn nodes\n}"}, {"instruction": "// Admit checks Pods and admits or rejects them. It also resolves the priority of pods based on their PriorityClass.\n// Note that pod validation mechanism prevents update of a pod priority.", "input": "go language", "output": "func (p *priorityPlugin) Admit(a admission.Attributes, o admission.ObjectInterfaces) error {\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.PodPriority) {\n\t\treturn nil\n\t}\n\n\toperation := a.GetOperation()\n\t// Ignore all calls to subresources\n\tif len(a.GetSubresource()) != 0 {\n\t\treturn nil\n\t}\n\n\tswitch a.GetResource().GroupResource() {\n\tcase podResource:\n\t\tif operation == admission.Create || operation == admission.Update {\n\t\t\treturn p.admitPod(a)\n\t\t}\n\t\treturn nil\n\n\tdefault:\n\t\treturn nil\n\t}\n}"}, {"instruction": "// ValidateLogOpt looks for syslog specific log options\n// syslog-address, syslog-facility.", "input": "go language", "output": "func ValidateLogOpt(cfg map[string]string) error {\n\tfor key := range cfg {\n\t\tswitch key {\n\t\tcase \"env\":\n\t\tcase \"env-regex\":\n\t\tcase \"labels\":\n\t\tcase \"labels-regex\":\n\t\tcase \"syslog-address\":\n\t\tcase \"syslog-facility\":\n\t\tcase \"syslog-tls-ca-cert\":\n\t\tcase \"syslog-tls-cert\":\n\t\tcase \"syslog-tls-key\":\n\t\tcase \"syslog-tls-skip-verify\":\n\t\tcase \"tag\":\n\t\tcase \"syslog-format\":\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"unknown log opt '%s' for syslog log driver\", key)\n\t\t}\n\t}\n\tif _, _, err := parseAddress(cfg[\"syslog-address\"]); err != nil {\n\t\treturn err\n\t}\n\tif _, err := parseFacility(cfg[\"syslog-facility\"]); err != nil {\n\t\treturn err\n\t}\n\tif _, _, err := parseLogFormat(cfg[\"syslog-format\"], \"\"); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ResourceQuotaStatus) DeepCopyInto(out *ResourceQuotaStatus) {\n\t*out = *in\n\tif in.Hard != nil {\n\t\tin, out := &in.Hard, &out.Hard\n\t\t*out = make(ResourceList, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val.DeepCopy()\n\t\t}\n\t}\n\tif in.Used != nil {\n\t\tin, out := &in.Used, &out.Used\n\t\t*out = make(ResourceList, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val.DeepCopy()\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// Visit in a FileVisitor is just taking care of opening/closing files", "input": "go language", "output": "func (v *FileVisitor) Visit(fn VisitorFunc) error {\n\tvar f *os.File\n\tif v.Path == constSTDINstr {\n\t\tf = os.Stdin\n\t} else {\n\t\tvar err error\n\t\tf, err = os.Open(v.Path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer f.Close()\n\t}\n\n\t// TODO: Consider adding a flag to force to UTF16, apparently some\n\t// Windows tools don't write the BOM\n\tutf16bom := unicode.BOMOverride(unicode.UTF8.NewDecoder())\n\tv.StreamVisitor.Reader = transform.NewReader(f, utf16bom)\n\n\treturn v.StreamVisitor.Visit(fn)\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of DaemonSets that match those selectors.", "input": "go language", "output": "func (c *FakeDaemonSets) List(opts v1.ListOptions) (result *v1beta2.DaemonSetList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(daemonsetsResource, daemonsetsKind, c.ns, opts), &v1beta2.DaemonSetList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta2.DaemonSetList{ListMeta: obj.(*v1beta2.DaemonSetList).ListMeta}\n\tfor _, item := range obj.(*v1beta2.DaemonSetList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// Validate provides a mock function with given fields: block, namespace, txPosition, actionPosition, policy", "input": "go language", "output": "func (_m *TransactionValidator) Validate(block *common.Block, namespace string, txPosition int, actionPosition int, policy []byte) errors.TxValidationError {\n\tret := _m.Called(block, namespace, txPosition, actionPosition, policy)\n\n\tvar r0 errors.TxValidationError\n\tif rf, ok := ret.Get(0).(func(*common.Block, string, int, int, []byte) errors.TxValidationError); ok {\n\t\tr0 = rf(block, namespace, txPosition, actionPosition, policy)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(errors.TxValidationError)\n\t\t}\n\t}\n\n\treturn r0\n}"}, {"instruction": "// processPorts returns the configured port.\n// An explicitly specified port is preferred. If none is specified, it selects\n// one of the available port. The first such found port is returned unless an\n// optional index is provided.", "input": "go language", "output": "func processPorts(app marathon.Application, task marathon.Task, serverPort string) (int, error) {\n\tif len(serverPort) > 0 && !strings.HasPrefix(serverPort, \"index:\") {\n\t\tport, err := strconv.Atoi(serverPort)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\tif port <= 0 {\n\t\t\treturn 0, fmt.Errorf(\"explicitly specified port %d must be greater than zero\", port)\n\t\t} else if port > 0 {\n\t\t\treturn port, nil\n\t\t}\n\t}\n\n\tports := retrieveAvailablePorts(app, task)\n\tif len(ports) == 0 {\n\t\treturn 0, errors.New(\"no port found\")\n\t}\n\n\tportIndex := 0\n\tif strings.HasPrefix(serverPort, \"index:\") {\n\t\tsplit := strings.SplitN(serverPort, \":\", 2)\n\t\tindex, err := strconv.Atoi(split[1])\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\tif index < 0 || index > len(ports)-1 {\n\t\t\treturn 0, fmt.Errorf(\"index %d must be within range (0, %d)\", index, len(ports)-1)\n\t\t}\n\t\tportIndex = index\n\t}\n\treturn ports[portIndex], nil\n}"}, {"instruction": "// SelectorFromSet returns a Selector which will match exactly the given Set. A\n// nil and empty Sets are considered equivalent to Everything().", "input": "go language", "output": "func SelectorFromSet(ls Set) Selector {\n\tif ls == nil || len(ls) == 0 {\n\t\treturn internalSelector{}\n\t}\n\tvar requirements internalSelector\n\tfor label, value := range ls {\n\t\tr, err := NewRequirement(label, selection.Equals, []string{value})\n\t\tif err == nil {\n\t\t\trequirements = append(requirements, *r)\n\t\t} else {\n\t\t\t//TODO: double check errors when input comes from serialization?\n\t\t\treturn internalSelector{}\n\t\t}\n\t}\n\t// sort to have deterministic string representation\n\tsort.Sort(ByKey(requirements))\n\treturn requirements\n}"}, {"instruction": "// AuthZResponse authorized and manipulates the response from docker daemon using authZ plugins", "input": "go language", "output": "func (ctx *Ctx) AuthZResponse(rm ResponseModifier, r *http.Request) error {\n\tctx.authReq.ResponseStatusCode = rm.StatusCode()\n\tctx.authReq.ResponseHeaders = headers(rm.Header())\n\n\tif sendBody(ctx.requestURI, rm.Header()) {\n\t\tctx.authReq.ResponseBody = rm.RawBody()\n\t}\n\n\tfor _, plugin := range ctx.plugins {\n\t\tlogrus.Debugf(\"AuthZ response using plugin %s\", plugin.Name())\n\n\t\tauthRes, err := plugin.AuthZResponse(ctx.authReq)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"plugin %s failed with error: %s\", plugin.Name(), err)\n\t\t}\n\n\t\tif !authRes.Allow {\n\t\t\treturn newAuthorizationError(plugin.Name(), authRes.Msg)\n\t\t}\n\t}\n\n\trm.FlushAll()\n\n\treturn nil\n}"}, {"instruction": "// newManager returns an implementation of cgroups.Manager", "input": "go language", "output": "func (l *libcontainerAdapter) newManager(cgroups *libcontainerconfigs.Cgroup, paths map[string]string) (libcontainercgroups.Manager, error) {\n\tswitch l.cgroupManagerType {\n\tcase libcontainerCgroupfs:\n\t\treturn &cgroupfs.Manager{\n\t\t\tCgroups: cgroups,\n\t\t\tPaths:   paths,\n\t\t}, nil\n\tcase libcontainerSystemd:\n\t\t// this means you asked systemd to manage cgroups, but systemd was not on the host, so all you can do is panic...\n\t\tif !cgroupsystemd.UseSystemd() {\n\t\t\tpanic(\"systemd cgroup manager not available\")\n\t\t}\n\t\treturn &cgroupsystemd.Manager{\n\t\t\tCgroups: cgroups,\n\t\t\tPaths:   paths,\n\t\t}, nil\n\t}\n\treturn nil, fmt.Errorf(\"invalid cgroup manager configuration\")\n}"}, {"instruction": "// InterpretListError converts a generic error on a retrieval\n// operation into the appropriate API error.", "input": "go language", "output": "func InterpretListError(err error, qualifiedResource schema.GroupResource) error {\n\tswitch {\n\tcase storage.IsNotFound(err):\n\t\treturn errors.NewNotFound(qualifiedResource, \"\")\n\tcase storage.IsUnreachable(err):\n\t\treturn errors.NewServerTimeout(qualifiedResource, \"list\", 2) // TODO: make configurable or handled at a higher level\n\tcase storage.IsInternalError(err):\n\t\treturn errors.NewInternalError(err)\n\tdefault:\n\t\treturn err\n\t}\n}"}, {"instruction": "// pullScannerRoutine aggregates paths to be scanned after pulling. The scan is\n// scheduled once when scanChan is closed (scanning can not happen during pulling).", "input": "go language", "output": "func (f *sendReceiveFolder) pullScannerRoutine(scanChan <-chan string) {\n\ttoBeScanned := make(map[string]struct{})\n\n\tfor path := range scanChan {\n\t\ttoBeScanned[path] = struct{}{}\n\t}\n\n\tif len(toBeScanned) != 0 {\n\t\tscanList := make([]string, 0, len(toBeScanned))\n\t\tfor path := range toBeScanned {\n\t\t\tl.Debugln(f, \"scheduling scan after pulling for\", path)\n\t\t\tscanList = append(scanList, path)\n\t\t}\n\t\tf.Scan(scanList)\n\t}\n}"}, {"instruction": "// Command provides a mock function with given fields: name, help, onCommand", "input": "go language", "output": "func (_m *CommandRegistrar) Command(name string, help string, onCommand common.CLICommand) *kingpin.CmdClause {\n\tret := _m.Called(name, help, onCommand)\n\n\tvar r0 *kingpin.CmdClause\n\tif rf, ok := ret.Get(0).(func(string, string, common.CLICommand) *kingpin.CmdClause); ok {\n\t\tr0 = rf(name, help, onCommand)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*kingpin.CmdClause)\n\t\t}\n\t}\n\n\treturn r0\n}"}, {"instruction": "// Read keeps a cursor so cannot be called simulateously, see ReadAt", "input": "go language", "output": "func (r *LazyChunkReader) Read(b []byte) (read int, err error) {\n\tlog.Trace(\"lazychunkreader.read\", \"key\", r.addr)\n\tmetrics.GetOrRegisterCounter(\"lazychunkreader.read\", nil).Inc(1)\n\n\tread, err = r.ReadAt(b, r.off)\n\tif err != nil && err != io.EOF {\n\t\tlog.Trace(\"lazychunkreader.readat\", \"read\", read, \"err\", err)\n\t\tmetrics.GetOrRegisterCounter(\"lazychunkreader.read.err\", nil).Inc(1)\n\t}\n\n\tmetrics.GetOrRegisterCounter(\"lazychunkreader.read.bytes\", nil).Inc(int64(read))\n\n\tr.off += int64(read)\n\treturn read, err\n}"}, {"instruction": "// Prefetch processes the state changes according to the Ethereum rules by running\n// the transaction messages using the statedb, but any changes are discarded. The\n// only goal is to pre-cache transaction signatures and state trie nodes.", "input": "go language", "output": "func (p *statePrefetcher) Prefetch(block *types.Block, statedb *state.StateDB, cfg vm.Config, interrupt *uint32) {\n\tvar (\n\t\theader  = block.Header()\n\t\tgaspool = new(GasPool).AddGas(block.GasLimit())\n\t)\n\t// Iterate over and process the individual transactions\n\tfor i, tx := range block.Transactions() {\n\t\t// If block precaching was interrupted, abort\n\t\tif interrupt != nil && atomic.LoadUint32(interrupt) == 1 {\n\t\t\treturn\n\t\t}\n\t\t// Block precaching permitted to continue, execute the transaction\n\t\tstatedb.Prepare(tx.Hash(), block.Hash(), i)\n\t\tif err := precacheTransaction(p.config, p.bc, nil, gaspool, statedb, header, tx, cfg); err != nil {\n\t\t\treturn // Ugh, something went horribly wrong, bail out\n\t\t}\n\t}\n}"}, {"instruction": "// rewriteHTML scans the HTML for tags with url-valued attributes, and updates\n// those values with the urlRewriter function. The updated HTML is output to the\n// writer.", "input": "go language", "output": "func rewriteHTML(reader io.Reader, writer io.Writer, urlRewriter func(string) string) error {\n\t// Note: This assumes the content is UTF-8.\n\ttokenizer := html.NewTokenizer(reader)\n\n\tvar err error\n\tfor err == nil {\n\t\ttokenType := tokenizer.Next()\n\t\tswitch tokenType {\n\t\tcase html.ErrorToken:\n\t\t\terr = tokenizer.Err()\n\t\tcase html.StartTagToken, html.SelfClosingTagToken:\n\t\t\ttoken := tokenizer.Token()\n\t\t\tif urlAttrs, ok := atomsToAttrs[token.DataAtom]; ok {\n\t\t\t\tfor i, attr := range token.Attr {\n\t\t\t\t\tif urlAttrs.Has(attr.Key) {\n\t\t\t\t\t\ttoken.Attr[i].Val = urlRewriter(attr.Val)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t_, err = writer.Write([]byte(token.String()))\n\t\tdefault:\n\t\t\t_, err = writer.Write(tokenizer.Raw())\n\t\t}\n\t}\n\tif err != io.EOF {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// findProcess for non-Windows. Note that this very likely doesn't\n// work for all non-Windows platforms Go supports and we should expand\n// support as we experience it.", "input": "go language", "output": "func findProcess(pid int) (*os.Process, error) {\n\t// FindProcess never fails on unix-like systems.\n\tp, err := os.FindProcess(pid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// On Unix-like systems, we can verify a process is alive by sending\n\t// a 0 signal. This will do nothing to the process but will still\n\t// return errors if the process is gone.\n\terr = p.Signal(syscall.Signal(0))\n\tif err == nil {\n\t\treturn p, nil\n\t}\n\n\treturn nil, fmt.Errorf(\"process %d is dead or running as another user\", pid)\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of PersistentVolumeClaims that match those selectors.", "input": "go language", "output": "func (c *FakePersistentVolumeClaims) List(opts v1.ListOptions) (result *corev1.PersistentVolumeClaimList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(persistentvolumeclaimsResource, persistentvolumeclaimsKind, c.ns, opts), &corev1.PersistentVolumeClaimList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &corev1.PersistentVolumeClaimList{ListMeta: obj.(*corev1.PersistentVolumeClaimList).ListMeta}\n\tfor _, item := range obj.(*corev1.PersistentVolumeClaimList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// ToHashKey removes the leading and trailing zeros and generates a hash key.\n// Two Decimals dec0 and dec1 with different fraction will generate the same hash keys if dec0.Compare(dec1) == 0.", "input": "go language", "output": "func (d *MyDecimal) ToHashKey() ([]byte, error) {\n\t_, digitsInt := d.removeLeadingZeros()\n\t_, digitsFrac := d.removeTrailingZeros()\n\tprec := digitsInt + digitsFrac\n\tif prec == 0 { // zeroDecimal\n\t\tprec = 1\n\t}\n\tbuf, err := d.ToBin(prec, digitsFrac)\n\tif err == ErrTruncated {\n\t\t// This err is caused by shorter digitsFrac;\n\t\t// After removing the trailing zeros from a Decimal,\n\t\t// so digitsFrac may be less than the real digitsFrac of the Decimal,\n\t\t// thus ErrTruncated may be raised, we can ignore it here.\n\t\terr = nil\n\t}\n\treturn buf, err\n}"}, {"instruction": "// GetMissingPvtDataInfoForMostRecentBlocks invokes the function on underlying pvtdata store", "input": "go language", "output": "func (s *Store) GetMissingPvtDataInfoForMostRecentBlocks(maxBlock int) (ledger.MissingPvtDataInfo, error) {\n\t// it is safe to not acquire a read lock on s.rwlock. Without a lock, the value of\n\t// lastCommittedBlock can change due to a new block commit. As a result, we may not\n\t// be able to fetch the missing data info of truly the most recent blocks. This\n\t// decision was made to ensure that the regular block commit rate is not affected.\n\treturn s.pvtdataStore.GetMissingPvtDataInfoForMostRecentBlocks(maxBlock)\n}"}, {"instruction": "// WithIPv4 sets the specified ip for the specified network of the container", "input": "go language", "output": "func WithIPv4(network, ip string) func(*TestContainerConfig) {\n\treturn func(c *TestContainerConfig) {\n\t\tif c.NetworkingConfig.EndpointsConfig == nil {\n\t\t\tc.NetworkingConfig.EndpointsConfig = map[string]*networktypes.EndpointSettings{}\n\t\t}\n\t\tif v, ok := c.NetworkingConfig.EndpointsConfig[network]; !ok || v == nil {\n\t\t\tc.NetworkingConfig.EndpointsConfig[network] = &networktypes.EndpointSettings{}\n\t\t}\n\t\tif c.NetworkingConfig.EndpointsConfig[network].IPAMConfig == nil {\n\t\t\tc.NetworkingConfig.EndpointsConfig[network].IPAMConfig = &networktypes.EndpointIPAMConfig{}\n\t\t}\n\t\tc.NetworkingConfig.EndpointsConfig[network].IPAMConfig.IPv4Address = ip\n\t}\n}"}, {"instruction": "// ListLeases retrieves a list of the current master IPs from storage", "input": "go language", "output": "func (s *storageLeases) ListLeases() ([]string, error) {\n\tipInfoList := &corev1.EndpointsList{}\n\tif err := s.storage.List(apirequest.NewDefaultContext(), s.baseKey, \"0\", storage.Everything, ipInfoList); err != nil {\n\t\treturn nil, err\n\t}\n\n\tipList := make([]string, len(ipInfoList.Items))\n\tfor i, ip := range ipInfoList.Items {\n\t\tipList[i] = ip.Subsets[0].Addresses[0].IP\n\t}\n\n\tklog.V(6).Infof(\"Current master IPs listed in storage are %v\", ipList)\n\n\treturn ipList, nil\n}"}, {"instruction": "// dataForPseudoProfiling returns pseudo data for table profiling when system variable `profiling` is set to `ON`.", "input": "go language", "output": "func dataForPseudoProfiling() [][]types.Datum {\n\tvar rows [][]types.Datum\n\trow := types.MakeDatums(\n\t\t0,                      // QUERY_ID\n\t\t0,                      // SEQ\n\t\t\"\",                     // STATE\n\t\ttypes.NewDecFromInt(0), // DURATION\n\t\ttypes.NewDecFromInt(0), // CPU_USER\n\t\ttypes.NewDecFromInt(0), // CPU_SYSTEM\n\t\t0,                      // CONTEXT_VOLUNTARY\n\t\t0,                      // CONTEXT_INVOLUNTARY\n\t\t0,                      // BLOCK_OPS_IN\n\t\t0,                      // BLOCK_OPS_OUT\n\t\t0,                      // MESSAGES_SENT\n\t\t0,                      // MESSAGES_RECEIVED\n\t\t0,                      // PAGE_FAULTS_MAJOR\n\t\t0,                      // PAGE_FAULTS_MINOR\n\t\t0,                      // SWAPS\n\t\t\"\",                     // SOURCE_FUNCTION\n\t\t\"\",                     // SOURCE_FILE\n\t\t0,                      // SOURCE_LINE\n\t)\n\trows = append(rows, row)\n\treturn rows\n}"}, {"instruction": "// SetContentHash sets the content hash associated with a name. Only works if the caller\n// owns the name, and the associated resolver implements a `setContenthash` function.", "input": "go language", "output": "func (ens *ENS) SetContentHash(name string, hash []byte) (*types.Transaction, error) {\n\tnode := EnsNode(name)\n\n\tresolver, err := ens.getResolver(node)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\topts := ens.TransactOpts\n\topts.GasLimit = 200000\n\n\t// IMPORTANT: The old contract is deprecated. This code should be removed latest on June 1st 2019\n\tsupported, err := resolver.SupportsInterface(contentHash_Interface_Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !supported {\n\t\tresolver, err := ens.getFallbackResolver(node)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\topts := ens.TransactOpts\n\t\topts.GasLimit = 200000\n\t\tvar b [32]byte\n\t\tcopy(b[:], hash)\n\t\treturn resolver.Contract.SetContent(&opts, node, b)\n\t}\n\n\t// END DEPRECATED CODE\n\treturn resolver.Contract.SetContenthash(&opts, node, hash)\n}"}, {"instruction": "// TarResourceRebase is like TarResource but renames the first path element of\n// items in the resulting tar archive to match the given rebaseName if not \"\".", "input": "go language", "output": "func TarResourceRebase(sourcePath, rebaseName string) (content io.ReadCloser, err error) {\n\tsourcePath = normalizePath(sourcePath)\n\tif _, err = os.Lstat(sourcePath); err != nil {\n\t\t// Catches the case where the source does not exist or is not a\n\t\t// directory if asserted to be a directory, as this also causes an\n\t\t// error.\n\t\treturn\n\t}\n\n\t// Separate the source path between its directory and\n\t// the entry in that directory which we are archiving.\n\tsourceDir, sourceBase := SplitPathDirEntry(sourcePath)\n\topts := TarResourceRebaseOpts(sourceBase, rebaseName)\n\n\tlogrus.Debugf(\"copying %q from %q\", sourceBase, sourceDir)\n\treturn TarWithOptions(sourceDir, opts)\n}"}, {"instruction": "// NewLeaderElectionService returns a new LeaderElectionService", "input": "go language", "output": "func NewLeaderElectionService(adapter LeaderElectionAdapter, id string, callback leadershipCallback, config ElectionConfig) LeaderElectionService {\n\tif len(id) == 0 {\n\t\tpanic(\"Empty id\")\n\t}\n\tle := &leaderElectionSvcImpl{\n\t\tid:            peerID(id),\n\t\tproposals:     util.NewSet(),\n\t\tadapter:       adapter,\n\t\tstopChan:      make(chan struct{}, 1),\n\t\tinterruptChan: make(chan struct{}, 1),\n\t\tlogger:        util.GetLogger(util.ElectionLogger, \"\"),\n\t\tcallback:      noopCallback,\n\t\tconfig:        config,\n\t}\n\n\tif callback != nil {\n\t\tle.callback = callback\n\t}\n\n\tgo le.start()\n\treturn le\n}"}, {"instruction": "// Execute executes the command", "input": "go language", "output": "func (pc *ConfigCmd) Execute(conf common.Config) error {\n\tif pc.server == nil || *pc.server == \"\" {\n\t\treturn errors.New(\"no server specified\")\n\t}\n\tif pc.channel == nil || *pc.channel == \"\" {\n\t\treturn errors.New(\"no channel specified\")\n\t}\n\n\tserver := *pc.server\n\tchannel := *pc.channel\n\n\treq := discovery.NewRequest().OfChannel(channel).AddConfigQuery()\n\tres, err := pc.stub.Send(server, conf, req)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn pc.parser.ParseResponse(channel, res)\n}"}, {"instruction": "// checkArgs makes sure all the arguments' types are known and can be handled.\n// integer types are converted to int64 and uint64, time.Time is converted to types.Time.\n// time.Duration is converted to types.Duration, other known types are leaved as it is.", "input": "go language", "output": "func checkArgs(args ...interface{}) error {\n\tfor i, v := range args {\n\t\tswitch x := v.(type) {\n\t\tcase bool:\n\t\t\tif x {\n\t\t\t\targs[i] = int64(1)\n\t\t\t} else {\n\t\t\t\targs[i] = int64(0)\n\t\t\t}\n\t\tcase int8:\n\t\t\targs[i] = int64(x)\n\t\tcase int16:\n\t\t\targs[i] = int64(x)\n\t\tcase int32:\n\t\t\targs[i] = int64(x)\n\t\tcase int:\n\t\t\targs[i] = int64(x)\n\t\tcase uint8:\n\t\t\targs[i] = uint64(x)\n\t\tcase uint16:\n\t\t\targs[i] = uint64(x)\n\t\tcase uint32:\n\t\t\targs[i] = uint64(x)\n\t\tcase uint:\n\t\t\targs[i] = uint64(x)\n\t\tcase int64:\n\t\tcase uint64:\n\t\tcase float32:\n\t\tcase float64:\n\t\tcase string:\n\t\tcase []byte:\n\t\tcase time.Duration:\n\t\t\targs[i] = types.Duration{Duration: x}\n\t\tcase time.Time:\n\t\t\targs[i] = types.Time{Time: types.FromGoTime(x), Type: mysql.TypeDatetime}\n\t\tcase nil:\n\t\tdefault:\n\t\t\treturn errors.Errorf(\"cannot use arg[%d] (type %T):unsupported type\", i, v)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *LabelSelector) DeepCopyInto(out *LabelSelector) {\n\t*out = *in\n\tif in.MatchLabels != nil {\n\t\tin, out := &in.MatchLabels, &out.MatchLabels\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.MatchExpressions != nil {\n\t\tin, out := &in.MatchExpressions, &out.MatchExpressions\n\t\t*out = make([]LabelSelectorRequirement, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// saves state to a file, caller is responsible for locking", "input": "go language", "output": "func (sf *stateFile) storeState() {\n\tvar content []byte\n\tvar err error\n\n\tdata := stateFileData{\n\t\tPolicyName:    sf.policyName,\n\t\tDefaultCPUSet: sf.cache.GetDefaultCPUSet().String(),\n\t\tEntries:       map[string]string{},\n\t}\n\n\tfor containerID, cset := range sf.cache.GetCPUAssignments() {\n\t\tdata.Entries[containerID] = cset.String()\n\t}\n\n\tif content, err = json.Marshal(data); err != nil {\n\t\tpanic(\"[cpumanager] state file: could not serialize state to json\")\n\t}\n\n\tif err = ioutil.WriteFile(sf.stateFilePath, content, 0644); err != nil {\n\t\tpanic(\"[cpumanager] state file not written\")\n\t}\n\treturn\n}"}, {"instruction": "// AddFlags registers flags for a cli", "input": "go language", "output": "func (flags *WaitFlags) AddFlags(cmd *cobra.Command) {\n\tflags.PrintFlags.AddFlags(cmd)\n\tflags.ResourceBuilderFlags.AddFlags(cmd.Flags())\n\n\tcmd.Flags().DurationVar(&flags.Timeout, \"timeout\", flags.Timeout, \"The length of time to wait before giving up.  Zero means check once and don't wait, negative means wait for a week.\")\n\tcmd.Flags().StringVar(&flags.ForCondition, \"for\", flags.ForCondition, \"The condition to wait on: [delete|condition=condition-name].\")\n}"}, {"instruction": "// Get returns the rootfs path for the id. It is reference counted and\n// effectively can be thought of as a \"mount the layer into the utility\n// vm if it isn't already\". The contract from the caller of this is that\n// all Gets and Puts are matched. It -should- be the case that on cleanup,\n// nothing is mounted.\n//\n// For optimisation, we don't actually mount the filesystem (which in our\n// case means [hot-]adding it to a service VM. But we track that and defer\n// the actual adding to the point we need to access it.", "input": "go language", "output": "func (d *Driver) Get(id, mountLabel string) (containerfs.ContainerFS, error) {\n\ttitle := fmt.Sprintf(\"lcowdriver: get: %s\", id)\n\tlogrus.Debugf(title)\n\n\t// Generate the mounts needed for the deferred operation.\n\tdisks, err := d.getAllMounts(id)\n\tif err != nil {\n\t\tlogrus.Debugf(\"%s failed to get all layer details for %s: %s\", title, d.dir(id), err)\n\t\treturn nil, fmt.Errorf(\"%s failed to get layer details for %s: %s\", title, d.dir(id), err)\n\t}\n\n\tlogrus.Debugf(\"%s: got layer mounts: %+v\", title, disks)\n\treturn &lcowfs{\n\t\troot:        unionMountName(disks),\n\t\td:           d,\n\t\tmappedDisks: disks,\n\t\tvmID:        d.getVMID(id),\n\t}, nil\n}"}, {"instruction": "// snapshot is the internal function analogous to Snapshot but expects\n// a lock to already be held.\n//\n// checkDup when set will store the snapshot on lastSnapshot and use\n// reflect.DeepEqual to verify that its not writing an identical snapshot.", "input": "go language", "output": "func (m *Manager) snapshot(path string, checkDup bool) error {\n\t// Build the snapshot\n\ts := snapshot{\n\t\tVersion: snapshotVersion,\n\t\tProxies: make(map[string]snapshotProxy, len(m.proxies)),\n\t}\n\tfor id, p := range m.proxies {\n\t\t// Get the snapshot configuration. If the configuration is nil or\n\t\t// empty then we don't persist this proxy.\n\t\tconfig := p.MarshalSnapshot()\n\t\tif len(config) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\ts.Proxies[id] = snapshotProxy{\n\t\t\tMode:   proxyExecMode(p),\n\t\t\tConfig: config,\n\t\t}\n\t}\n\n\t// Dup detection, if the snapshot is identical to the last, do nothing\n\tif checkDup && reflect.DeepEqual(m.lastSnapshot, &s) {\n\t\treturn nil\n\t}\n\n\t// Encode as JSON\n\tencoded, err := json.Marshal(&s)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Write the file\n\terr = file.WriteAtomic(path, encoded)\n\n\t// If we are checking for dups and we had a successful write, store\n\t// it so we don't rewrite the same value.\n\tif checkDup && err == nil {\n\t\tm.lastSnapshot = &s\n\t}\n\treturn err\n}"}, {"instruction": "// ViewHistory returns a list of the revision history of a statefulset\n// TODO: this should be a describer\n// TODO: needs to implement detailed revision view", "input": "go language", "output": "func (h *StatefulSetHistoryViewer) ViewHistory(namespace, name string, revision int64) (string, error) {\n\t_, history, err := statefulSetHistory(h.c.AppsV1(), namespace, name)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(history) <= 0 {\n\t\treturn \"No rollout history found.\", nil\n\t}\n\trevisions := make([]int64, len(history))\n\tfor _, revision := range history {\n\t\trevisions = append(revisions, revision.Revision)\n\t}\n\tsliceutil.SortInts64(revisions)\n\n\treturn tabbedString(func(out io.Writer) error {\n\t\tfmt.Fprintf(out, \"REVISION\\n\")\n\t\tfor _, r := range revisions {\n\t\t\tfmt.Fprintf(out, \"%d\\n\", r)\n\t\t}\n\t\treturn nil\n\t})\n}"}, {"instruction": "// isForbidden determines if an import is forbidden,\n// which is true when the import is:\n//   - of a package under the rootPackage\n//   - is not of the base import path or a sub-package of it\n//   - is not of an allowed path or a sub-package of one", "input": "go language", "output": "func (i *ImportRestriction) isForbidden(imp string) bool {\n\timportsBelowRoot := strings.HasPrefix(imp, rootPackage)\n\timportsBelowBase := strings.HasPrefix(imp, i.BaseDir)\n\timportsAllowed := false\n\tfor _, allowed := range i.AllowedImports {\n\t\texactlyImportsAllowed := imp == allowed\n\t\timportsBelowAllowed := strings.HasPrefix(imp, fmt.Sprintf(\"%s/\", allowed))\n\t\timportsAllowed = importsAllowed || (importsBelowAllowed || exactlyImportsAllowed)\n\t}\n\n\treturn importsBelowRoot && !importsBelowBase && !importsAllowed\n}"}, {"instruction": "// StrToUint converts a string to an unsigned integer at the best-effortt.", "input": "go language", "output": "func StrToUint(sc *stmtctx.StatementContext, str string) (uint64, error) {\n\tstr = strings.TrimSpace(str)\n\tvalidPrefix, err := getValidIntPrefix(sc, str)\n\tif validPrefix[0] == '+' {\n\t\tvalidPrefix = validPrefix[1:]\n\t}\n\tuVal, err1 := strconv.ParseUint(validPrefix, 10, 64)\n\tif err1 != nil {\n\t\treturn uVal, ErrOverflow.GenWithStackByArgs(\"BIGINT UNSIGNED\", validPrefix)\n\t}\n\treturn uVal, errors.Trace(err)\n}"}, {"instruction": "// Next implements the Executor Next interface.", "input": "go language", "output": "func (e *CheckTableExec) Next(ctx context.Context, req *chunk.RecordBatch) error {\n\tif e.done {\n\t\treturn nil\n\t}\n\tdefer func() { e.done = true }()\n\tfor _, t := range e.tables {\n\t\tdbName := t.DBInfo.Name\n\t\ttb, err := e.is.TableByName(dbName, t.Name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif tb.Meta().GetPartitionInfo() != nil {\n\t\t\terr = e.doCheckPartitionedTable(tb.(table.PartitionedTable))\n\t\t} else {\n\t\t\terr = e.doCheckTable(tb)\n\t\t}\n\t\tif err != nil {\n\t\t\tlogutil.Logger(ctx).Warn(\"check table failed\", zap.String(\"tableName\", t.Name.O), zap.Error(err))\n\t\t\tif admin.ErrDataInConsistent.Equal(err) {\n\t\t\t\treturn ErrAdminCheckTable.GenWithStack(\"%v err:%v\", t.Name, err)\n\t\t\t}\n\n\t\t\treturn errors.Errorf(\"%v err:%v\", t.Name, err)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// Log is intended to be called once at the end of your request handler, via defer", "input": "go language", "output": "func (rl *respLogger) Log() {\n\tlatency := time.Since(rl.startTime)\n\tif klog.V(3) {\n\t\tif !rl.hijacked {\n\t\t\tklog.InfoDepth(1, fmt.Sprintf(\"%s %s: (%v) %v%v%v [%s %s]\", rl.req.Method, rl.req.RequestURI, latency, rl.status, rl.statusStack, rl.addedInfo, rl.req.UserAgent(), rl.req.RemoteAddr))\n\t\t} else {\n\t\t\tklog.InfoDepth(1, fmt.Sprintf(\"%s %s: (%v) hijacked [%s %s]\", rl.req.Method, rl.req.RequestURI, latency, rl.req.UserAgent(), rl.req.RemoteAddr))\n\t\t}\n\t}\n}"}, {"instruction": "// SetServerRootCAs sets the list of authorities used to verify server\n// certificates based on a list of PEM-encoded X509 certificate authorities", "input": "go language", "output": "func (client *GRPCClient) SetServerRootCAs(serverRoots [][]byte) error {\n\n\t// NOTE: if no serverRoots are specified, the current cert pool will be\n\t// replaced with an empty one\n\tcertPool := x509.NewCertPool()\n\tfor _, root := range serverRoots {\n\t\terr := AddPemToCertPool(root, certPool)\n\t\tif err != nil {\n\t\t\treturn errors.WithMessage(err, \"error adding root certificate\")\n\t\t}\n\t}\n\tclient.tlsConfig.RootCAs = certPool\n\treturn nil\n}"}, {"instruction": "// semverCompare returns whether the client's version is older, equal or newer than the given image's version.", "input": "go language", "output": "func semverCompare(image string) int {\n\tsplit := strings.Split(image, \":\")\n\tif len(split) < 2 {\n\t\t// If we don't know the version, we consider the client version newer.\n\t\treturn 1\n\t}\n\ttillerVersion, err := semver.NewVersion(split[1])\n\tif err != nil {\n\t\t// same thing with unparsable tiller versions (e.g. canary releases).\n\t\treturn 1\n\t}\n\tclientVersion, err := semver.NewVersion(version.Version)\n\tif err != nil {\n\t\t// aaaaaand same thing with unparsable helm versions (e.g. canary releases).\n\t\treturn 1\n\t}\n\treturn clientVersion.Compare(tillerVersion)\n}"}, {"instruction": "// bumpInBucket moves the given node to the front of the bucket entry list\n// if it is contained in that list.", "input": "go language", "output": "func (tab *Table) bumpInBucket(b *bucket, n *node) bool {\n\tfor i := range b.entries {\n\t\tif b.entries[i].ID() == n.ID() {\n\t\t\tif !n.IP().Equal(b.entries[i].IP()) {\n\t\t\t\t// Endpoint has changed, ensure that the new IP fits into table limits.\n\t\t\t\ttab.removeIP(b, b.entries[i].IP())\n\t\t\t\tif !tab.addIP(b, n.IP()) {\n\t\t\t\t\t// It doesn't, put the previous one back.\n\t\t\t\t\ttab.addIP(b, b.entries[i].IP())\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Move it to the front.\n\t\t\tcopy(b.entries[1:], b.entries[:i])\n\t\t\tb.entries[0] = n\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}"}, {"instruction": "// Patch applies the patch and returns the patched validatingWebhookConfiguration.", "input": "go language", "output": "func (c *FakeValidatingWebhookConfigurations) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *v1beta1.ValidatingWebhookConfiguration, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootPatchSubresourceAction(validatingwebhookconfigurationsResource, name, pt, data, subresources...), &v1beta1.ValidatingWebhookConfiguration{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*v1beta1.ValidatingWebhookConfiguration), err\n}"}, {"instruction": "// bitsetEncodeBytes compresses the input byte slice according to the sparse\n// bitset representation algorithm.", "input": "go language", "output": "func bitsetEncodeBytes(data []byte) []byte {\n\t// Empty slices get compressed to nil\n\tif len(data) == 0 {\n\t\treturn nil\n\t}\n\t// One byte slices compress to nil or retain the single byte\n\tif len(data) == 1 {\n\t\tif data[0] == 0 {\n\t\t\treturn nil\n\t\t}\n\t\treturn data\n\t}\n\t// Calculate the bitset of set bytes, and gather the non-zero bytes\n\tnonZeroBitset := make([]byte, (len(data)+7)/8)\n\tnonZeroBytes := make([]byte, 0, len(data))\n\n\tfor i, b := range data {\n\t\tif b != 0 {\n\t\t\tnonZeroBytes = append(nonZeroBytes, b)\n\t\t\tnonZeroBitset[i/8] |= 1 << byte(7-i%8)\n\t\t}\n\t}\n\tif len(nonZeroBytes) == 0 {\n\t\treturn nil\n\t}\n\treturn append(bitsetEncodeBytes(nonZeroBitset), nonZeroBytes...)\n}"}, {"instruction": "// PrintFs prints the given filesystem to the given writer starting from the given path.\n// This is useful for debugging.", "input": "go language", "output": "func PrintFs(fs afero.Fs, path string, w io.Writer) {\n\tif fs == nil {\n\t\treturn\n\t}\n\tafero.Walk(fs, path, func(path string, info os.FileInfo, err error) error {\n\t\tif info != nil && !info.IsDir() {\n\t\t\ts := path\n\t\t\tif lang, ok := info.(hugofs.LanguageAnnouncer); ok {\n\t\t\t\ts = s + \"\\tLANG: \" + lang.Lang()\n\t\t\t}\n\t\t\tif fp, ok := info.(hugofs.FilePather); ok {\n\t\t\t\ts = s + \"\\tRF: \" + fp.Filename() + \"\\tBP: \" + fp.BaseDir()\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"    \", s)\n\t\t}\n\t\treturn nil\n\t})\n}"}, {"instruction": "// GetRoleReferenceRules attempts to resolve the RoleBinding or ClusterRoleBinding.", "input": "go language", "output": "func (r *DefaultRuleResolver) GetRoleReferenceRules(roleRef rbacv1.RoleRef, bindingNamespace string) ([]rbacv1.PolicyRule, error) {\n\tswitch roleRef.Kind {\n\tcase \"Role\":\n\t\trole, err := r.roleGetter.GetRole(bindingNamespace, roleRef.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn role.Rules, nil\n\n\tcase \"ClusterRole\":\n\t\tclusterRole, err := r.clusterRoleGetter.GetClusterRole(roleRef.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn clusterRole.Rules, nil\n\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported role reference kind: %q\", roleRef.Kind)\n\t}\n}"}, {"instruction": "// GetZoneByNodeName gets availability zone for the specified node. If the node is not running\n// with availability zone, then it returns fault domain.", "input": "go language", "output": "func (as *availabilitySet) GetZoneByNodeName(name string) (cloudprovider.Zone, error) {\n\tvm, err := as.getVirtualMachine(types.NodeName(name))\n\tif err != nil {\n\t\treturn cloudprovider.Zone{}, err\n\t}\n\n\tvar failureDomain string\n\tif vm.Zones != nil && len(*vm.Zones) > 0 {\n\t\t// Get availability zone for the node.\n\t\tzones := *vm.Zones\n\t\tzoneID, err := strconv.Atoi(zones[0])\n\t\tif err != nil {\n\t\t\treturn cloudprovider.Zone{}, fmt.Errorf(\"failed to parse zone %q: %v\", zones, err)\n\t\t}\n\n\t\tfailureDomain = as.makeZone(zoneID)\n\t} else {\n\t\t// Availability zone is not used for the node, falling back to fault domain.\n\t\tfailureDomain = strconv.Itoa(int(*vm.VirtualMachineProperties.InstanceView.PlatformFaultDomain))\n\t}\n\n\tzone := cloudprovider.Zone{\n\t\tFailureDomain: failureDomain,\n\t\tRegion:        *(vm.Location),\n\t}\n\treturn zone, nil\n}"}, {"instruction": "// getResourceNamesForGroup is a private method for getting the canonical names for each resource to build in an api group", "input": "go language", "output": "func getResourceNamesForGroup(apiPrefix string, apiGroupInfo *APIGroupInfo, pathsToIgnore openapiutil.Trie) ([]string, error) {\n\t// Get the canonical names of every resource we need to build in this api group\n\tresourceNames := make([]string, 0)\n\tfor _, groupVersion := range apiGroupInfo.PrioritizedVersions {\n\t\tfor resource, storage := range apiGroupInfo.VersionedResourcesStorageMap[groupVersion.Version] {\n\t\t\tpath := gpath.Join(apiPrefix, groupVersion.Group, groupVersion.Version, resource)\n\t\t\tif !pathsToIgnore.HasPrefix(path) {\n\t\t\t\tkind, err := genericapi.GetResourceKind(groupVersion, storage, apiGroupInfo.Scheme)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tsampleObject, err := apiGroupInfo.Scheme.New(kind)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tname := openapiutil.GetCanonicalTypeName(sampleObject)\n\t\t\t\tresourceNames = append(resourceNames, name)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn resourceNames, nil\n}"}, {"instruction": "// update takes a hash that forms the next leaf level (level-1) node in the merkle tree.\n// Also, complete the merkle tree as much as possible with the addition of this new leaf node -\n// i.e. recursively build the higher level nodes and delete the underlying sub-tree.", "input": "go language", "output": "func (m *merkleTree) update(nextLeafLevelHash Hash) error {\n\tlogger.Debugf(\"Before update() = %s\", m)\n\tdefer logger.Debugf(\"After update() = %s\", m)\n\tm.tree[leafLevel] = append(m.tree[leafLevel], nextLeafLevelHash)\n\tcurrentLevel := leafLevel\n\tfor {\n\t\tcurrentLevelHashes := m.tree[currentLevel]\n\t\tif uint32(len(currentLevelHashes)) <= m.maxDegree {\n\t\t\treturn nil\n\t\t}\n\t\tnextLevelHash, err := computeCombinedHash(currentLevelHashes)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdelete(m.tree, currentLevel)\n\t\tnextLevel := currentLevel + 1\n\t\tm.tree[nextLevel] = append(m.tree[nextLevel], nextLevelHash)\n\t\tif nextLevel > m.maxLevel {\n\t\t\tm.maxLevel = nextLevel\n\t\t}\n\t\tcurrentLevel = nextLevel\n\t}\n}"}, {"instruction": "// applyPreparedQueryOperation applies the given prepared query operation to the\n// state store.", "input": "go language", "output": "func (c *FSM) applyPreparedQueryOperation(buf []byte, index uint64) interface{} {\n\tvar req structs.PreparedQueryRequest\n\tif err := structs.Decode(buf, &req); err != nil {\n\t\tpanic(fmt.Errorf(\"failed to decode request: %v\", err))\n\t}\n\n\tdefer metrics.MeasureSinceWithLabels([]string{\"fsm\", \"prepared-query\"}, time.Now(),\n\t\t[]metrics.Label{{Name: \"op\", Value: string(req.Op)}})\n\tswitch req.Op {\n\tcase structs.PreparedQueryCreate, structs.PreparedQueryUpdate:\n\t\treturn c.state.PreparedQuerySet(index, req.Query)\n\tcase structs.PreparedQueryDelete:\n\t\treturn c.state.PreparedQueryDelete(index, req.Query.ID)\n\tdefault:\n\t\tc.logger.Printf(\"[WARN] consul.fsm: Invalid PreparedQuery operation '%s'\", req.Op)\n\t\treturn fmt.Errorf(\"Invalid PreparedQuery operation '%s'\", req.Op)\n\t}\n}"}, {"instruction": "// SetupWorkingDirectory sets up the container's working directory as set in container.Config.WorkingDir", "input": "go language", "output": "func (container *Container) SetupWorkingDirectory(rootIdentity idtools.Identity) error {\n\t// TODO @jhowardmsft, @gupta-ak LCOW Support. This will need revisiting.\n\t// We will need to do remote filesystem operations here.\n\tif container.OS != runtime.GOOS {\n\t\treturn nil\n\t}\n\n\tif container.Config.WorkingDir == \"\" {\n\t\treturn nil\n\t}\n\n\tcontainer.Config.WorkingDir = filepath.Clean(container.Config.WorkingDir)\n\tpth, err := container.GetResourcePath(container.Config.WorkingDir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := idtools.MkdirAllAndChownNew(pth, 0755, rootIdentity); err != nil {\n\t\tpthInfo, err2 := os.Stat(pth)\n\t\tif err2 == nil && pthInfo != nil && !pthInfo.IsDir() {\n\t\t\treturn errors.Errorf(\"Cannot mkdir: %s is not a directory\", container.Config.WorkingDir)\n\t\t}\n\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// initPvtdataStoreFromExistingBlockchain updates the initial state of the pvtdata store\n// if an existing block store has a blockchain and the pvtdata store is empty.\n// This situation is expected to happen when a peer is upgrated from version 1.0\n// and an existing blockchain is present that was generated with version 1.0.\n// Under this scenario, the pvtdata store is brought upto the point as if it has\n// processed existing blocks with no pvt data. This function returns true if the\n// above mentioned condition is found to be true and pvtdata store is successfully updated", "input": "go language", "output": "func (s *Store) initPvtdataStoreFromExistingBlockchain() (bool, error) {\n\tvar bcInfo *common.BlockchainInfo\n\tvar pvtdataStoreEmpty bool\n\tvar err error\n\n\tif bcInfo, err = s.BlockStore.GetBlockchainInfo(); err != nil {\n\t\treturn false, err\n\t}\n\tif pvtdataStoreEmpty, err = s.pvtdataStore.IsEmpty(); err != nil {\n\t\treturn false, err\n\t}\n\tif pvtdataStoreEmpty && bcInfo.Height > 0 {\n\t\tif err = s.pvtdataStore.InitLastCommittedBlock(bcInfo.Height - 1); err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn true, nil\n\t}\n\treturn false, nil\n}"}, {"instruction": "// resolveInputIPAddr tries to resolve the IP address from the string passed as input\n// - tries to match the string as an interface name, if so returns the IP address associated with it\n// - on failure of previous step tries to parse the string as an IP address itself\n//\t if succeeds returns the IP address", "input": "go language", "output": "func resolveInputIPAddr(input string, isUnspecifiedValid bool) (net.IP, error) {\n\t// Try to see if it is an interface name\n\tinterfaceAddr, err := resolveInterfaceAddr(input)\n\tif err == nil {\n\t\treturn interfaceAddr, nil\n\t}\n\t// String matched interface but there is a potential ambiguity to be resolved\n\tif err != errNoSuchInterface {\n\t\treturn nil, err\n\t}\n\n\t// String is not an interface check if it is a valid IP\n\tif ip := net.ParseIP(input); ip != nil && (isUnspecifiedValid || !ip.IsUnspecified()) {\n\t\treturn ip, nil\n\t}\n\n\t// Not valid IP found\n\treturn nil, errBadNetworkIdentifier\n}"}, {"instruction": "// Detach the given device from the given host.", "input": "go language", "output": "func (detacher *photonPersistentDiskDetacher) Detach(volumeName string, nodeName types.NodeName) error {\n\n\thostName := string(nodeName)\n\tpdID := volumeName\n\tattached, err := detacher.photonDisks.DiskIsAttached(context.TODO(), pdID, nodeName)\n\tif err != nil {\n\t\t// Log error and continue with detach\n\t\tklog.Errorf(\n\t\t\t\"Error checking if persistent disk (%q) is already attached to current node (%q). Will continue and try detach anyway. err=%v\",\n\t\t\tpdID, hostName, err)\n\t}\n\n\tif err == nil && !attached {\n\t\t// Volume is already detached from node.\n\t\tklog.V(4).Infof(\"detach operation was successful. persistent disk %q is already detached from node %q.\", pdID, hostName)\n\t\treturn nil\n\t}\n\n\tif err := detacher.photonDisks.DetachDisk(context.TODO(), pdID, nodeName); err != nil {\n\t\tklog.Errorf(\"Error detaching volume %q: %v\", pdID, err)\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// preparedQueryCreate makes a new prepared query.", "input": "go language", "output": "func (s *HTTPServer) preparedQueryCreate(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\targs := structs.PreparedQueryRequest{\n\t\tOp: structs.PreparedQueryCreate,\n\t}\n\ts.parseDC(req, &args.Datacenter)\n\ts.parseToken(req, &args.Token)\n\tif err := decodeBody(req, &args.Query, nil); err != nil {\n\t\tresp.WriteHeader(http.StatusBadRequest)\n\t\tfmt.Fprintf(resp, \"Request decode failed: %v\", err)\n\t\treturn nil, nil\n\t}\n\n\tvar reply string\n\tif err := s.agent.RPC(\"PreparedQuery.Apply\", &args, &reply); err != nil {\n\t\treturn nil, err\n\t}\n\treturn preparedQueryCreateResponse{reply}, nil\n}"}, {"instruction": "// NewDatabaseWithCache creates a new trie database to store ephemeral trie content\n// before its written out to disk or garbage collected. It also acts as a read cache\n// for nodes loaded from disk.", "input": "go language", "output": "func NewDatabaseWithCache(diskdb ethdb.KeyValueStore, cache int) *Database {\n\tvar cleans *bigcache.BigCache\n\tif cache > 0 {\n\t\tcleans, _ = bigcache.NewBigCache(bigcache.Config{\n\t\t\tShards:             1024,\n\t\t\tLifeWindow:         time.Hour,\n\t\t\tMaxEntriesInWindow: cache * 1024,\n\t\t\tMaxEntrySize:       512,\n\t\t\tHardMaxCacheSize:   cache,\n\t\t\tHasher:             trienodeHasher{},\n\t\t})\n\t}\n\treturn &Database{\n\t\tdiskdb: diskdb,\n\t\tcleans: cleans,\n\t\tdirties: map[common.Hash]*cachedNode{{}: {\n\t\t\tchildren: make(map[common.Hash]uint16),\n\t\t}},\n\t\tpreimages: make(map[common.Hash][]byte),\n\t}\n}"}, {"instruction": "// CreateOrRetainConfigMap creates a ConfigMap if the target resource doesn't exist. If the resource exists already, this function will retain the resource instead.", "input": "go language", "output": "func CreateOrRetainConfigMap(client clientset.Interface, cm *v1.ConfigMap, configMapName string) error {\n\tif _, err := client.CoreV1().ConfigMaps(cm.ObjectMeta.Namespace).Get(configMapName, metav1.GetOptions{}); err != nil {\n\t\tif !apierrors.IsNotFound(err) {\n\t\t\treturn nil\n\t\t}\n\t\tif _, err := client.CoreV1().ConfigMaps(cm.ObjectMeta.Namespace).Create(cm); err != nil {\n\t\t\tif !apierrors.IsAlreadyExists(err) {\n\t\t\t\treturn errors.Wrap(err, \"unable to create configmap\")\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// CompareKubeAwareVersionStrings compares two kube-like version strings.\n// Kube-like version strings are starting with a v, followed by a major version, optional \"alpha\" or \"beta\" strings\n// followed by a minor version (e.g. v1, v2beta1). Versions will be sorted based on GA/alpha/beta first and then major\n// and minor versions. e.g. v2, v1, v1beta2, v1beta1, v1alpha1.", "input": "go language", "output": "func CompareKubeAwareVersionStrings(v1, v2 string) int {\n\tif v1 == v2 {\n\t\treturn 0\n\t}\n\tv1major, v1type, v1minor, ok1 := parseKubeVersion(v1)\n\tv2major, v2type, v2minor, ok2 := parseKubeVersion(v2)\n\tswitch {\n\tcase !ok1 && !ok2:\n\t\treturn strings.Compare(v2, v1)\n\tcase !ok1 && ok2:\n\t\treturn -1\n\tcase ok1 && !ok2:\n\t\treturn 1\n\t}\n\tif v1type != v2type {\n\t\treturn int(v1type) - int(v2type)\n\t}\n\tif v1major != v2major {\n\t\treturn v1major - v2major\n\t}\n\treturn v1minor - v2minor\n}"}, {"instruction": "// UpdateLease resets the TTL on a master IP in storage", "input": "go language", "output": "func (s *storageLeases) UpdateLease(ip string) error {\n\tkey := path.Join(s.baseKey, ip)\n\treturn s.storage.GuaranteedUpdate(apirequest.NewDefaultContext(), key, &corev1.Endpoints{}, true, nil, func(input kruntime.Object, respMeta storage.ResponseMeta) (kruntime.Object, *uint64, error) {\n\t\t// just make sure we've got the right IP set, and then refresh the TTL\n\t\texisting := input.(*corev1.Endpoints)\n\t\texisting.Subsets = []corev1.EndpointSubset{\n\t\t\t{\n\t\t\t\tAddresses: []corev1.EndpointAddress{{IP: ip}},\n\t\t\t},\n\t\t}\n\n\t\t// leaseTime needs to be in seconds\n\t\tleaseTime := uint64(s.leaseTime / time.Second)\n\n\t\t// NB: GuaranteedUpdate does not perform the store operation unless\n\t\t// something changed between load and store (not including resource\n\t\t// version), meaning we can't refresh the TTL without actually\n\t\t// changing a field.\n\t\texisting.Generation++\n\n\t\tklog.V(6).Infof(\"Resetting TTL on master IP %q listed in storage to %v\", ip, leaseTime)\n\n\t\treturn existing, &leaseTime, nil\n\t})\n}"}, {"instruction": "// DeprecateBackend can be used to wrap a backend to retrun a deprecation\n// warning during validation.", "input": "go language", "output": "func deprecateBackend(b backend.Backend, message string) backend.Backend {\n\t// Since a Backend wrapped by deprecatedBackendShim can no longer be\n\t// asserted as an Enhanced or Local backend, disallow those types here\n\t// entirely.  If something other than a basic backend.Backend needs to be\n\t// deprecated, we can add that functionality to schema.Backend or the\n\t// backend itself.\n\tif _, ok := b.(backend.Enhanced); ok {\n\t\tpanic(\"cannot use DeprecateBackend on an Enhanced Backend\")\n\t}\n\n\tif _, ok := b.(backend.Local); ok {\n\t\tpanic(\"cannot use DeprecateBackend on a Local Backend\")\n\t}\n\n\treturn deprecatedBackendShim{\n\t\tBackend: b,\n\t\tMessage: message,\n\t}\n}"}, {"instruction": "// Stop stops the node by first sending SIGTERM and then SIGKILL if the node\n// doesn't stop within 5s", "input": "go language", "output": "func (n *ExecNode) Stop() error {\n\tif n.Cmd == nil {\n\t\treturn nil\n\t}\n\tdefer func() {\n\t\tn.Cmd = nil\n\t}()\n\n\tif n.client != nil {\n\t\tn.client.Close()\n\t\tn.client = nil\n\t\tn.wsAddr = \"\"\n\t\tn.Info = nil\n\t}\n\n\tif err := n.Cmd.Process.Signal(syscall.SIGTERM); err != nil {\n\t\treturn n.Cmd.Process.Kill()\n\t}\n\twaitErr := make(chan error)\n\tgo func() {\n\t\twaitErr <- n.Cmd.Wait()\n\t}()\n\tselect {\n\tcase err := <-waitErr:\n\t\treturn err\n\tcase <-time.After(5 * time.Second):\n\t\treturn n.Cmd.Process.Kill()\n\t}\n}"}, {"instruction": "// ReadDockerConfigJSONFile attempts to read a docker config.json file from the given paths.\n// if searchPaths is empty, the default paths are used.", "input": "go language", "output": "func ReadDockerConfigJSONFile(searchPaths []string) (cfg DockerConfig, err error) {\n\tif len(searchPaths) == 0 {\n\t\tsearchPaths = DefaultDockerConfigJSONPaths()\n\t}\n\tfor _, configPath := range searchPaths {\n\t\tabsDockerConfigFileLocation, err := filepath.Abs(filepath.Join(configPath, configJsonFileName))\n\t\tif err != nil {\n\t\t\tklog.Errorf(\"while trying to canonicalize %s: %v\", configPath, err)\n\t\t\tcontinue\n\t\t}\n\t\tklog.V(4).Infof(\"looking for %s at %s\", configJsonFileName, absDockerConfigFileLocation)\n\t\tcfg, err = ReadSpecificDockerConfigJsonFile(absDockerConfigFileLocation)\n\t\tif err != nil {\n\t\t\tif !os.IsNotExist(err) {\n\t\t\t\tklog.V(4).Infof(\"while trying to read %s: %v\", absDockerConfigFileLocation, err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tklog.V(4).Infof(\"found valid %s at %s\", configJsonFileName, absDockerConfigFileLocation)\n\t\treturn cfg, nil\n\t}\n\treturn nil, fmt.Errorf(\"couldn't find valid %s after checking in %v\", configJsonFileName, searchPaths)\n\n}"}, {"instruction": "// isPrivileged will return true a pod has any privileged containers", "input": "go language", "output": "func isPrivileged(pod *corev1.Pod) bool {\n\tfor _, c := range pod.Spec.InitContainers {\n\t\tif c.SecurityContext == nil || c.SecurityContext.Privileged == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif *c.SecurityContext.Privileged {\n\t\t\treturn true\n\t\t}\n\t}\n\tfor _, c := range pod.Spec.Containers {\n\t\tif c.SecurityContext == nil || c.SecurityContext.Privileged == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif *c.SecurityContext.Privileged {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}"}, {"instruction": "// writePacket writes data that already have header", "input": "go language", "output": "func (p *packetIO) writePacket(data []byte) error {\n\tlength := len(data) - 4\n\n\tfor length >= mysql.MaxPayloadLen {\n\t\tdata[0] = 0xff\n\t\tdata[1] = 0xff\n\t\tdata[2] = 0xff\n\n\t\tdata[3] = p.sequence\n\n\t\tif n, err := p.bufWriter.Write(data[:4+mysql.MaxPayloadLen]); err != nil {\n\t\t\treturn errors.Trace(mysql.ErrBadConn)\n\t\t} else if n != (4 + mysql.MaxPayloadLen) {\n\t\t\treturn errors.Trace(mysql.ErrBadConn)\n\t\t} else {\n\t\t\tp.sequence++\n\t\t\tlength -= mysql.MaxPayloadLen\n\t\t\tdata = data[mysql.MaxPayloadLen:]\n\t\t}\n\t}\n\n\tdata[0] = byte(length)\n\tdata[1] = byte(length >> 8)\n\tdata[2] = byte(length >> 16)\n\tdata[3] = p.sequence\n\n\tif n, err := p.bufWriter.Write(data); err != nil {\n\t\tterror.Log(errors.Trace(err))\n\t\treturn errors.Trace(mysql.ErrBadConn)\n\t} else if n != len(data) {\n\t\treturn errors.Trace(mysql.ErrBadConn)\n\t} else {\n\t\tp.sequence++\n\t\treturn nil\n\t}\n}"}, {"instruction": "// create is used as the entry function for \"create\" app command.", "input": "go language", "output": "func create(ctx *cli.Context) error {\n\tlog.PrintOrigins(true)\n\tlog.Root().SetHandler(log.LvlFilterHandler(log.Lvl(ctx.Int(\"verbosity\")), log.StreamHandler(os.Stdout, log.TerminalFormat(true))))\n\n\tif len(ctx.Args()) < 1 {\n\t\treturn errors.New(\"argument should be the filename to verify or write-to\")\n\t}\n\tfilename, err := touchPath(ctx.Args()[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn createSnapshot(filename, ctx.Int(\"nodes\"), strings.Split(ctx.String(\"services\"), \",\"))\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *VolumeAttachmentStatus) DeepCopyInto(out *VolumeAttachmentStatus) {\n\t*out = *in\n\tif in.AttachmentMetadata != nil {\n\t\tin, out := &in.AttachmentMetadata, &out.AttachmentMetadata\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.AttachError != nil {\n\t\tin, out := &in.AttachError, &out.AttachError\n\t\t*out = new(VolumeError)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.DetachError != nil {\n\t\tin, out := &in.DetachError, &out.DetachError\n\t\t*out = new(VolumeError)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\treturn\n}"}, {"instruction": "// MustGetGlobalVersion implements SchemaSyncer.MustGetGlobalVersion interface.", "input": "go language", "output": "func (s *schemaVersionSyncer) MustGetGlobalVersion(ctx context.Context) (int64, error) {\n\tstartTime := time.Now()\n\tvar (\n\t\terr  error\n\t\tver  int\n\t\tresp *clientv3.GetResponse\n\t)\n\tfailedCnt := 0\n\tintervalCnt := int(time.Second / keyOpRetryInterval)\n\n\tdefer func() {\n\t\tmetrics.OwnerHandleSyncerHistogram.WithLabelValues(metrics.OwnerGetGlobalVersion, metrics.RetLabel(err)).Observe(time.Since(startTime).Seconds())\n\t}()\n\tfor {\n\t\tif err != nil {\n\t\t\tif failedCnt%intervalCnt == 0 {\n\t\t\t\tlogutil.Logger(ddlLogCtx).Info(\"[ddl] syncer get global version failed\", zap.Error(err))\n\t\t\t}\n\t\t\ttime.Sleep(keyOpRetryInterval)\n\t\t\tfailedCnt++\n\t\t}\n\n\t\tif isContextDone(ctx) {\n\t\t\terr = errors.Trace(ctx.Err())\n\t\t\treturn 0, err\n\t\t}\n\n\t\tresp, err = s.etcdCli.Get(ctx, DDLGlobalSchemaVersion)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tif len(resp.Kvs) > 0 {\n\t\t\tver, err = strconv.Atoi(string(resp.Kvs[0].Value))\n\t\t\tif err == nil {\n\t\t\t\treturn int64(ver), nil\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// NewFilteredPriorityClassInformer constructs a new informer for PriorityClass type.\n// Always prefer using an informer factory to get a shared informer instead of getting an independent\n// one. This reduces memory footprint and number of connections to the server.", "input": "go language", "output": "func NewFilteredPriorityClassInformer(client kubernetes.Interface, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\n\treturn cache.NewSharedIndexInformer(\n\t\t&cache.ListWatch{\n\t\t\tListFunc: func(options v1.ListOptions) (runtime.Object, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.SchedulingV1alpha1().PriorityClasses().List(options)\n\t\t\t},\n\t\t\tWatchFunc: func(options v1.ListOptions) (watch.Interface, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.SchedulingV1alpha1().PriorityClasses().Watch(options)\n\t\t\t},\n\t\t},\n\t\t&schedulingv1alpha1.PriorityClass{},\n\t\tresyncPeriod,\n\t\tindexers,\n\t)\n}"}, {"instruction": "// GetNetworkDriverList returns the list of plugins drivers\n// registered for network.", "input": "go language", "output": "func (daemon *Daemon) GetNetworkDriverList() []string {\n\tif !daemon.NetworkControllerEnabled() {\n\t\treturn nil\n\t}\n\n\tpluginList := daemon.netController.BuiltinDrivers()\n\n\tmanagedPlugins := daemon.PluginStore.GetAllManagedPluginsByCap(driverapi.NetworkPluginEndpointType)\n\n\tfor _, plugin := range managedPlugins {\n\t\tpluginList = append(pluginList, plugin.Name())\n\t}\n\n\tpluginMap := make(map[string]bool)\n\tfor _, plugin := range pluginList {\n\t\tpluginMap[plugin] = true\n\t}\n\n\tnetworks := daemon.netController.Networks()\n\n\tfor _, network := range networks {\n\t\tif !pluginMap[network.Type()] {\n\t\t\tpluginList = append(pluginList, network.Type())\n\t\t\tpluginMap[network.Type()] = true\n\t\t}\n\t}\n\n\tsort.Strings(pluginList)\n\n\treturn pluginList\n}"}, {"instruction": "// getStatefulSetsForPod returns a list of StatefulSets that potentially match\n// a given pod.", "input": "go language", "output": "func (ssc *StatefulSetController) getStatefulSetsForPod(pod *v1.Pod) []*apps.StatefulSet {\n\tsets, err := ssc.setLister.GetPodStatefulSets(pod)\n\tif err != nil {\n\t\treturn nil\n\t}\n\t// More than one set is selecting the same Pod\n\tif len(sets) > 1 {\n\t\t// ControllerRef will ensure we don't do anything crazy, but more than one\n\t\t// item in this list nevertheless constitutes user error.\n\t\tutilruntime.HandleError(\n\t\t\tfmt.Errorf(\n\t\t\t\t\"user error: more than one StatefulSet is selecting pods with labels: %+v\",\n\t\t\t\tpod.Labels))\n\t}\n\treturn sets\n}"}, {"instruction": "// GetVersion returns the etcd version of the cluster.\n// An error is returned if the version of all endpoints do not match", "input": "go language", "output": "func (c *Client) GetVersion() (string, error) {\n\tvar clusterVersion string\n\n\tversions, err := c.GetClusterVersions()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tfor _, v := range versions {\n\t\tif clusterVersion != \"\" && clusterVersion != v {\n\t\t\treturn \"\", errors.Errorf(\"etcd cluster contains endpoints with mismatched versions: %v\", versions)\n\t\t}\n\t\tclusterVersion = v\n\t}\n\tif clusterVersion == \"\" {\n\t\treturn \"\", errors.New(\"could not determine cluster etcd version\")\n\t}\n\treturn clusterVersion, nil\n}"}, {"instruction": "// Flatten creates a nonce-sorted slice of transactions based on the loosely\n// sorted internal representation. The result of the sorting is cached in case\n// it's requested again before any modifications are made to the contents.", "input": "go language", "output": "func (m *txSortedMap) Flatten() types.Transactions {\n\t// If the sorting was not cached yet, create and cache it\n\tif m.cache == nil {\n\t\tm.cache = make(types.Transactions, 0, len(m.items))\n\t\tfor _, tx := range m.items {\n\t\t\tm.cache = append(m.cache, tx)\n\t\t}\n\t\tsort.Sort(types.TxByNonce(m.cache))\n\t}\n\t// Copy the cache to prevent accidental modifications\n\ttxs := make(types.Transactions, len(m.cache))\n\tcopy(txs, m.cache)\n\treturn txs\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of MutatingWebhookConfigurations that match those selectors.", "input": "go language", "output": "func (c *FakeMutatingWebhookConfigurations) List(opts v1.ListOptions) (result *v1beta1.MutatingWebhookConfigurationList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootListAction(mutatingwebhookconfigurationsResource, mutatingwebhookconfigurationsKind, opts), &v1beta1.MutatingWebhookConfigurationList{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta1.MutatingWebhookConfigurationList{ListMeta: obj.(*v1beta1.MutatingWebhookConfigurationList).ListMeta}\n\tfor _, item := range obj.(*v1beta1.MutatingWebhookConfigurationList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// tryAccessIdx tries to find index entry. If found then increments the access\n// count for garbage collection and returns the index entry and true for found,\n// otherwise returns nil and false.", "input": "go language", "output": "func (s *LDBStore) tryAccessIdx(addr Address, po uint8) (*dpaDBIndex, bool) {\n\tikey := getIndexKey(addr)\n\tidata, err := s.db.Get(ikey)\n\tif err != nil {\n\t\treturn nil, false\n\t}\n\n\tindex := new(dpaDBIndex)\n\tdecodeIndex(idata, index)\n\toldGCIdxKey := getGCIdxKey(index)\n\ts.batch.Put(keyAccessCnt, U64ToBytes(s.accessCnt))\n\tindex.Access = s.accessCnt\n\tidata = encodeIndex(index)\n\ts.accessCnt++\n\ts.batch.Put(ikey, idata)\n\tnewGCIdxKey := getGCIdxKey(index)\n\tnewGCIdxData := getGCIdxValue(index, po, ikey[1:])\n\ts.batch.Delete(oldGCIdxKey)\n\ts.batch.Put(newGCIdxKey, newGCIdxData)\n\tselect {\n\tcase s.batchesC <- struct{}{}:\n\tdefault:\n\t}\n\treturn index, true\n}"}, {"instruction": "// NewChildImage creates a new Image as a child of this image.", "input": "go language", "output": "func NewChildImage(img *Image, child ChildConfig, os string) *Image {\n\tisEmptyLayer := layer.IsEmpty(child.DiffID)\n\tvar rootFS *RootFS\n\tif img.RootFS != nil {\n\t\trootFS = img.RootFS.Clone()\n\t} else {\n\t\trootFS = NewRootFS()\n\t}\n\n\tif !isEmptyLayer {\n\t\trootFS.Append(child.DiffID)\n\t}\n\timgHistory := NewHistory(\n\t\tchild.Author,\n\t\tchild.Comment,\n\t\tstrings.Join(child.ContainerConfig.Cmd, \" \"),\n\t\tisEmptyLayer)\n\n\treturn &Image{\n\t\tV1Image: V1Image{\n\t\t\tDockerVersion:   dockerversion.Version,\n\t\t\tConfig:          child.Config,\n\t\t\tArchitecture:    img.BaseImgArch(),\n\t\t\tOS:              os,\n\t\t\tContainer:       child.ContainerID,\n\t\t\tContainerConfig: *child.ContainerConfig,\n\t\t\tAuthor:          child.Author,\n\t\t\tCreated:         imgHistory.Created,\n\t\t},\n\t\tRootFS:     rootFS,\n\t\tHistory:    append(img.History, imgHistory),\n\t\tOSFeatures: img.OSFeatures,\n\t\tOSVersion:  img.OSVersion,\n\t}\n}"}, {"instruction": "// ScanIndexData scans the index handles and values in a limited number, according to the index information.\n// It returns data and the next startVals until it doesn't have data, then returns data is nil and\n// the next startVals is the values which can't get data. If startVals = nil and limit = -1,\n// it returns the index data of the whole.", "input": "go language", "output": "func ScanIndexData(sc *stmtctx.StatementContext, txn kv.Transaction, kvIndex table.Index, startVals []types.Datum, limit int64) (\n\t[]*RecordData, []types.Datum, error) {\n\tit, _, err := kvIndex.Seek(sc, txn, startVals)\n\tif err != nil {\n\t\treturn nil, nil, errors.Trace(err)\n\t}\n\tdefer it.Close()\n\n\tvar idxRows []*RecordData\n\tvar curVals []types.Datum\n\tfor limit != 0 {\n\t\tval, h, err1 := it.Next()\n\t\tif terror.ErrorEqual(err1, io.EOF) {\n\t\t\treturn idxRows, nextIndexVals(curVals), nil\n\t\t} else if err1 != nil {\n\t\t\treturn nil, nil, errors.Trace(err1)\n\t\t}\n\t\tidxRows = append(idxRows, &RecordData{Handle: h, Values: val})\n\t\tlimit--\n\t\tcurVals = val\n\t}\n\n\tnextVals, _, err := it.Next()\n\tif terror.ErrorEqual(err, io.EOF) {\n\t\treturn idxRows, nextIndexVals(curVals), nil\n\t} else if err != nil {\n\t\treturn nil, nil, errors.Trace(err)\n\t}\n\n\treturn idxRows, nextVals, nil\n}"}, {"instruction": "// SameLineage returns true only if the state given in argument belongs\n// to the same \"lineage\" of states as the receiver.", "input": "go language", "output": "func (s *State) SameLineage(other *State) bool {\n\ts.Lock()\n\tdefer s.Unlock()\n\n\t// If one of the states has no lineage then it is assumed to predate\n\t// this concept, and so we'll accept it as belonging to any lineage\n\t// so that a lineage string can be assigned to newer versions\n\t// without breaking compatibility with older versions.\n\tif s.Lineage == \"\" || other.Lineage == \"\" {\n\t\treturn true\n\t}\n\n\treturn s.Lineage == other.Lineage\n}"}, {"instruction": "// HEALTHCHECK foo\n//\n// Set the default healthcheck command to run in the container (which may be empty).\n// Argument handling is the same as RUN.\n//", "input": "go language", "output": "func dispatchHealthcheck(d dispatchRequest, c *instructions.HealthCheckCommand) error {\n\trunConfig := d.state.runConfig\n\tif runConfig.Healthcheck != nil {\n\t\toldCmd := runConfig.Healthcheck.Test\n\t\tif len(oldCmd) > 0 && oldCmd[0] != \"NONE\" {\n\t\t\tfmt.Fprintf(d.builder.Stdout, \"Note: overriding previous HEALTHCHECK: %v\\n\", oldCmd)\n\t\t}\n\t}\n\trunConfig.Healthcheck = c.Health\n\treturn d.builder.commit(d.state, fmt.Sprintf(\"HEALTHCHECK %q\", runConfig.Healthcheck))\n}"}, {"instruction": "// parseCARoot returns a filled-in structs.CARoot from a raw PEM value.", "input": "go language", "output": "func parseCARoot(pemValue, provider, clusterID string) (*structs.CARoot, error) {\n\tid, err := connect.CalculateCertFingerprint(pemValue)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error parsing root fingerprint: %v\", err)\n\t}\n\trootCert, err := connect.ParseCert(pemValue)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error parsing root cert: %v\", err)\n\t}\n\treturn &structs.CARoot{\n\t\tID:                  id,\n\t\tName:                fmt.Sprintf(\"%s CA Root Cert\", strings.Title(provider)),\n\t\tSerialNumber:        rootCert.SerialNumber.Uint64(),\n\t\tSigningKeyID:        connect.HexString(rootCert.AuthorityKeyId),\n\t\tExternalTrustDomain: clusterID,\n\t\tNotBefore:           rootCert.NotBefore,\n\t\tNotAfter:            rootCert.NotAfter,\n\t\tRootCert:            pemValue,\n\t\tActive:              true,\n\t}, nil\n}"}, {"instruction": "// Helper function for the binding generators.\n// It reads the unmatched characters after the inner type-match,\n//  (since the inner type is a prefix of the total type declaration),\n//  looks for valid arrays (possibly a dynamic one) wrapping the inner type,\n//  and returns the sizes of these arrays.\n//\n// Returned array sizes are in the same order as solidity signatures; inner array size first.\n// Array sizes may also be \"\", indicating a dynamic array.", "input": "go language", "output": "func wrapArray(stringKind string, innerLen int, innerMapping string) (string, []string) {\n\tremainder := stringKind[innerLen:]\n\t//find all the sizes\n\tmatches := regexp.MustCompile(`\\[(\\d*)\\]`).FindAllStringSubmatch(remainder, -1)\n\tparts := make([]string, 0, len(matches))\n\tfor _, match := range matches {\n\t\t//get group 1 from the regex match\n\t\tparts = append(parts, match[1])\n\t}\n\treturn innerMapping, parts\n}"}, {"instruction": "// GraphNodeProviderConsumer", "input": "go language", "output": "func (n *NodeAbstractResource) ProvidedBy() (addrs.AbsProviderConfig, bool) {\n\t// If we have a config we prefer that above all else\n\tif n.Config != nil {\n\t\trelAddr := n.Config.ProviderConfigAddr()\n\t\treturn relAddr.Absolute(n.Path()), false\n\t}\n\n\t// Use our type and containing module path to guess a provider configuration address\n\treturn n.Addr.Resource.DefaultProviderConfig().Absolute(n.Addr.Module), false\n}"}, {"instruction": "// adjustColumnInfoInAddColumn is used to set the correct position of column info when adding column.\n// 1. The added column was append at the end of tblInfo.Columns, due to ddl state was not public then.\n//    It should be moved to the correct position when the ddl state to be changed to public.\n// 2. The offset of column should also to be set to the right value.", "input": "go language", "output": "func adjustColumnInfoInAddColumn(tblInfo *model.TableInfo, offset int) {\n\toldCols := tblInfo.Columns\n\tnewCols := make([]*model.ColumnInfo, 0, len(oldCols))\n\tnewCols = append(newCols, oldCols[:offset]...)\n\tnewCols = append(newCols, oldCols[len(oldCols)-1])\n\tnewCols = append(newCols, oldCols[offset:len(oldCols)-1]...)\n\t// Adjust column offset.\n\toffsetChanged := make(map[int]int)\n\tfor i := offset + 1; i < len(newCols); i++ {\n\t\toffsetChanged[newCols[i].Offset] = i\n\t\tnewCols[i].Offset = i\n\t}\n\tnewCols[offset].Offset = offset\n\t// Update index column offset info.\n\t// TODO: There may be some corner cases for index column offsets, we may check this later.\n\tfor _, idx := range tblInfo.Indices {\n\t\tfor _, col := range idx.Columns {\n\t\t\tnewOffset, ok := offsetChanged[col.Offset]\n\t\t\tif ok {\n\t\t\t\tcol.Offset = newOffset\n\t\t\t}\n\t\t}\n\t}\n\ttblInfo.Columns = newCols\n}"}, {"instruction": "// nodeCheckTxn is used as the inner method to handle reading a health check\n// from the state store.", "input": "go language", "output": "func (s *Store) getNodeCheckTxn(tx *memdb.Txn, nodeName string, checkID types.CheckID) (uint64, *structs.HealthCheck, error) {\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, \"checks\")\n\n\t// Return the check.\n\tcheck, err := tx.First(\"checks\", \"id\", nodeName, string(checkID))\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed check lookup: %s\", err)\n\t}\n\n\tif check != nil {\n\t\treturn idx, check.(*structs.HealthCheck), nil\n\t}\n\treturn idx, nil, nil\n}"}, {"instruction": "// ServerKeepaliveOptions returns gRPC keepalive options for server.  If\n// opts is nil, the default keepalive options are returned", "input": "go language", "output": "func ServerKeepaliveOptions(ka *KeepaliveOptions) []grpc.ServerOption {\n\t// use default keepalive options if nil\n\tif ka == nil {\n\t\tka = DefaultKeepaliveOptions\n\t}\n\tvar serverOpts []grpc.ServerOption\n\tkap := keepalive.ServerParameters{\n\t\tTime:    ka.ServerInterval,\n\t\tTimeout: ka.ServerTimeout,\n\t}\n\tserverOpts = append(serverOpts, grpc.KeepaliveParams(kap))\n\tkep := keepalive.EnforcementPolicy{\n\t\tMinTime: ka.ServerMinInterval,\n\t\t// allow keepalive w/o rpc\n\t\tPermitWithoutStream: true,\n\t}\n\tserverOpts = append(serverOpts, grpc.KeepaliveEnforcementPolicy(kep))\n\treturn serverOpts\n}"}, {"instruction": "// Gets the current load balancer state", "input": "go language", "output": "func (c *Cloud) describeLoadBalancer(name string) (*elb.LoadBalancerDescription, error) {\n\trequest := &elb.DescribeLoadBalancersInput{}\n\trequest.LoadBalancerNames = []*string{&name}\n\n\tresponse, err := c.elb.DescribeLoadBalancers(request)\n\tif err != nil {\n\t\tif awsError, ok := err.(awserr.Error); ok {\n\t\t\tif awsError.Code() == \"LoadBalancerNotFound\" {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tvar ret *elb.LoadBalancerDescription\n\tfor _, loadBalancer := range response.LoadBalancerDescriptions {\n\t\tif ret != nil {\n\t\t\tklog.Errorf(\"Found multiple load balancers with name: %s\", name)\n\t\t}\n\t\tret = loadBalancer\n\t}\n\treturn ret, nil\n}"}, {"instruction": "//genChaincodeDeploymentSpec creates ChaincodeDeploymentSpec as the package to install", "input": "go language", "output": "func genChaincodeDeploymentSpec(cmd *cobra.Command, chaincodeName, chaincodeVersion string) (*pb.ChaincodeDeploymentSpec, error) {\n\tif existed, _ := ccprovider.ChaincodePackageExists(chaincodeName, chaincodeVersion); existed {\n\t\treturn nil, fmt.Errorf(\"chaincode %s:%s already exists\", chaincodeName, chaincodeVersion)\n\t}\n\n\tspec, err := getChaincodeSpec(cmd)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcds, err := getChaincodeDeploymentSpec(spec, true)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting chaincode code %s: %s\", chaincodeName, err)\n\t}\n\n\treturn cds, nil\n}"}, {"instruction": "// FindServer takes out an internal \"read lock\" and searches through the list\n// of servers to find a \"healthy\" server.  If the server is actually\n// unhealthy, we rely on Serf to detect this and remove the node from the\n// server list.  If the server at the front of the list has failed or fails\n// during an RPC call, it is rotated to the end of the list.  If there are no\n// servers available, return nil.", "input": "go language", "output": "func (m *Manager) FindServer() *metadata.Server {\n\tl := m.getServerList()\n\tnumServers := len(l.servers)\n\tif numServers == 0 {\n\t\tm.logger.Printf(\"[WARN] manager: No servers available\")\n\t\treturn nil\n\t}\n\n\t// Return whatever is at the front of the list because it is\n\t// assumed to be the oldest in the server list (unless -\n\t// hypothetically - the server list was rotated right after a\n\t// server was added).\n\treturn l.servers[0]\n}"}, {"instruction": "// removeRegisterTopic deletes all tickets for the given topic.", "input": "go language", "output": "func (s *ticketStore) removeRegisterTopic(topic Topic) {\n\tlog.Trace(\"Removing discovery topic\", \"topic\", topic)\n\tif s.tickets[topic] == nil {\n\t\tlog.Warn(\"Removing non-existent discovery topic\", \"topic\", topic)\n\t\treturn\n\t}\n\tfor _, list := range s.tickets[topic].buckets {\n\t\tfor _, ref := range list {\n\t\t\tref.t.refCnt--\n\t\t\tif ref.t.refCnt == 0 {\n\t\t\t\tdelete(s.nodes, ref.t.node)\n\t\t\t\tdelete(s.nodeLastReq, ref.t.node)\n\t\t\t}\n\t\t}\n\t}\n\tdelete(s.tickets, topic)\n}"}, {"instruction": "// ApplyDefaults applies the default values to Options.", "input": "go language", "output": "func (o *Options) ApplyDefaults(in *kubeproxyconfig.KubeProxyConfiguration) (*kubeproxyconfig.KubeProxyConfiguration, error) {\n\texternal, err := o.scheme.ConvertToVersion(in, v1alpha1.SchemeGroupVersion)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\to.scheme.Default(external)\n\n\tinternal, err := o.scheme.ConvertToVersion(external, kubeproxyconfig.SchemeGroupVersion)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tout := internal.(*kubeproxyconfig.KubeProxyConfiguration)\n\n\treturn out, nil\n}"}, {"instruction": "// Validate container resource name\n// Refer to docs/design/resources.md for more details.", "input": "go language", "output": "func validateContainerResourceName(value string, fldPath *field.Path) field.ErrorList {\n\tallErrs := validateResourceName(value, fldPath)\n\n\tif len(strings.Split(value, \"/\")) == 1 {\n\t\tif !helper.IsStandardContainerResourceName(value) {\n\t\t\treturn append(allErrs, field.Invalid(fldPath, value, \"must be a standard resource for containers\"))\n\t\t}\n\t} else if !helper.IsNativeResource(core.ResourceName(value)) {\n\t\tif !helper.IsExtendedResourceName(core.ResourceName(value)) {\n\t\t\treturn append(allErrs, field.Invalid(fldPath, value, \"doesn't follow extended resource name standard\"))\n\t\t}\n\t}\n\treturn allErrs\n}"}, {"instruction": "// Get the volume and node object from actual state of world\n// This is an internal function and caller should acquire and release the lock\n//\n// Note that this returns disconnected objects, so if you change the volume object you must set it back with\n// `asw.attachedVolumes[volumeName]=volumeObj`.\n//\n// If you change the node object you must use `volumeObj.nodesAttachedTo[nodeName] = nodeObj`\n// This is correct, because if volumeObj is empty this function returns an error, and nodesAttachedTo\n// map is a reference type, and thus mutating the copy changes the original map.", "input": "go language", "output": "func (asw *actualStateOfWorld) getNodeAndVolume(\n\tvolumeName v1.UniqueVolumeName, nodeName types.NodeName) (attachedVolume, nodeAttachedTo, error) {\n\n\tvolumeObj, volumeExists := asw.attachedVolumes[volumeName]\n\tif volumeExists {\n\t\tnodeObj, nodeExists := volumeObj.nodesAttachedTo[nodeName]\n\t\tif nodeExists {\n\t\t\treturn volumeObj, nodeObj, nil\n\t\t}\n\t}\n\n\treturn attachedVolume{}, nodeAttachedTo{}, fmt.Errorf(\"volume %v is no longer attached to the node %q\",\n\t\tvolumeName,\n\t\tnodeName)\n}"}, {"instruction": "// Validate checks if a given ipset is valid or not.", "input": "go language", "output": "func (set *IPSet) Validate() bool {\n\t// Check if protocol is valid for `HashIPPort`, `HashIPPortIP` and `HashIPPortNet` type set.\n\tif set.SetType == HashIPPort || set.SetType == HashIPPortIP || set.SetType == HashIPPortNet {\n\t\tif valid := validateHashFamily(set.HashFamily); !valid {\n\t\t\treturn false\n\t\t}\n\t}\n\t// check set type\n\tif valid := validateIPSetType(set.SetType); !valid {\n\t\treturn false\n\t}\n\t// check port range for bitmap type set\n\tif set.SetType == BitmapPort {\n\t\tif valid := validatePortRange(set.PortRange); !valid {\n\t\t\treturn false\n\t\t}\n\t}\n\t// check hash size value of ipset\n\tif set.HashSize <= 0 {\n\t\tklog.Errorf(\"Invalid hashsize value %d, should be >0\", set.HashSize)\n\t\treturn false\n\t}\n\t// check max elem value of ipset\n\tif set.MaxElem <= 0 {\n\t\tklog.Errorf(\"Invalid maxelem value %d, should be >0\", set.MaxElem)\n\t\treturn false\n\t}\n\n\treturn true\n}"}, {"instruction": "// AuthenticateRequest authenticates the request using a chain of authenticator.Request objects.", "input": "go language", "output": "func (authHandler *unionAuthRequestHandler) AuthenticateRequest(req *http.Request) (*authenticator.Response, bool, error) {\n\tvar errlist []error\n\tfor _, currAuthRequestHandler := range authHandler.Handlers {\n\t\tresp, ok, err := currAuthRequestHandler.AuthenticateRequest(req)\n\t\tif err != nil {\n\t\t\tif authHandler.FailOnError {\n\t\t\t\treturn resp, ok, err\n\t\t\t}\n\t\t\terrlist = append(errlist, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif ok {\n\t\t\treturn resp, ok, err\n\t\t}\n\t}\n\n\treturn nil, false, utilerrors.NewAggregate(errlist)\n}"}, {"instruction": "// AcceptRequest returns whether a new request can be accepted and the missing\n// buffer amount if it was rejected due to a buffer underrun. If accepted, maxCost\n// is deducted from the flow control buffer.", "input": "go language", "output": "func (node *ClientNode) AcceptRequest(reqID, index, maxCost uint64) (accepted bool, bufShort uint64, priority int64) {\n\tnode.lock.Lock()\n\tdefer node.lock.Unlock()\n\n\tnow := node.cm.clock.Now()\n\tnode.update(now)\n\tif maxCost > node.bufValue {\n\t\tif node.log != nil {\n\t\t\tnode.log.add(now, fmt.Sprintf(\"rejected  reqID=%d  bv=%d  maxCost=%d\", reqID, node.bufValue, maxCost))\n\t\t\tnode.log.dump(now)\n\t\t}\n\t\treturn false, maxCost - node.bufValue, 0\n\t}\n\tnode.bufValue -= maxCost\n\tnode.sumCost += maxCost\n\tif node.log != nil {\n\t\tnode.log.add(now, fmt.Sprintf(\"accepted  reqID=%d  bv=%d  maxCost=%d  sumCost=%d\", reqID, node.bufValue, maxCost, node.sumCost))\n\t}\n\tnode.accepted[index] = node.sumCost\n\treturn true, 0, node.cm.accepted(node, maxCost, now)\n}"}, {"instruction": "// the functions below show some best practices on how\n// to use entities to perform cryptographic operations\n// over the ledger state\n// getStateAndDecrypt retrieves the value associated to key,\n// decrypts it with the supplied entity and returns the result\n// of the decryption", "input": "go language", "output": "func getStateAndDecrypt(stub shim.ChaincodeStubInterface, ent entities.Encrypter, key string) ([]byte, error) {\n\t// at first we retrieve the ciphertext from the ledger\n\tciphertext, err := stub.GetState(key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// GetState will return a nil slice if the key does not exist.\n\t// Note that the chaincode logic may want to distinguish between\n\t// nil slice (key doesn't exist in state db) and empty slice\n\t// (key found in state db but value is empty). We do not\n\t// distinguish the case here\n\tif len(ciphertext) == 0 {\n\t\treturn nil, errors.New(\"no ciphertext to decrypt\")\n\t}\n\n\treturn ent.Decrypt(ciphertext)\n}"}, {"instruction": "// handleCall processes method calls.", "input": "go language", "output": "func (h *handler) handleCall(cp *callProc, msg *jsonrpcMessage) *jsonrpcMessage {\n\tif msg.isSubscribe() {\n\t\treturn h.handleSubscribe(cp, msg)\n\t}\n\tvar callb *callback\n\tif msg.isUnsubscribe() {\n\t\tcallb = h.unsubscribeCb\n\t} else {\n\t\tcallb = h.reg.callback(msg.Method)\n\t}\n\tif callb == nil {\n\t\treturn msg.errorResponse(&methodNotFoundError{method: msg.Method})\n\t}\n\targs, err := parsePositionalArguments(msg.Params, callb.argTypes)\n\tif err != nil {\n\t\treturn msg.errorResponse(&invalidParamsError{err.Error()})\n\t}\n\n\treturn h.runMethod(cp.ctx, msg, callb, args)\n}"}, {"instruction": "// WaitForCacheSync waits for all started informers' cache were synced.", "input": "go language", "output": "func (f *dynamicSharedInformerFactory) WaitForCacheSync(stopCh <-chan struct{}) map[schema.GroupVersionResource]bool {\n\tinformers := func() map[schema.GroupVersionResource]cache.SharedIndexInformer {\n\t\tf.lock.Lock()\n\t\tdefer f.lock.Unlock()\n\n\t\tinformers := map[schema.GroupVersionResource]cache.SharedIndexInformer{}\n\t\tfor informerType, informer := range f.informers {\n\t\t\tif f.startedInformers[informerType] {\n\t\t\t\tinformers[informerType] = informer.Informer()\n\t\t\t}\n\t\t}\n\t\treturn informers\n\t}()\n\n\tres := map[schema.GroupVersionResource]bool{}\n\tfor informType, informer := range informers {\n\t\tres[informType] = cache.WaitForCacheSync(stopCh, informer.HasSynced)\n\t}\n\treturn res\n}"}, {"instruction": "// Unlock network operations for a specific pod.  The reference count for the\n// pod will be decreased.  If the reference count reaches zero, the pod will be\n// removed from the pod map.", "input": "go language", "output": "func (pm *PluginManager) podUnlock(fullPodName string) {\n\tpm.podsLock.Lock()\n\tdefer pm.podsLock.Unlock()\n\n\tlock, ok := pm.pods[fullPodName]\n\tif !ok {\n\t\tklog.Warningf(\"Unbalanced pod lock unref for %s\", fullPodName)\n\t\treturn\n\t} else if lock.refcount == 0 {\n\t\t// This should never ever happen, but handle it anyway\n\t\tdelete(pm.pods, fullPodName)\n\t\tklog.Warningf(\"Pod lock for %s still in map with zero refcount\", fullPodName)\n\t\treturn\n\t}\n\tlock.refcount--\n\tlock.mu.Unlock()\n\tif lock.refcount == 0 {\n\t\tdelete(pm.pods, fullPodName)\n\t}\n}"}, {"instruction": "// HasSupport verifies if the given gvk supports DryRun. An error is\n// returned if it doesn't.", "input": "go language", "output": "func (v *DryRunVerifier) HasSupport(gvk schema.GroupVersionKind) error {\n\toapi, err := v.OpenAPIGetter.OpenAPISchema()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to download openapi: %v\", err)\n\t}\n\tsupports, err := openapi.SupportsDryRun(oapi, gvk)\n\tif err != nil {\n\t\t// We assume that we couldn't find the type, then check for namespace:\n\t\tsupports, _ = openapi.SupportsDryRun(oapi, schema.GroupVersionKind{Group: \"\", Version: \"v1\", Kind: \"Namespace\"})\n\t\t// If namespace supports dryRun, then we will support dryRun for CRDs only.\n\t\tif supports {\n\t\t\tsupports, err = v.Finder.HasCRD(gvk.GroupKind())\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"failed to check CRD: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\tif !supports {\n\t\treturn fmt.Errorf(\"%v doesn't support dry-run\", gvk)\n\t}\n\treturn nil\n}"}, {"instruction": "// PrivateKeyToEncryptedPEM converts a private key to an encrypted PEM", "input": "go language", "output": "func PrivateKeyToEncryptedPEM(privateKey interface{}, pwd []byte) ([]byte, error) {\n\tif privateKey == nil {\n\t\treturn nil, errors.New(\"Invalid private key. It must be different from nil.\")\n\t}\n\n\tswitch k := privateKey.(type) {\n\tcase *ecdsa.PrivateKey:\n\t\tif k == nil {\n\t\t\treturn nil, errors.New(\"Invalid ecdsa private key. It must be different from nil.\")\n\t\t}\n\t\traw, err := x509.MarshalECPrivateKey(k)\n\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tblock, err := x509.EncryptPEMBlock(\n\t\t\trand.Reader,\n\t\t\t\"PRIVATE KEY\",\n\t\t\traw,\n\t\t\tpwd,\n\t\t\tx509.PEMCipherAES256)\n\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn pem.EncodeToMemory(block), nil\n\n\tdefault:\n\t\treturn nil, errors.New(\"Invalid key type. It must be *ecdsa.PrivateKey\")\n\t}\n}"}, {"instruction": "/*\n\tWhen splitting, data is given as a SectionReader, and the key is a hashSize long byte slice (Key), the root hash of the entire content will fill this once processing finishes.\n\tNew chunks to store are store using the putter which the caller provides.\n*/", "input": "go language", "output": "func TreeSplit(ctx context.Context, data io.Reader, size int64, putter Putter) (k Address, wait func(context.Context) error, err error) {\n\ttsp := &TreeSplitterParams{\n\t\tSplitterParams: SplitterParams{\n\t\t\tChunkerParams: ChunkerParams{\n\t\t\t\tchunkSize: chunk.DefaultSize,\n\t\t\t\thashSize:  putter.RefSize(),\n\t\t\t},\n\t\t\treader: data,\n\t\t\tputter: putter,\n\t\t},\n\t\tsize: size,\n\t}\n\treturn NewTreeSplitter(tsp).Split(ctx)\n}"}, {"instruction": "// ChaincodeInfo implements function in interface ledger.DeployedChaincodeInfoProvider", "input": "go language", "output": "func (p *DeployedCCInfoProvider) ChaincodeInfo(chaincodeName string, qe ledger.SimpleQueryExecutor) (*ledger.DeployedChaincodeInfo, error) {\n\tchaincodeDataBytes, err := qe.GetState(lsccNamespace, chaincodeName)\n\tif err != nil || chaincodeDataBytes == nil {\n\t\treturn nil, err\n\t}\n\tchaincodeData := &ccprovider.ChaincodeData{}\n\tif err := proto.Unmarshal(chaincodeDataBytes, chaincodeData); err != nil {\n\t\treturn nil, errors.Wrap(err, \"error unmarshalling chaincode state data\")\n\t}\n\tcollConfigPkg, err := fetchCollConfigPkg(chaincodeName, qe)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &ledger.DeployedChaincodeInfo{\n\t\tName:                chaincodeName,\n\t\tHash:                chaincodeData.Id,\n\t\tVersion:             chaincodeData.Version,\n\t\tCollectionConfigPkg: collConfigPkg,\n\t}, nil\n}"}, {"instruction": "// UnmarshalText implements encoding.TextUnmarshaler", "input": "go language", "output": "func (b *Big) UnmarshalText(input []byte) error {\n\traw, err := checkNumberText(input)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(raw) > 64 {\n\t\treturn ErrBig256Range\n\t}\n\twords := make([]big.Word, len(raw)/bigWordNibbles+1)\n\tend := len(raw)\n\tfor i := range words {\n\t\tstart := end - bigWordNibbles\n\t\tif start < 0 {\n\t\t\tstart = 0\n\t\t}\n\t\tfor ri := start; ri < end; ri++ {\n\t\t\tnib := decodeNibble(raw[ri])\n\t\t\tif nib == badNibble {\n\t\t\t\treturn ErrSyntax\n\t\t\t}\n\t\t\twords[i] *= 16\n\t\t\twords[i] += big.Word(nib)\n\t\t}\n\t\tend = start\n\t}\n\tvar dec big.Int\n\tdec.SetBits(words)\n\t*b = (Big)(dec)\n\treturn nil\n}"}, {"instruction": "// dropInitContainerAnnotations returns a copy of the annotations with init container annotations removed,\n// or the original annotations if no init container annotations were present.\n//\n// this can be removed once no clients prior to 1.8 are supported, and no kubelets prior to 1.8 can be run\n// (we don't support kubelets older than 2 versions skewed from the apiserver, but we don't prevent them, either)", "input": "go language", "output": "func dropInitContainerAnnotations(oldAnnotations map[string]string) map[string]string {\n\tif len(oldAnnotations) == 0 {\n\t\treturn oldAnnotations\n\t}\n\n\tfound := false\n\tfor k := range initContainerAnnotations {\n\t\tif _, ok := oldAnnotations[k]; ok {\n\t\t\tfound = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !found {\n\t\treturn oldAnnotations\n\t}\n\n\tnewAnnotations := make(map[string]string, len(oldAnnotations))\n\tfor k, v := range oldAnnotations {\n\t\tif !initContainerAnnotations[k] {\n\t\t\tnewAnnotations[k] = v\n\t\t}\n\t}\n\treturn newAnnotations\n}"}, {"instruction": "// readLoop runs in its own goroutine. it handles incoming UDP packets.", "input": "go language", "output": "func (t *UDPv4) readLoop(unhandled chan<- ReadPacket) {\n\tdefer t.wg.Done()\n\tif unhandled != nil {\n\t\tdefer close(unhandled)\n\t}\n\n\tbuf := make([]byte, maxPacketSize)\n\tfor {\n\t\tnbytes, from, err := t.conn.ReadFromUDP(buf)\n\t\tif netutil.IsTemporaryError(err) {\n\t\t\t// Ignore temporary read errors.\n\t\t\tt.log.Debug(\"Temporary UDP read error\", \"err\", err)\n\t\t\tcontinue\n\t\t} else if err != nil {\n\t\t\t// Shut down the loop for permament errors.\n\t\t\tif err != io.EOF {\n\t\t\t\tt.log.Debug(\"UDP read error\", \"err\", err)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif t.handlePacket(from, buf[:nbytes]) != nil && unhandled != nil {\n\t\t\tselect {\n\t\t\tcase unhandled <- ReadPacket{buf[:nbytes], from}:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// GetCmpFunction get the compare function according to two arguments.", "input": "go language", "output": "func GetCmpFunction(lhs, rhs Expression) CompareFunc {\n\tswitch GetAccurateCmpType(lhs, rhs) {\n\tcase types.ETInt:\n\t\treturn CompareInt\n\tcase types.ETReal:\n\t\treturn CompareReal\n\tcase types.ETDecimal:\n\t\treturn CompareDecimal\n\tcase types.ETString:\n\t\treturn CompareString\n\tcase types.ETDuration:\n\t\treturn CompareDuration\n\tcase types.ETDatetime, types.ETTimestamp:\n\t\treturn CompareTime\n\tcase types.ETJson:\n\t\treturn CompareJSON\n\t}\n\treturn nil\n}"}, {"instruction": "// ValidateTokenGroups validates token groups", "input": "go language", "output": "func ValidateTokenGroups(usages []string, groups []string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\t// adding groups only makes sense for authentication\n\tusagesSet := sets.NewString(usages...)\n\tusageAuthentication := strings.TrimPrefix(bootstrapapi.BootstrapTokenUsageAuthentication, bootstrapapi.BootstrapTokenUsagePrefix)\n\tif len(groups) > 0 && !usagesSet.Has(usageAuthentication) {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, groups, fmt.Sprintf(\"token groups cannot be specified unless --usages includes %q\", usageAuthentication)))\n\t}\n\n\t// validate any extra group names\n\tfor _, group := range groups {\n\t\tif err := bootstraputil.ValidateBootstrapGroupName(group); err != nil {\n\t\t\tallErrs = append(allErrs, field.Invalid(fldPath, groups, err.Error()))\n\t\t}\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// AttachFileDevice takes a path to a regular file and makes it available as an\n// attached block device.", "input": "go language", "output": "func (v VolumePathHandler) AttachFileDevice(path string) (string, error) {\n\tblockDevicePath, err := v.GetLoopDevice(path)\n\tif err != nil && err.Error() != ErrDeviceNotFound {\n\t\treturn \"\", err\n\t}\n\n\t// If no existing loop device for the path, create one\n\tif blockDevicePath == \"\" {\n\t\tklog.V(4).Infof(\"Creating device for path: %s\", path)\n\t\tblockDevicePath, err = makeLoopDevice(path)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\treturn blockDevicePath, nil\n}"}, {"instruction": "// HInc increments the integer value of a hash field, by step, returns\n// the value after the increment.", "input": "go language", "output": "func (t *TxStructure) HInc(key []byte, field []byte, step int64) (int64, error) {\n\tif t.readWriter == nil {\n\t\treturn 0, errWriteOnSnapshot\n\t}\n\tbase := int64(0)\n\terr := t.updateHash(key, field, func(oldValue []byte) ([]byte, error) {\n\t\tif oldValue != nil {\n\t\t\tvar err error\n\t\t\tbase, err = strconv.ParseInt(string(oldValue), 10, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Trace(err)\n\t\t\t}\n\t\t}\n\t\tbase += step\n\t\treturn t.hashFieldIntegerVal(base), nil\n\t})\n\n\treturn base, errors.Trace(err)\n}"}, {"instruction": "// LSet updates an element in the list by its index.", "input": "go language", "output": "func (t *TxStructure) LSet(key []byte, index int64, value []byte) error {\n\tif t.readWriter == nil {\n\t\treturn errWriteOnSnapshot\n\t}\n\tmetaKey := t.encodeListMetaKey(key)\n\tmeta, err := t.loadListMeta(metaKey)\n\tif err != nil || meta.IsEmpty() {\n\t\treturn errors.Trace(err)\n\t}\n\n\tindex = adjustIndex(index, meta.LIndex, meta.RIndex)\n\n\tif index >= meta.LIndex && index < meta.RIndex {\n\t\treturn t.readWriter.Set(t.encodeListDataKey(key, index), value)\n\t}\n\treturn errInvalidListIndex.GenWithStack(\"invalid list index %d\", index)\n}"}, {"instruction": "//Swap implements the protocols.Balance interface\n//Add is the (sole) accounting function", "input": "go language", "output": "func (s *Swap) Add(amount int64, peer *protocols.Peer) (err error) {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\t//load existing balances from the state store\n\terr = s.loadState(peer)\n\tif err != nil && err != state.ErrNotFound {\n\t\treturn\n\t}\n\t//adjust the balance\n\t//if amount is negative, it will decrease, otherwise increase\n\ts.balances[peer.ID()] += amount\n\t//save the new balance to the state store\n\tpeerBalance := s.balances[peer.ID()]\n\terr = s.stateStore.Put(peer.ID().String(), &peerBalance)\n\n\tlog.Debug(fmt.Sprintf(\"balance for peer %s: %s\", peer.ID().String(), strconv.FormatInt(peerBalance, 10)))\n\treturn err\n}"}, {"instruction": "// GetLogs returns logs matching the given argument that are stored within the state.\n//\n// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getlogs", "input": "go language", "output": "func (api *PublicFilterAPI) GetLogs(ctx context.Context, crit FilterCriteria) ([]*types.Log, error) {\n\tvar filter *Filter\n\tif crit.BlockHash != nil {\n\t\t// Block filter requested, construct a single-shot filter\n\t\tfilter = NewBlockFilter(api.backend, *crit.BlockHash, crit.Addresses, crit.Topics)\n\t} else {\n\t\t// Convert the RPC block numbers into internal representations\n\t\tbegin := rpc.LatestBlockNumber.Int64()\n\t\tif crit.FromBlock != nil {\n\t\t\tbegin = crit.FromBlock.Int64()\n\t\t}\n\t\tend := rpc.LatestBlockNumber.Int64()\n\t\tif crit.ToBlock != nil {\n\t\t\tend = crit.ToBlock.Int64()\n\t\t}\n\t\t// Construct the range filter\n\t\tfilter = NewRangeFilter(api.backend, begin, end, crit.Addresses, crit.Topics)\n\t}\n\t// Run the filter and return all the logs\n\tlogs, err := filter.Logs(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn returnLogs(logs), err\n}"}, {"instruction": "// NewFilteredCertificateSigningRequestInformer constructs a new informer for CertificateSigningRequest type.\n// Always prefer using an informer factory to get a shared informer instead of getting an independent\n// one. This reduces memory footprint and number of connections to the server.", "input": "go language", "output": "func NewFilteredCertificateSigningRequestInformer(client kubernetes.Interface, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\n\treturn cache.NewSharedIndexInformer(\n\t\t&cache.ListWatch{\n\t\t\tListFunc: func(options v1.ListOptions) (runtime.Object, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.CertificatesV1beta1().CertificateSigningRequests().List(options)\n\t\t\t},\n\t\t\tWatchFunc: func(options v1.ListOptions) (watch.Interface, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.CertificatesV1beta1().CertificateSigningRequests().Watch(options)\n\t\t\t},\n\t\t},\n\t\t&certificatesv1beta1.CertificateSigningRequest{},\n\t\tresyncPeriod,\n\t\tindexers,\n\t)\n}"}, {"instruction": "// GetChaincodeData gets the ChaincodeData", "input": "go language", "output": "func (ccpack *SignedCDSPackage) GetChaincodeData() *ChaincodeData {\n\t//this has to be after creating a package and initializing it\n\t//If those steps fail, GetChaincodeData() should never be called\n\tif ccpack.depSpec == nil || ccpack.datab == nil || ccpack.id == nil {\n\t\tpanic(\"GetChaincodeData called on uninitialized package\")\n\t}\n\n\tvar instPolicy []byte\n\tif ccpack.sDepSpec != nil {\n\t\tinstPolicy = ccpack.sDepSpec.InstantiationPolicy\n\t}\n\n\treturn &ChaincodeData{\n\t\tName:                ccpack.depSpec.ChaincodeSpec.ChaincodeId.Name,\n\t\tVersion:             ccpack.depSpec.ChaincodeSpec.ChaincodeId.Version,\n\t\tData:                ccpack.datab,\n\t\tId:                  ccpack.id,\n\t\tInstantiationPolicy: instPolicy,\n\t}\n}"}, {"instruction": "// RemoveNode removes the overall information about the node.", "input": "go language", "output": "func (n *NodeInfo) RemoveNode(node *v1.Node) error {\n\t// We don't remove NodeInfo for because there can still be some pods on this node -\n\t// this is because notifications about pods are delivered in a different watch,\n\t// and thus can potentially be observed later, even though they happened before\n\t// node removal. This is handled correctly in cache.go file.\n\tn.node = nil\n\tn.allocatableResource = &Resource{}\n\tn.taints, n.taintsErr = nil, nil\n\tn.memoryPressureCondition = v1.ConditionUnknown\n\tn.diskPressureCondition = v1.ConditionUnknown\n\tn.pidPressureCondition = v1.ConditionUnknown\n\tn.imageStates = make(map[string]*ImageStateSummary)\n\tn.generation = nextGeneration()\n\treturn nil\n}"}, {"instruction": "// Init initializes information.", "input": "go language", "output": "func Init() {\n\tdriver := tikv.Driver{}\n\tvar err error\n\tstore, err = driver.Open(fmt.Sprintf(\"tikv://%s?cluster=1\", *pdAddr))\n\tterror.MustNil(err)\n\n\tprometheus.MustRegister(txnCounter)\n\tprometheus.MustRegister(txnRolledbackCounter)\n\tprometheus.MustRegister(txnDurations)\n\thttp.Handle(\"/metrics\", prometheus.Handler())\n\n\tgo func() {\n\t\terr1 := http.ListenAndServe(\":9191\", nil)\n\t\tterror.Log(errors.Trace(err1))\n\t}()\n}"}, {"instruction": "// NewPeerClientForAddress creates an instance of a PeerClient using the\n// provided peer address and, if TLS is enabled, the TLS root cert file", "input": "go language", "output": "func NewPeerClientForAddress(address, tlsRootCertFile string) (*PeerClient, error) {\n\tif address == \"\" {\n\t\treturn nil, errors.New(\"peer address must be set\")\n\t}\n\n\t_, override, clientConfig, err := configFromEnv(\"peer\")\n\tif clientConfig.SecOpts.UseTLS {\n\t\tif tlsRootCertFile == \"\" {\n\t\t\treturn nil, errors.New(\"tls root cert file must be set\")\n\t\t}\n\t\tcaPEM, res := ioutil.ReadFile(tlsRootCertFile)\n\t\tif res != nil {\n\t\t\terr = errors.WithMessage(res, fmt.Sprintf(\"unable to load TLS root cert file from %s\", tlsRootCertFile))\n\t\t\treturn nil, err\n\t\t}\n\t\tclientConfig.SecOpts.ServerRootCAs = [][]byte{caPEM}\n\t}\n\treturn newPeerClientForClientConfig(address, override, clientConfig)\n}"}, {"instruction": "// Get returns the overall codebase version. It's for detecting\n// what code a binary was built from.", "input": "go language", "output": "func Get() apimachineryversion.Info {\n\t// These variables typically come from -ldflags settings and in\n\t// their absence fallback to the settings in ./base.go\n\treturn apimachineryversion.Info{\n\t\tMajor:        gitMajor,\n\t\tMinor:        gitMinor,\n\t\tGitVersion:   gitVersion,\n\t\tGitCommit:    gitCommit,\n\t\tGitTreeState: gitTreeState,\n\t\tBuildDate:    buildDate,\n\t\tGoVersion:    runtime.Version(),\n\t\tCompiler:     runtime.Compiler,\n\t\tPlatform:     fmt.Sprintf(\"%s/%s\", runtime.GOOS, runtime.GOARCH),\n\t}\n}"}, {"instruction": "// Equal normalizes two URLs and then compares for equality.", "input": "go language", "output": "func Equal(a, b string) bool {\n\tau, err := url.Parse(a)\n\tif err != nil {\n\t\ta = filepath.Clean(a)\n\t\tb = filepath.Clean(b)\n\t\t// If urls are paths, return true only if they are an exact match\n\t\treturn a == b\n\t}\n\tbu, err := url.Parse(b)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tfor _, u := range []*url.URL{au, bu} {\n\t\tif u.Path == \"\" {\n\t\t\tu.Path = \"/\"\n\t\t}\n\t\tu.Path = filepath.Clean(u.Path)\n\t}\n\treturn au.String() == bu.String()\n}"}, {"instruction": "// NewDeleteCommandFlags provides default flags and values for use with the \"delete\" command", "input": "go language", "output": "func NewDeleteCommandFlags(usage string) *DeleteFlags {\n\tcascade := true\n\tgracePeriod := -1\n\n\t// setup command defaults\n\tall := false\n\tallNamespaces := false\n\tforce := false\n\tignoreNotFound := false\n\tnow := false\n\toutput := \"\"\n\tlabelSelector := \"\"\n\tfieldSelector := \"\"\n\ttimeout := time.Duration(0)\n\twait := true\n\n\tfilenames := []string{}\n\trecursive := false\n\tkustomize := \"\"\n\n\treturn &DeleteFlags{\n\t\t// Not using helpers.go since it provides function to add '-k' for FileNameOptions, but not FileNameFlags\n\t\tFileNameFlags: &genericclioptions.FileNameFlags{Usage: usage, Filenames: &filenames, Kustomize: &kustomize, Recursive: &recursive},\n\t\tLabelSelector: &labelSelector,\n\t\tFieldSelector: &fieldSelector,\n\n\t\tCascade:     &cascade,\n\t\tGracePeriod: &gracePeriod,\n\n\t\tAll:            &all,\n\t\tAllNamespaces:  &allNamespaces,\n\t\tForce:          &force,\n\t\tIgnoreNotFound: &ignoreNotFound,\n\t\tNow:            &now,\n\t\tTimeout:        &timeout,\n\t\tWait:           &wait,\n\t\tOutput:         &output,\n\t}\n}"}, {"instruction": "// Modify modifies a JSON object by insert, replace or set.\n// All path expressions cannot contain * or ** wildcard.\n// If any error occurs, the input won't be changed.", "input": "go language", "output": "func (bj BinaryJSON) Modify(pathExprList []PathExpression, values []BinaryJSON, mt ModifyType) (retj BinaryJSON, err error) {\n\tif len(pathExprList) != len(values) {\n\t\t// TODO: should return 1582(42000)\n\t\treturn retj, errors.New(\"Incorrect parameter count\")\n\t}\n\tfor _, pathExpr := range pathExprList {\n\t\tif pathExpr.flags.containsAnyAsterisk() {\n\t\t\t// TODO: should return 3149(42000)\n\t\t\treturn retj, errors.New(\"Invalid path expression\")\n\t\t}\n\t}\n\tfor i := 0; i < len(pathExprList); i++ {\n\t\tpathExpr, value := pathExprList[i], values[i]\n\t\tmodifier := &binaryModifier{bj: bj}\n\t\tswitch mt {\n\t\tcase ModifyInsert:\n\t\t\tbj = modifier.insert(pathExpr, value)\n\t\tcase ModifyReplace:\n\t\t\tbj = modifier.replace(pathExpr, value)\n\t\tcase ModifySet:\n\t\t\tbj = modifier.set(pathExpr, value)\n\t\t}\n\t}\n\treturn bj, nil\n}"}, {"instruction": "// GraphNodeReferenceOutside implementation", "input": "go language", "output": "func (n *NodeApplyableModuleVariable) ReferenceOutside() (selfPath, referencePath addrs.ModuleInstance) {\n\n\t// Module input variables have their value expressions defined in the\n\t// context of their calling (parent) module, and so references from\n\t// a node of this type should be resolved in the parent module instance.\n\treferencePath = n.Addr.Module.Parent()\n\n\t// Input variables are _referenced_ from their own module, though.\n\tselfPath = n.Addr.Module\n\n\treturn // uses named return values\n}"}, {"instruction": "// IpcMounts returns the list of IPC mounts", "input": "go language", "output": "func (container *Container) IpcMounts() []Mount {\n\tvar mounts []Mount\n\tparser := volumemounts.NewParser(container.OS)\n\n\tif container.HasMountFor(\"/dev/shm\") {\n\t\treturn mounts\n\t}\n\tif container.ShmPath == \"\" {\n\t\treturn mounts\n\t}\n\n\tlabel.SetFileLabel(container.ShmPath, container.MountLabel)\n\tmounts = append(mounts, Mount{\n\t\tSource:      container.ShmPath,\n\t\tDestination: \"/dev/shm\",\n\t\tWritable:    true,\n\t\tPropagation: string(parser.DefaultPropagationMode()),\n\t})\n\n\treturn mounts\n}"}, {"instruction": "// StoreResult stores the retrieved data in local database", "input": "go language", "output": "func (req *BloomRequest) StoreResult(db ethdb.Database) {\n\tfor i, sectionIdx := range req.SectionIndexList {\n\t\tsectionHead := rawdb.ReadCanonicalHash(db, (sectionIdx+1)*req.Config.BloomTrieSize-1)\n\t\t// if we don't have the canonical hash stored for this section head number, we'll still store it under\n\t\t// a key with a zero sectionHead. GetBloomBits will look there too if we still don't have the canonical\n\t\t// hash. In the unlikely case we've retrieved the section head hash since then, we'll just retrieve the\n\t\t// bit vector again from the network.\n\t\trawdb.WriteBloomBits(db, req.BitIdx, sectionIdx, sectionHead, req.BloomBits[i])\n\t}\n}"}, {"instruction": "// Sender returns the address derived from the signature (V, R, S) using secp256k1\n// elliptic curve and an error if it failed deriving or upon an incorrect\n// signature.\n//\n// Sender may cache the address, allowing it to be used regardless of\n// signing method. The cache is invalidated if the cached signer does\n// not match the signer used in the current call.", "input": "go language", "output": "func Sender(signer Signer, tx *Transaction) (common.Address, error) {\n\tif sc := tx.from.Load(); sc != nil {\n\t\tsigCache := sc.(sigCache)\n\t\t// If the signer used to derive from in a previous\n\t\t// call is not the same as used current, invalidate\n\t\t// the cache.\n\t\tif sigCache.signer.Equal(signer) {\n\t\t\treturn sigCache.from, nil\n\t\t}\n\t}\n\n\taddr, err := signer.Sender(tx)\n\tif err != nil {\n\t\treturn common.Address{}, err\n\t}\n\ttx.from.Store(sigCache{signer: signer, from: addr})\n\treturn addr, nil\n}"}, {"instruction": "// Next moves the iterator to the next node, returning whether there are any\n// further nodes. In case of an internal error this method returns false and\n// sets the Error field to the encountered failure. If `descend` is false,\n// skips iterating over any subnodes of the current node.", "input": "go language", "output": "func (it *nodeIterator) Next(descend bool) bool {\n\tif it.err == errIteratorEnd {\n\t\treturn false\n\t}\n\tif seek, ok := it.err.(seekError); ok {\n\t\tif it.err = it.seek(seek.key); it.err != nil {\n\t\t\treturn false\n\t\t}\n\t}\n\t// Otherwise step forward with the iterator and report any errors.\n\tstate, parentIndex, path, err := it.peek(descend)\n\tit.err = err\n\tif it.err != nil {\n\t\treturn false\n\t}\n\tit.push(state, parentIndex, path)\n\treturn true\n}"}, {"instruction": "// PrepareForUpdate clears fields that are not allowed to be set by end users on update.", "input": "go language", "output": "func (networkPolicyStrategy) PrepareForUpdate(ctx context.Context, obj, old runtime.Object) {\n\tnewNetworkPolicy := obj.(*networking.NetworkPolicy)\n\toldNetworkPolicy := old.(*networking.NetworkPolicy)\n\n\t// Any changes to the spec increment the generation number, any changes to the\n\t// status should reflect the generation number of the corresponding object.\n\t// See metav1.ObjectMeta description for more information on Generation.\n\tif !reflect.DeepEqual(oldNetworkPolicy.Spec, newNetworkPolicy.Spec) {\n\t\tnewNetworkPolicy.Generation = oldNetworkPolicy.Generation + 1\n\t}\n}"}, {"instruction": "// Decode unmarshals the raw representation of the instance object being\n// changed. Pass the implied type of the corresponding resource type schema\n// for correct operation.", "input": "go language", "output": "func (rcs *ResourceInstanceChangeSrc) Decode(ty cty.Type) (*ResourceInstanceChange, error) {\n\tchange, err := rcs.ChangeSrc.Decode(ty)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &ResourceInstanceChange{\n\t\tAddr:            rcs.Addr,\n\t\tDeposedKey:      rcs.DeposedKey,\n\t\tProviderAddr:    rcs.ProviderAddr,\n\t\tChange:          *change,\n\t\tRequiredReplace: rcs.RequiredReplace,\n\t\tPrivate:         rcs.Private,\n\t}, nil\n}"}, {"instruction": "// returnStream is used when done with a stream\n// to allow re-use by a future RPC", "input": "go language", "output": "func (c *Conn) returnClient(client *StreamClient) {\n\tdidSave := false\n\tc.clientLock.Lock()\n\tif c.clients.Len() < c.pool.MaxStreams && atomic.LoadInt32(&c.shouldClose) == 0 {\n\t\tc.clients.PushFront(client)\n\t\tdidSave = true\n\n\t\t// If this is a Yamux stream, shrink the internal buffers so that\n\t\t// we can GC the idle memory\n\t\tif ys, ok := client.stream.(*yamux.Stream); ok {\n\t\t\tys.Shrink()\n\t\t}\n\t}\n\tc.clientLock.Unlock()\n\tif !didSave {\n\t\tclient.Close()\n\t}\n}"}, {"instruction": "// gcUnscheduledTerminating deletes pods that are terminating and haven't been scheduled to a particular node.", "input": "go language", "output": "func (gcc *PodGCController) gcUnscheduledTerminating(pods []*v1.Pod) {\n\tklog.V(4).Infof(\"GC'ing unscheduled pods which are terminating.\")\n\n\tfor _, pod := range pods {\n\t\tif pod.DeletionTimestamp == nil || len(pod.Spec.NodeName) > 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tklog.V(2).Infof(\"Found unscheduled terminating Pod %v/%v not assigned to any Node. Deleting.\", pod.Namespace, pod.Name)\n\t\tif err := gcc.deletePod(pod.Namespace, pod.Name); err != nil {\n\t\t\tutilruntime.HandleError(err)\n\t\t} else {\n\t\t\tklog.V(0).Infof(\"Forced deletion of unscheduled terminating Pod %v/%v succeeded\", pod.Namespace, pod.Name)\n\t\t}\n\t}\n}"}, {"instruction": "// cleanupStaleStickySessions cleans up any stale sticky session records in the hash map.", "input": "go language", "output": "func (proxier *Proxier) cleanupStaleStickySessions() {\n\tproxier.mu.Lock()\n\tdefer proxier.mu.Unlock()\n\tservicePortNameMap := make(map[proxy.ServicePortName]bool)\n\tfor name := range proxier.serviceMap {\n\t\tservicePortName := proxy.ServicePortName{\n\t\t\tNamespacedName: types.NamespacedName{\n\t\t\t\tNamespace: name.Namespace,\n\t\t\t\tName:      name.Name,\n\t\t\t},\n\t\t\tPort: name.Port,\n\t\t}\n\t\tif servicePortNameMap[servicePortName] == false {\n\t\t\t// ensure cleanup sticky sessions only gets called once per serviceportname\n\t\t\tservicePortNameMap[servicePortName] = true\n\t\t\tproxier.loadBalancer.CleanupStaleStickySessions(servicePortName)\n\t\t}\n\t}\n}"}, {"instruction": "// NewNodeID returns a new unique ID for a node to be added to g. The returned ID does\n// not become a valid ID in g until it is added to g.", "input": "go language", "output": "func (g *UndirectedGraph) NewNodeID() int {\n\tif len(g.nodes) == 0 {\n\t\treturn 0\n\t}\n\tif len(g.nodes) == maxInt {\n\t\tpanic(fmt.Sprintf(\"simple: cannot allocate node: no slot\"))\n\t}\n\n\tvar id int\n\tif g.freeIDs.Len() != 0 && g.freeIDs.TakeMin(&id) {\n\t\treturn id\n\t}\n\tif id = g.usedIDs.Max(); id < maxInt {\n\t\treturn id + 1\n\t}\n\tfor id = 0; id < maxInt; id++ {\n\t\tif !g.usedIDs.Has(id) {\n\t\t\treturn id\n\t\t}\n\t}\n\tpanic(\"unreachable\")\n}"}, {"instruction": "// GeneratePrivateKey creates a private key and stores it in keystorePath", "input": "go language", "output": "func GeneratePrivateKey(keystorePath string) (bccsp.Key,\n\tcrypto.Signer, error) {\n\n\tvar err error\n\tvar priv bccsp.Key\n\tvar s crypto.Signer\n\n\topts := &factory.FactoryOpts{\n\t\tProviderName: \"SW\",\n\t\tSwOpts: &factory.SwOpts{\n\t\t\tHashFamily: \"SHA2\",\n\t\t\tSecLevel:   256,\n\n\t\t\tFileKeystore: &factory.FileKeystoreOpts{\n\t\t\t\tKeyStorePath: keystorePath,\n\t\t\t},\n\t\t},\n\t}\n\tcsp, err := factory.GetBCCSPFromOpts(opts)\n\tif err == nil {\n\t\t// generate a key\n\t\tpriv, err = csp.KeyGen(&bccsp.ECDSAP256KeyGenOpts{Temporary: false})\n\t\tif err == nil {\n\t\t\t// create a crypto.Signer\n\t\t\ts, err = signer.New(csp, priv)\n\t\t}\n\t}\n\treturn priv, s, err\n}"}, {"instruction": "// IsSame checks if one HealthCheck is the same as another, without looking\n// at the Raft information (that's why we didn't call it IsEqual). This is\n// useful for seeing if an update would be idempotent for all the functional\n// parts of the structure.", "input": "go language", "output": "func (c *HealthCheck) IsSame(other *HealthCheck) bool {\n\tif c.Node != other.Node ||\n\t\tc.CheckID != other.CheckID ||\n\t\tc.Name != other.Name ||\n\t\tc.Status != other.Status ||\n\t\tc.Notes != other.Notes ||\n\t\tc.Output != other.Output ||\n\t\tc.ServiceID != other.ServiceID ||\n\t\tc.ServiceName != other.ServiceName ||\n\t\t!reflect.DeepEqual(c.ServiceTags, other.ServiceTags) ||\n\t\t!reflect.DeepEqual(c.Definition, other.Definition) {\n\t\treturn false\n\t}\n\n\treturn true\n}"}, {"instruction": "// ValidateSignatureValues verifies whether the signature values are valid with\n// the given chain rules. The v value is assumed to be either 0 or 1.", "input": "go language", "output": "func ValidateSignatureValues(v byte, r, s *big.Int, homestead bool) bool {\n\tif r.Cmp(common.Big1) < 0 || s.Cmp(common.Big1) < 0 {\n\t\treturn false\n\t}\n\t// reject upper range of s values (ECDSA malleability)\n\t// see discussion in secp256k1/libsecp256k1/include/secp256k1.h\n\tif homestead && s.Cmp(secp256k1halfN) > 0 {\n\t\treturn false\n\t}\n\t// Frontier: allow s to be in full N range\n\treturn r.Cmp(secp256k1N) < 0 && s.Cmp(secp256k1N) < 0 && (v == 0 || v == 1)\n}"}, {"instruction": "// fetchAllInners reads all data from the inner table and stores them in a List.", "input": "go language", "output": "func (e *NestedLoopApplyExec) fetchAllInners(ctx context.Context) error {\n\terr := e.innerExec.Open(ctx)\n\tdefer terror.Call(e.innerExec.Close)\n\tif err != nil {\n\t\treturn err\n\t}\n\te.innerList.Reset()\n\tinnerIter := chunk.NewIterator4Chunk(e.innerChunk)\n\tfor {\n\t\terr := e.innerExec.Next(ctx, chunk.NewRecordBatch(e.innerChunk))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif e.innerChunk.NumRows() == 0 {\n\t\t\treturn nil\n\t\t}\n\n\t\te.innerSelected, err = expression.VectorizedFilter(e.ctx, e.innerFilter, innerIter, e.innerSelected)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor row := innerIter.Begin(); row != innerIter.End(); row = innerIter.Next() {\n\t\t\tif e.innerSelected[row.Idx()] {\n\t\t\t\te.innerList.AppendRow(row)\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// RequestTransfer creates a TokenTransaction of type transfer request\n//func (t *Transactor) RequestTransfer(inTokens []*token.InputId, tokensToTransfer []*token.RecipientTransferShare) (*token.TokenTransaction, error) {", "input": "go language", "output": "func (t *Transactor) RequestTransfer(request *token.TransferRequest) (*token.TokenTransaction, error) {\n\tvar outputs []*token.PlainOutput\n\n\tinputs, tokenType, _, err := t.getInputsFromTokenIds(request.GetTokenIds())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ttt := range request.GetShares() {\n\t\toutputs = append(outputs, &token.PlainOutput{\n\t\t\tOwner:    ttt.Recipient,\n\t\t\tType:     tokenType,\n\t\t\tQuantity: ttt.Quantity,\n\t\t})\n\t}\n\n\t// prepare transfer request\n\ttransaction := &token.TokenTransaction{\n\t\tAction: &token.TokenTransaction_PlainAction{\n\t\t\tPlainAction: &token.PlainTokenAction{\n\t\t\t\tData: &token.PlainTokenAction_PlainTransfer{\n\t\t\t\t\tPlainTransfer: &token.PlainTransfer{\n\t\t\t\t\t\tInputs:  inputs,\n\t\t\t\t\t\tOutputs: outputs,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\treturn transaction, nil\n}"}, {"instruction": "// DecodeFormats takes a list of output format configurations and merges those,\n// in the order given, with the Hugo defaults as the last resort.", "input": "go language", "output": "func DecodeFormats(mediaTypes media.Types, maps ...map[string]interface{}) (Formats, error) {\n\tf := make(Formats, len(DefaultFormats))\n\tcopy(f, DefaultFormats)\n\n\tfor _, m := range maps {\n\t\tfor k, v := range m {\n\t\t\tfound := false\n\t\t\tfor i, vv := range f {\n\t\t\t\tif strings.EqualFold(k, vv.Name) {\n\t\t\t\t\t// Merge it with the existing\n\t\t\t\t\tif err := decode(mediaTypes, v, &f[i]); err != nil {\n\t\t\t\t\t\treturn f, err\n\t\t\t\t\t}\n\t\t\t\t\tfound = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tvar newOutFormat Format\n\t\t\t\tnewOutFormat.Name = k\n\t\t\t\tif err := decode(mediaTypes, v, &newOutFormat); err != nil {\n\t\t\t\t\treturn f, err\n\t\t\t\t}\n\n\t\t\t\t// We need values for these\n\t\t\t\tif newOutFormat.BaseName == \"\" {\n\t\t\t\t\tnewOutFormat.BaseName = \"index\"\n\t\t\t\t}\n\t\t\t\tif newOutFormat.Rel == \"\" {\n\t\t\t\t\tnewOutFormat.Rel = \"alternate\"\n\t\t\t\t}\n\n\t\t\t\tf = append(f, newOutFormat)\n\t\t\t}\n\t\t}\n\t}\n\n\tsort.Sort(f)\n\n\treturn f, nil\n}"}, {"instruction": "// LoadMirrors loads mirrors to config, after removing duplicates.\n// Returns an error if mirrors contains an invalid mirror.", "input": "go language", "output": "func (config *serviceConfig) LoadMirrors(mirrors []string) error {\n\tmMap := map[string]struct{}{}\n\tunique := []string{}\n\n\tfor _, mirror := range mirrors {\n\t\tm, err := ValidateMirror(mirror)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, exist := mMap[m]; !exist {\n\t\t\tmMap[m] = struct{}{}\n\t\t\tunique = append(unique, m)\n\t\t}\n\t}\n\n\tconfig.Mirrors = unique\n\n\t// Configure public registry since mirrors may have changed.\n\tconfig.IndexConfigs[IndexName] = &registrytypes.IndexInfo{\n\t\tName:     IndexName,\n\t\tMirrors:  config.Mirrors,\n\t\tSecure:   true,\n\t\tOfficial: true,\n\t}\n\n\treturn nil\n}"}, {"instruction": "// DeriveStats implement LogicalPlan DeriveStats interface.", "input": "go language", "output": "func (p *baseLogicalPlan) DeriveStats(childStats []*property.StatsInfo) (*property.StatsInfo, error) {\n\tif len(childStats) == 1 {\n\t\tp.stats = childStats[0]\n\t\treturn p.stats, nil\n\t}\n\tif len(childStats) > 1 {\n\t\terr := ErrInternal.GenWithStack(\"LogicalPlans with more than one child should implement their own DeriveStats().\")\n\t\treturn nil, err\n\t}\n\tprofile := &property.StatsInfo{\n\t\tRowCount:    float64(1),\n\t\tCardinality: make([]float64, p.self.Schema().Len()),\n\t}\n\tfor i := range profile.Cardinality {\n\t\tprofile.Cardinality[i] = float64(1)\n\t}\n\tp.stats = profile\n\treturn profile, nil\n}"}, {"instruction": "// Unpack performs the operation hexdata -> Go format", "input": "go language", "output": "func (arguments Arguments) Unpack(v interface{}, data []byte) error {\n\t// make sure the passed value is arguments pointer\n\tif reflect.Ptr != reflect.ValueOf(v).Kind() {\n\t\treturn fmt.Errorf(\"abi: Unpack(non-pointer %T)\", v)\n\t}\n\tmarshalledValues, err := arguments.UnpackValues(data)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif arguments.isTuple() {\n\t\treturn arguments.unpackTuple(v, marshalledValues)\n\t}\n\treturn arguments.unpackAtomic(v, marshalledValues[0])\n}"}, {"instruction": "// Syncing returns false in case the node is currently not syncing with the network. It can be up to date or has not\n// yet received the latest block headers from its pears. In case it is synchronizing:\n// - startingBlock: block number this node started to synchronise from\n// - currentBlock:  block number this node is currently importing\n// - highestBlock:  block number of the highest block header this node has received from peers\n// - pulledStates:  number of state entries processed until now\n// - knownStates:   number of known state entries that still need to be pulled", "input": "go language", "output": "func (s *PublicEthereumAPI) Syncing() (interface{}, error) {\n\tprogress := s.b.Downloader().Progress()\n\n\t// Return not syncing if the synchronisation already completed\n\tif progress.CurrentBlock >= progress.HighestBlock {\n\t\treturn false, nil\n\t}\n\t// Otherwise gather the block sync stats\n\treturn map[string]interface{}{\n\t\t\"startingBlock\": hexutil.Uint64(progress.StartingBlock),\n\t\t\"currentBlock\":  hexutil.Uint64(progress.CurrentBlock),\n\t\t\"highestBlock\":  hexutil.Uint64(progress.HighestBlock),\n\t\t\"pulledStates\":  hexutil.Uint64(progress.PulledStates),\n\t\t\"knownStates\":   hexutil.Uint64(progress.KnownStates),\n\t}, nil\n}"}, {"instruction": "// Cleanup aufs and unmount all mountpoints", "input": "go language", "output": "func (a *Driver) Cleanup() error {\n\tvar dirs []string\n\tif err := filepath.Walk(a.mntPath(), func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !info.IsDir() {\n\t\t\treturn nil\n\t\t}\n\t\tdirs = append(dirs, path)\n\t\treturn nil\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, m := range dirs {\n\t\tif err := a.unmount(m); err != nil {\n\t\t\tlogger.Debugf(\"error unmounting %s: %s\", m, err)\n\t\t}\n\t}\n\treturn mount.RecursiveUnmount(a.root)\n}"}, {"instruction": "// ServerResourcesForGroupVersion returns the supported resources for a group\n// and version.", "input": "go language", "output": "func (c *FakeDiscovery) ServerResourcesForGroupVersion(groupVersion string) (*metav1.APIResourceList, error) {\n\taction := testing.ActionImpl{\n\t\tVerb:     \"get\",\n\t\tResource: schema.GroupVersionResource{Resource: \"resource\"},\n\t}\n\tc.Invokes(action, nil)\n\tfor _, resourceList := range c.Resources {\n\t\tif resourceList.GroupVersion == groupVersion {\n\t\t\treturn resourceList, nil\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"GroupVersion %q not found\", groupVersion)\n}"}, {"instruction": "// UntilWithoutRetry reads items from the watch until each provided condition succeeds, and then returns the last watch\n// encountered. The first condition that returns an error terminates the watch (and the event is also returned).\n// If no event has been received, the returned event will be nil.\n// Conditions are satisfied sequentially so as to provide a useful primitive for higher level composition.\n// Waits until context deadline or until context is canceled.\n//\n// Warning: Unless you have a very specific use case (probably a special Watcher) don't use this function!!!\n// Warning: This will fail e.g. on API timeouts and/or 'too old resource version' error.\n// Warning: You are most probably looking for a function *Until* or *UntilWithSync* below,\n// Warning: solving such issues.\n// TODO: Consider making this function private to prevent misuse when the other occurrences in our codebase are gone.", "input": "go language", "output": "func UntilWithoutRetry(ctx context.Context, watcher watch.Interface, conditions ...ConditionFunc) (*watch.Event, error) {\n\tch := watcher.ResultChan()\n\tdefer watcher.Stop()\n\tvar lastEvent *watch.Event\n\tfor _, condition := range conditions {\n\t\t// check the next condition against the previous event and short circuit waiting for the next watch\n\t\tif lastEvent != nil {\n\t\t\tdone, err := condition(*lastEvent)\n\t\t\tif err != nil {\n\t\t\t\treturn lastEvent, err\n\t\t\t}\n\t\t\tif done {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\tConditionSucceeded:\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase event, ok := <-ch:\n\t\t\t\tif !ok {\n\t\t\t\t\treturn lastEvent, ErrWatchClosed\n\t\t\t\t}\n\t\t\t\tlastEvent = &event\n\n\t\t\t\tdone, err := condition(event)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn lastEvent, err\n\t\t\t\t}\n\t\t\t\tif done {\n\t\t\t\t\tbreak ConditionSucceeded\n\t\t\t\t}\n\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn lastEvent, wait.ErrWaitTimeout\n\t\t\t}\n\t\t}\n\t}\n\treturn lastEvent, nil\n}"}, {"instruction": "// NodeService is used to retrieve a specific service associated with the given\n// node.", "input": "go language", "output": "func (s *Store) NodeService(nodeName string, serviceID string) (uint64, *structs.NodeService, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, \"services\")\n\n\t// Query the service\n\tservice, err := s.getNodeServiceTxn(tx, nodeName, serviceID)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed querying service for node %q: %s\", nodeName, err)\n\t}\n\n\treturn idx, service, nil\n}"}, {"instruction": "// Get returns a read-only copy of the system capabilities.", "input": "go language", "output": "func Get() Capabilities {\n\tcapInstance.lock.Lock()\n\tdefer capInstance.lock.Unlock()\n\t// This check prevents clobbering of capabilities that might've been set via SetForTests\n\tif capInstance.capabilities == nil {\n\t\tInitialize(Capabilities{\n\t\t\tAllowPrivileged: false,\n\t\t\tPrivilegedSources: PrivilegedSources{\n\t\t\t\tHostNetworkSources: []string{},\n\t\t\t\tHostPIDSources:     []string{},\n\t\t\t\tHostIPCSources:     []string{},\n\t\t\t},\n\t\t})\n\t}\n\treturn *capInstance.capabilities\n}"}, {"instruction": "// targetEncodingForTransform returns the appropriate serializer for the input media type", "input": "go language", "output": "func targetEncodingForTransform(scope *RequestScope, mediaType negotiation.MediaTypeOptions, req *http.Request) (schema.GroupVersionKind, runtime.NegotiatedSerializer, bool) {\n\tswitch target := mediaType.Convert; {\n\tcase target == nil:\n\tcase target.Kind == \"PartialObjectMetadata\" && target.GroupVersion() == metav1beta1.SchemeGroupVersion,\n\t\ttarget.Kind == \"PartialObjectMetadataList\" && target.GroupVersion() == metav1beta1.SchemeGroupVersion,\n\t\ttarget.Kind == \"Table\" && target.GroupVersion() == metav1beta1.SchemeGroupVersion:\n\t\treturn *target, metainternalversion.Codecs, true\n\t}\n\treturn scope.Kind, scope.Serializer, false\n}"}, {"instruction": "// setBootstrapNodesV5 creates a list of bootstrap nodes from the command line\n// flags, reverting to pre-configured ones if none have been specified.", "input": "go language", "output": "func setBootstrapNodesV5(ctx *cli.Context, cfg *p2p.Config) {\n\turls := params.DiscoveryV5Bootnodes\n\tswitch {\n\tcase ctx.GlobalIsSet(BootnodesFlag.Name) || ctx.GlobalIsSet(BootnodesV5Flag.Name):\n\t\tif ctx.GlobalIsSet(BootnodesV5Flag.Name) {\n\t\t\turls = strings.Split(ctx.GlobalString(BootnodesV5Flag.Name), \",\")\n\t\t} else {\n\t\t\turls = strings.Split(ctx.GlobalString(BootnodesFlag.Name), \",\")\n\t\t}\n\tcase ctx.GlobalBool(RinkebyFlag.Name):\n\t\turls = params.RinkebyBootnodes\n\tcase ctx.GlobalBool(GoerliFlag.Name):\n\t\turls = params.GoerliBootnodes\n\tcase cfg.BootstrapNodesV5 != nil:\n\t\treturn // already set, don't apply defaults.\n\t}\n\n\tcfg.BootstrapNodesV5 = make([]*discv5.Node, 0, len(urls))\n\tfor _, url := range urls {\n\t\tif url != \"\" {\n\t\t\tnode, err := discv5.ParseNode(url)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"Bootstrap URL invalid\", \"enode\", url, \"err\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcfg.BootstrapNodesV5 = append(cfg.BootstrapNodesV5, node)\n\t\t}\n\t}\n}"}, {"instruction": "// getChaincodeSpec get chaincode spec from the cli cmd pramameters", "input": "go language", "output": "func getChaincodeSpec(cmd *cobra.Command) (*pb.ChaincodeSpec, error) {\n\tspec := &pb.ChaincodeSpec{}\n\tif err := checkChaincodeCmdParams(cmd); err != nil {\n\t\t// unset usage silence because it's a command line usage error\n\t\tcmd.SilenceUsage = false\n\t\treturn spec, err\n\t}\n\n\t// Build the spec\n\tinput := &pb.ChaincodeInput{}\n\tif err := json.Unmarshal([]byte(chaincodeCtorJSON), &input); err != nil {\n\t\treturn spec, errors.Wrap(err, \"chaincode argument error\")\n\t}\n\n\tchaincodeLang = strings.ToUpper(chaincodeLang)\n\tspec = &pb.ChaincodeSpec{\n\t\tType:        pb.ChaincodeSpec_Type(pb.ChaincodeSpec_Type_value[chaincodeLang]),\n\t\tChaincodeId: &pb.ChaincodeID{Path: chaincodePath, Name: chaincodeName, Version: chaincodeVersion},\n\t\tInput:       input,\n\t}\n\treturn spec, nil\n}"}, {"instruction": "// RawReverseScan implements the RawKV interface.\n// Scan the range of [endKey, startKey)\n// It doesn't support Scanning from \"\", because locating the last Region is not yet implemented.", "input": "go language", "output": "func (mvcc *MVCCLevelDB) RawReverseScan(startKey, endKey []byte, limit int) []Pair {\n\tmvcc.mu.Lock()\n\tdefer mvcc.mu.Unlock()\n\n\titer := mvcc.db.NewIterator(&util.Range{\n\t\tLimit: startKey,\n\t}, nil)\n\n\tsuccess := iter.Last()\n\n\tvar pairs []Pair\n\tfor success && len(pairs) < limit {\n\t\tkey := iter.Key()\n\t\tvalue := iter.Value()\n\t\terr := iter.Error()\n\t\tif bytes.Compare(key, endKey) < 0 {\n\t\t\tbreak\n\t\t}\n\t\tpairs = append(pairs, Pair{\n\t\t\tKey:   append([]byte{}, key...),\n\t\t\tValue: append([]byte{}, value...),\n\t\t\tErr:   err,\n\t\t})\n\t\tsuccess = iter.Prev()\n\t}\n\treturn pairs\n}"}, {"instruction": "// populateResourceListV1 takes strings of form <resourceName1>=<value1>,<resourceName1>=<value2>\n// and returns ResourceList.", "input": "go language", "output": "func populateResourceListV1(spec string) (v1.ResourceList, error) {\n\t// empty input gets a nil response to preserve generator test expected behaviors\n\tif spec == \"\" {\n\t\treturn nil, nil\n\t}\n\n\tresult := v1.ResourceList{}\n\tresourceStatements := strings.Split(spec, \",\")\n\tfor _, resourceStatement := range resourceStatements {\n\t\tparts := strings.Split(resourceStatement, \"=\")\n\t\tif len(parts) != 2 {\n\t\t\treturn nil, fmt.Errorf(\"Invalid argument syntax %v, expected <resource>=<value>\", resourceStatement)\n\t\t}\n\t\tresourceName := v1.ResourceName(parts[0])\n\t\tresourceQuantity, err := resource.ParseQuantity(parts[1])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresult[resourceName] = resourceQuantity\n\t}\n\treturn result, nil\n}"}, {"instruction": "// NewEnvelopeTransformer returns a transformer which implements a KEK-DEK based envelope encryption scheme.\n// It uses envelopeService to encrypt and decrypt DEKs. Respective DEKs (in encrypted form) are prepended to\n// the data items they encrypt. A cache (of size cacheSize) is maintained to store the most recently\n// used decrypted DEKs in memory.", "input": "go language", "output": "func NewEnvelopeTransformer(envelopeService Service, cacheSize int, baseTransformerFunc func(cipher.Block) value.Transformer) (value.Transformer, error) {\n\tif cacheSize == 0 {\n\t\tcacheSize = defaultCacheSize\n\t}\n\tcache, err := lru.New(cacheSize)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &envelopeTransformer{\n\t\tenvelopeService:     envelopeService,\n\t\ttransformers:        cache,\n\t\tbaseTransformerFunc: baseTransformerFunc,\n\t}, nil\n}"}, {"instruction": "// GetNextLevel returns the frequency level a next update should be placed at, provided where\n// the last update was and what time it is now.\n// This is the first nonzero bit of the XOR of 'last' and 'now', counting from the highest significant bit\n// but limited to not return a level that is smaller than the last-1", "input": "go language", "output": "func GetNextLevel(last Epoch, now uint64) uint8 {\n\t// First XOR the last epoch base time with the current clock.\n\t// This will set all the common most significant bits to zero.\n\tmix := (last.Base() ^ now)\n\n\t// Then, make sure we stop the below loop before one level below the current, by setting\n\t// that level's bit to 1.\n\t// If the next level is lower than the current one, it must be exactly level-1 and not lower.\n\tmix |= (1 << (last.Level - 1))\n\n\t// if the last update was more than 2^highestLevel seconds ago, choose the highest level\n\tif mix > (maxuint64 >> (64 - HighestLevel - 1)) {\n\t\treturn HighestLevel\n\t}\n\n\t// set up a mask to scan for nonzero bits, starting at the highest level\n\tmask := uint64(1 << (HighestLevel))\n\n\tfor i := uint8(HighestLevel); i > LowestLevel; i-- {\n\t\tif mix&mask != 0 { // if we find a nonzero bit, this is the level the next update should be at.\n\t\t\treturn i\n\t\t}\n\t\tmask = mask >> 1 // move our bit one position to the right\n\t}\n\treturn 0\n}"}, {"instruction": "// FilterABIChanged is a free log retrieval operation binding the contract event 0xaa121bbeef5f32f5961a2a28966e769023910fc9479059ee3495d4c1a696efe3.\n//\n// Solidity: event ABIChanged(node indexed bytes32, contentType indexed uint256)", "input": "go language", "output": "func (_PublicResolver *PublicResolverFilterer) FilterABIChanged(opts *bind.FilterOpts, node [][32]byte, contentType []*big.Int) (*PublicResolverABIChangedIterator, error) {\n\n\tvar nodeRule []interface{}\n\tfor _, nodeItem := range node {\n\t\tnodeRule = append(nodeRule, nodeItem)\n\t}\n\tvar contentTypeRule []interface{}\n\tfor _, contentTypeItem := range contentType {\n\t\tcontentTypeRule = append(contentTypeRule, contentTypeItem)\n\t}\n\n\tlogs, sub, err := _PublicResolver.contract.FilterLogs(opts, \"ABIChanged\", nodeRule, contentTypeRule)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &PublicResolverABIChangedIterator{contract: _PublicResolver.contract, event: \"ABIChanged\", logs: logs, sub: sub}, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *Headers) DeepCopyInto(out *Headers) {\n\t*out = *in\n\tif in.CustomRequestHeaders != nil {\n\t\tin, out := &in.CustomRequestHeaders, &out.CustomRequestHeaders\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.CustomResponseHeaders != nil {\n\t\tin, out := &in.CustomResponseHeaders, &out.CustomResponseHeaders\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\tif in.AllowedHosts != nil {\n\t\tin, out := &in.AllowedHosts, &out.AllowedHosts\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.HostsProxyHeaders != nil {\n\t\tin, out := &in.HostsProxyHeaders, &out.HostsProxyHeaders\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.SSLProxyHeaders != nil {\n\t\tin, out := &in.SSLProxyHeaders, &out.SSLProxyHeaders\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// MakeDataDir retrieves the currently requested data directory, terminating\n// if none (or the empty string) is specified. If the node is starting a testnet,\n// the a subdirectory of the specified datadir will be used.", "input": "go language", "output": "func MakeDataDir(ctx *cli.Context) string {\n\tif path := ctx.GlobalString(DataDirFlag.Name); path != \"\" {\n\t\tif ctx.GlobalBool(TestnetFlag.Name) {\n\t\t\treturn filepath.Join(path, \"testnet\")\n\t\t}\n\t\tif ctx.GlobalBool(RinkebyFlag.Name) {\n\t\t\treturn filepath.Join(path, \"rinkeby\")\n\t\t}\n\t\tif ctx.GlobalBool(GoerliFlag.Name) {\n\t\t\treturn filepath.Join(path, \"goerli\")\n\t\t}\n\t\treturn path\n\t}\n\tFatalf(\"Cannot determine default data directory, please set manually (--datadir)\")\n\treturn \"\"\n}"}, {"instruction": "// This helper turns a provider configs field into a deterministic\n// string value for comparison in tests.", "input": "go language", "output": "func providerConfigsStr(pcs []*ProviderConfig) string {\n\tresult := \"\"\n\n\tns := make([]string, 0, len(pcs))\n\tm := make(map[string]*ProviderConfig)\n\tfor _, n := range pcs {\n\t\tns = append(ns, n.Name)\n\t\tm[n.Name] = n\n\t}\n\tsort.Strings(ns)\n\n\tfor _, n := range ns {\n\t\tpc := m[n]\n\n\t\tresult += fmt.Sprintf(\"%s\\n\", n)\n\n\t\tkeys := make([]string, 0, len(pc.RawConfig.Raw))\n\t\tfor k, _ := range pc.RawConfig.Raw {\n\t\t\tkeys = append(keys, k)\n\t\t}\n\t\tsort.Strings(keys)\n\n\t\tfor _, k := range keys {\n\t\t\tresult += fmt.Sprintf(\"  %s\\n\", k)\n\t\t}\n\n\t\tif len(pc.RawConfig.Variables) > 0 {\n\t\t\tresult += fmt.Sprintf(\"  vars\\n\")\n\t\t\tfor _, rawV := range pc.RawConfig.Variables {\n\t\t\t\tkind := \"unknown\"\n\t\t\t\tstr := rawV.FullKey()\n\n\t\t\t\tswitch rawV.(type) {\n\t\t\t\tcase *ResourceVariable:\n\t\t\t\t\tkind = \"resource\"\n\t\t\t\tcase *UserVariable:\n\t\t\t\t\tkind = \"user\"\n\t\t\t\t}\n\n\t\t\t\tresult += fmt.Sprintf(\"    %s: %s\\n\", kind, str)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn strings.TrimSpace(result)\n}"}, {"instruction": "// newEventRateLimit configures an admission controller that can enforce event rate limits", "input": "go language", "output": "func newEventRateLimit(config *eventratelimitapi.Configuration, clock flowcontrol.Clock) (*Plugin, error) {\n\tlimitEnforcers := make([]*limitEnforcer, 0, len(config.Limits))\n\tfor _, limitConfig := range config.Limits {\n\t\tenforcer, err := newLimitEnforcer(limitConfig, clock)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlimitEnforcers = append(limitEnforcers, enforcer)\n\t}\n\n\teventRateLimitAdmission := &Plugin{\n\t\tHandler:        admission.NewHandler(admission.Create, admission.Update),\n\t\tlimitEnforcers: limitEnforcers,\n\t}\n\n\treturn eventRateLimitAdmission, nil\n}"}, {"instruction": "// Into stores the result into obj, if possible. If obj is nil it is ignored.\n// If the returned object is of type Status and has .Status != StatusSuccess, the\n// additional information in Status will be used to enrich the error.", "input": "go language", "output": "func (r Result) Into(obj runtime.Object) error {\n\tif r.err != nil {\n\t\t// Check whether the result has a Status object in the body and prefer that.\n\t\treturn r.Error()\n\t}\n\tif r.decoder == nil {\n\t\treturn fmt.Errorf(\"serializer for %s doesn't exist\", r.contentType)\n\t}\n\tif len(r.body) == 0 {\n\t\treturn fmt.Errorf(\"0-length response with status code: %d and content type: %s\",\n\t\t\tr.statusCode, r.contentType)\n\t}\n\n\tout, _, err := r.decoder.Decode(r.body, nil, obj)\n\tif err != nil || out == obj {\n\t\treturn err\n\t}\n\t// if a different object is returned, see if it is Status and avoid double decoding\n\t// the object.\n\tswitch t := out.(type) {\n\tcase *metav1.Status:\n\t\t// any status besides StatusSuccess is considered an error.\n\t\tif t.Status != metav1.StatusSuccess {\n\t\t\treturn errors.FromObject(t)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *IndexReaderExecutor) Open(ctx context.Context) error {\n\tvar err error\n\tif e.corColInAccess {\n\t\te.ranges, err = rebuildIndexRanges(e.ctx, e.plans[0].(*plannercore.PhysicalIndexScan), e.idxCols, e.colLens)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tkvRanges, err := distsql.IndexRangesToKVRanges(e.ctx.GetSessionVars().StmtCtx, e.physicalTableID, e.index.ID, e.ranges, e.feedback)\n\tif err != nil {\n\t\te.feedback.Invalidate()\n\t\treturn err\n\t}\n\treturn e.open(ctx, kvRanges)\n}"}, {"instruction": "// UpdateAPIServiceSpec updates the api service's OpenAPI spec. It is thread safe.", "input": "go language", "output": "func (s *specAggregator) UpdateAPIServiceSpec(apiServiceName string, spec *spec.Swagger, etag string) error {\n\ts.rwMutex.Lock()\n\tdefer s.rwMutex.Unlock()\n\n\tspecInfo, existingService := s.openAPISpecs[apiServiceName]\n\tif !existingService {\n\t\treturn fmt.Errorf(\"APIService %q does not exists\", apiServiceName)\n\t}\n\n\t// For APIServices (non-local) specs, only merge their /apis/ prefixed endpoint as it is the only paths\n\t// proxy handler delegates.\n\tif specInfo.apiService.Spec.Service != nil {\n\t\tspec = aggregator.FilterSpecByPathsWithoutSideEffects(spec, []string{\"/apis/\"})\n\t}\n\n\treturn s.tryUpdatingServiceSpecs(&openAPISpecInfo{\n\t\tapiService: specInfo.apiService,\n\t\tspec:       spec,\n\t\thandler:    specInfo.handler,\n\t\tetag:       etag,\n\t})\n}"}, {"instruction": "// EqualDatums compare if a and b contains the same datum values.", "input": "go language", "output": "func EqualDatums(sc *stmtctx.StatementContext, a []Datum, b []Datum) (bool, error) {\n\tif len(a) != len(b) {\n\t\treturn false, nil\n\t}\n\tif a == nil && b == nil {\n\t\treturn true, nil\n\t}\n\tif a == nil || b == nil {\n\t\treturn false, nil\n\t}\n\tfor i, ai := range a {\n\t\tv, err := ai.CompareDatum(sc, &b[i])\n\t\tif err != nil {\n\t\t\treturn false, errors.Trace(err)\n\t\t}\n\t\tif v != 0 {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}"}, {"instruction": "// interpolationFuncSlice returns a portion of the input list between from, inclusive and to, exclusive.", "input": "go language", "output": "func interpolationFuncSlice() ast.Function {\n\treturn ast.Function{\n\t\tArgTypes: []ast.Type{\n\t\t\tast.TypeList, // inputList\n\t\t\tast.TypeInt,  // from\n\t\t\tast.TypeInt,  // to\n\t\t},\n\t\tReturnType: ast.TypeList,\n\t\tVariadic:   false,\n\t\tCallback: func(args []interface{}) (interface{}, error) {\n\t\t\tinputList := args[0].([]ast.Variable)\n\t\t\tfrom := args[1].(int)\n\t\t\tto := args[2].(int)\n\n\t\t\tif from < 0 {\n\t\t\t\treturn nil, fmt.Errorf(\"from index must be >= 0\")\n\t\t\t}\n\t\t\tif to > len(inputList) {\n\t\t\t\treturn nil, fmt.Errorf(\"to index must be <= length of the input list\")\n\t\t\t}\n\t\t\tif from > to {\n\t\t\t\treturn nil, fmt.Errorf(\"from index must be <= to index\")\n\t\t\t}\n\n\t\t\tvar outputList []ast.Variable\n\t\t\tfor i, val := range inputList {\n\t\t\t\tif i >= from && i < to {\n\t\t\t\t\toutputList = append(outputList, val)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn outputList, nil\n\t\t},\n\t}\n}"}, {"instruction": "// HandleDates updates all the dates given the current configuration and the\n// supplied front matter params. Note that this requires all lower-case keys\n// in the params map.", "input": "go language", "output": "func (f FrontMatterHandler) HandleDates(d *FrontMatterDescriptor) error {\n\tif d.Dates == nil {\n\t\tpanic(\"missing dates\")\n\t}\n\n\tif f.dateHandler == nil {\n\t\tpanic(\"missing date handler\")\n\t}\n\n\tif _, err := f.dateHandler(d); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := f.lastModHandler(d); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := f.publishDateHandler(d); err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := f.expiryDateHandler(d); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// CreateDirIfMissing creates a dir for dirPath if not already exists. If the dir is empty it returns true", "input": "go language", "output": "func CreateDirIfMissing(dirPath string) (bool, error) {\n\t// if dirPath does not end with a path separator, it leaves out the last segment while creating directories\n\tif !strings.HasSuffix(dirPath, \"/\") {\n\t\tdirPath = dirPath + \"/\"\n\t}\n\tlogger.Debugf(\"CreateDirIfMissing [%s]\", dirPath)\n\tlogDirStatus(\"Before creating dir\", dirPath)\n\terr := os.MkdirAll(path.Dir(dirPath), 0755)\n\tif err != nil {\n\t\tlogger.Debugf(\"Error creating dir [%s]\", dirPath)\n\t\treturn false, errors.Wrapf(err, \"error creating dir [%s]\", dirPath)\n\t}\n\tlogDirStatus(\"After creating dir\", dirPath)\n\treturn DirEmpty(dirPath)\n}"}, {"instruction": "// HugePageLimits converts the API representation to a map\n// from huge page size (in bytes) to huge page limit (in bytes).", "input": "go language", "output": "func HugePageLimits(resourceList v1.ResourceList) map[int64]int64 {\n\thugePageLimits := map[int64]int64{}\n\tfor k, v := range resourceList {\n\t\tif v1helper.IsHugePageResourceName(k) {\n\t\t\tpageSize, _ := v1helper.HugePageSizeFromResourceName(k)\n\t\t\tif value, exists := hugePageLimits[pageSize.Value()]; exists {\n\t\t\t\thugePageLimits[pageSize.Value()] = value + v.Value()\n\t\t\t} else {\n\t\t\t\thugePageLimits[pageSize.Value()] = v.Value()\n\t\t\t}\n\t\t}\n\t}\n\treturn hugePageLimits\n}"}, {"instruction": "// NewFilteredCustomResourceDefinitionInformer constructs a new informer for CustomResourceDefinition type.\n// Always prefer using an informer factory to get a shared informer instead of getting an independent\n// one. This reduces memory footprint and number of connections to the server.", "input": "go language", "output": "func NewFilteredCustomResourceDefinitionInformer(client internalclientset.Interface, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\n\treturn cache.NewSharedIndexInformer(\n\t\t&cache.ListWatch{\n\t\t\tListFunc: func(options v1.ListOptions) (runtime.Object, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.Apiextensions().CustomResourceDefinitions().List(options)\n\t\t\t},\n\t\t\tWatchFunc: func(options v1.ListOptions) (watch.Interface, error) {\n\t\t\t\tif tweakListOptions != nil {\n\t\t\t\t\ttweakListOptions(&options)\n\t\t\t\t}\n\t\t\t\treturn client.Apiextensions().CustomResourceDefinitions().Watch(options)\n\t\t\t},\n\t\t},\n\t\t&apiextensions.CustomResourceDefinition{},\n\t\tresyncPeriod,\n\t\tindexers,\n\t)\n}"}, {"instruction": "// WeakDecode behaves in the same way as mapstructure.WeakDecode but has a\n// DecodeHook which defeats the backward compatibility mode of mapstructure\n// which WeakDecodes []interface{}{} into an empty map[string]interface{}. This\n// allows us to use WeakDecode (desirable), but not fail on empty lists.", "input": "go language", "output": "func WeakDecode(m interface{}, rawVal interface{}) error {\n\tconfig := &mapstructure.DecoderConfig{\n\t\tDecodeHook: func(source reflect.Type, target reflect.Type, val interface{}) (interface{}, error) {\n\t\t\tsliceType := reflect.TypeOf(hilMapstructureDecodeHookEmptySlice)\n\t\t\tstringSliceType := reflect.TypeOf(hilMapstructureDecodeHookStringSlice)\n\t\t\tmapType := reflect.TypeOf(hilMapstructureDecodeHookEmptyMap)\n\n\t\t\tif (source == sliceType || source == stringSliceType) && target == mapType {\n\t\t\t\treturn nil, fmt.Errorf(\"Cannot convert a []interface{} into a map[string]interface{}\")\n\t\t\t}\n\n\t\t\treturn val, nil\n\t\t},\n\t\tWeaklyTypedInput: true,\n\t\tResult:           rawVal,\n\t}\n\n\tdecoder, err := mapstructure.NewDecoder(config)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn decoder.Decode(m)\n}"}, {"instruction": "// newTikvHandlerTool checks and prepares for tikv handler.\n// It would panic when any error happens.", "input": "go language", "output": "func (s *Server) newTikvHandlerTool() *tikvHandlerTool {\n\tvar tikvStore tikv.Storage\n\tstore, ok := s.driver.(*TiDBDriver)\n\tif !ok {\n\t\tpanic(\"Invalid KvStore with illegal driver\")\n\t}\n\n\tif tikvStore, ok = store.store.(tikv.Storage); !ok {\n\t\tpanic(\"Invalid KvStore with illegal store\")\n\t}\n\n\tregionCache := tikvStore.GetRegionCache()\n\n\treturn &tikvHandlerTool{\n\t\thelper.Helper{\n\t\t\tRegionCache: regionCache,\n\t\t\tStore:       tikvStore,\n\t\t},\n\t}\n}"}, {"instruction": "// enqueueTx inserts a new transaction into the non-executable transaction queue.\n//\n// Note, this method assumes the pool lock is held!", "input": "go language", "output": "func (pool *TxPool) enqueueTx(hash common.Hash, tx *types.Transaction) (bool, error) {\n\t// Try to insert the transaction into the future queue\n\tfrom, _ := types.Sender(pool.signer, tx) // already validated\n\tif pool.queue[from] == nil {\n\t\tpool.queue[from] = newTxList(false)\n\t}\n\tinserted, old := pool.queue[from].Add(tx, pool.config.PriceBump)\n\tif !inserted {\n\t\t// An older transaction was better, discard this\n\t\tqueuedDiscardCounter.Inc(1)\n\t\treturn false, ErrReplaceUnderpriced\n\t}\n\t// Discard any previous transaction and mark this\n\tif old != nil {\n\t\tpool.all.Remove(old.Hash())\n\t\tpool.priced.Removed()\n\t\tqueuedReplaceCounter.Inc(1)\n\t}\n\tif pool.all.Get(hash) == nil {\n\t\tpool.all.Add(tx)\n\t\tpool.priced.Put(tx)\n\t}\n\treturn old != nil, nil\n}"}, {"instruction": "// PullImage is a test-spy implementation of Interface.PullImage.\n// It adds an entry \"pull\" to the internal method call record.", "input": "go language", "output": "func (f *FakeDockerClient) PullImage(image string, auth dockertypes.AuthConfig, opts dockertypes.ImagePullOptions) error {\n\tf.Lock()\n\tdefer f.Unlock()\n\tf.appendCalled(CalledDetail{name: \"pull\"})\n\terr := f.popError(\"pull\")\n\tif err == nil {\n\t\tif !f.isAuthorizedForImage(image, auth) {\n\t\t\treturn ImageNotFoundError{ID: image}\n\t\t}\n\n\t\tauthJson, _ := json.Marshal(auth)\n\t\tinspect := createImageInspectFromRef(image)\n\t\tf.ImageInspects[image] = inspect\n\t\tf.appendPulled(fmt.Sprintf(\"%s using %s\", image, string(authJson)))\n\t\tf.Images = append(f.Images, *createImageFromImageInspect(*inspect))\n\t\tf.ImagesPulled = append(f.ImagesPulled, image)\n\t}\n\treturn err\n}"}, {"instruction": "// RequestHeadersByHash implements downloader.Peer, returning a batch of headers\n// defined by the origin hash and the associated query parameters.", "input": "go language", "output": "func (p *FakePeer) RequestHeadersByHash(hash common.Hash, amount int, skip int, reverse bool) error {\n\tvar (\n\t\theaders []*types.Header\n\t\tunknown bool\n\t)\n\tfor !unknown && len(headers) < amount {\n\t\torigin := p.hc.GetHeaderByHash(hash)\n\t\tif origin == nil {\n\t\t\tbreak\n\t\t}\n\t\tnumber := origin.Number.Uint64()\n\t\theaders = append(headers, origin)\n\t\tif reverse {\n\t\t\tfor i := 0; i <= skip; i++ {\n\t\t\t\tif header := p.hc.GetHeader(hash, number); header != nil {\n\t\t\t\t\thash = header.ParentHash\n\t\t\t\t\tnumber--\n\t\t\t\t} else {\n\t\t\t\t\tunknown = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tvar (\n\t\t\t\tcurrent = origin.Number.Uint64()\n\t\t\t\tnext    = current + uint64(skip) + 1\n\t\t\t)\n\t\t\tif header := p.hc.GetHeaderByNumber(next); header != nil {\n\t\t\t\tif p.hc.GetBlockHashesFromHash(header.Hash(), uint64(skip+1))[skip] == hash {\n\t\t\t\t\thash = header.Hash()\n\t\t\t\t} else {\n\t\t\t\t\tunknown = true\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tunknown = true\n\t\t\t}\n\t\t}\n\t}\n\tp.dl.DeliverHeaders(p.id, headers)\n\treturn nil\n}"}, {"instruction": "// Init takes two arguments, a string and int. These are stored in the key/value pair in the state", "input": "go language", "output": "func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response {\n\tvar event string // Indicates whether event has happened. Initially 0\n\tvar eventVal int // State of event\n\tvar err error\n\t_, args := stub.GetFunctionAndParameters()\n\tif len(args) != 2 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 2\")\n\t}\n\n\t// Initialize the chaincode\n\tevent = args[0]\n\teventVal, err = strconv.Atoi(args[1])\n\tif err != nil {\n\t\treturn shim.Error(\"Expecting integer value for event status\")\n\t}\n\tfmt.Printf(\"eventVal = %d\\n\", eventVal)\n\n\terr = stub.PutState(event, []byte(strconv.Itoa(eventVal)))\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\n\treturn shim.Success(nil)\n}"}, {"instruction": "// CreateProposalResponseFailure creates a proposal response for cases where\n// endorsement proposal fails either due to a endorsement failure or a\n// chaincode failure (chaincode response status >= shim.ERRORTHRESHOLD)", "input": "go language", "output": "func CreateProposalResponseFailure(hdrbytes []byte, payl []byte, response *peer.Response, results []byte, events []byte, ccid *peer.ChaincodeID, visibility []byte) (*peer.ProposalResponse, error) {\n\thdr, err := GetHeader(hdrbytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// obtain the proposal hash given proposal header, payload and the requested visibility\n\tpHashBytes, err := GetProposalHash1(hdr, payl, visibility)\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, \"error computing proposal hash\")\n\t}\n\n\t// get the bytes of the proposal response payload\n\tprpBytes, err := GetBytesProposalResponsePayload(pHashBytes, response, results, events, ccid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresp := &peer.ProposalResponse{\n\t\t// Timestamp: TODO!\n\t\tPayload:  prpBytes,\n\t\tResponse: response,\n\t}\n\n\treturn resp, nil\n}"}, {"instruction": "// MockPumpsClient creates a PumpsClient, used for test.", "input": "go language", "output": "func MockPumpsClient(client binlog.PumpClient) *pumpcli.PumpsClient {\n\tnodeID := \"pump-1\"\n\tpump := &pumpcli.PumpStatus{\n\t\tStatus: node.Status{\n\t\t\tNodeID: nodeID,\n\t\t\tState:  node.Online,\n\t\t},\n\t\tClient: client,\n\t}\n\n\tpumpInfos := &pumpcli.PumpInfos{\n\t\tPumps:            make(map[string]*pumpcli.PumpStatus),\n\t\tAvaliablePumps:   make(map[string]*pumpcli.PumpStatus),\n\t\tUnAvaliablePumps: make(map[string]*pumpcli.PumpStatus),\n\t}\n\tpumpInfos.Pumps[nodeID] = pump\n\tpumpInfos.AvaliablePumps[nodeID] = pump\n\n\tpCli := &pumpcli.PumpsClient{\n\t\tClusterID:          1,\n\t\tPumps:              pumpInfos,\n\t\tSelector:           pumpcli.NewSelector(pumpcli.Range),\n\t\tBinlogWriteTimeout: time.Second,\n\t}\n\tpCli.Selector.SetPumps([]*pumpcli.PumpStatus{pump})\n\n\treturn pCli\n}"}, {"instruction": "// ResourceList returns a resource list of this resource.", "input": "go language", "output": "func (r *Resource) ResourceList() v1.ResourceList {\n\tresult := v1.ResourceList{\n\t\tv1.ResourceCPU:              *resource.NewMilliQuantity(r.MilliCPU, resource.DecimalSI),\n\t\tv1.ResourceMemory:           *resource.NewQuantity(r.Memory, resource.BinarySI),\n\t\tv1.ResourcePods:             *resource.NewQuantity(int64(r.AllowedPodNumber), resource.BinarySI),\n\t\tv1.ResourceEphemeralStorage: *resource.NewQuantity(r.EphemeralStorage, resource.BinarySI),\n\t}\n\tfor rName, rQuant := range r.ScalarResources {\n\t\tif v1helper.IsHugePageResourceName(rName) {\n\t\t\tresult[rName] = *resource.NewQuantity(rQuant, resource.BinarySI)\n\t\t} else {\n\t\t\tresult[rName] = *resource.NewQuantity(rQuant, resource.DecimalSI)\n\t\t}\n\t}\n\treturn result\n}"}, {"instruction": "// ctr mutex must be held when calling this function.", "input": "go language", "output": "func (c *client) terminateContainer(ctr *container) error {\n\tconst terminateTimeout = time.Minute * 5\n\tctr.terminateInvoked = true\n\terr := ctr.hcsContainer.Terminate()\n\n\tif hcsshim.IsPending(err) {\n\t\terr = ctr.hcsContainer.WaitTimeout(terminateTimeout)\n\t} else if hcsshim.IsAlreadyStopped(err) {\n\t\terr = nil\n\t}\n\n\tif err != nil {\n\t\tc.logger.WithError(err).WithField(\"container\", ctr.id).\n\t\t\tDebug(\"failed to terminate container\")\n\t\treturn err\n\t}\n\n\treturn nil\n}"}, {"instruction": "// UnmarshalJSON implements the json.Unmarshaler interface by decoding the json\n// string values into the config fields", "input": "go language", "output": "func (n *NodeConfig) UnmarshalJSON(data []byte) error {\n\tvar confJSON nodeConfigJSON\n\tif err := json.Unmarshal(data, &confJSON); err != nil {\n\t\treturn err\n\t}\n\n\tif confJSON.ID != \"\" {\n\t\tif err := n.ID.UnmarshalText([]byte(confJSON.ID)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif confJSON.PrivateKey != \"\" {\n\t\tkey, err := hex.DecodeString(confJSON.PrivateKey)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tprivKey, err := crypto.ToECDSA(key)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tn.PrivateKey = privKey\n\t}\n\n\tn.Name = confJSON.Name\n\tn.Services = confJSON.Services\n\tn.Port = confJSON.Port\n\tn.EnableMsgEvents = confJSON.EnableMsgEvents\n\n\treturn nil\n}"}, {"instruction": "// signpackageCmd returns the cobra command for signing a package", "input": "go language", "output": "func signpackageCmd(cf *ChaincodeCmdFactory) *cobra.Command {\n\tspCmd := &cobra.Command{\n\t\tUse:       \"signpackage\",\n\t\tShort:     \"Sign the specified chaincode package\",\n\t\tLong:      \"Sign the specified chaincode package\",\n\t\tValidArgs: []string{\"2\"},\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tif len(args) < 2 {\n\t\t\t\treturn fmt.Errorf(\"peer chaincode signpackage <inputpackage> <outputpackage>\")\n\t\t\t}\n\t\t\treturn signpackage(cmd, args[0], args[1], cf)\n\t\t},\n\t}\n\n\treturn spCmd\n}"}, {"instruction": "// When a pod is deleted, enqueue the services the pod used to be a member of.\n// obj could be an *v1.Pod, or a DeletionFinalStateUnknown marker item.", "input": "go language", "output": "func (e *EndpointController) deletePod(obj interface{}) {\n\tif _, ok := obj.(*v1.Pod); ok {\n\t\t// Enqueue all the services that the pod used to be a member\n\t\t// of. This happens to be exactly the same thing we do when a\n\t\t// pod is added.\n\t\te.addPod(obj)\n\t\treturn\n\t}\n\t// If we reached here it means the pod was deleted but its final state is unrecorded.\n\ttombstone, ok := obj.(cache.DeletedFinalStateUnknown)\n\tif !ok {\n\t\tutilruntime.HandleError(fmt.Errorf(\"Couldn't get object from tombstone %#v\", obj))\n\t\treturn\n\t}\n\tpod, ok := tombstone.Obj.(*v1.Pod)\n\tif !ok {\n\t\tutilruntime.HandleError(fmt.Errorf(\"Tombstone contained object that is not a Pod: %#v\", obj))\n\t\treturn\n\t}\n\tklog.V(4).Infof(\"Enqueuing services of deleted pod %s/%s having final state unrecorded\", pod.Namespace, pod.Name)\n\te.addPod(pod)\n}"}, {"instruction": "// getKubeletContainers lists containers managed by kubelet.\n// The boolean parameter specifies whether returns all containers including\n// those already exited and dead containers (used for garbage collection).", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) getKubeletContainers(allContainers bool) ([]*runtimeapi.Container, error) {\n\tfilter := &runtimeapi.ContainerFilter{}\n\tif !allContainers {\n\t\tfilter.State = &runtimeapi.ContainerStateValue{\n\t\t\tState: runtimeapi.ContainerState_CONTAINER_RUNNING,\n\t\t}\n\t}\n\n\tcontainers, err := m.runtimeService.ListContainers(filter)\n\tif err != nil {\n\t\tklog.Errorf(\"getKubeletContainers failed: %v\", err)\n\t\treturn nil, err\n\t}\n\n\treturn containers, nil\n}"}, {"instruction": "// NewImageManager instantiates a new ImageManager object.", "input": "go language", "output": "func NewImageManager(recorder record.EventRecorder, imageService kubecontainer.ImageService, imageBackOff *flowcontrol.Backoff, serialized bool, qps float32, burst int) ImageManager {\n\timageService = throttleImagePulling(imageService, qps, burst)\n\n\tvar puller imagePuller\n\tif serialized {\n\t\tpuller = newSerialImagePuller(imageService)\n\t} else {\n\t\tpuller = newParallelImagePuller(imageService)\n\t}\n\treturn &imageManager{\n\t\trecorder:     recorder,\n\t\timageService: imageService,\n\t\tbackOff:      imageBackOff,\n\t\tpuller:       puller,\n\t}\n}"}, {"instruction": "// oldPodsRunning returns whether there are old pods running or any of the old ReplicaSets thinks that it runs pods.", "input": "go language", "output": "func oldPodsRunning(newRS *apps.ReplicaSet, oldRSs []*apps.ReplicaSet, podMap map[types.UID]*v1.PodList) bool {\n\tif oldPods := util.GetActualReplicaCountForReplicaSets(oldRSs); oldPods > 0 {\n\t\treturn true\n\t}\n\tfor rsUID, podList := range podMap {\n\t\t// If the pods belong to the new ReplicaSet, ignore.\n\t\tif newRS != nil && newRS.UID == rsUID {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, pod := range podList.Items {\n\t\t\tswitch pod.Status.Phase {\n\t\t\tcase v1.PodFailed, v1.PodSucceeded:\n\t\t\t\t// Don't count pods in terminal state.\n\t\t\t\tcontinue\n\t\t\tcase v1.PodUnknown:\n\t\t\t\t// This happens in situation like when the node is temporarily disconnected from the cluster.\n\t\t\t\t// If we can't be sure that the pod is not running, we have to count it.\n\t\t\t\treturn true\n\t\t\tdefault:\n\t\t\t\t// Pod is not in terminal phase.\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}"}, {"instruction": "// setNextValue sets the next value for the given datum. For types like float,\n// we do not set because it is not discrete and does not matter too much when estimating the scalar info.", "input": "go language", "output": "func setNextValue(d *types.Datum) {\n\tswitch d.Kind() {\n\tcase types.KindBytes, types.KindString:\n\t\td.SetBytes(kv.Key(d.GetBytes()).PrefixNext())\n\tcase types.KindInt64:\n\t\td.SetInt64(d.GetInt64() + 1)\n\tcase types.KindUint64:\n\t\td.SetUint64(d.GetUint64() + 1)\n\tcase types.KindMysqlDuration:\n\t\tduration := d.GetMysqlDuration()\n\t\tduration.Duration = duration.Duration + 1\n\t\td.SetMysqlDuration(duration)\n\tcase types.KindMysqlTime:\n\t\tt := d.GetMysqlTime()\n\t\tsc := &stmtctx.StatementContext{TimeZone: types.BoundTimezone}\n\t\tif _, err := t.Add(sc, types.Duration{Duration: 1, Fsp: 0}); err != nil {\n\t\t\tlog.Error(errors.ErrorStack(err))\n\t\t}\n\t\td.SetMysqlTime(t)\n\t}\n}"}, {"instruction": "// DataForAnalyzeStatus gets all the analyze jobs.", "input": "go language", "output": "func DataForAnalyzeStatus() (rows [][]types.Datum) {\n\tfor _, job := range statistics.GetAllAnalyzeJobs() {\n\t\tjob.Lock()\n\t\tvar startTime interface{}\n\t\tif job.StartTime.IsZero() {\n\t\t\tstartTime = nil\n\t\t} else {\n\t\t\tstartTime = types.Time{Time: types.FromGoTime(job.StartTime), Type: mysql.TypeDatetime}\n\t\t}\n\t\trows = append(rows, types.MakeDatums(\n\t\t\tjob.DBName,        // TABLE_SCHEMA\n\t\t\tjob.TableName,     // TABLE_NAME\n\t\t\tjob.PartitionName, // PARTITION_NAME\n\t\t\tjob.JobInfo,       // JOB_INFO\n\t\t\tjob.RowCount,      // ROW_COUNT\n\t\t\tstartTime,         // START_TIME\n\t\t\tjob.State,         // STATE\n\t\t))\n\t\tjob.Unlock()\n\t}\n\treturn\n}"}, {"instruction": "// DecodeIntValues is called when the current Feedback stores encoded int values.", "input": "go language", "output": "func (q *QueryFeedback) DecodeIntValues() *QueryFeedback {\n\tnq := &QueryFeedback{}\n\tnq.Feedback = make([]Feedback, 0, len(q.Feedback))\n\tfor _, fb := range q.Feedback {\n\t\t_, lowInt, err := codec.DecodeInt(fb.Lower.GetBytes())\n\t\tif err != nil {\n\t\t\tlogutil.Logger(context.Background()).Debug(\"decode feedback lower bound value to integer failed\", zap.Binary(\"value\", fb.Lower.GetBytes()), zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\t_, highInt, err := codec.DecodeInt(fb.Upper.GetBytes())\n\t\tif err != nil {\n\t\t\tlogutil.Logger(context.Background()).Debug(\"decode feedback upper bound value to integer failed\", zap.Binary(\"value\", fb.Upper.GetBytes()), zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tlow, high := types.NewIntDatum(lowInt), types.NewIntDatum(highInt)\n\t\tnq.Feedback = append(nq.Feedback, Feedback{Lower: &low, Upper: &high, Count: fb.Count})\n\t}\n\treturn nq\n}"}, {"instruction": "// NewInbox creates an Inbox. An Inboxes is not persisted, the cumulative sum is updated\n// from blockchain when first cheque is received.", "input": "go language", "output": "func NewInbox(prvKey *ecdsa.PrivateKey, contractAddr, beneficiary common.Address, signer *ecdsa.PublicKey, abigen bind.ContractBackend) (*Inbox, error) {\n\tif signer == nil {\n\t\treturn nil, fmt.Errorf(\"signer is null\")\n\t}\n\tchbook, err := contract.NewChequebook(contractAddr, abigen)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttransactOpts := bind.NewKeyedTransactor(prvKey)\n\ttransactOpts.GasLimit = gasToCash\n\tsession := &contract.ChequebookSession{\n\t\tContract:     chbook,\n\t\tTransactOpts: *transactOpts,\n\t}\n\tsender := transactOpts.From\n\n\tinbox := &Inbox{\n\t\tcontract:    contractAddr,\n\t\tbeneficiary: beneficiary,\n\t\tsender:      sender,\n\t\tsigner:      signer,\n\t\tsession:     session,\n\t\tcashed:      new(big.Int).Set(common.Big0),\n\t\tlog:         log.New(\"contract\", contractAddr),\n\t}\n\tinbox.log.Trace(\"New chequebook inbox initialized\", \"beneficiary\", inbox.beneficiary, \"signer\", hexutil.Bytes(crypto.FromECDSAPub(signer)))\n\treturn inbox, nil\n}"}, {"instruction": "// worker processes the queue of namespace objects.\n// Each namespace can be in the queue at most once.\n// The system ensures that no two workers can process\n// the same namespace at the same time.", "input": "go language", "output": "func (nm *NamespaceController) worker() {\n\tworkFunc := func() bool {\n\t\tkey, quit := nm.queue.Get()\n\t\tif quit {\n\t\t\treturn true\n\t\t}\n\t\tdefer nm.queue.Done(key)\n\n\t\terr := nm.syncNamespaceFromKey(key.(string))\n\t\tif err == nil {\n\t\t\t// no error, forget this entry and return\n\t\t\tnm.queue.Forget(key)\n\t\t\treturn false\n\t\t}\n\n\t\tif estimate, ok := err.(*deletion.ResourcesRemainingError); ok {\n\t\t\tt := estimate.Estimate/2 + 1\n\t\t\tklog.V(4).Infof(\"Content remaining in namespace %s, waiting %d seconds\", key, t)\n\t\t\tnm.queue.AddAfter(key, time.Duration(t)*time.Second)\n\t\t} else {\n\t\t\t// rather than wait for a full resync, re-add the namespace to the queue to be processed\n\t\t\tnm.queue.AddRateLimited(key)\n\t\t\tutilruntime.HandleError(err)\n\t\t}\n\t\treturn false\n\t}\n\n\tfor {\n\t\tquit := workFunc()\n\n\t\tif quit {\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// ValidateNetworking validates networking configuration", "input": "go language", "output": "func ValidateNetworking(c *kubeadm.Networking, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tallErrs = append(allErrs, apivalidation.ValidateDNS1123Subdomain(c.DNSDomain, field.NewPath(\"dnsDomain\"))...)\n\tallErrs = append(allErrs, ValidateIPNetFromString(c.ServiceSubnet, constants.MinimumAddressesInServiceSubnet, field.NewPath(\"serviceSubnet\"))...)\n\tif len(c.PodSubnet) != 0 {\n\t\tallErrs = append(allErrs, ValidateIPNetFromString(c.PodSubnet, constants.MinimumAddressesInServiceSubnet, field.NewPath(\"podSubnet\"))...)\n\t}\n\treturn allErrs\n}"}, {"instruction": "// HandleChain creates/returns a reference to a consensus.Chain object for the\n// given set of support resources. Implements the consensus.Consenter\n// interface. Called by consensus.newChainSupport(), which is itself called by\n// multichannel.NewManagerImpl() when ranging over the ledgerFactory's\n// existingChains.", "input": "go language", "output": "func (consenter *consenterImpl) HandleChain(support consensus.ConsenterSupport, metadata *cb.Metadata) (consensus.Chain, error) {\n\tlastOffsetPersisted, lastOriginalOffsetProcessed, lastResubmittedConfigOffset := getOffsets(metadata.Value, support.ChainID())\n\tch, err := newChain(consenter, support, lastOffsetPersisted, lastOriginalOffsetProcessed, lastResubmittedConfigOffset)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tconsenter.healthChecker.RegisterChecker(ch.channel.String(), ch)\n\treturn ch, nil\n}"}, {"instruction": "// NewXForwarded creates a new XForwarded.", "input": "go language", "output": "func NewXForwarded(insecure bool, trustedIps []string, next http.Handler) (*XForwarded, error) {\n\tvar ipChecker *ip.Checker\n\tif len(trustedIps) > 0 {\n\t\tvar err error\n\t\tipChecker, err = ip.NewChecker(trustedIps)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\thostname = \"localhost\"\n\t}\n\n\treturn &XForwarded{\n\t\tinsecure:   insecure,\n\t\ttrustedIps: trustedIps,\n\t\tipChecker:  ipChecker,\n\t\tnext:       next,\n\t\thostname:   hostname,\n\t}, nil\n}"}, {"instruction": "// FilteredBy filters by the given predicate. Empty APIResourceLists are dropped.", "input": "go language", "output": "func FilteredBy(pred ResourcePredicate, rls []*metav1.APIResourceList) []*metav1.APIResourceList {\n\tresult := []*metav1.APIResourceList{}\n\tfor _, rl := range rls {\n\t\tfiltered := *rl\n\t\tfiltered.APIResources = nil\n\t\tfor i := range rl.APIResources {\n\t\t\tif pred.Match(rl.GroupVersion, &rl.APIResources[i]) {\n\t\t\t\tfiltered.APIResources = append(filtered.APIResources, rl.APIResources[i])\n\t\t\t}\n\t\t}\n\t\tif filtered.APIResources != nil {\n\t\t\tresult = append(result, &filtered)\n\t\t}\n\t}\n\treturn result\n}"}, {"instruction": "// estimateGracefulTerminationForPods determines the graceful termination period for pods in the namespace", "input": "go language", "output": "func (d *namespacedResourcesDeleter) estimateGracefulTerminationForPods(ns string) (int64, error) {\n\tklog.V(5).Infof(\"namespace controller - estimateGracefulTerminationForPods - namespace %s\", ns)\n\testimate := int64(0)\n\tpodsGetter := d.podsGetter\n\tif podsGetter == nil || reflect.ValueOf(podsGetter).IsNil() {\n\t\treturn estimate, fmt.Errorf(\"unexpected: podsGetter is nil. Cannot estimate grace period seconds for pods\")\n\t}\n\titems, err := podsGetter.Pods(ns).List(metav1.ListOptions{})\n\tif err != nil {\n\t\treturn estimate, err\n\t}\n\tfor i := range items.Items {\n\t\tpod := items.Items[i]\n\t\t// filter out terminal pods\n\t\tphase := pod.Status.Phase\n\t\tif v1.PodSucceeded == phase || v1.PodFailed == phase {\n\t\t\tcontinue\n\t\t}\n\t\tif pod.Spec.TerminationGracePeriodSeconds != nil {\n\t\t\tgrace := *pod.Spec.TerminationGracePeriodSeconds\n\t\t\tif grace > estimate {\n\t\t\t\testimate = grace\n\t\t\t}\n\t\t}\n\t}\n\treturn estimate, nil\n}"}, {"instruction": "// New initialises a ReleaseHandler.", "input": "go language", "output": "func New(version string, skipPublish, try bool) *ReleaseHandler {\n\t// When triggered from CI release branch\n\tversion = strings.TrimPrefix(version, \"release-\")\n\tversion = strings.TrimPrefix(version, \"v\")\n\trh := &ReleaseHandler{cliVersion: version, skipPublish: skipPublish, try: try}\n\n\tif try {\n\t\trh.git = func(args ...string) (string, error) {\n\t\t\tfmt.Println(\"git\", strings.Join(args, \" \"))\n\t\t\treturn \"\", nil\n\t\t}\n\t} else {\n\t\trh.git = git\n\t}\n\n\treturn rh\n}"}, {"instruction": "// CopyMatchingTag copies fields tagged tag:\"value\" from \"from\" struct onto \"to\" struct.", "input": "go language", "output": "func CopyMatchingTag(from interface{}, to interface{}, tag string, shouldCopy func(value string) bool) {\n\tfromStruct := reflect.ValueOf(from).Elem()\n\tfromType := fromStruct.Type()\n\n\ttoStruct := reflect.ValueOf(to).Elem()\n\ttoType := toStruct.Type()\n\n\tif fromType != toType {\n\t\tpanic(fmt.Sprintf(\"non equal types: %s != %s\", fromType, toType))\n\t}\n\n\tfor i := 0; i < toStruct.NumField(); i++ {\n\t\tfromField := fromStruct.Field(i)\n\t\ttoField := toStruct.Field(i)\n\n\t\tif !toField.CanSet() {\n\t\t\t// Unexported fields\n\t\t\tcontinue\n\t\t}\n\n\t\tstructTag := toType.Field(i).Tag\n\n\t\tv := structTag.Get(tag)\n\t\tif shouldCopy(v) {\n\t\t\ttoField.Set(fromField)\n\t\t}\n\t}\n}"}, {"instruction": "// This is is just some helpers used to create some JSON used in the Hugo docs.", "input": "go language", "output": "func init() {\n\n\tdocsProvider := func() map[string]interface{} {\n\t\tdocs := make(map[string]interface{})\n\n\t\tvar chromaLexers []interface{}\n\n\t\tsort.Sort(lexers.Registry.Lexers)\n\n\t\tfor _, l := range lexers.Registry.Lexers {\n\n\t\t\tconfig := l.Config()\n\n\t\t\tvar filenames []string\n\t\t\tfilenames = append(filenames, config.Filenames...)\n\t\t\tfilenames = append(filenames, config.AliasFilenames...)\n\n\t\t\taliases := config.Aliases\n\n\t\t\tfor _, filename := range filenames {\n\t\t\t\talias := strings.TrimSpace(strings.TrimPrefix(filepath.Ext(filename), \".\"))\n\t\t\t\tif alias != \"\" {\n\t\t\t\t\taliases = append(aliases, alias)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tsort.Strings(aliases)\n\t\t\taliases = UniqueStrings(aliases)\n\n\t\t\tlexerEntry := struct {\n\t\t\t\tName    string\n\t\t\t\tAliases []string\n\t\t\t}{\n\t\t\t\tconfig.Name,\n\t\t\t\taliases,\n\t\t\t}\n\n\t\t\tchromaLexers = append(chromaLexers, lexerEntry)\n\n\t\t\tdocs[\"lexers\"] = chromaLexers\n\t\t}\n\t\treturn docs\n\n\t}\n\n\tdocshelper.AddDocProvider(\"chroma\", docsProvider)\n}"}, {"instruction": "// processed updates the client buffer according to actual request cost after\n// serving has been finished.\n//\n// Note: processed should always be called for all accepted requests", "input": "go language", "output": "func (cm *ClientManager) processed(node *ClientNode, maxCost, realCost uint64, now mclock.AbsTime) {\n\tcm.lock.Lock()\n\tdefer cm.lock.Unlock()\n\n\tif realCost > maxCost {\n\t\trealCost = maxCost\n\t}\n\tcm.updateNodeRc(node, int64(maxCost-realCost), &node.params, now)\n\tif uint64(node.corrBufValue) > node.bufValue {\n\t\tif node.log != nil {\n\t\t\tnode.log.add(now, fmt.Sprintf(\"corrected  bv=%d  oldBv=%d\", node.corrBufValue, node.bufValue))\n\t\t}\n\t\tnode.bufValue = uint64(node.corrBufValue)\n\t}\n}"}, {"instruction": "// applyLayerHandler parses a diff in the standard layer format from `layer`, and\n// applies it to the directory `dest`. Returns the size in bytes of the\n// contents of the layer.", "input": "go language", "output": "func applyLayerHandler(dest string, layer io.Reader, options *archive.TarOptions, decompress bool) (size int64, err error) {\n\tdest = filepath.Clean(dest)\n\n\t// Ensure it is a Windows-style volume path\n\tdest = longpath.AddPrefix(dest)\n\n\tif decompress {\n\t\tdecompressed, err := archive.DecompressStream(layer)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\tdefer decompressed.Close()\n\n\t\tlayer = decompressed\n\t}\n\n\ttmpDir, err := ioutil.TempDir(os.Getenv(\"temp\"), \"temp-docker-extract\")\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"ApplyLayer failed to create temp-docker-extract under %s. %s\", dest, err)\n\t}\n\n\ts, err := archive.UnpackLayer(dest, layer, nil)\n\tos.RemoveAll(tmpDir)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"ApplyLayer %s failed UnpackLayer to %s: %s\", layer, dest, err)\n\t}\n\n\treturn s, nil\n}"}, {"instruction": "// itemFromIterator returns the Item from the current iterator position.\n// If the complete encoded key does not start with totalPrefix,\n// leveldb.ErrNotFound is returned. Value for totalPrefix must start with\n// Index prefix.", "input": "go language", "output": "func (f Index) itemFromIterator(it iterator.Iterator, totalPrefix []byte) (i Item, err error) {\n\tkey := it.Key()\n\tif !bytes.HasPrefix(key, totalPrefix) {\n\t\treturn i, leveldb.ErrNotFound\n\t}\n\t// create a copy of key byte slice not to share leveldb underlaying slice array\n\tkeyItem, err := f.decodeKeyFunc(append([]byte(nil), key...))\n\tif err != nil {\n\t\treturn i, err\n\t}\n\t// create a copy of value byte slice not to share leveldb underlaying slice array\n\tvalueItem, err := f.decodeValueFunc(keyItem, append([]byte(nil), it.Value()...))\n\tif err != nil {\n\t\treturn i, err\n\t}\n\treturn keyItem.Merge(valueItem), it.Error()\n}"}, {"instruction": "// IsFullyQualifiedName checks if the name is fully qualified.", "input": "go language", "output": "func IsFullyQualifiedName(fldPath *field.Path, name string) field.ErrorList {\n\tvar allErrors field.ErrorList\n\tif len(name) == 0 {\n\t\treturn append(allErrors, field.Required(fldPath, \"\"))\n\t}\n\tif errs := IsDNS1123Subdomain(name); len(errs) > 0 {\n\t\treturn append(allErrors, field.Invalid(fldPath, name, strings.Join(errs, \",\")))\n\t}\n\tif len(strings.Split(name, \".\")) < 3 {\n\t\treturn append(allErrors, field.Invalid(fldPath, name, \"should be a domain with at least three segments separated by dots\"))\n\t}\n\treturn allErrors\n}"}, {"instruction": "// NewServer initializes and configures a kubelet.Server object to handle HTTP requests.", "input": "go language", "output": "func NewServer(\n\thost HostInterface,\n\tresourceAnalyzer stats.ResourceAnalyzer,\n\tauth AuthInterface,\n\tenableDebuggingHandlers,\n\tenableContentionProfiling,\n\tredirectContainerStreaming bool,\n\tcriHandler http.Handler) Server {\n\tserver := Server{\n\t\thost:                       host,\n\t\tresourceAnalyzer:           resourceAnalyzer,\n\t\tauth:                       auth,\n\t\trestfulCont:                &filteringContainer{Container: restful.NewContainer()},\n\t\tredirectContainerStreaming: redirectContainerStreaming,\n\t}\n\tif auth != nil {\n\t\tserver.InstallAuthFilter()\n\t}\n\tserver.InstallDefaultHandlers()\n\tif enableDebuggingHandlers {\n\t\tserver.InstallDebuggingHandlers(criHandler)\n\t\tif enableContentionProfiling {\n\t\t\tgoruntime.SetBlockProfileRate(1)\n\t\t}\n\t} else {\n\t\tserver.InstallDebuggingDisabledHandlers()\n\t}\n\treturn server\n}"}, {"instruction": "// HandleDelete handles a DELETE request to bzz:/<manifest>/<path>, removes\n// <path> from <manifest> and returns the resulting manifest hash as a\n// text/plain response", "input": "go language", "output": "func (s *Server) HandleDelete(w http.ResponseWriter, r *http.Request) {\n\truid := GetRUID(r.Context())\n\turi := GetURI(r.Context())\n\tlog.Debug(\"handle.delete\", \"ruid\", ruid)\n\tdeleteCount.Inc(1)\n\tnewKey, err := s.api.Delete(r.Context(), uri.Addr, uri.Path)\n\tif err != nil {\n\t\tdeleteFail.Inc(1)\n\t\trespondError(w, r, fmt.Sprintf(\"could not delete from manifest: %v\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\tw.WriteHeader(http.StatusOK)\n\tfmt.Fprint(w, newKey)\n}"}, {"instruction": "// resolveReceipts returns the list of receipts for this block, fetching them\n// if necessary.", "input": "go language", "output": "func (b *Block) resolveReceipts(ctx context.Context) ([]*types.Receipt, error) {\n\tif b.receipts == nil {\n\t\thash := b.hash\n\t\tif hash == (common.Hash{}) {\n\t\t\theader, err := b.resolveHeader(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\thash = header.Hash()\n\t\t}\n\n\t\treceipts, err := b.backend.GetReceipts(ctx, hash)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tb.receipts = []*types.Receipt(receipts)\n\t}\n\treturn b.receipts, nil\n}"}, {"instruction": "// WaitForObservedDeployment polls for deployment to be updated so that deployment.Status.ObservedGeneration >= desiredGeneration.\n// Returns error if polling timesout.", "input": "go language", "output": "func WaitForObservedDeployment(getDeploymentFunc func() (*apps.Deployment, error), desiredGeneration int64, interval, timeout time.Duration) error {\n\t// TODO: This should take clientset.Interface when all code is updated to use clientset. Keeping it this way allows the function to be used by callers who have client.Interface.\n\treturn wait.PollImmediate(interval, timeout, func() (bool, error) {\n\t\tdeployment, err := getDeploymentFunc()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn deployment.Status.ObservedGeneration >= desiredGeneration, nil\n\t})\n}"}, {"instruction": "// check opts for OpenStack", "input": "go language", "output": "func checkOpenStackOpts(openstackOpts *OpenStack) error {\n\tlbOpts := openstackOpts.lbOpts\n\n\t// if need to create health monitor for Neutron LB,\n\t// monitor-delay, monitor-timeout and monitor-max-retries should be set.\n\temptyDuration := MyDuration{}\n\tif lbOpts.CreateMonitor {\n\t\tif lbOpts.MonitorDelay == emptyDuration {\n\t\t\treturn fmt.Errorf(\"monitor-delay not set in cloud provider config\")\n\t\t}\n\t\tif lbOpts.MonitorTimeout == emptyDuration {\n\t\t\treturn fmt.Errorf(\"monitor-timeout not set in cloud provider config\")\n\t\t}\n\t\tif lbOpts.MonitorMaxRetries == uint(0) {\n\t\t\treturn fmt.Errorf(\"monitor-max-retries not set in cloud provider config\")\n\t\t}\n\t}\n\treturn checkMetadataSearchOrder(openstackOpts.metadataOpts.SearchOrder)\n}"}, {"instruction": "// SubscribeFilterLogs subscribes to the results of a streaming filter query.", "input": "go language", "output": "func (ec *EthereumClient) SubscribeFilterLogs(ctx *Context, query *FilterQuery, handler FilterLogsHandler, buffer int) (sub *Subscription, _ error) {\n\t// Subscribe to the event internally\n\tch := make(chan types.Log, buffer)\n\trawSub, err := ec.client.SubscribeFilterLogs(ctx.context, query.query, ch)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Start up a dispatcher to feed into the callback\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase log := <-ch:\n\t\t\t\thandler.OnFilterLogs(&Log{&log})\n\n\t\t\tcase err := <-rawSub.Err():\n\t\t\t\tif err != nil {\n\t\t\t\t\thandler.OnError(err.Error())\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\treturn &Subscription{rawSub}, nil\n}"}, {"instruction": "// DeleteRelease uninstalls a named release and returns the response.", "input": "go language", "output": "func (h *Client) DeleteRelease(rlsName string, opts ...DeleteOption) (*rls.UninstallReleaseResponse, error) {\n\t// apply the uninstall options\n\treqOpts := h.opts\n\tfor _, opt := range opts {\n\t\topt(&reqOpts)\n\t}\n\n\tif reqOpts.dryRun {\n\t\t// In the dry run case, just see if the release exists\n\t\tr, err := h.ReleaseContent(rlsName)\n\t\tif err != nil {\n\t\t\treturn &rls.UninstallReleaseResponse{}, err\n\t\t}\n\t\treturn &rls.UninstallReleaseResponse{Release: r.Release}, nil\n\t}\n\n\treq := &reqOpts.uninstallReq\n\treq.Name = rlsName\n\treq.DisableHooks = reqOpts.disableHooks\n\tctx := NewContext()\n\n\tif reqOpts.before != nil {\n\t\tif err := reqOpts.before(ctx, req); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn h.delete(ctx, req)\n}"}, {"instruction": "// equalFoldRight is a specialization of bytes.EqualFold when s is\n// known to be all ASCII (including punctuation), but contains an 's',\n// 'S', 'k', or 'K', requiring a Unicode fold on the bytes in t.\n// See comments on foldFunc.", "input": "go language", "output": "func equalFoldRight(s, t []byte) bool {\n\tfor _, sb := range s {\n\t\tif len(t) == 0 {\n\t\t\treturn false\n\t\t}\n\t\ttb := t[0]\n\t\tif tb < utf8.RuneSelf {\n\t\t\tif sb != tb {\n\t\t\t\tsbUpper := sb & caseMask\n\t\t\t\tif 'A' <= sbUpper && sbUpper <= 'Z' {\n\t\t\t\t\tif sbUpper != tb&caseMask {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tt = t[1:]\n\t\t\tcontinue\n\t\t}\n\t\t// sb is ASCII and t is not. t must be either kelvin\n\t\t// sign or long s; sb must be s, S, k, or K.\n\t\ttr, size := utf8.DecodeRune(t)\n\t\tswitch sb {\n\t\tcase 's', 'S':\n\t\t\tif tr != smallLongEss {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase 'k', 'K':\n\t\t\tif tr != kelvin {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t\tt = t[size:]\n\n\t}\n\tif len(t) > 0 {\n\t\treturn false\n\t}\n\treturn true\n}"}, {"instruction": "// Connect returns a handler for the pod exec proxy", "input": "go language", "output": "func (r *ExecREST) Connect(ctx context.Context, name string, opts runtime.Object, responder rest.Responder) (http.Handler, error) {\n\texecOpts, ok := opts.(*api.PodExecOptions)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"invalid options object: %#v\", opts)\n\t}\n\tlocation, transport, err := pod.ExecLocation(r.Store, r.KubeletConn, ctx, name, execOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newThrottledUpgradeAwareProxyHandler(location, transport, false, true, true, responder), nil\n}"}, {"instruction": "// Consensus passes the given ConsensusRequest message to the raft.Node instance.", "input": "go language", "output": "func (s *RPC) SendConsensus(destination uint64, msg *orderer.ConsensusRequest) error {\n\tif s.Logger.IsEnabledFor(zapcore.DebugLevel) {\n\t\tdefer s.consensusSent(time.Now(), destination, msg)\n\t}\n\n\tstream, err := s.getOrCreateStream(destination, ConsensusOperation)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq := &orderer.StepRequest{\n\t\tPayload: &orderer.StepRequest_ConsensusRequest{\n\t\t\tConsensusRequest: msg,\n\t\t},\n\t}\n\n\ts.consensusLock.Lock()\n\tdefer s.consensusLock.Unlock()\n\n\terr = stream.Send(req)\n\tif err != nil {\n\t\ts.unMapStream(destination, ConsensusOperation)\n\t}\n\n\treturn err\n}"}, {"instruction": "//TODO: need to finish the method to get the rules when using webhook mode", "input": "go language", "output": "func (w *WebhookAuthorizer) RulesFor(user user.Info, namespace string) ([]authorizer.ResourceRuleInfo, []authorizer.NonResourceRuleInfo, bool, error) {\n\tvar (\n\t\tresourceRules    []authorizer.ResourceRuleInfo\n\t\tnonResourceRules []authorizer.NonResourceRuleInfo\n\t)\n\tincomplete := true\n\treturn resourceRules, nonResourceRules, incomplete, fmt.Errorf(\"webhook authorizer does not support user rule resolution\")\n}"}, {"instruction": "// ValidateTopologySelectorTerm tests that the specified topology selector term has valid data,\n// and constructs a map representing the term in raw form.", "input": "go language", "output": "func ValidateTopologySelectorTerm(term core.TopologySelectorTerm, fldPath *field.Path) (map[string]sets.String, field.ErrorList) {\n\tallErrs := field.ErrorList{}\n\texprMap := make(map[string]sets.String)\n\texprPath := fldPath.Child(\"matchLabelExpressions\")\n\n\t// Allow empty MatchLabelExpressions, in case this field becomes optional in the future.\n\tfor i, req := range term.MatchLabelExpressions {\n\t\tidxPath := exprPath.Index(i)\n\t\tvalueSet, exprErrs := validateTopologySelectorLabelRequirement(req, idxPath)\n\t\tallErrs = append(allErrs, exprErrs...)\n\n\t\t// Validate no duplicate keys exist.\n\t\tif _, exists := exprMap[req.Key]; exists {\n\t\t\tallErrs = append(allErrs, field.Duplicate(idxPath.Child(\"key\"), req.Key))\n\t\t}\n\t\texprMap[req.Key] = valueSet\n\t}\n\n\treturn exprMap, allErrs\n}"}, {"instruction": "// convertToRuntimeCapabilities converts v1.Capabilities to runtimeapi.Capability.", "input": "go language", "output": "func convertToRuntimeCapabilities(opts *v1.Capabilities) *runtimeapi.Capability {\n\tif opts == nil {\n\t\treturn nil\n\t}\n\n\tcapabilities := &runtimeapi.Capability{\n\t\tAddCapabilities:  make([]string, len(opts.Add)),\n\t\tDropCapabilities: make([]string, len(opts.Drop)),\n\t}\n\tfor index, value := range opts.Add {\n\t\tcapabilities.AddCapabilities[index] = string(value)\n\t}\n\tfor index, value := range opts.Drop {\n\t\tcapabilities.DropCapabilities[index] = string(value)\n\t}\n\n\treturn capabilities\n}"}, {"instruction": "// AddWork adds a work to the WorkerQueue which will be executed not earlier than `fireAt`.", "input": "go language", "output": "func (q *TimedWorkerQueue) AddWork(args *WorkArgs, createdAt time.Time, fireAt time.Time) {\n\tkey := args.KeyFromWorkArgs()\n\tklog.V(4).Infof(\"Adding TimedWorkerQueue item %v at %v to be fired at %v\", key, createdAt, fireAt)\n\n\tq.Lock()\n\tdefer q.Unlock()\n\tif _, exists := q.workers[key]; exists {\n\t\tklog.Warningf(\"Trying to add already existing work for %+v. Skipping.\", args)\n\t\treturn\n\t}\n\tworker := CreateWorker(args, createdAt, fireAt, q.getWrappedWorkerFunc(key))\n\tq.workers[key] = worker\n}"}, {"instruction": "// RetrieveValidatedConfigInfo connects to the API Server and makes sure it can talk\n// securely to the API Server using the provided CA cert and\n// optionally refreshes the cluster-info information from the cluster-info ConfigMap", "input": "go language", "output": "func RetrieveValidatedConfigInfo(httpsURL, clustername string) (*clientcmdapi.Config, error) {\n\tclient := &http.Client{Transport: netutil.SetOldTransportDefaults(&http.Transport{})}\n\tresponse, err := client.Get(httpsURL)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer response.Body.Close()\n\n\tkubeconfig, err := ioutil.ReadAll(response.Body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tconfig, err := clientcmd.Load(kubeconfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn file.ValidateConfigInfo(config, clustername)\n}"}, {"instruction": "// Verify verifies a signed GossipMessage with a given Verifier.\n// Returns nil on success, error on failure.", "input": "go language", "output": "func (m *SignedGossipMessage) Verify(peerIdentity []byte, verify Verifier) error {\n\tif m.Envelope == nil {\n\t\treturn errors.New(\"Missing envelope\")\n\t}\n\tif len(m.Envelope.Payload) == 0 {\n\t\treturn errors.New(\"Empty payload\")\n\t}\n\tif len(m.Envelope.Signature) == 0 {\n\t\treturn errors.New(\"Empty signature\")\n\t}\n\tpayloadSigVerificationErr := verify(peerIdentity, m.Envelope.Signature, m.Envelope.Payload)\n\tif payloadSigVerificationErr != nil {\n\t\treturn payloadSigVerificationErr\n\t}\n\tif m.Envelope.SecretEnvelope != nil {\n\t\tpayload := m.Envelope.SecretEnvelope.Payload\n\t\tsig := m.Envelope.SecretEnvelope.Signature\n\t\tif len(payload) == 0 {\n\t\t\treturn errors.New(\"Empty payload\")\n\t\t}\n\t\tif len(sig) == 0 {\n\t\t\treturn errors.New(\"Empty signature\")\n\t\t}\n\t\treturn verify(peerIdentity, sig, payload)\n\t}\n\treturn nil\n}"}, {"instruction": "// EnsureLoadBalancer is a test-spy implementation of LoadBalancer.EnsureLoadBalancer.\n// It adds an entry \"create\" into the internal method call record.", "input": "go language", "output": "func (f *FakeCloud) EnsureLoadBalancer(ctx context.Context, clusterName string, service *v1.Service, nodes []*v1.Node) (*v1.LoadBalancerStatus, error) {\n\tf.addCall(\"create\")\n\tif f.Balancers == nil {\n\t\tf.Balancers = make(map[string]FakeBalancer)\n\t}\n\n\tname := f.GetLoadBalancerName(ctx, clusterName, service)\n\tspec := service.Spec\n\n\tzone, err := f.GetZone(context.TODO())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tregion := zone.Region\n\n\tf.Balancers[name] = FakeBalancer{name, region, spec.LoadBalancerIP, spec.Ports, nodes}\n\n\tstatus := &v1.LoadBalancerStatus{}\n\tstatus.Ingress = []v1.LoadBalancerIngress{{IP: f.ExternalIP.String()}}\n\n\treturn status, f.Err\n}"}, {"instruction": "// determineSubnetURL queries for all subnetworks in a region for a given network and returns\n// the URL of the subnetwork which exists in the auto-subnet range.", "input": "go language", "output": "func determineSubnetURL(service *compute.Service, networkProjectID, networkName, region string) (string, error) {\n\tsubnets, err := listSubnetworksOfNetwork(service, networkProjectID, networkName, region)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tautoSubnets, err := subnetsInCIDR(subnets, autoSubnetIPRange)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(autoSubnets) == 0 {\n\t\treturn \"\", fmt.Errorf(\"no subnet exists in auto CIDR\")\n\t}\n\n\tif len(autoSubnets) > 1 {\n\t\treturn \"\", fmt.Errorf(\"multiple subnetworks in the same region exist in auto CIDR\")\n\t}\n\n\treturn autoSubnets[0].SelfLink, nil\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of ReplicaSets that match those selectors.", "input": "go language", "output": "func (c *FakeReplicaSets) List(opts v1.ListOptions) (result *v1beta2.ReplicaSetList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(replicasetsResource, replicasetsKind, c.ns, opts), &v1beta2.ReplicaSetList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta2.ReplicaSetList{ListMeta: obj.(*v1beta2.ReplicaSetList).ListMeta}\n\tfor _, item := range obj.(*v1beta2.ReplicaSetList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// ValidateAvoidPodsInNodeAnnotations tests that the serialized AvoidPods in Node.Annotations has valid data", "input": "go language", "output": "func ValidateAvoidPodsInNodeAnnotations(annotations map[string]string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\tv1Avoids, err := v1helper.GetAvoidPodsFromNodeAnnotations(annotations)\n\tif err != nil {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath.Child(\"AvoidPods\"), core.PreferAvoidPodsAnnotationKey, err.Error()))\n\t\treturn allErrs\n\t}\n\tvar avoids core.AvoidPods\n\tif err := corev1.Convert_v1_AvoidPods_To_core_AvoidPods(&v1Avoids, &avoids, nil); err != nil {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath.Child(\"AvoidPods\"), core.PreferAvoidPodsAnnotationKey, err.Error()))\n\t\treturn allErrs\n\t}\n\n\tif len(avoids.PreferAvoidPods) != 0 {\n\t\tfor i, pa := range avoids.PreferAvoidPods {\n\t\t\tidxPath := fldPath.Child(core.PreferAvoidPodsAnnotationKey).Index(i)\n\t\t\tallErrs = append(allErrs, validatePreferAvoidPodsEntry(pa, idxPath)...)\n\t\t}\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// Func gets the translate func for the given language, or for the default\n// configured language if not found.", "input": "go language", "output": "func (t Translator) Func(lang string) bundle.TranslateFunc {\n\tif f, ok := t.translateFuncs[lang]; ok {\n\t\treturn f\n\t}\n\tt.logger.INFO.Printf(\"Translation func for language %v not found, use default.\", lang)\n\tif f, ok := t.translateFuncs[t.cfg.GetString(\"defaultContentLanguage\")]; ok {\n\t\treturn f\n\t}\n\tt.logger.INFO.Println(\"i18n not initialized; if you need string translations, check that you have a bundle in /i18n that matches the site language or the default language.\")\n\treturn func(translationID string, args ...interface{}) string {\n\t\treturn \"\"\n\t}\n\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *Event) DeepCopyInto(out *Event) {\n\t*out = *in\n\tout.TypeMeta = in.TypeMeta\n\tin.ObjectMeta.DeepCopyInto(&out.ObjectMeta)\n\tin.EventTime.DeepCopyInto(&out.EventTime)\n\tif in.Series != nil {\n\t\tin, out := &in.Series, &out.Series\n\t\t*out = new(EventSeries)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tout.Regarding = in.Regarding\n\tif in.Related != nil {\n\t\tin, out := &in.Related, &out.Related\n\t\t*out = new(v1.ObjectReference)\n\t\t**out = **in\n\t}\n\tout.DeprecatedSource = in.DeprecatedSource\n\tin.DeprecatedFirstTimestamp.DeepCopyInto(&out.DeprecatedFirstTimestamp)\n\tin.DeprecatedLastTimestamp.DeepCopyInto(&out.DeprecatedLastTimestamp)\n\treturn\n}"}, {"instruction": "// StringInSlice returns a SchemaValidateFunc which tests if the provided value\n// is of type string and matches the value of an element in the valid slice\n// will test with in lower case if ignoreCase is true", "input": "go language", "output": "func StringInSlice(valid []string, ignoreCase bool) schema.SchemaValidateFunc {\n\treturn func(i interface{}, k string) (s []string, es []error) {\n\t\tv, ok := i.(string)\n\t\tif !ok {\n\t\t\tes = append(es, fmt.Errorf(\"expected type of %s to be string\", k))\n\t\t\treturn\n\t\t}\n\n\t\tfor _, str := range valid {\n\t\t\tif v == str || (ignoreCase && strings.ToLower(v) == strings.ToLower(str)) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tes = append(es, fmt.Errorf(\"expected %s to be one of %v, got %s\", k, valid, v))\n\t\treturn\n\t}\n}"}, {"instruction": "// killContainersWithSyncResult kills all pod's containers with sync results.", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) killContainersWithSyncResult(pod *v1.Pod, runningPod kubecontainer.Pod, gracePeriodOverride *int64) (syncResults []*kubecontainer.SyncResult) {\n\tcontainerResults := make(chan *kubecontainer.SyncResult, len(runningPod.Containers))\n\twg := sync.WaitGroup{}\n\n\twg.Add(len(runningPod.Containers))\n\tfor _, container := range runningPod.Containers {\n\t\tgo func(container *kubecontainer.Container) {\n\t\t\tdefer utilruntime.HandleCrash()\n\t\t\tdefer wg.Done()\n\n\t\t\tkillContainerResult := kubecontainer.NewSyncResult(kubecontainer.KillContainer, container.Name)\n\t\t\tif err := m.killContainer(pod, container.ID, container.Name, \"\", gracePeriodOverride); err != nil {\n\t\t\t\tkillContainerResult.Fail(kubecontainer.ErrKillContainer, err.Error())\n\t\t\t}\n\t\t\tcontainerResults <- killContainerResult\n\t\t}(container)\n\t}\n\twg.Wait()\n\tclose(containerResults)\n\n\tfor containerResult := range containerResults {\n\t\tsyncResults = append(syncResults, containerResult)\n\t}\n\treturn\n}"}, {"instruction": "// DownloadIndexFile fetches the index from a repository.\n//\n// cachePath is prepended to any index that does not have an absolute path. This\n// is for pre-2.2.0 repo files.", "input": "go language", "output": "func (r *ChartRepository) DownloadIndexFile(cachePath string) error {\n\tvar indexURL string\n\tparsedURL, err := url.Parse(r.Config.URL)\n\tif err != nil {\n\t\treturn err\n\t}\n\tparsedURL.Path = strings.TrimSuffix(parsedURL.Path, \"/\") + \"/index.yaml\"\n\n\tindexURL = parsedURL.String()\n\n\tr.setCredentials()\n\tresp, err := r.Client.Get(indexURL)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tindex, err := ioutil.ReadAll(resp)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := loadIndex(index); err != nil {\n\t\treturn err\n\t}\n\n\t// In Helm 2.2.0 the config.cache was accidentally switched to an absolute\n\t// path, which broke backward compatibility. This fixes it by prepending a\n\t// global cache path to relative paths.\n\t//\n\t// It is changed on DownloadIndexFile because that was the method that\n\t// originally carried the cache path.\n\tcp := r.Config.Cache\n\tif !filepath.IsAbs(cp) {\n\t\tcp = filepath.Join(cachePath, cp)\n\t}\n\n\treturn ioutil.WriteFile(cp, index, 0644)\n}"}, {"instruction": "// Shutdown stops all nodes in the network and closes the quit channel", "input": "go language", "output": "func (net *Network) Shutdown() {\n\tfor _, node := range net.Nodes {\n\t\tlog.Debug(\"Stopping node\", \"id\", node.ID())\n\t\tif err := node.Stop(); err != nil {\n\t\t\tlog.Warn(\"Can't stop node\", \"id\", node.ID(), \"err\", err)\n\t\t}\n\t\t// If the node has the close method, call it.\n\t\tif closer, ok := node.Node.(io.Closer); ok {\n\t\t\tif err := closer.Close(); err != nil {\n\t\t\t\tlog.Warn(\"Can't close node\", \"id\", node.ID(), \"err\", err)\n\t\t\t}\n\t\t}\n\t}\n\tclose(net.quitc)\n}"}, {"instruction": "// eventLoop runs a loop until the event mux closes. It will install and uninstall new\n// sync subscriptions and broadcasts sync status updates to the installed sync subscriptions.", "input": "go language", "output": "func (api *PublicDownloaderAPI) eventLoop() {\n\tvar (\n\t\tsub               = api.mux.Subscribe(StartEvent{}, DoneEvent{}, FailedEvent{})\n\t\tsyncSubscriptions = make(map[chan interface{}]struct{})\n\t)\n\n\tfor {\n\t\tselect {\n\t\tcase i := <-api.installSyncSubscription:\n\t\t\tsyncSubscriptions[i] = struct{}{}\n\t\tcase u := <-api.uninstallSyncSubscription:\n\t\t\tdelete(syncSubscriptions, u.c)\n\t\t\tclose(u.uninstalled)\n\t\tcase event := <-sub.Chan():\n\t\t\tif event == nil {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar notification interface{}\n\t\t\tswitch event.Data.(type) {\n\t\t\tcase StartEvent:\n\t\t\t\tnotification = &SyncingResult{\n\t\t\t\t\tSyncing: true,\n\t\t\t\t\tStatus:  api.d.Progress(),\n\t\t\t\t}\n\t\t\tcase DoneEvent, FailedEvent:\n\t\t\t\tnotification = false\n\t\t\t}\n\t\t\t// broadcast\n\t\t\tfor c := range syncSubscriptions {\n\t\t\t\tc <- notification\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// toggleRecursorHandlerFromConfig enables or disables the recursor handler based on config idempotently", "input": "go language", "output": "func (d *DNSServer) toggleRecursorHandlerFromConfig(cfg *dnsConfig) {\n\tshouldEnable := len(cfg.Recursors) > 0\n\n\tif shouldEnable && atomic.CompareAndSwapUint32(&d.recursorEnabled, 0, 1) {\n\t\td.mux.HandleFunc(\".\", d.handleRecurse)\n\t\td.logger.Println(\"[DEBUG] dns: recursor enabled\")\n\t\treturn\n\t}\n\n\tif !shouldEnable && atomic.CompareAndSwapUint32(&d.recursorEnabled, 1, 0) {\n\t\td.mux.HandleRemove(\".\")\n\t\td.logger.Println(\"[DEBUG] dns: recursor disabled\")\n\t\treturn\n\t}\n}"}, {"instruction": "// ParseSetValue creates a Set with special number.", "input": "go language", "output": "func ParseSetValue(elems []string, number uint64) (Set, error) {\n\tif number == 0 {\n\t\treturn zeroSet, nil\n\t}\n\n\tvalue := number\n\tvar items []string\n\tfor i := 0; i < len(elems); i++ {\n\t\tif number&setIndexValue[i] > 0 {\n\t\t\titems = append(items, elems[i])\n\t\t\tnumber &= setIndexInvertValue[i]\n\t\t}\n\t}\n\n\tif number != 0 {\n\t\treturn Set{}, errors.Errorf(\"invalid number %d for Set %v\", number, elems)\n\t}\n\n\treturn Set{Name: strings.Join(items, \",\"), Value: value}, nil\n}"}, {"instruction": "// SelectPeers returns a slice of peers that match the routing filter", "input": "go language", "output": "func SelectPeers(k int, peerPool []discovery.NetworkMember, filter RoutingFilter) []*comm.RemotePeer {\n\tvar res []*comm.RemotePeer\n\trand.Seed(int64(util.RandomUInt64()))\n\t// Iterate over the possible candidates in random order\n\tfor _, index := range rand.Perm(len(peerPool)) {\n\t\t// If we collected K peers, we can stop the iteration.\n\t\tif len(res) == k {\n\t\t\tbreak\n\t\t}\n\t\tpeer := peerPool[index]\n\t\t// For each one, check if it is a worthy candidate to be selected\n\t\tif !filter(peer) {\n\t\t\tcontinue\n\t\t}\n\t\tp := &comm.RemotePeer{PKIID: peer.PKIid, Endpoint: peer.PreferredEndpoint()}\n\t\tres = append(res, p)\n\t}\n\treturn res\n}"}, {"instruction": "// PatchNodeStatus patches node status.", "input": "go language", "output": "func PatchNodeStatus(c v1core.CoreV1Interface, nodeName types.NodeName, oldNode *v1.Node, newNode *v1.Node) (*v1.Node, []byte, error) {\n\tpatchBytes, err := preparePatchBytesforNodeStatus(nodeName, oldNode, newNode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tupdatedNode, err := c.Nodes().Patch(string(nodeName), types.StrategicMergePatchType, patchBytes, \"status\")\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to patch status %q for node %q: %v\", patchBytes, nodeName, err)\n\t}\n\treturn updatedNode, patchBytes, nil\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of Jobs that match those selectors.", "input": "go language", "output": "func (c *FakeJobs) List(opts v1.ListOptions) (result *batchv1.JobList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewListAction(jobsResource, jobsKind, c.ns, opts), &batchv1.JobList{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &batchv1.JobList{ListMeta: obj.(*batchv1.JobList).ListMeta}\n\tfor _, item := range obj.(*batchv1.JobList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// NewWatchingConfigMapManager creates a manager that keeps a cache of all configmaps\n// necessary for registered pods.\n// It implements the following logic:\n// - whenever a pod is created or updated, we start inidvidual watches for all\n//   referenced objects that aren't referenced from other registered pods\n// - every GetObject() returns a value from local cache propagated via watches", "input": "go language", "output": "func NewWatchingConfigMapManager(kubeClient clientset.Interface) Manager {\n\tlistConfigMap := func(namespace string, opts metav1.ListOptions) (runtime.Object, error) {\n\t\treturn kubeClient.CoreV1().ConfigMaps(namespace).List(opts)\n\t}\n\twatchConfigMap := func(namespace string, opts metav1.ListOptions) (watch.Interface, error) {\n\t\treturn kubeClient.CoreV1().ConfigMaps(namespace).Watch(opts)\n\t}\n\tnewConfigMap := func() runtime.Object {\n\t\treturn &v1.ConfigMap{}\n\t}\n\tgr := corev1.Resource(\"configmap\")\n\treturn &configMapManager{\n\t\tmanager: manager.NewWatchBasedManager(listConfigMap, watchConfigMap, newConfigMap, gr, getConfigMapNames),\n\t}\n}"}, {"instruction": "// sniffJSONStateTerraformVersion attempts to sniff the Terraform version\n// specification from the given state file source code. The result is either\n// a version string or an empty string if no version number could be extracted.\n//\n// This is a best-effort function intended to produce nicer error messages. It\n// should not be used for any real processing.", "input": "go language", "output": "func sniffJSONStateTerraformVersion(src []byte) string {\n\ttype VersionSniff struct {\n\t\tVersion string `json:\"terraform_version\"`\n\t}\n\tvar sniff VersionSniff\n\n\terr := json.Unmarshal(src, &sniff)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\n\t// Attempt to parse the string as a version so we won't report garbage\n\t// as a version number.\n\t_, err = version.NewVersion(sniff.Version)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\n\treturn sniff.Version\n}"}, {"instruction": "// NewREST returns a RESTStorage object that will work against priority classes.", "input": "go language", "output": "func NewREST(optsGetter generic.RESTOptionsGetter) *REST {\n\tstore := &genericregistry.Store{\n\t\tNewFunc:                  func() runtime.Object { return &scheduling.PriorityClass{} },\n\t\tNewListFunc:              func() runtime.Object { return &scheduling.PriorityClassList{} },\n\t\tDefaultQualifiedResource: scheduling.Resource(\"priorityclasses\"),\n\n\t\tCreateStrategy: priorityclass.Strategy,\n\t\tUpdateStrategy: priorityclass.Strategy,\n\t\tDeleteStrategy: priorityclass.Strategy,\n\n\t\tTableConvertor: printerstorage.TableConvertor{TableGenerator: printers.NewTableGenerator().With(printersinternal.AddHandlers)},\n\t}\n\toptions := &generic.StoreOptions{RESTOptions: optsGetter}\n\tif err := store.CompleteWithOptions(options); err != nil {\n\t\tpanic(err) // TODO: Propagate error up\n\t}\n\n\treturn &REST{store}\n}"}, {"instruction": "// ValidateConditionalService validates conditionally valid fields.", "input": "go language", "output": "func ValidateConditionalService(service, oldService *api.Service) field.ErrorList {\n\tvar errs field.ErrorList\n\t// If the SCTPSupport feature is disabled, and the old object isn't using the SCTP feature, prevent the new object from using it\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.SCTPSupport) && len(serviceSCTPFields(oldService)) == 0 {\n\t\tfor _, f := range serviceSCTPFields(service) {\n\t\t\terrs = append(errs, field.NotSupported(f, api.ProtocolSCTP, []string{string(api.ProtocolTCP), string(api.ProtocolUDP)}))\n\t\t}\n\t}\n\treturn errs\n}"}, {"instruction": "// Generate an elliptic curve public / private keypair. If params is nil,\n// the recommended default parameters for the key will be chosen.", "input": "go language", "output": "func GenerateKey(rand io.Reader, curve elliptic.Curve, params *ECIESParams) (prv *PrivateKey, err error) {\n\tpb, x, y, err := elliptic.GenerateKey(curve, rand)\n\tif err != nil {\n\t\treturn\n\t}\n\tprv = new(PrivateKey)\n\tprv.PublicKey.X = x\n\tprv.PublicKey.Y = y\n\tprv.PublicKey.Curve = curve\n\tprv.D = new(big.Int).SetBytes(pb)\n\tif params == nil {\n\t\tparams = ParamsFromCurve(curve)\n\t}\n\tprv.PublicKey.Params = params\n\treturn\n}"}, {"instruction": "// isSingleReference returns true when all references are from one repository\n// and there is at most one tag. Returns false for empty input.", "input": "go language", "output": "func isSingleReference(repoRefs []reference.Named) bool {\n\tif len(repoRefs) <= 1 {\n\t\treturn len(repoRefs) == 1\n\t}\n\tvar singleRef reference.Named\n\tcanonicalRefs := map[string]struct{}{}\n\tfor _, repoRef := range repoRefs {\n\t\tif _, isCanonical := repoRef.(reference.Canonical); isCanonical {\n\t\t\tcanonicalRefs[repoRef.Name()] = struct{}{}\n\t\t} else if singleRef == nil {\n\t\t\tsingleRef = repoRef\n\t\t} else {\n\t\t\treturn false\n\t\t}\n\t}\n\tif singleRef == nil {\n\t\t// Just use first canonical ref\n\t\tsingleRef = repoRefs[0]\n\t}\n\t_, ok := canonicalRefs[singleRef.Name()]\n\treturn len(canonicalRefs) == 1 && ok\n}"}, {"instruction": "// normalizePortPortion attempts to normalize the \"port portion\" of a hostname,\n// which begins with the first colon in the hostname and should be followed\n// by a string of decimal digits.\n//\n// If the port portion is valid, a normalized version of it is returned along\n// with a nil error.\n//\n// If the port portion is invalid, the input string is returned verbatim along\n// with a non-nil error.\n//\n// An empty string is a valid port portion representing the absense of a port.\n// If non-empty, the first character must be a colon.", "input": "go language", "output": "func normalizePortPortion(s string) (string, error) {\n\tif s == \"\" {\n\t\treturn s, nil\n\t}\n\n\tif s[0] != ':' {\n\t\t// should never happen, since caller tends to guarantee the presence\n\t\t// of a colon due to how it's extracted from the string.\n\t\treturn s, errors.New(\"port portion is missing its initial colon\")\n\t}\n\n\tnumStr := s[1:]\n\tnum, err := strconv.Atoi(numStr)\n\tif err != nil {\n\t\treturn s, errors.New(\"port portion contains non-digit characters\")\n\t}\n\tif num == 443 {\n\t\treturn \"\", nil // \":443\" is the default\n\t}\n\tif num > 65535 {\n\t\treturn s, errors.New(\"port number is greater than 65535\")\n\t}\n\treturn fmt.Sprintf(\":%d\", num), nil\n}"}, {"instruction": "// LoadOrGenerateKeyFile looks for a key in the file at the given path. If it\n// can't find one, it will generate a new key and store it there.", "input": "go language", "output": "func LoadOrGenerateKeyFile(keyPath string) (data []byte, wasGenerated bool, err error) {\n\tloadedData, err := ioutil.ReadFile(keyPath)\n\t// Call verifyKeyData to ensure the file wasn't empty/corrupt.\n\tif err == nil && verifyKeyData(loadedData) {\n\t\treturn loadedData, false, err\n\t}\n\tif !os.IsNotExist(err) {\n\t\treturn nil, false, fmt.Errorf(\"error loading key from %s: %v\", keyPath, err)\n\t}\n\n\tgeneratedData, err := MakeEllipticPrivateKeyPEM()\n\tif err != nil {\n\t\treturn nil, false, fmt.Errorf(\"error generating key: %v\", err)\n\t}\n\tif err := WriteKey(keyPath, generatedData); err != nil {\n\t\treturn nil, false, fmt.Errorf(\"error writing key to %s: %v\", keyPath, err)\n\t}\n\treturn generatedData, true, nil\n}"}, {"instruction": "// Write sends the buffer to the underneath writer.\n// It inserts the prefix header before the buffer,\n// so stdcopy.StdCopy knows where to multiplex the output.\n// It makes stdWriter to implement io.Writer.", "input": "go language", "output": "func (w *stdWriter) Write(p []byte) (n int, err error) {\n\tif w == nil || w.Writer == nil {\n\t\treturn 0, errors.New(\"Writer not instantiated\")\n\t}\n\tif p == nil {\n\t\treturn 0, nil\n\t}\n\n\theader := [stdWriterPrefixLen]byte{stdWriterFdIndex: w.prefix}\n\tbinary.BigEndian.PutUint32(header[stdWriterSizeIndex:], uint32(len(p)))\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Write(header[:])\n\tbuf.Write(p)\n\n\tn, err = w.Writer.Write(buf.Bytes())\n\tn -= stdWriterPrefixLen\n\tif n < 0 {\n\t\tn = 0\n\t}\n\n\tbuf.Reset()\n\tbufPool.Put(buf)\n\treturn\n}"}, {"instruction": "// adds a symmetric key to the pss key pool, and optionally adds the key to the\n// collection of keys used to attempt symmetric decryption of incoming messages", "input": "go language", "output": "func (ks *KeyStore) addSymmetricKeyToPool(keyid string, topic Topic, address PssAddress, addtocache bool, protected bool) {\n\tpsp := &pssPeer{\n\t\taddress:   address,\n\t\tprotected: protected,\n\t}\n\tks.mx.Lock()\n\tif _, ok := ks.symKeyPool[keyid]; !ok {\n\t\tks.symKeyPool[keyid] = make(map[Topic]*pssPeer)\n\t}\n\tks.symKeyPool[keyid][topic] = psp\n\tks.mx.Unlock()\n\tif addtocache {\n\t\tks.symKeyDecryptCacheCursor++\n\t\tks.symKeyDecryptCache[ks.symKeyDecryptCacheCursor%cap(ks.symKeyDecryptCache)] = &keyid\n\t}\n}"}, {"instruction": "// Attempt to decrypt, validate and unpack an asymmetrically encrypted message.\n// If successful, returns the unpacked whisper ReceivedMessage struct\n// encapsulating the decrypted message, and the byte representation of\n// the public key used to decrypt the message.\n// It fails if decryption of message fails, or if the message is corrupted.", "input": "go language", "output": "func (ks *Pss) processAsym(envelope *whisper.Envelope) (*whisper.ReceivedMessage, string, PssAddress, error) {\n\tmetrics.GetOrRegisterCounter(\"pss.process.asym\", nil).Inc(1)\n\n\trecvmsg, err := envelope.OpenAsymmetric(ks.privateKey)\n\tif err != nil {\n\t\treturn nil, \"\", nil, fmt.Errorf(\"could not decrypt message: %s\", err)\n\t}\n\t// check signature (if signed), strip padding\n\tif !recvmsg.ValidateAndParse() {\n\t\treturn nil, \"\", nil, errors.New(\"invalid message\")\n\t}\n\tpubkeyid := common.ToHex(crypto.FromECDSAPub(recvmsg.Src))\n\tvar from PssAddress\n\tks.mx.RLock()\n\tif ks.pubKeyPool[pubkeyid][Topic(envelope.Topic)] != nil {\n\t\tfrom = ks.pubKeyPool[pubkeyid][Topic(envelope.Topic)].address\n\t}\n\tks.mx.RUnlock()\n\treturn recvmsg, pubkeyid, from, nil\n}"}, {"instruction": "// extractJoinGroup extracts all the join nodes connected with continuous\n// InnerJoins to construct a join group. This join group is further used to\n// construct a new join order based on a reorder algorithm.\n//\n// For example: \"InnerJoin(InnerJoin(a, b), LeftJoin(c, d))\"\n// results in a join group {a, b, LeftJoin(c, d)}.", "input": "go language", "output": "func extractJoinGroup(p LogicalPlan) (group []LogicalPlan, eqEdges []*expression.ScalarFunction, otherConds []expression.Expression) {\n\tjoin, isJoin := p.(*LogicalJoin)\n\tif !isJoin || join.preferJoinType > uint(0) || join.JoinType != InnerJoin || join.StraightJoin {\n\t\treturn []LogicalPlan{p}, nil, nil\n\t}\n\n\tlhsGroup, lhsEqualConds, lhsOtherConds := extractJoinGroup(join.children[0])\n\trhsGroup, rhsEqualConds, rhsOtherConds := extractJoinGroup(join.children[1])\n\n\tgroup = append(group, lhsGroup...)\n\tgroup = append(group, rhsGroup...)\n\teqEdges = append(eqEdges, join.EqualConditions...)\n\teqEdges = append(eqEdges, lhsEqualConds...)\n\teqEdges = append(eqEdges, rhsEqualConds...)\n\totherConds = append(otherConds, join.OtherConditions...)\n\totherConds = append(otherConds, lhsOtherConds...)\n\totherConds = append(otherConds, rhsOtherConds...)\n\treturn group, eqEdges, otherConds\n}"}, {"instruction": "// updateClaim runs in worker thread and handles \"claim added\",\n// \"claim updated\" and \"periodic sync\" events.", "input": "go language", "output": "func (ctrl *PersistentVolumeController) updateClaim(claim *v1.PersistentVolumeClaim) {\n\t// Store the new claim version in the cache and do not process it if this is\n\t// an old version.\n\tnew, err := ctrl.storeClaimUpdate(claim)\n\tif err != nil {\n\t\tklog.Errorf(\"%v\", err)\n\t}\n\tif !new {\n\t\treturn\n\t}\n\terr = ctrl.syncClaim(claim)\n\tif err != nil {\n\t\tif errors.IsConflict(err) {\n\t\t\t// Version conflict error happens quite often and the controller\n\t\t\t// recovers from it easily.\n\t\t\tklog.V(3).Infof(\"could not sync claim %q: %+v\", claimToClaimKey(claim), err)\n\t\t} else {\n\t\t\tklog.Errorf(\"could not sync volume %q: %+v\", claimToClaimKey(claim), err)\n\t\t}\n\t}\n}"}, {"instruction": "// LoadConfig extract the KubeConfigFile from configFile", "input": "go language", "output": "func LoadConfig(configFile io.Reader) (string, error) {\n\tvar kubeconfigFile string\n\tif configFile != nil {\n\t\t// we have a config so parse it.\n\t\tdata, err := ioutil.ReadAll(configFile)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tdecoder := codecs.UniversalDecoder()\n\t\tdecodedObj, err := runtime.Decode(decoder, data)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tconfig, ok := decodedObj.(*webhookadmission.WebhookAdmission)\n\t\tif !ok {\n\t\t\treturn \"\", fmt.Errorf(\"unexpected type: %T\", decodedObj)\n\t\t}\n\n\t\tif !path.IsAbs(config.KubeConfigFile) {\n\t\t\treturn \"\", field.Invalid(field.NewPath(\"kubeConfigFile\"), config.KubeConfigFile, \"must be an absolute file path\")\n\t\t}\n\n\t\tkubeconfigFile = config.KubeConfigFile\n\t}\n\treturn kubeconfigFile, nil\n}"}, {"instruction": "// following functions are used by the instruction jump  table\n// make log instruction function", "input": "go language", "output": "func makeLog(size int) executionFunc {\n\treturn func(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {\n\t\ttopics := make([]common.Hash, size)\n\t\tmStart, mSize := stack.pop(), stack.pop()\n\t\tfor i := 0; i < size; i++ {\n\t\t\ttopics[i] = common.BigToHash(stack.pop())\n\t\t}\n\n\t\td := memory.Get(mStart.Int64(), mSize.Int64())\n\t\tinterpreter.evm.StateDB.AddLog(&types.Log{\n\t\t\tAddress: contract.Address(),\n\t\t\tTopics:  topics,\n\t\t\tData:    d,\n\t\t\t// This is a non-consensus field, but assigned here because\n\t\t\t// core/state doesn't know the current block number.\n\t\t\tBlockNumber: interpreter.evm.BlockNumber.Uint64(),\n\t\t})\n\n\t\tinterpreter.intPool.put(mStart, mSize)\n\t\treturn nil, nil\n\t}\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ImageReviewSpec) DeepCopyInto(out *ImageReviewSpec) {\n\t*out = *in\n\tif in.Containers != nil {\n\t\tin, out := &in.Containers, &out.Containers\n\t\t*out = make([]ImageReviewContainerSpec, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.Annotations != nil {\n\t\tin, out := &in.Annotations, &out.Annotations\n\t\t*out = make(map[string]string, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// Set associates key with value.", "input": "go language", "output": "func (m *memDbBuffer) Set(k Key, v []byte) error {\n\tif len(v) == 0 {\n\t\treturn errors.Trace(ErrCannotSetNilValue)\n\t}\n\tif len(k)+len(v) > m.entrySizeLimit {\n\t\treturn ErrEntryTooLarge.GenWithStackByArgs(m.entrySizeLimit, len(k)+len(v))\n\t}\n\n\terr := m.db.Put(k, v)\n\tif m.Size() > m.bufferSizeLimit {\n\t\treturn ErrTxnTooLarge.GenWithStack(\"transaction too large, size:%d\", m.Size())\n\t}\n\tif m.Len() > int(m.bufferLenLimit) {\n\t\treturn ErrTxnTooLarge.GenWithStack(\"transaction too large, len:%d\", m.Len())\n\t}\n\treturn errors.Trace(err)\n}"}, {"instruction": "// NewWindowFuncDesc creates a window function signature descriptor.", "input": "go language", "output": "func NewWindowFuncDesc(ctx sessionctx.Context, name string, args []expression.Expression) *WindowFuncDesc {\n\tswitch strings.ToLower(name) {\n\tcase ast.WindowFuncNthValue:\n\t\tval, isNull, ok := expression.GetUint64FromConstant(args[1])\n\t\t// nth_value does not allow `0`, but allows `null`.\n\t\tif !ok || (val == 0 && !isNull) {\n\t\t\treturn nil\n\t\t}\n\tcase ast.WindowFuncNtile:\n\t\tval, isNull, ok := expression.GetUint64FromConstant(args[0])\n\t\t// ntile does not allow `0`, but allows `null`.\n\t\tif !ok || (val == 0 && !isNull) {\n\t\t\treturn nil\n\t\t}\n\tcase ast.WindowFuncLead, ast.WindowFuncLag:\n\t\tif len(args) < 2 {\n\t\t\tbreak\n\t\t}\n\t\t_, isNull, ok := expression.GetUint64FromConstant(args[1])\n\t\tif !ok || isNull {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn &WindowFuncDesc{newBaseFuncDesc(ctx, name, args)}\n}"}, {"instruction": "// AsCanonicalBytes accepts a buffer to write the base-10 string value of this field to, and returns\n// either that buffer or a larger buffer and the current exponent of the value. The value is adjusted\n// until the exponent is a multiple of 3 - i.e. 1.1e5 would return \"110\", 3.", "input": "go language", "output": "func (a int64Amount) AsCanonicalBytes(out []byte) (result []byte, exponent int32) {\n\tmantissa := a.value\n\texponent = int32(a.scale)\n\n\tamount, times := removeInt64Factors(mantissa, 10)\n\texponent += int32(times)\n\n\t// make sure exponent is a multiple of 3\n\tvar ok bool\n\tswitch exponent % 3 {\n\tcase 1, -2:\n\t\tamount, ok = int64MultiplyScale10(amount)\n\t\tif !ok {\n\t\t\treturn infDecAmount{a.AsDec()}.AsCanonicalBytes(out)\n\t\t}\n\t\texponent = exponent - 1\n\tcase 2, -1:\n\t\tamount, ok = int64MultiplyScale100(amount)\n\t\tif !ok {\n\t\t\treturn infDecAmount{a.AsDec()}.AsCanonicalBytes(out)\n\t\t}\n\t\texponent = exponent - 2\n\t}\n\treturn strconv.AppendInt(out, amount, 10), exponent\n}"}, {"instruction": "// NewServerTimeout returns an error indicating the requested action could not be completed due to a\n// transient error, and the client should try again.", "input": "go language", "output": "func NewServerTimeout(qualifiedResource schema.GroupResource, operation string, retryAfterSeconds int) *StatusError {\n\treturn &StatusError{metav1.Status{\n\t\tStatus: metav1.StatusFailure,\n\t\tCode:   http.StatusInternalServerError,\n\t\tReason: metav1.StatusReasonServerTimeout,\n\t\tDetails: &metav1.StatusDetails{\n\t\t\tGroup:             qualifiedResource.Group,\n\t\t\tKind:              qualifiedResource.Resource,\n\t\t\tName:              operation,\n\t\t\tRetryAfterSeconds: int32(retryAfterSeconds),\n\t\t},\n\t\tMessage: fmt.Sprintf(\"The %s operation against %s could not be completed at this time, please try again.\", operation, qualifiedResource.String()),\n\t}}\n}"}, {"instruction": "// NewCmdAlpha returns \"kubeadm alpha\" command.", "input": "go language", "output": "func NewCmdAlpha(in io.Reader, out io.Writer) *cobra.Command {\n\tcmd := &cobra.Command{\n\t\tUse:   \"alpha\",\n\t\tShort: \"Kubeadm experimental sub-commands\",\n\t}\n\n\tcmd.AddCommand(newCmdCertsUtility())\n\tcmd.AddCommand(newCmdKubeletUtility())\n\tcmd.AddCommand(newCmdKubeConfigUtility(out))\n\tcmd.AddCommand(NewCmdSelfhosting(in))\n\n\t// TODO: This command should be removed as soon as the kubeadm init phase refactoring is completed.\n\t//\t\t current phases implemented as cobra.Commands should become workflow.Phases, while other utilities\n\t// \t\t hosted under kubeadm alpha phases command should found a new home under kubeadm alpha (without phases)\n\tcmd.AddCommand(newCmdPhase(out))\n\n\treturn cmd\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ResourceQuotaSpec) DeepCopyInto(out *ResourceQuotaSpec) {\n\t*out = *in\n\tif in.Hard != nil {\n\t\tin, out := &in.Hard, &out.Hard\n\t\t*out = make(ResourceList, len(*in))\n\t\tfor key, val := range *in {\n\t\t\t(*out)[key] = val.DeepCopy()\n\t\t}\n\t}\n\tif in.Scopes != nil {\n\t\tin, out := &in.Scopes, &out.Scopes\n\t\t*out = make([]ResourceQuotaScope, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.ScopeSelector != nil {\n\t\tin, out := &in.ScopeSelector, &out.ScopeSelector\n\t\t*out = new(ScopeSelector)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\treturn\n}"}, {"instruction": "// Init creates a driver with the given home and the set of options.", "input": "go language", "output": "func Init(home string, options []string, uidMaps, gidMaps []idtools.IDMap) (graphdriver.Driver, error) {\n\tdeviceSet, err := NewDeviceSet(home, true, options, uidMaps, gidMaps)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Driver{\n\t\tDeviceSet: deviceSet,\n\t\thome:      home,\n\t\tuidMaps:   uidMaps,\n\t\tgidMaps:   gidMaps,\n\t\tctr:       graphdriver.NewRefCounter(graphdriver.NewDefaultChecker()),\n\t\tlocker:    locker.New(),\n\t}\n\n\treturn graphdriver.NewNaiveDiffDriver(d, uidMaps, gidMaps), nil\n}"}, {"instruction": "// VersionFromCILabel resolves a version label like \"latest\" or \"stable\" to an actual version using the public Kubernetes CI uploads", "input": "go language", "output": "func (g *KubeVersionGetter) VersionFromCILabel(ciVersionLabel, description string) (string, *versionutil.Version, error) {\n\tversionStr, err := kubeadmutil.KubernetesReleaseVersion(ciVersionLabel)\n\tif err != nil {\n\t\treturn \"\", nil, errors.Wrapf(err, \"Couldn't fetch latest %s from the internet\", description)\n\t}\n\n\tif description != \"\" {\n\t\tfmt.Fprintf(g.w, \"[upgrade/versions] Latest %s: %s\\n\", description, versionStr)\n\t}\n\n\tver, err := versionutil.ParseSemantic(versionStr)\n\tif err != nil {\n\t\treturn \"\", nil, errors.Wrapf(err, \"Couldn't parse latest %s\", description)\n\t}\n\treturn versionStr, ver, nil\n}"}, {"instruction": "// evalDuration evals a builtinAddDurationAndStringSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html#function_addtime", "input": "go language", "output": "func (b *builtinAddDurationAndStringSig) evalDuration(row chunk.Row) (types.Duration, bool, error) {\n\targ0, isNull, err := b.args[0].EvalDuration(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn types.ZeroDuration, isNull, err\n\t}\n\ts, isNull, err := b.args[1].EvalString(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn types.ZeroDuration, isNull, err\n\t}\n\tif !isDuration(s) {\n\t\treturn types.ZeroDuration, true, nil\n\t}\n\targ1, err := types.ParseDuration(b.ctx.GetSessionVars().StmtCtx, s, types.GetFsp(s))\n\tif err != nil {\n\t\treturn types.ZeroDuration, true, err\n\t}\n\tresult, err := arg0.Add(arg1)\n\tif err != nil {\n\t\treturn types.ZeroDuration, true, err\n\t}\n\treturn result, false, nil\n}"}, {"instruction": "// parseRuncVersion parses the output of `runc --version` and extracts the\n// \"version\" and \"git commit\" from the output.\n//\n// Output example from `runc --version`:\n//\n//   runc version 1.0.0-rc5+dev\n//   commit: 69663f0bd4b60df09991c08812a60108003fa340\n//   spec: 1.0.0", "input": "go language", "output": "func parseRuncVersion(v string) (version string, commit string, err error) {\n\tlines := strings.Split(strings.TrimSpace(v), \"\\n\")\n\tfor _, line := range lines {\n\t\tif strings.HasPrefix(line, \"runc version\") {\n\t\t\tversion = strings.TrimSpace(strings.TrimPrefix(line, \"runc version\"))\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(line, \"commit:\") {\n\t\t\tcommit = strings.TrimSpace(strings.TrimPrefix(line, \"commit:\"))\n\t\t\tcontinue\n\t\t}\n\t}\n\tif version == \"\" && commit == \"\" {\n\t\terr = errors.Errorf(\"unknown output format: %s\", v)\n\t}\n\treturn version, commit, err\n}"}, {"instruction": "// lanNodeJoin is used to handle join events on the LAN pool.", "input": "go language", "output": "func (s *Server) lanNodeJoin(me serf.MemberEvent) {\n\tfor _, m := range me.Members {\n\t\tok, serverMeta := metadata.IsConsulServer(m)\n\t\tif !ok || serverMeta.Segment != \"\" {\n\t\t\tcontinue\n\t\t}\n\t\ts.logger.Printf(\"[INFO] consul: Adding LAN server %s\", serverMeta)\n\n\t\t// Update server lookup\n\t\ts.serverLookup.AddServer(serverMeta)\n\n\t\t// If we're still expecting to bootstrap, may need to handle this.\n\t\tif s.config.BootstrapExpect != 0 {\n\t\t\ts.maybeBootstrap()\n\t\t}\n\n\t\t// Kick the join flooders.\n\t\ts.FloodNotify()\n\t}\n}"}, {"instruction": "// NewStateSync create a new state trie download scheduler.", "input": "go language", "output": "func NewStateSync(root common.Hash, database ethdb.Reader) *trie.Sync {\n\tvar syncer *trie.Sync\n\tcallback := func(leaf []byte, parent common.Hash) error {\n\t\tvar obj Account\n\t\tif err := rlp.Decode(bytes.NewReader(leaf), &obj); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsyncer.AddSubTrie(obj.Root, 64, parent, nil)\n\t\tsyncer.AddRawEntry(common.BytesToHash(obj.CodeHash), 64, parent)\n\t\treturn nil\n\t}\n\tsyncer = trie.NewSync(root, database, callback)\n\treturn syncer\n}"}, {"instruction": "// lockInfo reads the lock file, parses its contents and returns the parsed\n// LockInfo struct.", "input": "go language", "output": "func (c *remoteClient) lockInfo() (*state.LockInfo, error) {\n\tr, err := c.lockFile().NewReader(c.storageContext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer r.Close()\n\n\trawData, err := ioutil.ReadAll(r)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinfo := &state.LockInfo{}\n\tif err := json.Unmarshal(rawData, info); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We use the Generation as the ID, so overwrite the ID in the json.\n\t// This can't be written into the Info, since the generation isn't known\n\t// until it's written.\n\tattrs, err := c.lockFile().Attrs(c.storageContext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.ID = strconv.FormatInt(attrs.Generation, 10)\n\n\treturn info, nil\n}"}, {"instruction": "// RegisterDefaults adds defaulters functions to the given scheme.\n// Public to allow building arbitrary schemes.\n// All generated defaulters are covering - they call all nested defaulters.", "input": "go language", "output": "func RegisterDefaults(scheme *runtime.Scheme) error {\n\tscheme.AddTypeDefaultingFunc(&v1beta1.MutatingWebhookConfiguration{}, func(obj interface{}) {\n\t\tSetObjectDefaults_MutatingWebhookConfiguration(obj.(*v1beta1.MutatingWebhookConfiguration))\n\t})\n\tscheme.AddTypeDefaultingFunc(&v1beta1.MutatingWebhookConfigurationList{}, func(obj interface{}) {\n\t\tSetObjectDefaults_MutatingWebhookConfigurationList(obj.(*v1beta1.MutatingWebhookConfigurationList))\n\t})\n\tscheme.AddTypeDefaultingFunc(&v1beta1.ValidatingWebhookConfiguration{}, func(obj interface{}) {\n\t\tSetObjectDefaults_ValidatingWebhookConfiguration(obj.(*v1beta1.ValidatingWebhookConfiguration))\n\t})\n\tscheme.AddTypeDefaultingFunc(&v1beta1.ValidatingWebhookConfigurationList{}, func(obj interface{}) {\n\t\tSetObjectDefaults_ValidatingWebhookConfigurationList(obj.(*v1beta1.ValidatingWebhookConfigurationList))\n\t})\n\treturn nil\n}"}, {"instruction": "// ListPredicate returns a list of all the items matching the given\n// SelectionPredicate.", "input": "go language", "output": "func (e *Store) ListPredicate(ctx context.Context, p storage.SelectionPredicate, options *metainternalversion.ListOptions) (runtime.Object, error) {\n\tif options == nil {\n\t\t// By default we should serve the request from etcd.\n\t\toptions = &metainternalversion.ListOptions{ResourceVersion: \"\"}\n\t}\n\tp.Limit = options.Limit\n\tp.Continue = options.Continue\n\tlist := e.NewListFunc()\n\tqualifiedResource := e.qualifiedResourceFromContext(ctx)\n\tif name, ok := p.MatchesSingle(); ok {\n\t\tif key, err := e.KeyFunc(ctx, name); err == nil {\n\t\t\terr := e.Storage.GetToList(ctx, key, options.ResourceVersion, p, list)\n\t\t\treturn list, storeerr.InterpretListError(err, qualifiedResource)\n\t\t}\n\t\t// if we cannot extract a key based on the current context, the optimization is skipped\n\t}\n\n\terr := e.Storage.List(ctx, e.KeyRootFunc(ctx), options.ResourceVersion, p, list)\n\treturn list, storeerr.InterpretListError(err, qualifiedResource)\n}"}, {"instruction": "// This validate will make sure targetPath:\n// 1. is not abs path\n// 2. does not contain any '..' elements\n// 3. does not start with '..'", "input": "go language", "output": "func validateLocalNonReservedPath(targetPath string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\tallErrs = append(allErrs, validateLocalDescendingPath(targetPath, fldPath)...)\n\t// Don't report this error if the check for .. elements already caught it.\n\tif strings.HasPrefix(targetPath, \"..\") && !strings.HasPrefix(targetPath, \"../\") {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, targetPath, \"must not start with '..'\"))\n\t}\n\treturn allErrs\n}"}, {"instruction": "// NewFilter creates a new filter and returns the filter id. It can be\n// used to retrieve logs when the state changes. This method cannot be\n// used to fetch logs that are already stored in the state.\n//\n// Default criteria for the from and to block are \"latest\".\n// Using \"latest\" as block number will return logs for mined blocks.\n// Using \"pending\" as block number returns logs for not yet mined (pending) blocks.\n// In case logs are removed (chain reorg) previously returned logs are returned\n// again but with the removed property set to true.\n//\n// In case \"fromBlock\" > \"toBlock\" an error is returned.\n//\n// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_newfilter", "input": "go language", "output": "func (api *PublicFilterAPI) NewFilter(crit FilterCriteria) (rpc.ID, error) {\n\tlogs := make(chan []*types.Log)\n\tlogsSub, err := api.events.SubscribeLogs(ethereum.FilterQuery(crit), logs)\n\tif err != nil {\n\t\treturn rpc.ID(\"\"), err\n\t}\n\n\tapi.filtersMu.Lock()\n\tapi.filters[logsSub.ID] = &filter{typ: LogsSubscription, crit: crit, deadline: time.NewTimer(deadline), logs: make([]*types.Log, 0), s: logsSub}\n\tapi.filtersMu.Unlock()\n\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase l := <-logs:\n\t\t\t\tapi.filtersMu.Lock()\n\t\t\t\tif f, found := api.filters[logsSub.ID]; found {\n\t\t\t\t\tf.logs = append(f.logs, l...)\n\t\t\t\t}\n\t\t\t\tapi.filtersMu.Unlock()\n\t\t\tcase <-logsSub.Err():\n\t\t\t\tapi.filtersMu.Lock()\n\t\t\t\tdelete(api.filters, logsSub.ID)\n\t\t\t\tapi.filtersMu.Unlock()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn logsSub.ID, nil\n}"}, {"instruction": "// Growing Persistent volumes is only allowed for PVCs for which their StorageClass\n// explicitly allows it.", "input": "go language", "output": "func (pvcr *persistentVolumeClaimResize) allowResize(pvc, oldPvc *api.PersistentVolumeClaim) bool {\n\tpvcStorageClass := apihelper.GetPersistentVolumeClaimClass(pvc)\n\toldPvcStorageClass := apihelper.GetPersistentVolumeClaimClass(oldPvc)\n\tif pvcStorageClass == \"\" || oldPvcStorageClass == \"\" || pvcStorageClass != oldPvcStorageClass {\n\t\treturn false\n\t}\n\tsc, err := pvcr.scLister.Get(pvcStorageClass)\n\tif err != nil {\n\t\treturn false\n\t}\n\tif sc.AllowVolumeExpansion != nil {\n\t\treturn *sc.AllowVolumeExpansion\n\t}\n\treturn false\n}"}, {"instruction": "// locatePartition returns the partition ID of the input record.", "input": "go language", "output": "func (t *partitionedTable) locatePartition(ctx sessionctx.Context, pi *model.PartitionInfo, r []types.Datum) (int64, error) {\n\tvar err error\n\tvar idx int\n\tswitch t.meta.Partition.Type {\n\tcase model.PartitionTypeRange:\n\t\tidx, err = t.locateRangePartition(ctx, pi, r)\n\tcase model.PartitionTypeHash:\n\t\tidx, err = t.locateHashPartition(ctx, pi, r)\n\t}\n\tif err != nil {\n\t\treturn 0, errors.Trace(err)\n\t}\n\treturn pi.Definitions[idx].ID, nil\n}"}, {"instruction": "// CalculatePatch calls the mutation function on the provided info object, and generates a strategic merge patch for\n// the changes in the object. Encoder must be able to encode the info into the appropriate destination type.\n// This function returns whether the mutation function made any change in the original object.", "input": "go language", "output": "func CalculatePatch(patch *Patch, encoder runtime.Encoder, mutateFn PatchFn) bool {\n\tpatch.Before, patch.Err = runtime.Encode(encoder, patch.Info.Object)\n\tpatch.After, patch.Err = mutateFn(patch.Info.Object)\n\tif patch.Err != nil {\n\t\treturn true\n\t}\n\tif patch.After == nil {\n\t\treturn false\n\t}\n\n\tpatch.Patch, patch.Err = strategicpatch.CreateTwoWayMergePatch(patch.Before, patch.After, patch.Info.Object)\n\treturn true\n}"}, {"instruction": "// Config return a cloud controller manager config objective", "input": "go language", "output": "func (o *CloudControllerManagerOptions) Config(allControllers, disabledByDefaultControllers []string) (*cloudcontrollerconfig.Config, error) {\n\tif err := o.Validate(allControllers, disabledByDefaultControllers); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := o.SecureServing.MaybeDefaultWithSelfSignedCerts(\"localhost\", nil, []net.IP{net.ParseIP(\"127.0.0.1\")}); err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating self-signed certificates: %v\", err)\n\t}\n\n\tc := &cloudcontrollerconfig.Config{}\n\tif err := o.ApplyTo(c, CloudControllerManagerUserAgent); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// Open initializes the secure channel.", "input": "go language", "output": "func (s *SecureChannelSession) Open() error {\n\tif s.iv != nil {\n\t\treturn fmt.Errorf(\"Session already opened\")\n\t}\n\n\tresponse, err := s.open()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Generate the encryption/mac key by hashing our shared secret,\n\t// pairing key, and the first bytes returned from the Open APDU.\n\tmd := sha512.New()\n\tmd.Write(s.secret)\n\tmd.Write(s.PairingKey)\n\tmd.Write(response.Data[:scSecretLength])\n\tkeyData := md.Sum(nil)\n\ts.sessionEncKey = keyData[:scSecretLength]\n\ts.sessionMacKey = keyData[scSecretLength : scSecretLength*2]\n\n\t// The IV is the last bytes returned from the Open APDU.\n\ts.iv = response.Data[scSecretLength:]\n\n\treturn s.mutuallyAuthenticate()\n}"}, {"instruction": "// Heap returns a pprof heap dump", "input": "go language", "output": "func (d *Debug) Heap() ([]byte, error) {\n\tr := d.c.newRequest(\"GET\", \"/debug/pprof/heap\")\n\t_, resp, err := d.c.doRequest(r)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error making request: %s\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// We return a raw response because we're just passing through a response\n\t// from the pprof handlers\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error decoding body: %s\", err)\n\t}\n\n\treturn body, nil\n}"}, {"instruction": "// AllocAutoID implements table.Table AllocAutoID interface.", "input": "go language", "output": "func (t *tableCommon) AllocAutoID(ctx sessionctx.Context) (int64, error) {\n\trowID, err := t.Allocator(ctx).Alloc(t.tableID)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tif t.meta.ShardRowIDBits > 0 {\n\t\t// Use max record ShardRowIDBits to check overflow.\n\t\tif OverflowShardBits(rowID, t.meta.MaxShardRowIDBits) {\n\t\t\t// If overflow, the rowID may be duplicated. For examples,\n\t\t\t// t.meta.ShardRowIDBits = 4\n\t\t\t// rowID = 0010111111111111111111111111111111111111111111111111111111111111\n\t\t\t// shard = 01000000000000000000000000000000000000000000000000000000000000000\n\t\t\t// will be duplicated with:\n\t\t\t// rowID = 0100111111111111111111111111111111111111111111111111111111111111\n\t\t\t// shard = 0010000000000000000000000000000000000000000000000000000000000000\n\t\t\treturn 0, autoid.ErrAutoincReadFailed\n\t\t}\n\t\ttxnCtx := ctx.GetSessionVars().TxnCtx\n\t\tif txnCtx.Shard == nil {\n\t\t\tshard := t.calcShard(txnCtx.StartTS)\n\t\t\ttxnCtx.Shard = &shard\n\t\t}\n\t\trowID |= *txnCtx.Shard\n\t}\n\treturn rowID, nil\n}"}, {"instruction": "// assignPod assigns the given pod to the given machine.", "input": "go language", "output": "func (r *BindingREST) assignPod(ctx context.Context, podID string, machine string, annotations map[string]string, dryRun bool) (err error) {\n\tif _, err = r.setPodHostAndAnnotations(ctx, podID, \"\", machine, annotations, dryRun); err != nil {\n\t\terr = storeerr.InterpretGetError(err, api.Resource(\"pods\"), podID)\n\t\terr = storeerr.InterpretUpdateError(err, api.Resource(\"pods\"), podID)\n\t\tif _, ok := err.(*errors.StatusError); !ok {\n\t\t\terr = errors.NewConflict(api.Resource(\"pods/binding\"), podID, err)\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// AuthenticateToken authenticates the token using a chain of authenticator.Token objects.", "input": "go language", "output": "func (authHandler *unionAuthTokenHandler) AuthenticateToken(ctx context.Context, token string) (*authenticator.Response, bool, error) {\n\tvar errlist []error\n\tfor _, currAuthRequestHandler := range authHandler.Handlers {\n\t\tinfo, ok, err := currAuthRequestHandler.AuthenticateToken(ctx, token)\n\t\tif err != nil {\n\t\t\tif authHandler.FailOnError {\n\t\t\t\treturn info, ok, err\n\t\t\t}\n\t\t\terrlist = append(errlist, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif ok {\n\t\t\treturn info, ok, err\n\t\t}\n\t}\n\n\treturn nil, false, utilerrors.NewAggregate(errlist)\n}"}, {"instruction": "// DeleteVolume uses the cloud entrypoint to delete specified volume", "input": "go language", "output": "func (util *DiskUtil) DeleteVolume(cd *cinderVolumeDeleter) error {\n\tcloud, err := cd.plugin.getCloudProvider()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err = cloud.DeleteVolume(cd.pdName); err != nil {\n\t\t// OpenStack cloud provider returns volume.tryAgainError when necessary,\n\t\t// no handling needed here.\n\t\tklog.V(2).Infof(\"Error deleting cinder volume %s: %v\", cd.pdName, err)\n\t\treturn err\n\t}\n\tklog.V(2).Infof(\"Successfully deleted cinder volume %s\", cd.pdName)\n\treturn nil\n}"}, {"instruction": "// localEvent is called when we receive an event on the local Serf", "input": "go language", "output": "func (c *Client) localEvent(event serf.UserEvent) {\n\t// Handle only consul events\n\tif !strings.HasPrefix(event.Name, \"consul:\") {\n\t\treturn\n\t}\n\n\tswitch name := event.Name; {\n\tcase name == newLeaderEvent:\n\t\tc.logger.Printf(\"[INFO] consul: New leader elected: %s\", event.Payload)\n\n\t\t// Trigger the callback\n\t\tif c.config.ServerUp != nil {\n\t\t\tc.config.ServerUp()\n\t\t}\n\tcase isUserEvent(name):\n\t\tevent.Name = rawUserEventName(name)\n\t\tc.logger.Printf(\"[DEBUG] consul: user event: %s\", event.Name)\n\n\t\t// Trigger the callback\n\t\tif c.config.UserEventHandler != nil {\n\t\t\tc.config.UserEventHandler(event)\n\t\t}\n\tdefault:\n\t\tif !c.handleEnterpriseUserEvents(event) {\n\t\t\tc.logger.Printf(\"[WARN] consul: Unhandled local event: %v\", event)\n\t\t}\n\t}\n}"}, {"instruction": "// New creates a new table convertor for the provided CRD column definition. If the printer definition cannot be parsed,\n// error will be returned along with a default table convertor.", "input": "go language", "output": "func New(crdColumns []apiextensions.CustomResourceColumnDefinition) (rest.TableConvertor, error) {\n\theaders := []metav1beta1.TableColumnDefinition{\n\t\t{Name: \"Name\", Type: \"string\", Format: \"name\", Description: swaggerMetadataDescriptions[\"name\"]},\n\t}\n\tc := &convertor{\n\t\theaders: headers,\n\t}\n\n\tfor _, col := range crdColumns {\n\t\tpath := jsonpath.New(col.Name)\n\t\tif err := path.Parse(fmt.Sprintf(\"{%s}\", col.JSONPath)); err != nil {\n\t\t\treturn c, fmt.Errorf(\"unrecognized column definition %q\", col.JSONPath)\n\t\t}\n\t\tpath.AllowMissingKeys(true)\n\n\t\tdesc := fmt.Sprintf(\"Custom resource definition column (in JSONPath format): %s\", col.JSONPath)\n\t\tif len(col.Description) > 0 {\n\t\t\tdesc = col.Description\n\t\t}\n\n\t\tc.additionalColumns = append(c.additionalColumns, path)\n\t\tc.headers = append(c.headers, metav1beta1.TableColumnDefinition{\n\t\t\tName:        col.Name,\n\t\t\tType:        col.Type,\n\t\t\tFormat:      col.Format,\n\t\t\tDescription: desc,\n\t\t\tPriority:    col.Priority,\n\t\t})\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// GetDriver initializes and returns the registered driver", "input": "go language", "output": "func GetDriver(name string, pg plugingetter.PluginGetter, config Options) (Driver, error) {\n\tif initFunc, exists := drivers[name]; exists {\n\t\treturn initFunc(filepath.Join(config.Root, name), config.DriverOptions, config.UIDMaps, config.GIDMaps)\n\t}\n\n\tpluginDriver, err := lookupPlugin(name, pg, config)\n\tif err == nil {\n\t\treturn pluginDriver, nil\n\t}\n\tlogrus.WithError(err).WithField(\"driver\", name).WithField(\"home-dir\", config.Root).Error(\"Failed to GetDriver graph\")\n\treturn nil, ErrNotSupported\n}"}, {"instruction": "// EvalReference evaluates the given reference in the receiving scope and\n// returns the resulting value. The value will be converted to the given type before\n// it is returned if possible, or else an error diagnostic will be produced\n// describing the conversion error.\n//\n// Pass an expected type of cty.DynamicPseudoType to skip automatic conversion\n// and just obtain the returned value directly.\n//\n// If the returned diagnostics contains errors then the result may be\n// incomplete, but will always be of the requested type.", "input": "go language", "output": "func (s *Scope) EvalReference(ref *addrs.Reference, wantType cty.Type) (cty.Value, tfdiags.Diagnostics) {\n\tvar diags tfdiags.Diagnostics\n\n\t// We cheat a bit here and just build an EvalContext for our requested\n\t// reference with the \"self\" address overridden, and then pull the \"self\"\n\t// result out of it to return.\n\tctx, ctxDiags := s.evalContext([]*addrs.Reference{ref}, ref.Subject)\n\tdiags = diags.Append(ctxDiags)\n\tval := ctx.Variables[\"self\"]\n\tif val == cty.NilVal {\n\t\tval = cty.DynamicVal\n\t}\n\n\tvar convErr error\n\tval, convErr = convert.Convert(val, wantType)\n\tif convErr != nil {\n\t\tval = cty.UnknownVal(wantType)\n\t\tdiags = diags.Append(&hcl.Diagnostic{\n\t\t\tSeverity: hcl.DiagError,\n\t\t\tSummary:  \"Incorrect value type\",\n\t\t\tDetail:   fmt.Sprintf(\"Invalid expression value: %s.\", tfdiags.FormatError(convErr)),\n\t\t\tSubject:  ref.SourceRange.ToHCL().Ptr(),\n\t\t})\n\t}\n\n\treturn val, diags\n}"}, {"instruction": "// findMaxScores returns the indexes of nodes in the \"priorityList\" that has the highest \"Score\".", "input": "go language", "output": "func findMaxScores(priorityList schedulerapi.HostPriorityList) []int {\n\tmaxScoreIndexes := make([]int, 0, len(priorityList)/2)\n\tmaxScore := priorityList[0].Score\n\tfor i, hp := range priorityList {\n\t\tif hp.Score > maxScore {\n\t\t\tmaxScore = hp.Score\n\t\t\tmaxScoreIndexes = maxScoreIndexes[:0]\n\t\t\tmaxScoreIndexes = append(maxScoreIndexes, i)\n\t\t} else if hp.Score == maxScore {\n\t\t\tmaxScoreIndexes = append(maxScoreIndexes, i)\n\t\t}\n\t}\n\treturn maxScoreIndexes\n}"}, {"instruction": "// FillNilSlices sets default value on slices that are still nil.", "input": "go language", "output": "func FillNilSlices(data interface{}) error {\n\ts := reflect.ValueOf(data).Elem()\n\tt := s.Type()\n\n\tfor i := 0; i < s.NumField(); i++ {\n\t\tf := s.Field(i)\n\t\ttag := t.Field(i).Tag\n\n\t\tv := tag.Get(\"default\")\n\t\tif len(v) > 0 {\n\t\t\tswitch f.Interface().(type) {\n\t\t\tcase []string:\n\t\t\t\tif f.IsNil() {\n\t\t\t\t\t// Treat the default as a comma separated slice\n\t\t\t\t\tvs := strings.Split(v, \",\")\n\t\t\t\t\tfor i := range vs {\n\t\t\t\t\t\tvs[i] = strings.TrimSpace(vs[i])\n\t\t\t\t\t}\n\n\t\t\t\t\trv := reflect.MakeSlice(reflect.TypeOf([]string{}), len(vs), len(vs))\n\t\t\t\t\tfor i, v := range vs {\n\t\t\t\t\t\trv.Index(i).SetString(v)\n\t\t\t\t\t}\n\t\t\t\t\tf.Set(rv)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// SupportsAttributes ignores all calls that do not deal with pod resources or storage requests (PVCs).\n// Also ignores any call that has a subresource defined.", "input": "go language", "output": "func (d *DefaultLimitRangerActions) SupportsAttributes(a admission.Attributes) bool {\n\tif a.GetSubresource() != \"\" {\n\t\treturn false\n\t}\n\n\t// Since containers and initContainers cannot currently be added, removed, or updated, it is unnecessary\n\t// to mutate and validate limitrange on pod updates. Trying to mutate containers or initContainers on a pod\n\t// update request will always fail pod validation because those fields are immutable once the object is created.\n\tif a.GetKind().GroupKind() == api.Kind(\"Pod\") && a.GetOperation() == admission.Update {\n\t\treturn false\n\t}\n\n\treturn a.GetKind().GroupKind() == api.Kind(\"Pod\") || a.GetKind().GroupKind() == api.Kind(\"PersistentVolumeClaim\")\n}"}, {"instruction": "// Uniq takes in a slice or array and returns a slice with subsequent\n// duplicate elements removed.", "input": "go language", "output": "func (ns *Namespace) Uniq(seq interface{}) (interface{}, error) {\n\tif seq == nil {\n\t\treturn make([]interface{}, 0), nil\n\t}\n\n\tv := reflect.ValueOf(seq)\n\tvar slice reflect.Value\n\n\tswitch v.Kind() {\n\tcase reflect.Slice:\n\t\tslice = reflect.MakeSlice(v.Type(), 0, 0)\n\tcase reflect.Array:\n\t\tslice = reflect.MakeSlice(reflect.SliceOf(v.Type().Elem()), 0, 0)\n\tdefault:\n\t\treturn nil, errors.Errorf(\"type %T not supported\", seq)\n\t}\n\n\tseen := make(map[interface{}]bool)\n\tfor i := 0; i < v.Len(); i++ {\n\t\tev, _ := indirectInterface(v.Index(i))\n\t\tif !ev.Type().Comparable() {\n\t\t\treturn nil, errors.New(\"elements must be comparable\")\n\t\t}\n\t\tkey := normalize(ev)\n\t\tif _, found := seen[key]; !found {\n\t\t\tslice = reflect.Append(slice, ev)\n\t\t\tseen[key] = true\n\t\t}\n\t}\n\n\treturn slice.Interface(), nil\n\n}"}, {"instruction": "// PrintSections prints the given names flag sets in sections, with the maximal given column number.\n// If cols is zero, lines are not wrapped.", "input": "go language", "output": "func PrintSections(w io.Writer, fss NamedFlagSets, cols int) {\n\tfor _, name := range fss.Order {\n\t\tfs := fss.FlagSets[name]\n\t\tif !fs.HasFlags() {\n\t\t\tcontinue\n\t\t}\n\n\t\twideFS := pflag.NewFlagSet(\"\", pflag.ExitOnError)\n\t\twideFS.AddFlagSet(fs)\n\n\t\tvar zzz string\n\t\tif cols > 24 {\n\t\t\tzzz = strings.Repeat(\"z\", cols-24)\n\t\t\twideFS.Int(zzz, 0, strings.Repeat(\"z\", cols-24))\n\t\t}\n\n\t\tvar buf bytes.Buffer\n\t\tfmt.Fprintf(&buf, \"\\n%s flags:\\n\\n%s\", strings.ToUpper(name[:1])+name[1:], wideFS.FlagUsagesWrapped(cols))\n\n\t\tif cols > 24 {\n\t\t\ti := strings.Index(buf.String(), zzz)\n\t\t\tlines := strings.Split(buf.String()[:i], \"\\n\")\n\t\t\tfmt.Fprint(w, strings.Join(lines[:len(lines)-1], \"\\n\"))\n\t\t\tfmt.Fprintln(w)\n\t\t} else {\n\t\t\tfmt.Fprint(w, buf.String())\n\t\t}\n\t}\n}"}, {"instruction": "// Set32 sets the 32 bytes starting at offset to the value of val, left-padded with zeroes to\n// 32 bytes.", "input": "go language", "output": "func (m *Memory) Set32(offset uint64, val *big.Int) {\n\t// length of store may never be less than offset + size.\n\t// The store should be resized PRIOR to setting the memory\n\tif offset+32 > uint64(len(m.store)) {\n\t\tpanic(\"invalid memory: store empty\")\n\t}\n\t// Zero the memory area\n\tcopy(m.store[offset:offset+32], []byte{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0})\n\t// Fill in relevant bits\n\tmath.ReadBits(val, m.store[offset:offset+32])\n}"}, {"instruction": "// saveToDb saves pool status to the database storage\n// (automatically called during shutdown)", "input": "go language", "output": "func (f *freeClientPool) saveToDb() {\n\tnow := f.clock.Now()\n\tstorage := freeClientPoolStorage{\n\t\tLogOffset: uint64(f.logOffset(now)),\n\t\tList:      make([]*freeClientPoolEntry, len(f.addressMap)),\n\t}\n\ti := 0\n\tfor _, e := range f.addressMap {\n\t\tif e.connected {\n\t\t\tf.calcLogUsage(e, now)\n\t\t}\n\t\tstorage.List[i] = e\n\t\ti++\n\t}\n\tenc, err := rlp.EncodeToBytes(storage)\n\tif err != nil {\n\t\tlog.Error(\"Failed to encode client list\", \"err\", err)\n\t} else {\n\t\tf.db.Put([]byte(\"freeClientPool\"), enc)\n\t}\n}"}, {"instruction": "// createSessionLocal is used to create a new session in a foreign datacenter\n// This is more complex since the local agent cannot be used to create\n// a session, and we must associate with a node in the remote datacenter.", "input": "go language", "output": "func (c *cmd) createSessionForeign() (string, error) {\n\t// Look for a remote node to bind to\n\thealth := c.apiclient.Health()\n\tservices, _, err := health.Service(\"consul\", \"\", true, nil)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"Failed to find Consul server in remote datacenter: %v\", err)\n\t}\n\tif len(services) == 0 {\n\t\treturn \"\", fmt.Errorf(\"Failed to find Consul server in remote datacenter\")\n\t}\n\tnode := services[0].Node.Node\n\tif c.conf.verbose {\n\t\tc.UI.Info(fmt.Sprintf(\"Binding session to remote node %s@%s\", node, c.http.Datacenter()))\n\t}\n\n\tsession := c.apiclient.Session()\n\tse := api.SessionEntry{\n\t\tName:     fmt.Sprintf(\"Remote Exec via %s@%s\", c.conf.localNode, c.conf.localDC),\n\t\tNode:     node,\n\t\tChecks:   []string{},\n\t\tBehavior: api.SessionBehaviorDelete,\n\t\tTTL:      rExecTTL,\n\t}\n\tid, _, err := session.CreateNoChecks(&se, nil)\n\treturn id, err\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *SubjectAccessReviewSpec) DeepCopyInto(out *SubjectAccessReviewSpec) {\n\t*out = *in\n\tif in.ResourceAttributes != nil {\n\t\tin, out := &in.ResourceAttributes, &out.ResourceAttributes\n\t\t*out = new(ResourceAttributes)\n\t\t**out = **in\n\t}\n\tif in.NonResourceAttributes != nil {\n\t\tin, out := &in.NonResourceAttributes, &out.NonResourceAttributes\n\t\t*out = new(NonResourceAttributes)\n\t\t**out = **in\n\t}\n\tif in.Groups != nil {\n\t\tin, out := &in.Groups, &out.Groups\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.Extra != nil {\n\t\tin, out := &in.Extra, &out.Extra\n\t\t*out = make(map[string]ExtraValue, len(*in))\n\t\tfor key, val := range *in {\n\t\t\tvar outVal []string\n\t\t\tif val == nil {\n\t\t\t\t(*out)[key] = nil\n\t\t\t} else {\n\t\t\t\tin, out := &val, &outVal\n\t\t\t\t*out = make(ExtraValue, len(*in))\n\t\t\t\tcopy(*out, *in)\n\t\t\t}\n\t\t\t(*out)[key] = outVal\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// AddSymKeyFromPassword generates the key from password, stores it, and returns its id.", "input": "go language", "output": "func (whisper *Whisper) AddSymKeyFromPassword(password string) (string, error) {\n\tid, err := GenerateRandomID()\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to generate ID: %s\", err)\n\t}\n\tif whisper.HasSymKey(id) {\n\t\treturn \"\", fmt.Errorf(\"failed to generate unique ID\")\n\t}\n\n\t// kdf should run no less than 0.1 seconds on an average computer,\n\t// because it's an once in a session experience\n\tderived := pbkdf2.Key([]byte(password), nil, 65356, aesKeyLength, sha256.New)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\twhisper.keyMu.Lock()\n\tdefer whisper.keyMu.Unlock()\n\n\t// double check is necessary, because deriveKeyMaterial() is very slow\n\tif whisper.symKeys[id] != nil {\n\t\treturn \"\", fmt.Errorf(\"critical error: failed to generate unique ID\")\n\t}\n\twhisper.symKeys[id] = derived\n\treturn id, nil\n}"}, {"instruction": "// GetLoadBalancer returns whether the specified load balancer exists, and\n// if so, what its status is.", "input": "go language", "output": "func (az *Cloud) GetLoadBalancer(ctx context.Context, clusterName string, service *v1.Service) (status *v1.LoadBalancerStatus, exists bool, err error) {\n\t_, status, exists, err = az.getServiceLoadBalancer(service, clusterName, nil, false)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tif !exists {\n\t\tserviceName := getServiceName(service)\n\t\tklog.V(5).Infof(\"getloadbalancer (cluster:%s) (service:%s) - doesn't exist\", clusterName, serviceName)\n\t\treturn nil, false, nil\n\t}\n\treturn status, true, nil\n}"}, {"instruction": "// SubmitTransaction is a helper function that submits tx to txPool and logs a message.", "input": "go language", "output": "func SubmitTransaction(ctx context.Context, b Backend, tx *types.Transaction) (common.Hash, error) {\n\tif err := b.SendTx(ctx, tx); err != nil {\n\t\treturn common.Hash{}, err\n\t}\n\tif tx.To() == nil {\n\t\tsigner := types.MakeSigner(b.ChainConfig(), b.CurrentBlock().Number())\n\t\tfrom, err := types.Sender(signer, tx)\n\t\tif err != nil {\n\t\t\treturn common.Hash{}, err\n\t\t}\n\t\taddr := crypto.CreateAddress(from, tx.Nonce())\n\t\tlog.Info(\"Submitted contract creation\", \"fullhash\", tx.Hash().Hex(), \"contract\", addr.Hex())\n\t} else {\n\t\tlog.Info(\"Submitted transaction\", \"fullhash\", tx.Hash().Hex(), \"recipient\", tx.To())\n\t}\n\treturn tx.Hash(), nil\n}"}, {"instruction": "// newLightFetcher creates a new light fetcher", "input": "go language", "output": "func newLightFetcher(pm *ProtocolManager) *lightFetcher {\n\tf := &lightFetcher{\n\t\tpm:             pm,\n\t\tchain:          pm.blockchain.(*light.LightChain),\n\t\todr:            pm.odr,\n\t\tpeers:          make(map[*peer]*fetcherPeerInfo),\n\t\tdeliverChn:     make(chan fetchResponse, 100),\n\t\trequested:      make(map[uint64]fetchRequest),\n\t\ttimeoutChn:     make(chan uint64),\n\t\trequestChn:     make(chan bool, 100),\n\t\tsyncDone:       make(chan *peer),\n\t\tmaxConfirmedTd: big.NewInt(0),\n\t}\n\tpm.peers.notify(f)\n\n\tf.pm.wg.Add(1)\n\tgo f.syncLoop()\n\treturn f\n}"}, {"instruction": "// getPodSandboxID gets the sandbox id by podUID and returns ([]sandboxID, error).\n// Param state could be nil in order to get all sandboxes belonging to same pod.", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) getSandboxIDByPodUID(podUID kubetypes.UID, state *runtimeapi.PodSandboxState) ([]string, error) {\n\tfilter := &runtimeapi.PodSandboxFilter{\n\t\tLabelSelector: map[string]string{types.KubernetesPodUIDLabel: string(podUID)},\n\t}\n\tif state != nil {\n\t\tfilter.State = &runtimeapi.PodSandboxStateValue{\n\t\t\tState: *state,\n\t\t}\n\t}\n\tsandboxes, err := m.runtimeService.ListPodSandbox(filter)\n\tif err != nil {\n\t\tklog.Errorf(\"ListPodSandbox with pod UID %q failed: %v\", podUID, err)\n\t\treturn nil, err\n\t}\n\n\tif len(sandboxes) == 0 {\n\t\treturn nil, nil\n\t}\n\n\t// Sort with newest first.\n\tsandboxIDs := make([]string, len(sandboxes))\n\tsort.Sort(podSandboxByCreated(sandboxes))\n\tfor i, s := range sandboxes {\n\t\tsandboxIDs[i] = s.Id\n\t}\n\n\treturn sandboxIDs, nil\n}"}, {"instruction": "// UnmarshalJSON decodes the byte slice whether it's a string or an array of\n// strings. This method is needed to implement json.Unmarshaler.", "input": "go language", "output": "func (e *StrSlice) UnmarshalJSON(b []byte) error {\n\tif len(b) == 0 {\n\t\t// With no input, we preserve the existing value by returning nil and\n\t\t// leaving the target alone. This allows defining default values for\n\t\t// the type.\n\t\treturn nil\n\t}\n\n\tp := make([]string, 0, 1)\n\tif err := json.Unmarshal(b, &p); err != nil {\n\t\tvar s string\n\t\tif err := json.Unmarshal(b, &s); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tp = append(p, s)\n\t}\n\n\t*e = p\n\treturn nil\n}"}, {"instruction": "// ValidateFinalizers tests if the finalizers name are valid, and if there are conflicting finalizers.", "input": "go language", "output": "func ValidateFinalizers(finalizers []string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\thasFinalizerOrphanDependents := false\n\thasFinalizerDeleteDependents := false\n\tfor _, finalizer := range finalizers {\n\t\tallErrs = append(allErrs, ValidateFinalizerName(finalizer, fldPath)...)\n\t\tif finalizer == metav1.FinalizerOrphanDependents {\n\t\t\thasFinalizerOrphanDependents = true\n\t\t}\n\t\tif finalizer == metav1.FinalizerDeleteDependents {\n\t\t\thasFinalizerDeleteDependents = true\n\t\t}\n\t}\n\tif hasFinalizerDeleteDependents && hasFinalizerOrphanDependents {\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, finalizers, fmt.Sprintf(\"finalizer %s and %s cannot be both set\", metav1.FinalizerOrphanDependents, metav1.FinalizerDeleteDependents)))\n\t}\n\treturn allErrs\n}"}, {"instruction": "// MarkForFSResize marks pvc with condition that indicates a fs resize is pending", "input": "go language", "output": "func (resizeMap *volumeResizeMap) MarkForFSResize(pvcr *PVCWithResizeRequest) error {\n\tpvcCondition := v1.PersistentVolumeClaimCondition{\n\t\tType:               v1.PersistentVolumeClaimFileSystemResizePending,\n\t\tStatus:             v1.ConditionTrue,\n\t\tLastTransitionTime: metav1.Now(),\n\t\tMessage:            \"Waiting for user to (re-)start a pod to finish file system resize of volume on node.\",\n\t}\n\tconditions := []v1.PersistentVolumeClaimCondition{pvcCondition}\n\tnewPVC := pvcr.PVC.DeepCopy()\n\tnewPVC = util.MergeResizeConditionOnPVC(newPVC, conditions)\n\t_, err := util.PatchPVCStatus(pvcr.PVC /*oldPVC*/, newPVC, resizeMap.kubeClient)\n\treturn err\n}"}, {"instruction": "// expandOptionalAddrs expands the go-sockaddr template in s and returns the\n// result as a list of strings. If s does not contain a go-sockaddr template,\n// the result list will contain the input string as a single element with no\n// error set. In contrast to expandAddrs, expandOptionalAddrs does not validate\n// if the result contains valid addresses and returns a list of strings.\n// However, if the expansion of the go-sockaddr template fails an error is set.", "input": "go language", "output": "func (b *Builder) expandOptionalAddrs(name string, s *string) []string {\n\tif s == nil || *s == \"\" {\n\t\treturn nil\n\t}\n\n\tx, err := template.Parse(*s)\n\tif err != nil {\n\t\tb.err = multierror.Append(b.err, fmt.Errorf(\"%s: error parsing %q: %s\", name, *s, err))\n\t\treturn nil\n\t}\n\n\tif x != *s {\n\t\t// A template has been expanded, split the results from go-sockaddr\n\t\treturn strings.Fields(x)\n\t} else {\n\t\t// No template has been expanded, pass through the input\n\t\treturn []string{*s}\n\t}\n}"}, {"instruction": "// rewriteWithPreprocess is for handling the situation that we need to adjust the input ast tree\n// before really using its node in `expressionRewriter.Leave`. In that case, we first call\n// er.preprocess(expr), which returns a new expr. Then we use the new expr in `Leave`.", "input": "go language", "output": "func (b *PlanBuilder) rewriteWithPreprocess(exprNode ast.ExprNode, p LogicalPlan, aggMapper map[*ast.AggregateFuncExpr]int, asScalar bool, preprocess func(ast.Node) ast.Node) (expression.Expression, LogicalPlan, error) {\n\tb.rewriterCounter++\n\tdefer func() { b.rewriterCounter-- }()\n\n\trewriter := b.getExpressionRewriter(p)\n\t// The rewriter maybe is obtained from \"b.rewriterPool\", \"rewriter.err\" is\n\t// not nil means certain previous procedure has not handled this error.\n\t// Here we give us one more chance to make a correct behavior by handling\n\t// this missed error.\n\tif rewriter.err != nil {\n\t\treturn nil, nil, rewriter.err\n\t}\n\n\trewriter.aggrMap = aggMapper\n\trewriter.asScalar = asScalar\n\trewriter.preprocess = preprocess\n\n\texpr, resultPlan, err := b.rewriteExprNode(rewriter, exprNode, asScalar)\n\treturn expr, resultPlan, err\n}"}, {"instruction": "// Dial establishes the gRPC communication with the picked up plugin socket. https://godoc.org/google.golang.org/grpc#Dial", "input": "go language", "output": "func dial(unixSocketPath string, timeout time.Duration) (registerapi.RegistrationClient, *grpc.ClientConn, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), timeout)\n\tdefer cancel()\n\n\tc, err := grpc.DialContext(ctx, unixSocketPath, grpc.WithInsecure(), grpc.WithBlock(),\n\t\tgrpc.WithDialer(func(addr string, timeout time.Duration) (net.Conn, error) {\n\t\t\treturn net.DialTimeout(\"unix\", addr, timeout)\n\t\t}),\n\t)\n\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to dial socket %s, err: %v\", unixSocketPath, err)\n\t}\n\n\treturn registerapi.NewRegistrationClient(c), c, nil\n}"}, {"instruction": "// GetProposalHash1 gets the proposal hash bytes after sanitizing the\n// chaincode proposal payload according to the rules of visibility", "input": "go language", "output": "func GetProposalHash1(header *common.Header, ccPropPayl []byte, visibility []byte) ([]byte, error) {\n\t// check for nil argument\n\tif header == nil ||\n\t\theader.ChannelHeader == nil ||\n\t\theader.SignatureHeader == nil ||\n\t\tccPropPayl == nil {\n\t\treturn nil, errors.New(\"nil arguments\")\n\t}\n\n\t// unmarshal the chaincode proposal payload\n\tcpp, err := GetChaincodeProposalPayload(ccPropPayl)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tppBytes, err := GetBytesProposalPayloadForTx(cpp, visibility)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thash2, err := factory.GetDefault().GetHash(&bccsp.SHA256Opts{})\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, \"error instantiating hash function\")\n\t}\n\t// hash the serialized Channel Header object\n\thash2.Write(header.ChannelHeader)\n\t// hash the serialized Signature Header object\n\thash2.Write(header.SignatureHeader)\n\t// hash of the part of the chaincode proposal payload that will go to the tx\n\thash2.Write(ppBytes)\n\treturn hash2.Sum(nil), nil\n}"}, {"instruction": "// composeGlobalPrivUpdate composes update stmt assignment list string for global scope privilege update.", "input": "go language", "output": "func composeGlobalPrivUpdate(priv mysql.PrivilegeType, value string) (string, error) {\n\tif priv == mysql.AllPriv {\n\t\tstrs := make([]string, 0, len(mysql.Priv2UserCol))\n\t\tfor _, v := range mysql.Priv2UserCol {\n\t\t\tstrs = append(strs, fmt.Sprintf(`%s='%s'`, v, value))\n\t\t}\n\t\treturn strings.Join(strs, \", \"), nil\n\t}\n\tcol, ok := mysql.Priv2UserCol[priv]\n\tif !ok {\n\t\treturn \"\", errors.Errorf(\"Unknown priv: %v\", priv)\n\t}\n\treturn fmt.Sprintf(`%s='%s'`, col, value), nil\n}"}, {"instruction": "// NewPathSpecWithBaseBaseFsProvided creats a new PathSpec from the given filesystems and language.\n// If an existing BaseFs is provided, parts of that is reused.", "input": "go language", "output": "func NewPathSpecWithBaseBaseFsProvided(fs *hugofs.Fs, cfg config.Provider, baseBaseFs *filesystems.BaseFs) (*PathSpec, error) {\n\n\tp, err := paths.New(fs, cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar options []func(*filesystems.BaseFs) error\n\tif baseBaseFs != nil {\n\t\toptions = []func(*filesystems.BaseFs) error{\n\t\t\tfilesystems.WithBaseFs(baseBaseFs),\n\t\t}\n\t}\n\tbfs, err := filesystems.NewBase(p, options...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tps := &PathSpec{\n\t\tPaths:           p,\n\t\tBaseFs:          bfs,\n\t\tFs:              fs,\n\t\tCfg:             cfg,\n\t\tProcessingStats: NewProcessingStats(p.Lang()),\n\t}\n\n\tbasePath := ps.BaseURL.Path()\n\tif basePath != \"\" && basePath != \"/\" {\n\t\tps.BasePath = basePath\n\t}\n\n\treturn ps, nil\n}"}, {"instruction": "// New builds a new IPWhiteLister given a list of CIDR-Strings to whitelist", "input": "go language", "output": "func New(ctx context.Context, next http.Handler, config config.IPWhiteList, name string) (http.Handler, error) {\n\tlogger := middlewares.GetLogger(ctx, name, typeName)\n\tlogger.Debug(\"Creating middleware\")\n\n\tif len(config.SourceRange) == 0 {\n\t\treturn nil, errors.New(\"sourceRange is empty, IPWhiteLister not created\")\n\t}\n\n\tchecker, err := ip.NewChecker(config.SourceRange)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot parse CIDR whitelist %s: %v\", config.SourceRange, err)\n\t}\n\n\tstrategy, err := config.IPStrategy.Get()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlogger.Debugf(\"Setting up IPWhiteLister with sourceRange: %s\", config.SourceRange)\n\treturn &ipWhiteLister{\n\t\tstrategy:    strategy,\n\t\twhiteLister: checker,\n\t\tnext:        next,\n\t\tname:        name,\n\t}, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *NetworkPolicyPeer) DeepCopyInto(out *NetworkPolicyPeer) {\n\t*out = *in\n\tif in.PodSelector != nil {\n\t\tin, out := &in.PodSelector, &out.PodSelector\n\t\t*out = new(metav1.LabelSelector)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.NamespaceSelector != nil {\n\t\tin, out := &in.NamespaceSelector, &out.NamespaceSelector\n\t\t*out = new(metav1.LabelSelector)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\tif in.IPBlock != nil {\n\t\tin, out := &in.IPBlock, &out.IPBlock\n\t\t*out = new(IPBlock)\n\t\t(*in).DeepCopyInto(*out)\n\t}\n\treturn\n}"}, {"instruction": "// MetadataFromContext extracts Metadata from a given context.Context", "input": "go language", "output": "func MetadataFromContext(ctx context.Context) Metadata {\n\tm := Metadata{\"NA\", \"NA\", \"NA\", \"\", \"\"} // batman\n\n\tif v := ctx.Value(\"remote\"); v != nil {\n\t\tm.Remote = v.(string)\n\t}\n\tif v := ctx.Value(\"scheme\"); v != nil {\n\t\tm.Scheme = v.(string)\n\t}\n\tif v := ctx.Value(\"local\"); v != nil {\n\t\tm.Local = v.(string)\n\t}\n\tif v := ctx.Value(\"Origin\"); v != nil {\n\t\tm.Origin = v.(string)\n\t}\n\tif v := ctx.Value(\"User-Agent\"); v != nil {\n\t\tm.UserAgent = v.(string)\n\t}\n\treturn m\n}"}, {"instruction": "// InitializeStdio is called by libcontainerd to connect the stdio.", "input": "go language", "output": "func (container *Container) InitializeStdio(iop *cio.DirectIO) (cio.IO, error) {\n\tif err := container.startLogging(); err != nil {\n\t\tcontainer.Reset(false)\n\t\treturn nil, err\n\t}\n\n\tcontainer.StreamConfig.CopyToPipe(iop)\n\n\tif container.StreamConfig.Stdin() == nil && !container.Config.Tty {\n\t\tif iop.Stdin != nil {\n\t\t\tif err := iop.Stdin.Close(); err != nil {\n\t\t\t\tlogrus.Warnf(\"error closing stdin: %+v\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn &rio{IO: iop, sc: container.StreamConfig}, nil\n}"}, {"instruction": "// IsCorruptedMnt return true if err is about corrupted mount point", "input": "go language", "output": "func IsCorruptedMnt(err error) bool {\n\tif err == nil {\n\t\treturn false\n\t}\n\tvar underlyingError error\n\tswitch pe := err.(type) {\n\tcase nil:\n\t\treturn false\n\tcase *os.PathError:\n\t\tunderlyingError = pe.Err\n\tcase *os.LinkError:\n\t\tunderlyingError = pe.Err\n\tcase *os.SyscallError:\n\t\tunderlyingError = pe.Err\n\t}\n\n\treturn underlyingError == syscall.ENOTCONN || underlyingError == syscall.ESTALE || underlyingError == syscall.EIO || underlyingError == syscall.EACCES\n}"}, {"instruction": "// BatchDelete deletes key-value pairs from TiKV", "input": "go language", "output": "func (c *RawKVClient) BatchDelete(keys [][]byte) error {\n\tstart := time.Now()\n\tdefer func() {\n\t\ttikvRawkvCmdHistogramWithBatchDelete.Observe(time.Since(start).Seconds())\n\t}()\n\n\tbo := NewBackoffer(context.Background(), rawkvMaxBackoff)\n\tresp, err := c.sendBatchReq(bo, keys, tikvrpc.CmdRawBatchDelete)\n\tif err != nil {\n\t\treturn errors.Trace(err)\n\t}\n\tcmdResp := resp.RawBatchDelete\n\tif cmdResp == nil {\n\t\treturn errors.Trace(ErrBodyMissing)\n\t}\n\tif cmdResp.GetError() != \"\" {\n\t\treturn errors.New(cmdResp.GetError())\n\t}\n\treturn nil\n}"}, {"instruction": "// GetContainerLogs get container logs directly from docker daemon.", "input": "go language", "output": "func (d *dockerService) GetContainerLogs(_ context.Context, pod *v1.Pod, containerID kubecontainer.ContainerID, logOptions *v1.PodLogOptions, stdout, stderr io.Writer) error {\n\tcontainer, err := d.client.InspectContainer(containerID.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar since int64\n\tif logOptions.SinceSeconds != nil {\n\t\tt := metav1.Now().Add(-time.Duration(*logOptions.SinceSeconds) * time.Second)\n\t\tsince = t.Unix()\n\t}\n\tif logOptions.SinceTime != nil {\n\t\tsince = logOptions.SinceTime.Unix()\n\t}\n\topts := dockertypes.ContainerLogsOptions{\n\t\tShowStdout: true,\n\t\tShowStderr: true,\n\t\tSince:      strconv.FormatInt(since, 10),\n\t\tTimestamps: logOptions.Timestamps,\n\t\tFollow:     logOptions.Follow,\n\t}\n\tif logOptions.TailLines != nil {\n\t\topts.Tail = strconv.FormatInt(*logOptions.TailLines, 10)\n\t}\n\n\tsopts := libdocker.StreamOptions{\n\t\tOutputStream: stdout,\n\t\tErrorStream:  stderr,\n\t\tRawTerminal:  container.Config.Tty,\n\t}\n\treturn d.client.Logs(containerID.ID, opts, sopts)\n}"}, {"instruction": "// NewVolumeBinder sets up the volume binding library and binding queue", "input": "go language", "output": "func NewVolumeBinder(\n\tclient clientset.Interface,\n\tnodeInformer coreinformers.NodeInformer,\n\tpvcInformer coreinformers.PersistentVolumeClaimInformer,\n\tpvInformer coreinformers.PersistentVolumeInformer,\n\tstorageClassInformer storageinformers.StorageClassInformer,\n\tbindTimeout time.Duration) *VolumeBinder {\n\n\treturn &VolumeBinder{\n\t\tBinder: persistentvolume.NewVolumeBinder(client, nodeInformer, pvcInformer, pvInformer, storageClassInformer, bindTimeout),\n\t}\n}"}, {"instruction": "// CreateOrUpdateRouteTable invokes az.RouteTablesClient.CreateOrUpdate with exponential backoff retry", "input": "go language", "output": "func (az *Cloud) CreateOrUpdateRouteTable(routeTable network.RouteTable) error {\n\tif az.Config.shouldOmitCloudProviderBackoff() {\n\t\tctx, cancel := getContextWithCancel()\n\t\tdefer cancel()\n\n\t\tresp, err := az.RouteTablesClient.CreateOrUpdate(ctx, az.RouteTableResourceGroup, az.RouteTableName, routeTable)\n\t\treturn az.processHTTPResponse(nil, \"\", resp, err)\n\t}\n\n\treturn az.createOrUpdateRouteTableWithRetry(routeTable)\n}"}, {"instruction": "// RemoveMember notifies an etcd cluster to remove an existing member", "input": "go language", "output": "func (c *Client) RemoveMember(id uint64) ([]Member, error) {\n\tcli, err := clientv3.New(clientv3.Config{\n\t\tEndpoints:   c.Endpoints,\n\t\tDialTimeout: 30 * time.Second,\n\t\tTLS:         c.TLS,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer cli.Close()\n\n\t// Remove an existing member from the cluster\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tresp, err := cli.MemberRemove(ctx, id)\n\tcancel()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Returns the updated list of etcd members\n\tret := []Member{}\n\tfor _, m := range resp.Members {\n\t\tret = append(ret, Member{Name: m.Name, PeerURL: m.PeerURLs[0]})\n\t}\n\n\treturn ret, nil\n}"}, {"instruction": "// GetResourcesAndPairs retrieves resources and \"KEY=VALUE or KEY-\" pair args from given args", "input": "go language", "output": "func GetResourcesAndPairs(args []string, pairType string) (resources []string, pairArgs []string, err error) {\n\tfoundPair := false\n\tfor _, s := range args {\n\t\tnonResource := (strings.Contains(s, \"=\") && s[0] != '=') || (strings.HasSuffix(s, \"-\") && s != \"-\")\n\t\tswitch {\n\t\tcase !foundPair && nonResource:\n\t\t\tfoundPair = true\n\t\t\tfallthrough\n\t\tcase foundPair && nonResource:\n\t\t\tpairArgs = append(pairArgs, s)\n\t\tcase !foundPair && !nonResource:\n\t\t\tresources = append(resources, s)\n\t\tcase foundPair && !nonResource:\n\t\t\terr = fmt.Errorf(\"all resources must be specified before %s changes: %s\", pairType, s)\n\t\t\treturn\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// A Zero date is a signal that the name can not be parsed.\n// This follows the format as outlined in Jekyll, https://jekyllrb.com/docs/posts/:\n// \"Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers\"", "input": "go language", "output": "func dateAndSlugFromBaseFilename(name string) (time.Time, string) {\n\twithoutExt, _ := helpers.FileAndExt(name)\n\n\tif len(withoutExt) < 10 {\n\t\t// This can not be a date.\n\t\treturn time.Time{}, \"\"\n\t}\n\n\t// Note: Hugo currently have no custom timezone support.\n\t// We will have to revisit this when that is in place.\n\td, err := time.Parse(\"2006-01-02\", withoutExt[:10])\n\tif err != nil {\n\t\treturn time.Time{}, \"\"\n\t}\n\n\t// Be a little lenient with the format here.\n\tslug := strings.Trim(withoutExt[10:], \" -_\")\n\n\treturn d, slug\n}"}, {"instruction": "// evalDecimal evals ABS(value).\n// See https://dev.mysql.com/doc/refman/5.7/en/mathematical-functions.html#function_abs", "input": "go language", "output": "func (b *builtinAbsDecSig) evalDecimal(row chunk.Row) (*types.MyDecimal, bool, error) {\n\tval, isNull, err := b.args[0].EvalDecimal(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn nil, isNull, err\n\t}\n\tto := new(types.MyDecimal)\n\tif !val.IsNegative() {\n\t\t*to = *val\n\t} else {\n\t\tif err = types.DecimalSub(new(types.MyDecimal), val, to); err != nil {\n\t\t\treturn nil, true, err\n\t\t}\n\t}\n\treturn to, false, nil\n}"}, {"instruction": "// MakeChainDatabase open an LevelDB using the flags passed to the client and will hard crash if it fails.", "input": "go language", "output": "func MakeChainDatabase(ctx *cli.Context, stack *node.Node) ethdb.Database {\n\tvar (\n\t\tcache   = ctx.GlobalInt(CacheFlag.Name) * ctx.GlobalInt(CacheDatabaseFlag.Name) / 100\n\t\thandles = makeDatabaseHandles()\n\t)\n\tname := \"chaindata\"\n\tif ctx.GlobalString(SyncModeFlag.Name) == \"light\" {\n\t\tname = \"lightchaindata\"\n\t}\n\tchainDb, err := stack.OpenDatabase(name, cache, handles, \"\")\n\tif err != nil {\n\t\tFatalf(\"Could not open database: %v\", err)\n\t}\n\treturn chainDb\n}"}, {"instruction": "// gvkWithDefaults returns group kind and version defaulting from provided default", "input": "go language", "output": "func gvkWithDefaults(actual, defaultGVK schema.GroupVersionKind) schema.GroupVersionKind {\n\tif len(actual.Kind) == 0 {\n\t\tactual.Kind = defaultGVK.Kind\n\t}\n\tif len(actual.Version) == 0 && len(actual.Group) == 0 {\n\t\tactual.Group = defaultGVK.Group\n\t\tactual.Version = defaultGVK.Version\n\t}\n\tif len(actual.Version) == 0 && actual.Group == defaultGVK.Group {\n\t\tactual.Version = defaultGVK.Version\n\t}\n\treturn actual\n}"}, {"instruction": "// podDiskUsage aggregates pod disk usage and inode consumption for the specified stats to measure.", "input": "go language", "output": "func podDiskUsage(podStats statsapi.PodStats, pod *v1.Pod, statsToMeasure []fsStatsType) (v1.ResourceList, error) {\n\tdisk := resource.Quantity{Format: resource.BinarySI}\n\tinodes := resource.Quantity{Format: resource.DecimalSI}\n\n\tcontainerUsageList := containerUsage(podStats, statsToMeasure)\n\tdisk.Add(containerUsageList[v1.ResourceEphemeralStorage])\n\tinodes.Add(containerUsageList[resourceInodes])\n\n\tif hasFsStatsType(statsToMeasure, fsStatsLocalVolumeSource) {\n\t\tvolumeNames := localVolumeNames(pod)\n\t\tpodLocalVolumeUsageList := podLocalVolumeUsage(volumeNames, podStats)\n\t\tdisk.Add(podLocalVolumeUsageList[v1.ResourceEphemeralStorage])\n\t\tinodes.Add(podLocalVolumeUsageList[resourceInodes])\n\t}\n\treturn v1.ResourceList{\n\t\tv1.ResourceEphemeralStorage: disk,\n\t\tresourceInodes:              inodes,\n\t}, nil\n}"}, {"instruction": "// isVolumeUsed returns list of pods that use given PV.", "input": "go language", "output": "func (ctrl *PersistentVolumeController) isVolumeUsed(pv *v1.PersistentVolume) ([]string, bool, error) {\n\tif pv.Spec.ClaimRef == nil {\n\t\treturn nil, false, nil\n\t}\n\tclaimName := pv.Spec.ClaimRef.Name\n\n\tpodNames := sets.NewString()\n\tpods, err := ctrl.podLister.Pods(pv.Spec.ClaimRef.Namespace).List(labels.Everything())\n\tif err != nil {\n\t\treturn nil, false, fmt.Errorf(\"error listing pods: %s\", err)\n\t}\n\tfor _, pod := range pods {\n\t\tif util.IsPodTerminated(pod, pod.Status) {\n\t\t\tcontinue\n\t\t}\n\t\tfor i := range pod.Spec.Volumes {\n\t\t\tusedPV := &pod.Spec.Volumes[i]\n\t\t\tif usedPV.PersistentVolumeClaim != nil && usedPV.PersistentVolumeClaim.ClaimName == claimName {\n\t\t\t\tpodNames.Insert(pod.Namespace + \"/\" + pod.Name)\n\t\t\t}\n\t\t}\n\t}\n\treturn podNames.List(), podNames.Len() != 0, nil\n}"}, {"instruction": "// loadChartRepositories reads the repositories.yaml, and then builds a map of\n// ChartRepositories.\n//\n// The key is the local name (which is only present in the repositories.yaml).", "input": "go language", "output": "func (m *Manager) loadChartRepositories() (map[string]*repo.ChartRepository, error) {\n\tindices := map[string]*repo.ChartRepository{}\n\trepoyaml := m.HelmHome.RepositoryFile()\n\n\t// Load repositories.yaml file\n\trf, err := repo.LoadRepositoriesFile(repoyaml)\n\tif err != nil {\n\t\treturn indices, fmt.Errorf(\"failed to load %s: %s\", repoyaml, err)\n\t}\n\n\tfor _, re := range rf.Repositories {\n\t\tlname := re.Name\n\t\tcacheindex := m.HelmHome.CacheIndex(lname)\n\t\tindex, err := repo.LoadIndexFile(cacheindex)\n\t\tif err != nil {\n\t\t\treturn indices, err\n\t\t}\n\n\t\t// TODO: use constructor\n\t\tcr := &repo.ChartRepository{\n\t\t\tConfig:    re,\n\t\t\tIndexFile: index,\n\t\t}\n\t\tindices[lname] = cr\n\t}\n\treturn indices, nil\n}"}, {"instruction": "// NewEditOptions returns an initialized EditOptions instance", "input": "go language", "output": "func NewEditOptions(editMode EditMode, ioStreams genericclioptions.IOStreams) *EditOptions {\n\treturn &EditOptions{\n\t\tRecordFlags: genericclioptions.NewRecordFlags(),\n\n\t\tEditMode: editMode,\n\n\t\tPrintFlags: genericclioptions.NewPrintFlags(\"edited\").WithTypeSetter(scheme.Scheme),\n\n\t\teditPrinterOptions: &editPrinterOptions{\n\t\t\t// create new editor-specific PrintFlags, with all\n\t\t\t// output flags disabled, except json / yaml\n\t\t\tprintFlags: (&genericclioptions.PrintFlags{\n\t\t\t\tJSONYamlPrintFlags: genericclioptions.NewJSONYamlPrintFlags(),\n\t\t\t}).WithDefaultOutput(\"yaml\"),\n\t\t\text:       \".yaml\",\n\t\t\taddHeader: true,\n\t\t},\n\n\t\tWindowsLineEndings: goruntime.GOOS == \"windows\",\n\n\t\tRecorder: genericclioptions.NoopRecorder{},\n\n\t\tIOStreams: ioStreams,\n\t}\n}"}, {"instruction": "// NewWorker instantiates a local worker", "input": "go language", "output": "func NewWorker(opt Opt) (*Worker, error) {\n\tsm, err := source.NewManager()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcm := opt.CacheManager\n\tsm.Register(opt.ImageSource)\n\n\tgs, err := git.NewSource(git.Opt{\n\t\tCacheAccessor: cm,\n\t\tMetadataStore: opt.MetadataStore,\n\t})\n\tif err == nil {\n\t\tsm.Register(gs)\n\t} else {\n\t\tlogrus.Warnf(\"Could not register builder git source: %s\", err)\n\t}\n\n\ths, err := http.NewSource(http.Opt{\n\t\tCacheAccessor: cm,\n\t\tMetadataStore: opt.MetadataStore,\n\t\tTransport:     opt.Transport,\n\t})\n\tif err == nil {\n\t\tsm.Register(hs)\n\t} else {\n\t\tlogrus.Warnf(\"Could not register builder http source: %s\", err)\n\t}\n\n\tss, err := local.NewSource(local.Opt{\n\t\tCacheAccessor: cm,\n\t\tMetadataStore: opt.MetadataStore,\n\t})\n\tif err == nil {\n\t\tsm.Register(ss)\n\t} else {\n\t\tlogrus.Warnf(\"Could not register builder local source: %s\", err)\n\t}\n\n\treturn &Worker{\n\t\tOpt:           opt,\n\t\tSourceManager: sm,\n\t}, nil\n}"}, {"instruction": "// ObjectKinds returns all possible group,version,kind of the go object, true if the\n// object is considered unversioned, or an error if it's not a pointer or is unregistered.", "input": "go language", "output": "func (s *Scheme) ObjectKinds(obj Object) ([]schema.GroupVersionKind, bool, error) {\n\t// Unstructured objects are always considered to have their declared GVK\n\tif _, ok := obj.(Unstructured); ok {\n\t\t// we require that the GVK be populated in order to recognize the object\n\t\tgvk := obj.GetObjectKind().GroupVersionKind()\n\t\tif len(gvk.Kind) == 0 {\n\t\t\treturn nil, false, NewMissingKindErr(\"unstructured object has no kind\")\n\t\t}\n\t\tif len(gvk.Version) == 0 {\n\t\t\treturn nil, false, NewMissingVersionErr(\"unstructured object has no version\")\n\t\t}\n\t\treturn []schema.GroupVersionKind{gvk}, false, nil\n\t}\n\n\tv, err := conversion.EnforcePtr(obj)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\tt := v.Type()\n\n\tgvks, ok := s.typeToGVK[t]\n\tif !ok {\n\t\treturn nil, false, NewNotRegisteredErrForType(s.schemeName, t)\n\t}\n\t_, unversionedType := s.unversionedTypes[t]\n\n\treturn gvks, unversionedType, nil\n}"}, {"instruction": "// writeToTar writes a single file to a tar archive.", "input": "go language", "output": "func writeToTar(out *tar.Writer, name string, body []byte) error {\n\t// TODO: Do we need to create dummy parent directory names if none exist?\n\th := &tar.Header{\n\t\tName:    filepath.ToSlash(name),\n\t\tMode:    0755,\n\t\tSize:    int64(len(body)),\n\t\tModTime: time.Now(),\n\t}\n\tif err := out.WriteHeader(h); err != nil {\n\t\treturn err\n\t}\n\tif _, err := out.Write(body); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// validateParameters tests that keys are qualified names and that provisionerParameter are < 256kB.", "input": "go language", "output": "func validateParameters(params map[string]string, fldPath *field.Path) field.ErrorList {\n\tvar totalSize int64\n\tallErrs := field.ErrorList{}\n\n\tif len(params) > maxProvisionerParameterLen {\n\t\tallErrs = append(allErrs, field.TooLong(fldPath, \"Provisioner Parameters exceeded max allowed\", maxProvisionerParameterLen))\n\t\treturn allErrs\n\t}\n\n\tfor k, v := range params {\n\t\tif len(k) < 1 {\n\t\t\tallErrs = append(allErrs, field.Invalid(fldPath, k, \"field can not be empty.\"))\n\t\t}\n\t\ttotalSize += (int64)(len(k)) + (int64)(len(v))\n\t}\n\n\tif totalSize > maxProvisionerParameterSize {\n\t\tallErrs = append(allErrs, field.TooLong(fldPath, \"\", maxProvisionerParameterSize))\n\t}\n\treturn allErrs\n}"}, {"instruction": "// New creates a new ledger factory", "input": "go language", "output": "func New(directory string) blockledger.Factory {\n\tlogger.Debugf(\"Initializing ledger at: %s\", directory)\n\tif err := os.MkdirAll(directory, 0700); err != nil {\n\t\tlogger.Panicf(\"Could not create directory %s: %s\", directory, err)\n\t}\n\n\tjlf := &jsonLedgerFactory{\n\t\tdirectory: directory,\n\t\tledgers:   make(map[string]blockledger.ReadWriter),\n\t}\n\n\tinfos, err := ioutil.ReadDir(jlf.directory)\n\tif err != nil {\n\t\tlogger.Panicf(\"Error reading from directory %s while initializing ledger: %s\", jlf.directory, err)\n\t}\n\n\tfor _, info := range infos {\n\t\tif !info.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tvar chainID string\n\t\t_, err := fmt.Sscanf(info.Name(), chainDirectoryFormatString, &chainID)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tjlf.GetOrCreate(chainID)\n\t}\n\n\treturn jlf\n}"}, {"instruction": "// ValidateSocketPath validates format of socket path or url", "input": "go language", "output": "func ValidateSocketPath(socket string, fldPath *field.Path) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\tu, err := url.Parse(socket)\n\tif err != nil {\n\t\treturn append(allErrs, field.Invalid(fldPath, socket, fmt.Sprintf(\"URL parsing error: %v\", err)))\n\t}\n\n\tif u.Scheme == \"\" {\n\t\tif !filepath.IsAbs(u.Path) {\n\t\t\treturn append(allErrs, field.Invalid(fldPath, socket, fmt.Sprintf(\"path is not absolute: %s\", socket)))\n\t\t}\n\t} else if u.Scheme != kubeadmapiv1beta2.DefaultUrlScheme {\n\t\treturn append(allErrs, field.Invalid(fldPath, socket, fmt.Sprintf(\"URL scheme %s is not supported\", u.Scheme)))\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// Transformer returns a func that can be used in the transformer publishing chain.\n// TODO(bep) minify config etc", "input": "go language", "output": "func (m Client) Transformer(mediatype media.Type) transform.Transformer {\n\t_, params, min := m.m.Match(mediatype.Type())\n\tif min == nil {\n\t\t// No minifier for this MIME type\n\t\treturn nil\n\t}\n\n\treturn func(ft transform.FromTo) error {\n\t\t// Note that the source io.Reader will already be buffered, but it implements\n\t\t// the Bytes() method, which is recognized by the Minify library.\n\t\treturn min.Minify(m.m, ft.To(), ft.From(), params)\n\t}\n}"}, {"instruction": "// GetLackHandles gets the handles in expectedHandles but not in obtainedHandlesMap.", "input": "go language", "output": "func GetLackHandles(expectedHandles []int64, obtainedHandlesMap map[int64]struct{}) []int64 {\n\tdiffCnt := len(expectedHandles) - len(obtainedHandlesMap)\n\tdiffHandles := make([]int64, 0, diffCnt)\n\tvar cnt int\n\tfor _, handle := range expectedHandles {\n\t\tisExist := false\n\t\tif _, ok := obtainedHandlesMap[handle]; ok {\n\t\t\tdelete(obtainedHandlesMap, handle)\n\t\t\tisExist = true\n\t\t}\n\t\tif !isExist {\n\t\t\tdiffHandles = append(diffHandles, handle)\n\t\t\tcnt++\n\t\t\tif cnt == diffCnt {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\treturn diffHandles\n}"}, {"instruction": "// GetPvtDataAndBlockByNum provides a mock function with given fields: seqNum", "input": "go language", "output": "func (_m *Committer) GetPvtDataAndBlockByNum(seqNum uint64) (*ledger.BlockAndPvtData, error) {\n\tret := _m.Called(seqNum)\n\n\tvar r0 *ledger.BlockAndPvtData\n\tif rf, ok := ret.Get(0).(func(uint64) *ledger.BlockAndPvtData); ok {\n\t\tr0 = rf(seqNum)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*ledger.BlockAndPvtData)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(uint64) error); ok {\n\t\tr1 = rf(seqNum)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// extractToDeleteItems takes a list and\n// returns 2 lists: one contains items that should be kept and the other contains items to be deleted.", "input": "go language", "output": "func extractToDeleteItems(l []interface{}) ([]interface{}, []interface{}, error) {\n\tvar nonDelete, toDelete []interface{}\n\tfor _, v := range l {\n\t\tm, ok := v.(map[string]interface{})\n\t\tif !ok {\n\t\t\treturn nil, nil, mergepatch.ErrBadArgType(m, v)\n\t\t}\n\n\t\tdirective, foundDirective := m[directiveMarker]\n\t\tif foundDirective && directive == deleteDirective {\n\t\t\ttoDelete = append(toDelete, v)\n\t\t} else {\n\t\t\tnonDelete = append(nonDelete, v)\n\t\t}\n\t}\n\treturn nonDelete, toDelete, nil\n}"}, {"instruction": "// GetLabelsForVolume gets the volume labels for a volume", "input": "go language", "output": "func (c *Cloud) GetLabelsForVolume(ctx context.Context, pv *v1.PersistentVolume) (map[string]string, error) {\n\t// Ignore if not AWSElasticBlockStore.\n\tif pv.Spec.AWSElasticBlockStore == nil {\n\t\treturn nil, nil\n\t}\n\n\t// Ignore any volumes that are being provisioned\n\tif pv.Spec.AWSElasticBlockStore.VolumeID == cloudvolume.ProvisionedVolumeName {\n\t\treturn nil, nil\n\t}\n\n\tspec := KubernetesVolumeID(pv.Spec.AWSElasticBlockStore.VolumeID)\n\tlabels, err := c.GetVolumeLabels(spec)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn labels, nil\n}"}, {"instruction": "// AddFlags adds flags related to NamespaceController for controller manager to the specified FlagSet.", "input": "go language", "output": "func (o *NamespaceControllerOptions) AddFlags(fs *pflag.FlagSet) {\n\tif o == nil {\n\t\treturn\n\t}\n\n\tfs.DurationVar(&o.NamespaceSyncPeriod.Duration, \"namespace-sync-period\", o.NamespaceSyncPeriod.Duration, \"The period for syncing namespace life-cycle updates\")\n\tfs.Int32Var(&o.ConcurrentNamespaceSyncs, \"concurrent-namespace-syncs\", o.ConcurrentNamespaceSyncs, \"The number of namespace objects that are allowed to sync concurrently. Larger number = more responsive namespace termination, but more CPU (and network) load\")\n}"}, {"instruction": "// RenderResult renders the explain result as specified format.", "input": "go language", "output": "func (e *Explain) RenderResult() error {\n\tif e.StmtPlan == nil {\n\t\treturn nil\n\t}\n\tswitch strings.ToLower(e.Format) {\n\tcase ast.ExplainFormatROW:\n\t\te.explainedPlans = map[int]bool{}\n\t\te.explainPlanInRowFormat(e.StmtPlan.(PhysicalPlan), \"root\", \"\", true)\n\tcase ast.ExplainFormatDOT:\n\t\te.prepareDotInfo(e.StmtPlan.(PhysicalPlan))\n\tdefault:\n\t\treturn errors.Errorf(\"explain format '%s' is not supported now\", e.Format)\n\t}\n\treturn nil\n}"}, {"instruction": "// PendingPods returns all the pending pods in the queue. This function is\n// used for debugging purposes in the scheduler cache dumper and comparer.", "input": "go language", "output": "func (p *PriorityQueue) PendingPods() []*v1.Pod {\n\tp.lock.RLock()\n\tdefer p.lock.RUnlock()\n\tresult := []*v1.Pod{}\n\tfor _, pInfo := range p.activeQ.List() {\n\t\tresult = append(result, pInfo.(*podInfo).pod)\n\t}\n\tfor _, pInfo := range p.podBackoffQ.List() {\n\t\tresult = append(result, pInfo.(*podInfo).pod)\n\t}\n\tfor _, pInfo := range p.unschedulableQ.podInfoMap {\n\t\tresult = append(result, pInfo.pod)\n\t}\n\treturn result\n}"}, {"instruction": "// exceedMemoryRequests compares whether or not pods' memory usage exceeds their requests", "input": "go language", "output": "func exceedMemoryRequests(stats statsFunc) cmpFunc {\n\treturn func(p1, p2 *v1.Pod) int {\n\t\tp1Stats, p1Found := stats(p1)\n\t\tp2Stats, p2Found := stats(p2)\n\t\tif !p1Found || !p2Found {\n\t\t\t// prioritize evicting the pod for which no stats were found\n\t\t\treturn cmpBool(!p1Found, !p2Found)\n\t\t}\n\n\t\tp1Memory := memoryUsage(p1Stats.Memory)\n\t\tp2Memory := memoryUsage(p2Stats.Memory)\n\t\tp1ExceedsRequests := p1Memory.Cmp(podRequest(p1, v1.ResourceMemory)) == 1\n\t\tp2ExceedsRequests := p2Memory.Cmp(podRequest(p2, v1.ResourceMemory)) == 1\n\t\t// prioritize evicting the pod which exceeds its requests\n\t\treturn cmpBool(p1ExceedsRequests, p2ExceedsRequests)\n\t}\n}"}, {"instruction": "// NodeUnpublishVolume implements csi method", "input": "go language", "output": "func (f *NodeClient) NodeUnpublishVolume(ctx context.Context, req *csipb.NodeUnpublishVolumeRequest, opts ...grpc.CallOption) (*csipb.NodeUnpublishVolumeResponse, error) {\n\tif f.nextErr != nil {\n\t\treturn nil, f.nextErr\n\t}\n\n\tif req.GetVolumeId() == \"\" {\n\t\treturn nil, errors.New(\"missing volume id\")\n\t}\n\tif req.GetTargetPath() == \"\" {\n\t\treturn nil, errors.New(\"missing target path\")\n\t}\n\tdelete(f.nodePublishedVolumes, req.GetVolumeId())\n\treturn &csipb.NodeUnpublishVolumeResponse{}, nil\n}"}, {"instruction": "// NewCmdWait returns a cobra command for waiting", "input": "go language", "output": "func NewCmdWait(restClientGetter genericclioptions.RESTClientGetter, streams genericclioptions.IOStreams) *cobra.Command {\n\tflags := NewWaitFlags(restClientGetter, streams)\n\n\tcmd := &cobra.Command{\n\t\tUse:     \"wait ([-f FILENAME] | resource.group/resource.name | resource.group [(-l label | --all)]) [--for=delete|--for condition=available]\",\n\t\tShort:   \"Experimental: Wait for a specific condition on one or many resources.\",\n\t\tLong:    waitLong,\n\t\tExample: waitExample,\n\n\t\tDisableFlagsInUseLine: true,\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\to, err := flags.ToOptions(args)\n\t\t\tcmdutil.CheckErr(err)\n\t\t\terr = o.RunWait()\n\t\t\tcmdutil.CheckErr(err)\n\t\t},\n\t\tSuggestFor: []string{\"list\", \"ps\"},\n\t}\n\n\tflags.AddFlags(cmd)\n\n\treturn cmd\n}"}, {"instruction": "// Copy data from a remote to a destination directory.", "input": "go language", "output": "func (cst *ClientSessionTransport) Copy(ctx context.Context, id fscache.RemoteIdentifier, dest string, cu filesync.CacheUpdater) error {\n\tcsi, ok := id.(*ClientSessionSourceIdentifier)\n\tif !ok {\n\t\treturn errors.New(\"invalid identifier for client session\")\n\t}\n\n\treturn filesync.FSSync(ctx, csi.caller, filesync.FSSendRequestOpt{\n\t\tIncludePatterns: csi.includePatterns,\n\t\tDestDir:         dest,\n\t\tCacheUpdater:    cu,\n\t})\n}"}, {"instruction": "// reloadShutdownTimeout updates configuration with daemon shutdown timeout option\n// and updates the passed attributes", "input": "go language", "output": "func (daemon *Daemon) reloadShutdownTimeout(conf *config.Config, attributes map[string]string) {\n\t// update corresponding configuration\n\tif conf.IsValueSet(\"shutdown-timeout\") {\n\t\tdaemon.configStore.ShutdownTimeout = conf.ShutdownTimeout\n\t\tlogrus.Debugf(\"Reset Shutdown Timeout: %d\", daemon.configStore.ShutdownTimeout)\n\t}\n\n\t// prepare reload event attributes with updatable configurations\n\tattributes[\"shutdown-timeout\"] = fmt.Sprintf(\"%d\", daemon.configStore.ShutdownTimeout)\n}"}, {"instruction": "// verifySandboxStatus verified whether all required fields are set in PodSandboxStatus.", "input": "go language", "output": "func verifySandboxStatus(status *runtimeapi.PodSandboxStatus) error {\n\tif status.Id == \"\" {\n\t\treturn fmt.Errorf(\"Id is not set\")\n\t}\n\n\tif status.Metadata == nil {\n\t\treturn fmt.Errorf(\"Metadata is not set\")\n\t}\n\n\tmetadata := status.Metadata\n\tif metadata.Name == \"\" || metadata.Namespace == \"\" || metadata.Uid == \"\" {\n\t\treturn fmt.Errorf(\"Name, Namespace or Uid is not in metadata %q\", metadata)\n\t}\n\n\tif status.CreatedAt == 0 {\n\t\treturn fmt.Errorf(\"CreatedAt is not set\")\n\t}\n\n\treturn nil\n}"}, {"instruction": "// SetNamedPortsOfInstanceGroup sets the list of named ports on a given instance group", "input": "go language", "output": "func (g *Cloud) SetNamedPortsOfInstanceGroup(igName, zone string, namedPorts []*compute.NamedPort) error {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\tmc := newInstanceGroupMetricContext(\"set_namedports\", zone)\n\treq := &compute.InstanceGroupsSetNamedPortsRequest{NamedPorts: namedPorts}\n\treturn mc.Observe(g.c.InstanceGroups().SetNamedPorts(ctx, meta.ZonalKey(igName, zone), req))\n}"}, {"instruction": "// setClientCapacity sets the priority capacity assigned to a given client", "input": "go language", "output": "func (v *priorityClientPool) setClientCapacity(id enode.ID, cap uint64) error {\n\tv.lock.Lock()\n\tdefer v.lock.Unlock()\n\n\tc := v.clients[id]\n\tif c.cap == cap {\n\t\treturn nil\n\t}\n\tif c.connected {\n\t\tif v.totalConnectedCap+cap > v.totalCap+c.cap {\n\t\t\treturn ErrTotalCap\n\t\t}\n\t\tif c.cap == 0 {\n\t\t\tif v.child != nil {\n\t\t\t\tv.child.unregisterPeer(c.peer)\n\t\t\t}\n\t\t\tv.priorityCount++\n\t\t}\n\t\tif cap == 0 {\n\t\t\tv.priorityCount--\n\t\t}\n\t\tv.totalConnectedCap += cap - c.cap\n\t\tif v.child != nil {\n\t\t\tv.child.setLimits(v.maxPeers-v.priorityCount, v.totalCap-v.totalConnectedCap)\n\t\t}\n\t\tif cap == 0 {\n\t\t\tif v.child != nil {\n\t\t\t\tv.child.registerPeer(c.peer)\n\t\t\t}\n\t\t\tc.peer.updateCapacity(v.freeClientCap)\n\t\t} else {\n\t\t\tc.peer.updateCapacity(cap)\n\t\t}\n\t}\n\tif cap != 0 || c.connected {\n\t\tc.cap = cap\n\t\tv.clients[id] = c\n\t} else {\n\t\tdelete(v.clients, id)\n\t}\n\treturn nil\n}"}, {"instruction": "// SelectorFromValidatedSet returns a Selector which will match exactly the given Set.\n// A nil and empty Sets are considered equivalent to Everything().\n// It assumes that Set is already validated and doesn't do any validation.", "input": "go language", "output": "func SelectorFromValidatedSet(ls Set) Selector {\n\tif ls == nil || len(ls) == 0 {\n\t\treturn internalSelector{}\n\t}\n\tvar requirements internalSelector\n\tfor label, value := range ls {\n\t\trequirements = append(requirements, Requirement{key: label, operator: selection.Equals, strValues: []string{value}})\n\t}\n\t// sort to have deterministic string representation\n\tsort.Sort(ByKey(requirements))\n\treturn requirements\n}"}, {"instruction": "// NewControllerRevision returns a ControllerRevision with a ControllerRef pointing to parent and indicating that\n// parent is of parentKind. The ControllerRevision has labels matching template labels, contains Data equal to data, and\n// has a Revision equal to revision. The collisionCount is used when creating the name of the ControllerRevision\n// so the name is likely unique. If the returned error is nil, the returned ControllerRevision is valid. If the\n// returned error is not nil, the returned ControllerRevision is invalid for use.", "input": "go language", "output": "func NewControllerRevision(parent metav1.Object,\n\tparentKind schema.GroupVersionKind,\n\ttemplateLabels map[string]string,\n\tdata runtime.RawExtension,\n\trevision int64,\n\tcollisionCount *int32) (*apps.ControllerRevision, error) {\n\tlabelMap := make(map[string]string)\n\tfor k, v := range templateLabels {\n\t\tlabelMap[k] = v\n\t}\n\tcr := &apps.ControllerRevision{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tLabels:          labelMap,\n\t\t\tOwnerReferences: []metav1.OwnerReference{*metav1.NewControllerRef(parent, parentKind)},\n\t\t},\n\t\tData:     data,\n\t\tRevision: revision,\n\t}\n\thash := HashControllerRevision(cr, collisionCount)\n\tcr.Name = ControllerRevisionName(parent.GetName(), hash)\n\tcr.Labels[ControllerRevisionHashLabel] = hash\n\treturn cr, nil\n}"}, {"instruction": "// Create a container", "input": "go language", "output": "func (c *containerManager) Create(runConfig *container.Config, hostConfig *container.HostConfig) (container.ContainerCreateCreatedBody, error) {\n\tcontainer, err := c.backend.ContainerCreateIgnoreImagesArgsEscaped(types.ContainerCreateConfig{\n\t\tConfig:     runConfig,\n\t\tHostConfig: hostConfig,\n\t})\n\tif err != nil {\n\t\treturn container, err\n\t}\n\tc.tmpContainers[container.ID] = struct{}{}\n\treturn container, nil\n}"}, {"instruction": "// newTimestampDir creates a new timestamp directory", "input": "go language", "output": "func (w *AtomicWriter) newTimestampDir() (string, error) {\n\ttsDir, err := ioutil.TempDir(w.targetDir, time.Now().UTC().Format(\"..2006_01_02_15_04_05.\"))\n\tif err != nil {\n\t\tklog.Errorf(\"%s: unable to create new temp directory: %v\", w.logContext, err)\n\t\treturn \"\", err\n\t}\n\n\t// 0755 permissions are needed to allow 'group' and 'other' to recurse the\n\t// directory tree.  do a chmod here to ensure that permissions are set correctly\n\t// regardless of the process' umask.\n\terr = os.Chmod(tsDir, 0755)\n\tif err != nil {\n\t\tklog.Errorf(\"%s: unable to set mode on new temp directory: %v\", w.logContext, err)\n\t\treturn \"\", err\n\t}\n\n\treturn tsDir, nil\n}"}, {"instruction": "// Encrypt encrypts a payload with a given secret.", "input": "go language", "output": "func Encrypt(payload []byte, secret string) ([]byte, error) {\n\tsalt := GetRandomString(saltLength)\n\n\tkey := encryptionKeyToBytes(secret, salt)\n\tblock, err := aes.NewCipher(key)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The IV needs to be unique, but not secure. Therefore it's common to\n\t// include it at the beginning of the ciphertext.\n\tciphertext := make([]byte, saltLength+aes.BlockSize+len(payload))\n\tcopy(ciphertext[:saltLength], []byte(salt))\n\tiv := ciphertext[saltLength : saltLength+aes.BlockSize]\n\tif _, err := io.ReadFull(rand.Reader, iv); err != nil {\n\t\treturn nil, err\n\t}\n\n\tstream := cipher.NewCFBEncrypter(block, iv)\n\tstream.XORKeyStream(ciphertext[saltLength+aes.BlockSize:], payload)\n\n\treturn ciphertext, nil\n}"}, {"instruction": "// Validate validates all the required options.", "input": "go language", "output": "func (o *Options) Validate() []error {\n\tvar errs []error\n\n\tif err := validation.ValidateKubeSchedulerConfiguration(&o.ComponentConfig).ToAggregate(); err != nil {\n\t\terrs = append(errs, err.Errors()...)\n\t}\n\terrs = append(errs, o.SecureServing.Validate()...)\n\terrs = append(errs, o.CombinedInsecureServing.Validate()...)\n\terrs = append(errs, o.Authentication.Validate()...)\n\terrs = append(errs, o.Authorization.Validate()...)\n\terrs = append(errs, o.Deprecated.Validate()...)\n\n\treturn errs\n}"}, {"instruction": "// SigningIdentityForRequest provides a mock function with given fields: _a0", "input": "go language", "output": "func (_m *SigningIdentityFetcher) SigningIdentityForRequest(_a0 *peer.SignedProposal) (endorsement.SigningIdentity, error) {\n\tret := _m.Called(_a0)\n\n\tvar r0 endorsement.SigningIdentity\n\tif rf, ok := ret.Get(0).(func(*peer.SignedProposal) endorsement.SigningIdentity); ok {\n\t\tr0 = rf(_a0)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(endorsement.SigningIdentity)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(*peer.SignedProposal) error); ok {\n\t\tr1 = rf(_a0)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// init registers the windows graph drivers to the register.", "input": "go language", "output": "func init() {\n\tgraphdriver.Register(\"windowsfilter\", InitFilter)\n\t// DOCKER_WINDOWSFILTER_NOREEXEC allows for inline processing which makes\n\t// debugging issues in the re-exec codepath significantly easier.\n\tif os.Getenv(\"DOCKER_WINDOWSFILTER_NOREEXEC\") != \"\" {\n\t\tlogrus.Warnf(\"WindowsGraphDriver is set to not re-exec. This is intended for debugging purposes only.\")\n\t\tnoreexec = true\n\t} else {\n\t\treexec.Register(\"docker-windows-write-layer\", writeLayerReexec)\n\t}\n}"}, {"instruction": "// Upload performs the upload of the directory and default path", "input": "go language", "output": "func (d *DirectoryUploader) Upload(upload UploadFn) error {\n\treturn filepath.Walk(d.Dir, func(path string, f os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif f.IsDir() {\n\t\t\treturn nil\n\t\t}\n\t\tfile, err := Open(path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\trelPath, err := filepath.Rel(d.Dir, path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfile.Path = filepath.ToSlash(relPath)\n\t\treturn upload(file)\n\t})\n}"}, {"instruction": "// Create takes the representation of a customResourceDefinition and creates it.  Returns the server's representation of the customResourceDefinition, and an error, if there is any.", "input": "go language", "output": "func (c *FakeCustomResourceDefinitions) Create(customResourceDefinition *v1beta1.CustomResourceDefinition) (result *v1beta1.CustomResourceDefinition, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootCreateAction(customresourcedefinitionsResource, customResourceDefinition), &v1beta1.CustomResourceDefinition{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*v1beta1.CustomResourceDefinition), err\n}"}, {"instruction": "// Get the remote state.", "input": "go language", "output": "func (r *remoteClient) Get() (*remote.Payload, error) {\n\tctx := context.Background()\n\n\tsv, err := r.client.StateVersions.Current(ctx, r.workspace.ID)\n\tif err != nil {\n\t\tif err == tfe.ErrResourceNotFound {\n\t\t\t// If no state exists, then return nil.\n\t\t\treturn nil, nil\n\t\t}\n\t\treturn nil, fmt.Errorf(\"Error retrieving state: %v\", err)\n\t}\n\n\tstate, err := r.client.StateVersions.Download(ctx, sv.DownloadURL)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error downloading state: %v\", err)\n\t}\n\n\t// If the state is empty, then return nil.\n\tif len(state) == 0 {\n\t\treturn nil, nil\n\t}\n\n\t// Get the MD5 checksum of the state.\n\tsum := md5.Sum(state)\n\n\treturn &remote.Payload{\n\t\tData: state,\n\t\tMD5:  sum[:],\n\t}, nil\n}"}, {"instruction": "// String implements fmt.Stringer and sanitizes sensitive fields of\n// TLSClientConfig to prevent accidental leaking via logs.", "input": "go language", "output": "func (c TLSClientConfig) String() string {\n\tcc := sanitizedTLSClientConfig{\n\t\tInsecure:   c.Insecure,\n\t\tServerName: c.ServerName,\n\t\tCertFile:   c.CertFile,\n\t\tKeyFile:    c.KeyFile,\n\t\tCAFile:     c.CAFile,\n\t\tCertData:   c.CertData,\n\t\tKeyData:    c.KeyData,\n\t\tCAData:     c.CAData,\n\t}\n\t// Explicitly mark non-empty credential fields as redacted.\n\tif len(cc.CertData) != 0 {\n\t\tcc.CertData = []byte(\"--- TRUNCATED ---\")\n\t}\n\tif len(cc.KeyData) != 0 {\n\t\tcc.KeyData = []byte(\"--- REDACTED ---\")\n\t}\n\treturn fmt.Sprintf(\"%#v\", cc)\n}"}, {"instruction": "// updateSchemaVersion increments the schema version by 1 and sets SchemaDiff.", "input": "go language", "output": "func updateSchemaVersion(t *meta.Meta, job *model.Job) (int64, error) {\n\tschemaVersion, err := t.GenSchemaVersion()\n\tif err != nil {\n\t\treturn 0, errors.Trace(err)\n\t}\n\tdiff := &model.SchemaDiff{\n\t\tVersion:  schemaVersion,\n\t\tType:     job.Type,\n\t\tSchemaID: job.SchemaID,\n\t}\n\tif job.Type == model.ActionTruncateTable {\n\t\t// Truncate table has two table ID, should be handled differently.\n\t\terr = job.DecodeArgs(&diff.TableID)\n\t\tif err != nil {\n\t\t\treturn 0, errors.Trace(err)\n\t\t}\n\t\tdiff.OldTableID = job.TableID\n\t} else if job.Type == model.ActionRenameTable {\n\t\terr = job.DecodeArgs(&diff.OldSchemaID)\n\t\tif err != nil {\n\t\t\treturn 0, errors.Trace(err)\n\t\t}\n\t\tdiff.TableID = job.TableID\n\t} else {\n\t\tdiff.TableID = job.TableID\n\t}\n\terr = t.SetSchemaDiff(diff)\n\treturn schemaVersion, errors.Trace(err)\n}"}, {"instruction": "// createTxidRangeEndKey returns a endKey to do a range query on transient store using txid", "input": "go language", "output": "func createTxidRangeEndKey(txid string) []byte {\n\tvar endKey []byte\n\tendKey = append(endKey, prwsetPrefix)\n\tendKey = append(endKey, compositeKeySep)\n\tendKey = append(endKey, []byte(txid)...)\n\t// As txid is a fixed length string (i.e., 128 bits long UUID), 0xff can be used as a stopper.\n\t// Otherwise a super-string of a given txid would also fall under the end key of range query.\n\tendKey = append(endKey, byte(0xff))\n\treturn endKey\n}"}, {"instruction": "// parseConfig returns a parsed configuration for an Azure cloudprovider config file", "input": "go language", "output": "func parseConfig(configReader io.Reader) (*Config, error) {\n\tvar config Config\n\n\tif configReader == nil {\n\t\treturn &config, nil\n\t}\n\n\tconfigContents, err := ioutil.ReadAll(configReader)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = yaml.Unmarshal(configContents, &config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The resource group name may be in different cases from different Azure APIs, hence it is converted to lower here.\n\t// See more context at https://github.com/kubernetes/kubernetes/issues/71994.\n\tconfig.ResourceGroup = strings.ToLower(config.ResourceGroup)\n\treturn &config, nil\n}"}, {"instruction": "// DropDisabledFields removes disabled fields from the pod security policy spec.\n// This should be called from PrepareForCreate/PrepareForUpdate for all resources containing a od security policy spec.", "input": "go language", "output": "func DropDisabledFields(pspSpec, oldPSPSpec *policy.PodSecurityPolicySpec) {\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.ProcMountType) && !allowedProcMountTypesInUse(oldPSPSpec) {\n\t\tpspSpec.AllowedProcMountTypes = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.RunAsGroup) && (oldPSPSpec == nil || oldPSPSpec.RunAsGroup == nil) {\n\t\tpspSpec.RunAsGroup = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.Sysctls) && !sysctlsInUse(oldPSPSpec) {\n\t\tpspSpec.AllowedUnsafeSysctls = nil\n\t\tpspSpec.ForbiddenSysctls = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.CSIInlineVolume) {\n\t\tpspSpec.AllowedCSIDrivers = nil\n\t}\n\tif !utilfeature.DefaultFeatureGate.Enabled(features.RuntimeClass) &&\n\t\t(oldPSPSpec == nil || oldPSPSpec.RuntimeClass == nil) {\n\t\tpspSpec.RuntimeClass = nil\n\t}\n}"}, {"instruction": "// PeersInfo returns an array of metadata objects describing connected peers.", "input": "go language", "output": "func (srv *Server) PeersInfo() []*PeerInfo {\n\t// Gather all the generic and sub-protocol specific infos\n\tinfos := make([]*PeerInfo, 0, srv.PeerCount())\n\tfor _, peer := range srv.Peers() {\n\t\tif peer != nil {\n\t\t\tinfos = append(infos, peer.Info())\n\t\t}\n\t}\n\t// Sort the result array alphabetically by node identifier\n\tfor i := 0; i < len(infos); i++ {\n\t\tfor j := i + 1; j < len(infos); j++ {\n\t\t\tif infos[i].ID > infos[j].ID {\n\t\t\t\tinfos[i], infos[j] = infos[j], infos[i]\n\t\t\t}\n\t\t}\n\t}\n\treturn infos\n}"}, {"instruction": "// PrepareForCreate clears the status of a CustomResource before creation.", "input": "go language", "output": "func (a customResourceStrategy) PrepareForCreate(ctx context.Context, obj runtime.Object) {\n\tif utilfeature.DefaultFeatureGate.Enabled(apiextensionsfeatures.CustomResourceSubresources) && a.status != nil {\n\t\tcustomResourceObject := obj.(*unstructured.Unstructured)\n\t\tcustomResource := customResourceObject.UnstructuredContent()\n\n\t\t// create cannot set status\n\t\tif _, ok := customResource[\"status\"]; ok {\n\t\t\tdelete(customResource, \"status\")\n\t\t}\n\t}\n\n\taccessor, _ := meta.Accessor(obj)\n\taccessor.SetGeneration(1)\n}"}, {"instruction": "// EnsurePortProxyRule checks if the specified redirect exists, if not creates it.", "input": "go language", "output": "func (runner *runner) EnsurePortProxyRule(args []string) (bool, error) {\n\tklog.V(4).Infof(\"running netsh interface portproxy add v4tov4 %v\", args)\n\tout, err := runner.exec.Command(cmdNetsh, args...).CombinedOutput()\n\n\tif err == nil {\n\t\treturn true, nil\n\t}\n\tif ee, ok := err.(utilexec.ExitError); ok {\n\t\t// netsh uses exit(0) to indicate a success of the operation,\n\t\t// as compared to a malformed commandline, for example.\n\t\tif ee.Exited() && ee.ExitStatus() != 0 {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn false, fmt.Errorf(\"error checking portproxy rule: %v: %s\", err, out)\n\n}"}, {"instruction": "// Compare compares the nodes and pods of NodeLister with Cache.Snapshot.", "input": "go language", "output": "func (c *CacheComparer) Compare() error {\n\tklog.V(3).Info(\"cache comparer started\")\n\tdefer klog.V(3).Info(\"cache comparer finished\")\n\n\tnodes, err := c.NodeLister.List(labels.Everything())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tpods, err := c.PodLister.List(labels.Everything())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsnapshot := c.Cache.Snapshot()\n\n\tpendingPods := c.PodQueue.PendingPods()\n\n\tif missed, redundant := c.CompareNodes(nodes, snapshot.Nodes); len(missed)+len(redundant) != 0 {\n\t\tklog.Warningf(\"cache mismatch: missed nodes: %s; redundant nodes: %s\", missed, redundant)\n\t}\n\n\tif missed, redundant := c.ComparePods(pods, pendingPods, snapshot.Nodes); len(missed)+len(redundant) != 0 {\n\t\tklog.Warningf(\"cache mismatch: missed pods: %s; redundant pods: %s\", missed, redundant)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// ValidateIgnorePreflightErrors validates duplicates in ignore-preflight-errors flag.", "input": "go language", "output": "func ValidateIgnorePreflightErrors(ignorePreflightErrors []string) (sets.String, error) {\n\tignoreErrors := sets.NewString()\n\tallErrs := field.ErrorList{}\n\n\tfor _, item := range ignorePreflightErrors {\n\t\tignoreErrors.Insert(strings.ToLower(item)) // parameters are case insensitive\n\t}\n\n\tif ignoreErrors.Has(\"all\") && ignoreErrors.Len() > 1 {\n\t\tallErrs = append(allErrs, field.Invalid(field.NewPath(\"ignore-preflight-errors\"), strings.Join(ignoreErrors.List(), \",\"), \"don't specify individual checks if 'all' is used\"))\n\t}\n\n\treturn ignoreErrors, allErrs.ToAggregate()\n}"}, {"instruction": "// Equal compares two diffs for exact equality.\n//\n// This is different from the Same comparison that is supported which\n// checks for operation equality taking into account computed values. Equal\n// instead checks for exact equality.", "input": "go language", "output": "func (d *Diff) Equal(d2 *Diff) bool {\n\t// If one is nil, they must both be nil\n\tif d == nil || d2 == nil {\n\t\treturn d == d2\n\t}\n\n\t// Sort the modules\n\tsort.Sort(moduleDiffSort(d.Modules))\n\tsort.Sort(moduleDiffSort(d2.Modules))\n\n\t// Copy since we have to modify the module destroy flag to false so\n\t// we don't compare that. TODO: delete this when we get rid of the\n\t// destroy flag on modules.\n\tdCopy := d.DeepCopy()\n\td2Copy := d2.DeepCopy()\n\tfor _, m := range dCopy.Modules {\n\t\tm.Destroy = false\n\t}\n\tfor _, m := range d2Copy.Modules {\n\t\tm.Destroy = false\n\t}\n\n\t// Use DeepEqual\n\treturn reflect.DeepEqual(dCopy, d2Copy)\n}"}, {"instruction": "// SetSecurityPolicyForAlphaGlobalBackendService sets the given\n// SecurityPolicyReference for the BackendService identified by the given name.", "input": "go language", "output": "func (g *Cloud) SetSecurityPolicyForAlphaGlobalBackendService(backendServiceName string, securityPolicyReference *computealpha.SecurityPolicyReference) error {\n\tctx, cancel := cloud.ContextWithCallTimeout()\n\tdefer cancel()\n\n\tmc := newBackendServiceMetricContextWithVersion(\"set_security_policy\", \"\", computeAlphaVersion)\n\treturn mc.Observe(g.c.AlphaBackendServices().SetSecurityPolicy(ctx, meta.GlobalKey(backendServiceName), securityPolicyReference))\n}"}, {"instruction": "// AnonymousClientConfig returns a copy of the given config with all user credentials (cert/key, bearer token, and username/password) and custom transports (WrapTransport, Transport) removed", "input": "go language", "output": "func AnonymousClientConfig(config *Config) *Config {\n\t// copy only known safe fields\n\treturn &Config{\n\t\tHost:          config.Host,\n\t\tAPIPath:       config.APIPath,\n\t\tContentConfig: config.ContentConfig,\n\t\tTLSClientConfig: TLSClientConfig{\n\t\t\tInsecure:   config.Insecure,\n\t\t\tServerName: config.ServerName,\n\t\t\tCAFile:     config.TLSClientConfig.CAFile,\n\t\t\tCAData:     config.TLSClientConfig.CAData,\n\t\t},\n\t\tRateLimiter: config.RateLimiter,\n\t\tUserAgent:   config.UserAgent,\n\t\tQPS:         config.QPS,\n\t\tBurst:       config.Burst,\n\t\tTimeout:     config.Timeout,\n\t\tDial:        config.Dial,\n\t}\n}"}, {"instruction": "// Implements p2p.MsgWriter", "input": "go language", "output": "func (prw *PssReadWriter) WriteMsg(msg p2p.Msg) error {\n\tlog.Trace(\"pssrw writemsg\", \"msg\", msg)\n\tif prw.closed {\n\t\treturn fmt.Errorf(\"connection closed\")\n\t}\n\trlpdata := make([]byte, msg.Size)\n\tmsg.Payload.Read(rlpdata)\n\tpmsg, err := rlp.EncodeToBytes(ProtocolMsg{\n\t\tCode:    msg.Code,\n\t\tSize:    msg.Size,\n\t\tPayload: rlpdata,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn prw.sendFunc(prw.key, *prw.topic, pmsg)\n}"}, {"instruction": "// Subscribe creates a subscription for events of the given types. The\n// subscription's channel is closed when it is unsubscribed\n// or the mux is closed.", "input": "go language", "output": "func (mux *TypeMux) Subscribe(types ...interface{}) *TypeMuxSubscription {\n\tsub := newsub(mux)\n\tmux.mutex.Lock()\n\tdefer mux.mutex.Unlock()\n\tif mux.stopped {\n\t\t// set the status to closed so that calling Unsubscribe after this\n\t\t// call will short circuit.\n\t\tsub.closed = true\n\t\tclose(sub.postC)\n\t} else {\n\t\tif mux.subm == nil {\n\t\t\tmux.subm = make(map[reflect.Type][]*TypeMuxSubscription)\n\t\t}\n\t\tfor _, t := range types {\n\t\t\trtyp := reflect.TypeOf(t)\n\t\t\toldsubs := mux.subm[rtyp]\n\t\t\tif find(oldsubs, sub) != -1 {\n\t\t\t\tpanic(fmt.Sprintf(\"event: duplicate type %s in Subscribe\", rtyp))\n\t\t\t}\n\t\t\tsubs := make([]*TypeMuxSubscription, len(oldsubs)+1)\n\t\t\tcopy(subs, oldsubs)\n\t\t\tsubs[len(oldsubs)] = sub\n\t\t\tmux.subm[rtyp] = subs\n\t\t}\n\t}\n\treturn sub\n}"}, {"instruction": "// ParseBitStr parses bit string.\n// The string format can be b'val', B'val' or 0bval, val must be 0 or 1.\n// See https://dev.mysql.com/doc/refman/5.7/en/bit-value-literals.html", "input": "go language", "output": "func ParseBitStr(s string) (BinaryLiteral, error) {\n\tif len(s) == 0 {\n\t\treturn nil, errors.Errorf(\"invalid empty string for parsing bit type\")\n\t}\n\n\tif s[0] == 'b' || s[0] == 'B' {\n\t\t// format is b'val' or B'val'\n\t\ts = strings.Trim(s[1:], \"'\")\n\t} else if strings.HasPrefix(s, \"0b\") {\n\t\ts = s[2:]\n\t} else {\n\t\t// here means format is not b'val', B'val' or 0bval.\n\t\treturn nil, errors.Errorf(\"invalid bit type format %s\", s)\n\t}\n\n\tif len(s) == 0 {\n\t\treturn ZeroBinaryLiteral, nil\n\t}\n\n\talignedLength := (len(s) + 7) &^ 7\n\ts = (\"00000000\" + s)[len(s)+8-alignedLength:] // Pad with zero (slice from `-alignedLength`)\n\tbyteLength := len(s) >> 3\n\tbuf := make([]byte, byteLength)\n\n\tfor i := 0; i < byteLength; i++ {\n\t\tstrPosition := i << 3\n\t\tval, err := strconv.ParseUint(s[strPosition:strPosition+8], 2, 8)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tbuf[i] = byte(val)\n\t}\n\n\treturn buf, nil\n}"}, {"instruction": "// checkFolderDeviceStatusLocked first checks the folder and then whether the\n// given device is connected and shares this folder.\n// Need to hold (read) lock on both m.fmut and m.pmut when calling this.", "input": "go language", "output": "func (m *model) checkDeviceFolderConnectedLocked(device protocol.DeviceID, folder string) error {\n\tif err := m.checkFolderRunningLocked(folder); err != nil {\n\t\treturn err\n\t}\n\n\tif cfg, ok := m.cfg.Device(device); !ok {\n\t\treturn errDeviceUnknown\n\t} else if cfg.Paused {\n\t\treturn errDevicePaused\n\t}\n\n\tif _, ok := m.conn[device]; !ok {\n\t\treturn errors.New(\"device is not connected\")\n\t}\n\n\tif cfg, ok := m.cfg.Folder(folder); !ok || !cfg.SharedWith(device) {\n\t\treturn errors.New(\"folder is not shared with device\")\n\t}\n\treturn nil\n}"}, {"instruction": "// ValidateUpdate is the default update validation for an end user.", "input": "go language", "output": "func (jobStrategy) ValidateUpdate(ctx context.Context, obj, old runtime.Object) field.ErrorList {\n\tjob := obj.(*batch.Job)\n\toldJob := old.(*batch.Job)\n\tvalidationErrorList := validation.ValidateJob(job)\n\tupdateErrorList := validation.ValidateJobUpdate(job, oldJob)\n\tupdateErrorList = append(updateErrorList, corevalidation.ValidateConditionalPodTemplate(&job.Spec.Template, &oldJob.Spec.Template, field.NewPath(\"spec.template\"))...)\n\treturn append(validationErrorList, updateErrorList...)\n}"}, {"instruction": "// Validate checks ServerRunOptions and return a slice of found errs.", "input": "go language", "output": "func (s *ServerRunOptions) Validate() []error {\n\tvar errs []error\n\tif s.MasterCount <= 0 {\n\t\terrs = append(errs, fmt.Errorf(\"--apiserver-count should be a positive number, but value '%d' provided\", s.MasterCount))\n\t}\n\terrs = append(errs, s.Etcd.Validate()...)\n\terrs = append(errs, validateClusterIPFlags(s)...)\n\terrs = append(errs, validateServiceNodePort(s)...)\n\terrs = append(errs, s.SecureServing.Validate()...)\n\terrs = append(errs, s.Authentication.Validate()...)\n\terrs = append(errs, s.Authorization.Validate()...)\n\terrs = append(errs, s.Audit.Validate()...)\n\terrs = append(errs, s.Admission.Validate()...)\n\terrs = append(errs, s.InsecureServing.Validate()...)\n\terrs = append(errs, s.APIEnablement.Validate(legacyscheme.Scheme, apiextensionsapiserver.Scheme, aggregatorscheme.Scheme)...)\n\terrs = append(errs, validateTokenRequest(s)...)\n\n\treturn errs\n}"}, {"instruction": "// execute fetches Chunks from src and update each aggregate function for each row in Chunk.", "input": "go language", "output": "func (e *HashAggExec) execute(ctx context.Context) (err error) {\n\tinputIter := chunk.NewIterator4Chunk(e.childResult)\n\tfor {\n\t\terr := e.children[0].Next(ctx, chunk.NewRecordBatch(e.childResult))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfailpoint.Inject(\"unparallelHashAggError\", func(val failpoint.Value) {\n\t\t\tif val.(bool) {\n\t\t\t\tfailpoint.Return(errors.New(\"HashAggExec.unparallelExec error\"))\n\t\t\t}\n\t\t})\n\n\t\t// no more data.\n\t\tif e.childResult.NumRows() == 0 {\n\t\t\treturn nil\n\t\t}\n\t\tfor row := inputIter.Begin(); row != inputIter.End(); row = inputIter.Next() {\n\t\t\tgroupKey, err := e.getGroupKey(row)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif !e.groupSet.Exist(groupKey) {\n\t\t\t\te.groupSet.Insert(groupKey)\n\t\t\t\te.groupKeys = append(e.groupKeys, groupKey)\n\t\t\t}\n\t\t\tpartialResults := e.getPartialResults(groupKey)\n\t\t\tfor i, af := range e.PartialAggFuncs {\n\t\t\t\terr = af.UpdatePartialResult(e.ctx, []chunk.Row{row}, partialResults[i])\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// gatherAllHostports returns all hostports that should be presented on node,\n// given the list of pods running on that node and ignoring host network\n// pods (which don't need hostport <-> container port mapping).", "input": "go language", "output": "func gatherAllHostports(activePodPortMappings []*PodPortMapping) (map[*PortMapping]targetPod, error) {\n\tpodHostportMap := make(map[*PortMapping]targetPod)\n\tfor _, pm := range activePodPortMappings {\n\t\tif pm.IP.To4() == nil {\n\t\t\treturn nil, fmt.Errorf(\"Invalid or missing pod %s IP\", getPodFullName(pm))\n\t\t}\n\t\t// should not handle hostports for hostnetwork pods\n\t\tif pm.HostNetwork {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, port := range pm.PortMappings {\n\t\t\tif port.HostPort != 0 {\n\t\t\t\tpodHostportMap[port] = targetPod{podFullName: getPodFullName(pm), podIP: pm.IP.String()}\n\t\t\t}\n\t\t}\n\t}\n\treturn podHostportMap, nil\n}"}, {"instruction": "// Visit will call the visitor function on the path if it's a file, or for each\n// file in the path if it's a directory. Directories will not be recursed into,\n// and files in the directory will be visited in alphabetical order.", "input": "go language", "output": "func Visit(path string, visitor VisitFn) error {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error reading %q: %v\", path, err)\n\t}\n\tdefer f.Close()\n\n\tfi, err := f.Stat()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error checking %q: %v\", path, err)\n\t}\n\n\tif !fi.IsDir() {\n\t\tif err := visitor(path); err != nil {\n\t\t\treturn fmt.Errorf(\"error in %q: %v\", path, err)\n\t\t}\n\t\treturn nil\n\t}\n\n\tcontents, err := f.Readdir(-1)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error listing %q: %v\", path, err)\n\t}\n\n\tsort.Sort(dirEnts(contents))\n\tfor _, fi := range contents {\n\t\tif fi.IsDir() {\n\t\t\tcontinue\n\t\t}\n\n\t\tfullPath := filepath.Join(path, fi.Name())\n\t\tif err := visitor(fullPath); err != nil {\n\t\t\treturn fmt.Errorf(\"error in %q: %v\", fullPath, err)\n\t\t}\n\t}\n\n\treturn nil\n}"}, {"instruction": "// MakePortMappings creates internal port mapping from api port mapping.", "input": "go language", "output": "func MakePortMappings(container *v1.Container) (ports []PortMapping) {\n\tnames := make(map[string]struct{})\n\tfor _, p := range container.Ports {\n\t\tpm := PortMapping{\n\t\t\tHostPort:      int(p.HostPort),\n\t\t\tContainerPort: int(p.ContainerPort),\n\t\t\tProtocol:      p.Protocol,\n\t\t\tHostIP:        p.HostIP,\n\t\t}\n\n\t\t// We need to create some default port name if it's not specified, since\n\t\t// this is necessary for rkt.\n\t\t// http://issue.k8s.io/7710\n\t\tif p.Name == \"\" {\n\t\t\tpm.Name = fmt.Sprintf(\"%s-%s:%d\", container.Name, p.Protocol, p.ContainerPort)\n\t\t} else {\n\t\t\tpm.Name = fmt.Sprintf(\"%s-%s\", container.Name, p.Name)\n\t\t}\n\n\t\t// Protect against exposing the same protocol-port more than once in a container.\n\t\tif _, ok := names[pm.Name]; ok {\n\t\t\tklog.Warningf(\"Port name conflicted, %q is defined more than once\", pm.Name)\n\t\t\tcontinue\n\t\t}\n\t\tports = append(ports, pm)\n\t\tnames[pm.Name] = struct{}{}\n\t}\n\treturn\n}"}, {"instruction": "// notify sends notifications for pod with the given id, if the requirements\n// are met. Note that the caller should acquire the lock.", "input": "go language", "output": "func (c *cache) notify(id types.UID, timestamp time.Time) {\n\tlist, ok := c.subscribers[id]\n\tif !ok {\n\t\t// No one to notify.\n\t\treturn\n\t}\n\tnewList := []*subRecord{}\n\tfor i, r := range list {\n\t\tif timestamp.Before(r.time) {\n\t\t\t// Doesn't meet the time requirement; keep the record.\n\t\t\tnewList = append(newList, list[i])\n\t\t\tcontinue\n\t\t}\n\t\tr.ch <- c.get(id)\n\t\tclose(r.ch)\n\t}\n\tif len(newList) == 0 {\n\t\tdelete(c.subscribers, id)\n\t} else {\n\t\tc.subscribers[id] = newList\n\t}\n}"}, {"instruction": "//\n// Setting, updating & deleting state object methods.\n//\n// updateStateObject writes the given object to the trie.", "input": "go language", "output": "func (s *StateDB) updateStateObject(stateObject *stateObject) {\n\t// Track the amount of time wasted on updating the account from the trie\n\tif metrics.EnabledExpensive {\n\t\tdefer func(start time.Time) { s.AccountUpdates += time.Since(start) }(time.Now())\n\t}\n\t// Encode the account and update the account trie\n\taddr := stateObject.Address()\n\n\tdata, err := rlp.EncodeToBytes(stateObject)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"can't encode object at %x: %v\", addr[:], err))\n\t}\n\ts.setError(s.trie.TryUpdate(addr[:], data))\n}"}, {"instruction": "// TranslateInTreePVToCSI takes a PV with Cinder set from in-tree\n// and converts the Cinder source to a CSIPersistentVolumeSource", "input": "go language", "output": "func (t *osCinderCSITranslator) TranslateInTreePVToCSI(pv *v1.PersistentVolume) (*v1.PersistentVolume, error) {\n\tif pv == nil || pv.Spec.Cinder == nil {\n\t\treturn nil, fmt.Errorf(\"pv is nil or Cinder not defined on pv\")\n\t}\n\n\tcinderSource := pv.Spec.Cinder\n\n\tcsiSource := &v1.CSIPersistentVolumeSource{\n\t\tDriver:           CinderDriverName,\n\t\tVolumeHandle:     cinderSource.VolumeID,\n\t\tReadOnly:         cinderSource.ReadOnly,\n\t\tFSType:           cinderSource.FSType,\n\t\tVolumeAttributes: map[string]string{},\n\t}\n\n\tpv.Spec.Cinder = nil\n\tpv.Spec.CSI = csiSource\n\treturn pv, nil\n}"}, {"instruction": "// ReloadGlobalConfig reloads global configuration for this server.", "input": "go language", "output": "func ReloadGlobalConfig() error {\n\tconfReloadLock.Lock()\n\tdefer confReloadLock.Unlock()\n\n\tnc := NewConfig()\n\tif err := nc.Load(reloadConfPath); err != nil {\n\t\treturn err\n\t}\n\tif err := nc.Valid(); err != nil {\n\t\treturn err\n\t}\n\tc := GetGlobalConfig()\n\n\tdiffs := collectsDiff(*nc, *c, \"\")\n\tif len(diffs) == 0 {\n\t\treturn nil\n\t}\n\tvar formattedDiff bytes.Buffer\n\tfor k, vs := range diffs {\n\t\tformattedDiff.WriteString(fmt.Sprintf(\", %v:%v->%v\", k, vs[1], vs[0]))\n\t}\n\tunsupported := make([]string, 0, 2)\n\tfor k := range diffs {\n\t\tif _, ok := supportedReloadConfigs[k]; !ok {\n\t\t\tunsupported = append(unsupported, k)\n\t\t}\n\t}\n\tif len(unsupported) > 0 {\n\t\treturn fmt.Errorf(\"reloading config %v is not supported, only %v are supported now, \"+\n\t\t\t\"your changes%s\", unsupported, supportedReloadConfList, formattedDiff.String())\n\t}\n\n\tconfReloader(nc, c)\n\tglobalConf.Store(nc)\n\tlogutil.Logger(context.Background()).Info(\"reload config changes\" + formattedDiff.String())\n\treturn nil\n}"}, {"instruction": "// wantsCompressedResponse reads the Accept-Encoding header to see if and which encoding is requested.", "input": "go language", "output": "func wantsCompressedResponse(req *http.Request) (bool, string) {\n\t// don't compress watches\n\tctx := req.Context()\n\tinfo, ok := request.RequestInfoFrom(ctx)\n\tif !ok {\n\t\treturn false, \"\"\n\t}\n\tif !info.IsResourceRequest {\n\t\treturn false, \"\"\n\t}\n\tif info.Verb == \"watch\" {\n\t\treturn false, \"\"\n\t}\n\theader := req.Header.Get(headerAcceptEncoding)\n\tgi := strings.Index(header, encodingGzip)\n\tzi := strings.Index(header, encodingDeflate)\n\t// use in order of appearance\n\tswitch {\n\tcase gi == -1:\n\t\treturn zi != -1, encodingDeflate\n\tcase zi == -1:\n\t\treturn gi != -1, encodingGzip\n\tcase gi < zi:\n\t\treturn true, encodingGzip\n\tdefault:\n\t\treturn true, encodingDeflate\n\t}\n}"}, {"instruction": "// Hex returns an EIP55-compliant hex string representation of the address.", "input": "go language", "output": "func (a Address) Hex() string {\n\tunchecksummed := hex.EncodeToString(a[:])\n\tsha := sha3.NewLegacyKeccak256()\n\tsha.Write([]byte(unchecksummed))\n\thash := sha.Sum(nil)\n\n\tresult := []byte(unchecksummed)\n\tfor i := 0; i < len(result); i++ {\n\t\thashByte := hash[i/2]\n\t\tif i%2 == 0 {\n\t\t\thashByte = hashByte >> 4\n\t\t} else {\n\t\t\thashByte &= 0xf\n\t\t}\n\t\tif result[i] > '9' && hashByte > 7 {\n\t\t\tresult[i] -= 32\n\t\t}\n\t}\n\treturn \"0x\" + string(result)\n}"}, {"instruction": "// deleteFromIndices removes the object from each of the managed indexes\n// it is intended to be called from a function that already has a lock on the cache", "input": "go language", "output": "func (c *threadSafeMap) deleteFromIndices(obj interface{}, key string) {\n\tfor name, indexFunc := range c.indexers {\n\t\tindexValues, err := indexFunc(obj)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Errorf(\"unable to calculate an index entry for key %q on index %q: %v\", key, name, err))\n\t\t}\n\n\t\tindex := c.indices[name]\n\t\tif index == nil {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, indexValue := range indexValues {\n\t\t\tset := index[indexValue]\n\t\t\tif set != nil {\n\t\t\t\tset.Delete(key)\n\t\t\t}\n\t\t}\n\t}\n}"}, {"instruction": "// SyntaxError converts parser error to TiDB's syntax error.", "input": "go language", "output": "func SyntaxError(err error) error {\n\tif err == nil {\n\t\treturn nil\n\t}\n\tlogutil.Logger(context.Background()).Error(\"syntax error\", zap.Error(err))\n\n\t// If the error is already a terror with stack, pass it through.\n\tif errors.HasStack(err) {\n\t\tcause := errors.Cause(err)\n\t\tif _, ok := cause.(*terror.Error); ok {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn parser.ErrParse.GenWithStackByArgs(syntaxErrorPrefix, err.Error())\n}"}, {"instruction": "// UpstreamResolverFuncFromClient returns a closure that captures a consul\n// client and when called provides a ConsulResolver that can resolve the given\n// UpstreamConfig using the provided api.Client dependency.", "input": "go language", "output": "func UpstreamResolverFuncFromClient(client *api.Client) func(cfg UpstreamConfig) (connect.Resolver, error) {\n\treturn func(cfg UpstreamConfig) (connect.Resolver, error) {\n\t\t// For now default to service as it has the most natural meaning and the error\n\t\t// that the service doesn't exist is probably reasonable if misconfigured. We\n\t\t// should probably handle actual configs that have invalid types at a higher\n\t\t// level anyway (like when parsing).\n\t\ttyp := connect.ConsulResolverTypeService\n\t\tif cfg.DestinationType == \"prepared_query\" {\n\t\t\ttyp = connect.ConsulResolverTypePreparedQuery\n\t\t}\n\t\treturn &connect.ConsulResolver{\n\t\t\tClient:     client,\n\t\t\tNamespace:  cfg.DestinationNamespace,\n\t\t\tName:       cfg.DestinationName,\n\t\t\tType:       typ,\n\t\t\tDatacenter: cfg.Datacenter,\n\t\t}, nil\n\t}\n}"}, {"instruction": "// simplifyNode traverses the hierarchy of an expanded memory node and discards\n// all the internal caches, returning a node that only contains the raw data.", "input": "go language", "output": "func simplifyNode(n node) node {\n\tswitch n := n.(type) {\n\tcase *shortNode:\n\t\t// Short nodes discard the flags and cascade\n\t\treturn &rawShortNode{Key: n.Key, Val: simplifyNode(n.Val)}\n\n\tcase *fullNode:\n\t\t// Full nodes discard the flags and cascade\n\t\tnode := rawFullNode(n.Children)\n\t\tfor i := 0; i < len(node); i++ {\n\t\t\tif node[i] != nil {\n\t\t\t\tnode[i] = simplifyNode(node[i])\n\t\t\t}\n\t\t}\n\t\treturn node\n\n\tcase valueNode, hashNode, rawNode:\n\t\treturn n\n\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"unknown node type: %T\", n))\n\t}\n}"}, {"instruction": "// convertVolPathsToDevicePaths removes cluster or folder path from volPaths and convert to canonicalPath", "input": "go language", "output": "func (vs *VSphere) convertVolPathsToDevicePaths(ctx context.Context, nodeVolumes map[k8stypes.NodeName][]string) (map[k8stypes.NodeName][]string, error) {\n\tvmVolumes := make(map[k8stypes.NodeName][]string)\n\tfor nodeName, volPaths := range nodeVolumes {\n\t\tnodeInfo, err := vs.nodeManager.GetNodeInfo(nodeName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t_, err = vs.getVSphereInstanceForServer(nodeInfo.vcServer, ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor i, volPath := range volPaths {\n\t\t\tdeviceVolPath, err := convertVolPathToDevicePath(ctx, nodeInfo.dataCenter, volPath)\n\t\t\tif err != nil {\n\t\t\t\tklog.Errorf(\"Failed to convert vsphere volume path %s to device path for volume %s. err: %+v\", volPath, deviceVolPath, err)\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tvolPaths[i] = deviceVolPath\n\t\t}\n\t\tvmVolumes[nodeName] = volPaths\n\t}\n\treturn vmVolumes, nil\n}"}, {"instruction": "// Get is used to lookup a single key.", "input": "go language", "output": "func (k *KVS) Get(args *structs.KeyRequest, reply *structs.IndexedDirEntries) error {\n\tif done, err := k.srv.forward(\"KVS.Get\", args, args, reply); done {\n\t\treturn err\n\t}\n\n\taclRule, err := k.srv.ResolveToken(args.Token)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn k.srv.blockingQuery(\n\t\t&args.QueryOptions,\n\t\t&reply.QueryMeta,\n\t\tfunc(ws memdb.WatchSet, state *state.Store) error {\n\t\t\tindex, ent, err := state.KVSGet(ws, args.Key)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif aclRule != nil && !aclRule.KeyRead(args.Key) {\n\t\t\t\treturn acl.ErrPermissionDenied\n\t\t\t}\n\n\t\t\tif ent == nil {\n\t\t\t\t// Must provide non-zero index to prevent blocking\n\t\t\t\t// Index 1 is impossible anyways (due to Raft internals)\n\t\t\t\tif index == 0 {\n\t\t\t\t\treply.Index = 1\n\t\t\t\t} else {\n\t\t\t\t\treply.Index = index\n\t\t\t\t}\n\t\t\t\treply.Entries = nil\n\t\t\t} else {\n\t\t\t\treply.Index = ent.ModifyIndex\n\t\t\t\treply.Entries = structs.DirEntries{ent}\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n}"}, {"instruction": "// defaultPodLimitsForDownwardAPI copies the input pod, and optional container,\n// and applies default resource limits. it returns a copy of the input pod,\n// and a copy of the input container (if specified) with default limits\n// applied. if a container has no limit specified, it will default the limit to\n// the node allocatable.\n// TODO: if/when we have pod level resources, we need to update this function\n// to use those limits instead of node allocatable.", "input": "go language", "output": "func (kl *Kubelet) defaultPodLimitsForDownwardAPI(pod *v1.Pod, container *v1.Container) (*v1.Pod, *v1.Container, error) {\n\tif pod == nil {\n\t\treturn nil, nil, fmt.Errorf(\"invalid input, pod cannot be nil\")\n\t}\n\n\tnode, err := kl.getNodeAnyWay()\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to find node object, expected a node\")\n\t}\n\tallocatable := node.Status.Allocatable\n\tklog.Infof(\"allocatable: %v\", allocatable)\n\toutputPod := pod.DeepCopy()\n\tfor idx := range outputPod.Spec.Containers {\n\t\tresource.MergeContainerResourceLimits(&outputPod.Spec.Containers[idx], allocatable)\n\t}\n\n\tvar outputContainer *v1.Container\n\tif container != nil {\n\t\toutputContainer = container.DeepCopy()\n\t\tresource.MergeContainerResourceLimits(outputContainer, allocatable)\n\t}\n\treturn outputPod, outputContainer, nil\n}"}, {"instruction": "// Unlock released the lock. It is an error to call this\n// if the lock is not currently held.", "input": "go language", "output": "func (l *Lock) Unlock() error {\n\t// Hold the lock as we try to release\n\tl.l.Lock()\n\tdefer l.l.Unlock()\n\n\t// Ensure the lock is actually held\n\tif !l.isHeld {\n\t\treturn ErrLockNotHeld\n\t}\n\n\t// Set that we no longer own the lock\n\tl.isHeld = false\n\n\t// Stop the session renew\n\tif l.sessionRenew != nil {\n\t\tdefer func() {\n\t\t\tclose(l.sessionRenew)\n\t\t\tl.sessionRenew = nil\n\t\t}()\n\t}\n\n\t// Get the lock entry, and clear the lock session\n\tlockEnt := l.lockEntry(l.lockSession)\n\tl.lockSession = \"\"\n\n\t// Release the lock explicitly\n\tkv := l.c.KV()\n\t_, _, err := kv.Release(lockEnt, nil)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to release lock: %v\", err)\n\t}\n\treturn nil\n}"}, {"instruction": "// ContainerStatus returns the container status.", "input": "go language", "output": "func (r *RemoteRuntimeService) ContainerStatus(containerID string) (*runtimeapi.ContainerStatus, error) {\n\tctx, cancel := getContextWithTimeout(r.timeout)\n\tdefer cancel()\n\n\tresp, err := r.runtimeClient.ContainerStatus(ctx, &runtimeapi.ContainerStatusRequest{\n\t\tContainerId: containerID,\n\t})\n\tif err != nil {\n\t\t// Don't spam the log with endless messages about the same failure.\n\t\tif r.logReduction.ShouldMessageBePrinted(err.Error(), containerID) {\n\t\t\tklog.Errorf(\"ContainerStatus %q from runtime service failed: %v\", containerID, err)\n\t\t}\n\t\treturn nil, err\n\t}\n\tr.logReduction.ClearID(containerID)\n\n\tif resp.Status != nil {\n\t\tif err := verifyContainerStatus(resp.Status); err != nil {\n\t\t\tklog.Errorf(\"ContainerStatus of %q failed: %v\", containerID, err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn resp.Status, nil\n}"}, {"instruction": "// SetCapabilities sets the provided capabilities on the spec\n// All capabilities are added if privileged is true", "input": "go language", "output": "func SetCapabilities(s *specs.Spec, caplist []string) error {\n\ts.Process.Capabilities.Effective = caplist\n\ts.Process.Capabilities.Bounding = caplist\n\ts.Process.Capabilities.Permitted = caplist\n\ts.Process.Capabilities.Inheritable = caplist\n\t// setUser has already been executed here\n\t// if non root drop capabilities in the way execve does\n\tif s.Process.User.UID != 0 {\n\t\ts.Process.Capabilities.Effective = []string{}\n\t\ts.Process.Capabilities.Permitted = []string{}\n\t}\n\treturn nil\n}"}, {"instruction": "// Compile compiles the current tokens and returns a\n// binary string that can be interpreted by the EVM\n// and an error if it failed.\n//\n// compile is the second stage in the compile phase\n// which compiles the tokens to EVM instructions.", "input": "go language", "output": "func (c *Compiler) Compile() (string, []error) {\n\tvar errors []error\n\t// continue looping over the tokens until\n\t// the stack has been exhausted.\n\tfor c.pos < len(c.tokens) {\n\t\tif err := c.compileLine(); err != nil {\n\t\t\terrors = append(errors, err)\n\t\t}\n\t}\n\n\t// turn the binary to hex\n\tvar bin string\n\tfor _, v := range c.binary {\n\t\tswitch v := v.(type) {\n\t\tcase vm.OpCode:\n\t\t\tbin += fmt.Sprintf(\"%x\", []byte{byte(v)})\n\t\tcase []byte:\n\t\t\tbin += fmt.Sprintf(\"%x\", v)\n\t\t}\n\t}\n\treturn bin, errors\n}"}, {"instruction": "// Create makes a new prepared query. The ID of the new query is returned.", "input": "go language", "output": "func (c *PreparedQuery) Create(query *PreparedQueryDefinition, q *WriteOptions) (string, *WriteMeta, error) {\n\tr := c.c.newRequest(\"POST\", \"/v1/query\")\n\tr.setWriteOptions(q)\n\tr.obj = query\n\trtt, resp, err := requireOK(c.c.doRequest(r))\n\tif err != nil {\n\t\treturn \"\", nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\twm := &WriteMeta{}\n\twm.RequestTime = rtt\n\n\tvar out struct{ ID string }\n\tif err := decodeBody(resp, &out); err != nil {\n\t\treturn \"\", nil, err\n\t}\n\treturn out.ID, wm, nil\n}"}, {"instruction": "// MatchDomain return true if a domain match the cert domain", "input": "go language", "output": "func MatchDomain(domain string, certDomain string) bool {\n\tif domain == certDomain {\n\t\treturn true\n\t}\n\n\tfor len(certDomain) > 0 && certDomain[len(certDomain)-1] == '.' {\n\t\tcertDomain = certDomain[:len(certDomain)-1]\n\t}\n\n\tlabels := strings.Split(domain, \".\")\n\tfor i := range labels {\n\t\tlabels[i] = \"*\"\n\t\tcandidate := strings.Join(labels, \".\")\n\t\tif certDomain == candidate {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}"}, {"instruction": "// ToProtoModels builds the proto formatted models from OpenAPI spec", "input": "go language", "output": "func ToProtoModels(openAPISpec *spec.Swagger) (proto.Models, error) {\n\tspecBytes, err := json.MarshalIndent(openAPISpec, \" \", \" \")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar info yaml.MapSlice\n\terr = yaml.Unmarshal(specBytes, &info)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdoc, err := openapi_v2.NewDocument(info, compiler.NewContext(\"$root\", nil))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmodels, err := proto.NewOpenAPIData(doc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn models, nil\n}"}, {"instruction": "// ReadDataSource mocks base method", "input": "go language", "output": "func (m *MockProviderClient) ReadDataSource(arg0 context.Context, arg1 *tfplugin5.ReadDataSource_Request, arg2 ...grpc.CallOption) (*tfplugin5.ReadDataSource_Response, error) {\n\tm.ctrl.T.Helper()\n\tvarargs := []interface{}{arg0, arg1}\n\tfor _, a := range arg2 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tret := m.ctrl.Call(m, \"ReadDataSource\", varargs...)\n\tret0, _ := ret[0].(*tfplugin5.ReadDataSource_Response)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}"}, {"instruction": "// NodeKeys returns a paginated list of keys on a node with provided address.", "input": "go language", "output": "func (s *GlobalStore) NodeKeys(addr common.Address, startKey []byte, limit int) (keys mock.Keys, err error) {\n\ts.mu.RLock()\n\tdefer s.mu.RUnlock()\n\n\tvar i int\n\tif startKey != nil {\n\t\ti, _ = s.nodeKeyIndex(addr, startKey)\n\t}\n\ttotal := len(s.nodeKeys[addr])\n\tmax := maxIndex(i, limit, total)\n\tkeys.Keys = make([][]byte, 0, max-i)\n\tfor ; i < max; i++ {\n\t\tkeys.Keys = append(keys.Keys, append([]byte(nil), s.nodeKeys[addr][i]...))\n\t}\n\tif total > max {\n\t\tkeys.Next = s.nodeKeys[addr][max]\n\t}\n\treturn keys, nil\n}"}, {"instruction": "// getSessionVarsWaitTimeout get session variable wait_timeout", "input": "go language", "output": "func (cc *clientConn) getSessionVarsWaitTimeout(ctx context.Context) uint64 {\n\tvalStr, exists := cc.ctx.GetSessionVars().GetSystemVar(variable.WaitTimeout)\n\tif !exists {\n\t\treturn variable.DefWaitTimeout\n\t}\n\twaitTimeout, err := strconv.ParseUint(valStr, 10, 64)\n\tif err != nil {\n\t\tlogutil.Logger(ctx).Warn(\"get sysval wait_timeout error, use default value\", zap.Error(err))\n\t\t// if get waitTimeout error, use default value\n\t\treturn variable.DefWaitTimeout\n\t}\n\treturn waitTimeout\n}"}, {"instruction": "// NewCommandStartWardleServer provides a CLI handler for 'start master' command\n// with a default WardleServerOptions.", "input": "go language", "output": "func NewCommandStartWardleServer(defaults *WardleServerOptions, stopCh <-chan struct{}) *cobra.Command {\n\to := *defaults\n\tcmd := &cobra.Command{\n\t\tShort: \"Launch a wardle API server\",\n\t\tLong:  \"Launch a wardle API server\",\n\t\tRunE: func(c *cobra.Command, args []string) error {\n\t\t\tif err := o.Complete(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := o.Validate(args); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := o.RunWardleServer(stopCh); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tflags := cmd.Flags()\n\to.RecommendedOptions.AddFlags(flags)\n\tutilfeature.DefaultMutableFeatureGate.AddFlag(flags)\n\n\treturn cmd\n}"}, {"instruction": "// NewOwnerManager creates a new Manager.", "input": "go language", "output": "func NewOwnerManager(etcdCli *clientv3.Client, prompt, id, key string, cancel context.CancelFunc) Manager {\n\tlogPrefix := fmt.Sprintf(\"[%s] %s ownerManager %s\", prompt, key, id)\n\treturn &ownerManager{\n\t\tetcdCli:   etcdCli,\n\t\tid:        id,\n\t\tkey:       key,\n\t\tprompt:    prompt,\n\t\tcancel:    cancel,\n\t\tlogPrefix: logPrefix,\n\t\tlogCtx:    logutil.WithKeyValue(context.Background(), \"owner info\", logPrefix),\n\t}\n}"}, {"instruction": "// splitSlicesAndValues moves all slice values defined in c to 'slices'\n// and all other values to 'values'.", "input": "go language", "output": "func (b *Builder) splitSlicesAndValues(c Config) (slices, values Config) {\n\tv, t := reflect.ValueOf(c), reflect.TypeOf(c)\n\trs, rv := reflect.New(t), reflect.New(t)\n\n\tfor i := 0; i < t.NumField(); i++ {\n\t\tf := t.Field(i)\n\t\tif f.Type.Kind() == reflect.Slice {\n\t\t\trs.Elem().Field(i).Set(v.Field(i))\n\t\t} else {\n\t\t\trv.Elem().Field(i).Set(v.Field(i))\n\t\t}\n\t}\n\treturn rs.Elem().Interface().(Config), rv.Elem().Interface().(Config)\n}"}, {"instruction": "// InstanceKeyLess returns true if the first given instance key i should sort\n// before the second key j, and false otherwise.", "input": "go language", "output": "func InstanceKeyLess(i, j InstanceKey) bool {\n\tiTy := instanceKeyType(i)\n\tjTy := instanceKeyType(j)\n\n\tswitch {\n\tcase i == j:\n\t\treturn false\n\tcase i == NoKey:\n\t\treturn true\n\tcase j == NoKey:\n\t\treturn false\n\tcase iTy != jTy:\n\t\t// The ordering here is arbitrary except that we want NoKeyType\n\t\t// to sort before the others, so we'll just use the enum values\n\t\t// of InstanceKeyType here (where NoKey is zero, sorting before\n\t\t// any other).\n\t\treturn uint32(iTy) < uint32(jTy)\n\tcase iTy == IntKeyType:\n\t\treturn int(i.(IntKey)) < int(j.(IntKey))\n\tcase iTy == StringKeyType:\n\t\treturn string(i.(StringKey)) < string(j.(StringKey))\n\tdefault:\n\t\t// Shouldn't be possible to get down here in practice, since the\n\t\t// above is exhaustive.\n\t\treturn false\n\t}\n}"}, {"instruction": "// popOldEvents finds events that should be scheduled for scanning recursively in dirs,\n// removes those events and empty eventDirs and returns a map with all the removed\n// events referenced by their filesystem path", "input": "go language", "output": "func (a *aggregator) popOldEventsTo(to map[string]*aggregatedEvent, dir *eventDir, dirPath string, currTime time.Time, delayRem bool) {\n\tfor childName, childDir := range dir.dirs {\n\t\ta.popOldEventsTo(to, childDir, filepath.Join(dirPath, childName), currTime, delayRem)\n\t\tif childDir.childCount() == 0 {\n\t\t\tdelete(dir.dirs, childName)\n\t\t}\n\t}\n\tfor name, event := range dir.events {\n\t\tif a.isOld(event, currTime, delayRem) {\n\t\t\tto[filepath.Join(dirPath, name)] = event\n\t\t\tdelete(dir.events, name)\n\t\t\ta.counts[event.evType]--\n\t\t}\n\t}\n}"}, {"instruction": "// makeProtocols creates protocol descriptors for the given LES versions.", "input": "go language", "output": "func (c *lesCommons) makeProtocols(versions []uint) []p2p.Protocol {\n\tprotos := make([]p2p.Protocol, len(versions))\n\tfor i, version := range versions {\n\t\tversion := version\n\t\tprotos[i] = p2p.Protocol{\n\t\t\tName:     \"les\",\n\t\t\tVersion:  version,\n\t\t\tLength:   ProtocolLengths[version],\n\t\t\tNodeInfo: c.nodeInfo,\n\t\t\tRun: func(p *p2p.Peer, rw p2p.MsgReadWriter) error {\n\t\t\t\treturn c.protocolManager.runPeer(version, p, rw)\n\t\t\t},\n\t\t\tPeerInfo: func(id enode.ID) interface{} {\n\t\t\t\tif p := c.protocolManager.peers.Peer(fmt.Sprintf(\"%x\", id.Bytes())); p != nil {\n\t\t\t\t\treturn p.Info()\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t},\n\t\t}\n\t}\n\treturn protos\n}"}, {"instruction": "// RunConfigView gets the configuration persisted in the cluster", "input": "go language", "output": "func RunConfigView(out io.Writer, client clientset.Interface) error {\n\n\tklog.V(1).Infoln(\"[config] getting the cluster configuration\")\n\tcfgConfigMap, err := client.CoreV1().ConfigMaps(metav1.NamespaceSystem).Get(constants.KubeadmConfigConfigMap, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\t// No need to append \\n as that already exists in the ConfigMap\n\tfmt.Fprintf(out, \"%s\", cfgConfigMap.Data[constants.ClusterConfigurationConfigMapKey])\n\treturn nil\n}"}, {"instruction": "// controlledHistories returns all ControllerRevisions in namespace that selected by selector and owned by accessor\n// TODO: Rename this to controllerHistory when other controllers have been upgraded", "input": "go language", "output": "func controlledHistoryV1(\n\tapps clientappsv1.AppsV1Interface,\n\tnamespace string,\n\tselector labels.Selector,\n\taccessor metav1.Object) ([]*appsv1.ControllerRevision, error) {\n\tvar result []*appsv1.ControllerRevision\n\thistoryList, err := apps.ControllerRevisions(namespace).List(metav1.ListOptions{LabelSelector: selector.String()})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i := range historyList.Items {\n\t\thistory := historyList.Items[i]\n\t\t// Only add history that belongs to the API object\n\t\tif metav1.IsControlledBy(&history, accessor) {\n\t\t\tresult = append(result, &history)\n\t\t}\n\t}\n\treturn result, nil\n}"}, {"instruction": "// Read is used to perform a read-only transaction that doesn't modify the state\n// store. This is much more scalable since it doesn't go through Raft and\n// supports staleness, so this should be preferred if you're just performing\n// reads.", "input": "go language", "output": "func (t *Txn) Read(args *structs.TxnReadRequest, reply *structs.TxnReadResponse) error {\n\tif done, err := t.srv.forward(\"Txn.Read\", args, args, reply); done {\n\t\treturn err\n\t}\n\tdefer metrics.MeasureSince([]string{\"txn\", \"read\"}, time.Now())\n\n\t// We have to do this ourselves since we are not doing a blocking RPC.\n\tt.srv.setQueryMeta(&reply.QueryMeta)\n\tif args.RequireConsistent {\n\t\tif err := t.srv.consistentRead(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Run the pre-checks before we perform the read.\n\tauthorizer, err := t.srv.ResolveToken(args.Token)\n\tif err != nil {\n\t\treturn err\n\t}\n\treply.Errors = t.preCheck(authorizer, args.Ops)\n\tif len(reply.Errors) > 0 {\n\t\treturn nil\n\t}\n\n\t// Run the read transaction.\n\tstate := t.srv.fsm.State()\n\treply.Results, reply.Errors = state.TxnRO(args.Ops)\n\tif authorizer != nil {\n\t\treply.Results = FilterTxnResults(authorizer, reply.Results)\n\t}\n\treturn nil\n}"}, {"instruction": "// GetMountPoints gives a platform specific transformation to types.MountPoint. Callers must hold a Container lock.", "input": "go language", "output": "func (container *Container) GetMountPoints() []types.MountPoint {\n\tmountPoints := make([]types.MountPoint, 0, len(container.MountPoints))\n\tfor _, m := range container.MountPoints {\n\t\tmountPoints = append(mountPoints, types.MountPoint{\n\t\t\tType:        m.Type,\n\t\t\tName:        m.Name,\n\t\t\tSource:      m.Path(),\n\t\t\tDestination: m.Destination,\n\t\t\tDriver:      m.Driver,\n\t\t\tMode:        m.Mode,\n\t\t\tRW:          m.RW,\n\t\t\tPropagation: m.Propagation,\n\t\t})\n\t}\n\treturn mountPoints\n}"}, {"instruction": "// getAttach handles requests to attach to a container.", "input": "go language", "output": "func (s *Server) getAttach(request *restful.Request, response *restful.Response) {\n\tparams := getExecRequestParams(request)\n\tstreamOpts, err := remotecommandserver.NewOptions(request.Request)\n\tif err != nil {\n\t\tutilruntime.HandleError(err)\n\t\tresponse.WriteError(http.StatusBadRequest, err)\n\t\treturn\n\t}\n\tpod, ok := s.host.GetPodByName(params.podNamespace, params.podName)\n\tif !ok {\n\t\tresponse.WriteError(http.StatusNotFound, fmt.Errorf(\"pod does not exist\"))\n\t\treturn\n\t}\n\n\tpodFullName := kubecontainer.GetPodFullName(pod)\n\turl, err := s.host.GetAttach(podFullName, params.podUID, params.containerName, *streamOpts)\n\tif err != nil {\n\t\tstreaming.WriteError(err, response.ResponseWriter)\n\t\treturn\n\t}\n\n\tif s.redirectContainerStreaming {\n\t\thttp.Redirect(response.ResponseWriter, request.Request, url.String(), http.StatusFound)\n\t\treturn\n\t}\n\tproxyStream(response.ResponseWriter, request.Request, url)\n}"}, {"instruction": "// validatePSPSupplementalGroup validates the SupplementalGroupsStrategyOptions fields of the PodSecurityPolicy.", "input": "go language", "output": "func validatePSPSupplementalGroup(fldPath *field.Path, groupOptions *policy.SupplementalGroupsStrategyOptions) field.ErrorList {\n\tallErrs := field.ErrorList{}\n\n\tsupportedRules := sets.NewString(\n\t\tstring(policy.SupplementalGroupsStrategyRunAsAny),\n\t\tstring(policy.SupplementalGroupsStrategyMayRunAs),\n\t\tstring(policy.SupplementalGroupsStrategyMustRunAs),\n\t)\n\tif !supportedRules.Has(string(groupOptions.Rule)) {\n\t\tallErrs = append(allErrs, field.NotSupported(fldPath.Child(\"rule\"), groupOptions.Rule, supportedRules.List()))\n\t}\n\n\tfor idx, rng := range groupOptions.Ranges {\n\t\tallErrs = append(allErrs, validateGroupIDRange(fldPath.Child(\"ranges\").Index(idx), rng)...)\n\t}\n\treturn allErrs\n}"}, {"instruction": "// Commit implements the function in the interface `Store`", "input": "go language", "output": "func (s *store) Commit() error {\n\tif !s.batchPending {\n\t\treturn &ErrIllegalCall{\"No pending batch to commit\"}\n\t}\n\tcommittingBlockNum := s.nextBlockNum()\n\tlogger.Debugf(\"Committing private data for block [%d]\", committingBlockNum)\n\tbatch := leveldbhelper.NewUpdateBatch()\n\tbatch.Delete(pendingCommitKey)\n\tbatch.Put(lastCommittedBlkkey, encodeLastCommittedBlockVal(committingBlockNum))\n\tif err := s.db.WriteBatch(batch, true); err != nil {\n\t\treturn err\n\t}\n\ts.batchPending = false\n\ts.isEmpty = false\n\ts.lastCommittedBlock = committingBlockNum\n\tlogger.Debugf(\"Committed private data for block [%d]\", committingBlockNum)\n\ts.performPurgeIfScheduled(committingBlockNum)\n\treturn nil\n}"}, {"instruction": "// creates a unique path for disks (even if they share the same *.vhd name)", "input": "go language", "output": "func makeGlobalPDPath(host volume.VolumeHost, diskUri string, isManaged bool) (string, error) {\n\tdiskUri = libstrings.ToLower(diskUri) // always lower uri because users may enter it in caps.\n\tuniqueDiskNameTemplate := \"%s%s\"\n\thashedDiskUri := azure.MakeCRC32(diskUri)\n\tprefix := \"b\"\n\tif isManaged {\n\t\tprefix = \"m\"\n\t}\n\t// \"{m for managed b for blob}{hashed diskUri or DiskId depending on disk kind }\"\n\tdiskName := fmt.Sprintf(uniqueDiskNameTemplate, prefix, hashedDiskUri)\n\tpdPath := filepath.Join(host.GetPluginDir(azureDataDiskPluginName), util.MountsInGlobalPDPath, diskName)\n\n\treturn pdPath, nil\n}"}, {"instruction": "// evalRecursive visits the given value recursively and pushes all of them to result", "input": "go language", "output": "func (j *JSONPath) evalRecursive(input []reflect.Value, node *RecursiveNode) ([]reflect.Value, error) {\n\tresult := []reflect.Value{}\n\tfor _, value := range input {\n\t\tresults := []reflect.Value{}\n\t\tvalue, isNil := template.Indirect(value)\n\t\tif isNil {\n\t\t\tcontinue\n\t\t}\n\n\t\tkind := value.Kind()\n\t\tif kind == reflect.Struct {\n\t\t\tfor i := 0; i < value.NumField(); i++ {\n\t\t\t\tresults = append(results, value.Field(i))\n\t\t\t}\n\t\t} else if kind == reflect.Map {\n\t\t\tfor _, key := range value.MapKeys() {\n\t\t\t\tresults = append(results, value.MapIndex(key))\n\t\t\t}\n\t\t} else if kind == reflect.Array || kind == reflect.Slice || kind == reflect.String {\n\t\t\tfor i := 0; i < value.Len(); i++ {\n\t\t\t\tresults = append(results, value.Index(i))\n\t\t\t}\n\t\t}\n\t\tif len(results) != 0 {\n\t\t\tresult = append(result, value)\n\t\t\toutput, err := j.evalRecursive(results, node)\n\t\t\tif err != nil {\n\t\t\t\treturn result, err\n\t\t\t}\n\t\t\tresult = append(result, output...)\n\t\t}\n\t}\n\treturn result, nil\n}"}, {"instruction": "// Reload reads the configuration in the host and reloads the daemon and server.", "input": "go language", "output": "func Reload(configFile string, flags *pflag.FlagSet, reload func(*Config)) error {\n\tlogrus.Infof(\"Got signal to reload configuration, reloading from: %s\", configFile)\n\tnewConfig, err := getConflictFreeConfiguration(configFile, flags)\n\tif err != nil {\n\t\tif flags.Changed(\"config-file\") || !os.IsNotExist(err) {\n\t\t\treturn errors.Wrapf(err, \"unable to configure the Docker daemon with file %s\", configFile)\n\t\t}\n\t\tnewConfig = New()\n\t}\n\n\tif err := Validate(newConfig); err != nil {\n\t\treturn errors.Wrap(err, \"file configuration validation failed\")\n\t}\n\n\t// Check if duplicate label-keys with different values are found\n\tnewLabels, err := GetConflictFreeLabels(newConfig.Labels)\n\tif err != nil {\n\t\treturn err\n\t}\n\tnewConfig.Labels = newLabels\n\n\treload(newConfig)\n\treturn nil\n}"}, {"instruction": "// SignIntermediate returns a signed CA certificate with a path length constraint\n// of 0 to ensure that the certificate cannot be used to generate further CA certs.", "input": "go language", "output": "func (v *VaultProvider) SignIntermediate(csr *x509.CertificateRequest) (string, error) {\n\tvar pemBuf bytes.Buffer\n\terr := pem.Encode(&pemBuf, &pem.Block{Type: \"CERTIFICATE REQUEST\", Bytes: csr.Raw})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// Sign the CSR with the root backend.\n\tdata, err := v.client.Logical().Write(v.config.RootPKIPath+\"root/sign-intermediate\", map[string]interface{}{\n\t\t\"csr\":             pemBuf.String(),\n\t\t\"format\":          \"pem_bundle\",\n\t\t\"max_path_length\": 0,\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif data == nil || data.Data[\"certificate\"] == \"\" {\n\t\treturn \"\", fmt.Errorf(\"got empty value when generating intermediate certificate\")\n\t}\n\n\tintermediate, ok := data.Data[\"certificate\"].(string)\n\tif !ok {\n\t\treturn \"\", fmt.Errorf(\"signed intermediate result is not a string\")\n\t}\n\n\treturn intermediate, nil\n}"}, {"instruction": "// RegisterDefaults adds defaulters functions to the given scheme.\n// Public to allow building arbitrary schemes.\n// All generated defaulters are covering - they call all nested defaulters.", "input": "go language", "output": "func RegisterDefaults(scheme *runtime.Scheme) error {\n\tscheme.AddTypeDefaultingFunc(&ClusterConfiguration{}, func(obj interface{}) { SetObjectDefaults_ClusterConfiguration(obj.(*ClusterConfiguration)) })\n\tscheme.AddTypeDefaultingFunc(&ClusterStatus{}, func(obj interface{}) { SetObjectDefaults_ClusterStatus(obj.(*ClusterStatus)) })\n\tscheme.AddTypeDefaultingFunc(&InitConfiguration{}, func(obj interface{}) { SetObjectDefaults_InitConfiguration(obj.(*InitConfiguration)) })\n\tscheme.AddTypeDefaultingFunc(&JoinConfiguration{}, func(obj interface{}) { SetObjectDefaults_JoinConfiguration(obj.(*JoinConfiguration)) })\n\treturn nil\n}"}, {"instruction": "// Verify checks that the passed signatures is valid with the respect to the passed digest, issuer public key,\n// and pseudonym public key.", "input": "go language", "output": "func (*NymSignatureScheme) Verify(ipk handlers.IssuerPublicKey, Nym handlers.Ecp, signature, digest []byte) (err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = errors.Errorf(\"failure [%s]\", r)\n\t\t}\n\t}()\n\n\tiipk, ok := ipk.(*IssuerPublicKey)\n\tif !ok {\n\t\treturn errors.Errorf(\"invalid issuer public key, expected *IssuerPublicKey, got [%T]\", ipk)\n\t}\n\tinym, ok := Nym.(*Ecp)\n\tif !ok {\n\t\treturn errors.Errorf(\"invalid nym public key, expected *Ecp, got [%T]\", Nym)\n\t}\n\n\tsig := &cryptolib.NymSignature{}\n\terr = proto.Unmarshal(signature, sig)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"error unmarshalling signature\")\n\t}\n\n\treturn sig.Ver(inym.E, iipk.PK, digest)\n}"}, {"instruction": "// Create creates a volume with the given name and driver\n// If the volume needs to be created with a reference to prevent race conditions\n// with volume cleanup, make sure to use the `CreateWithReference` option.", "input": "go language", "output": "func (s *VolumeStore) Create(ctx context.Context, name, driverName string, createOpts ...opts.CreateOption) (volume.Volume, error) {\n\tvar cfg opts.CreateConfig\n\tfor _, o := range createOpts {\n\t\to(&cfg)\n\t}\n\n\tname = normalizeVolumeName(name)\n\ts.locks.Lock(name)\n\tdefer s.locks.Unlock(name)\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\tv, err := s.create(ctx, name, driverName, cfg.Options, cfg.Labels)\n\tif err != nil {\n\t\tif _, ok := err.(*OpErr); ok {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn nil, &OpErr{Err: err, Name: name, Op: \"create\"}\n\t}\n\n\ts.setNamed(v, cfg.Reference)\n\treturn v, nil\n}"}, {"instruction": "// expire is the generic check that move expired tasks from a pending pool back\n// into a task pool, returning all entities caught with expired tasks.\n//\n// Note, this method expects the queue lock to be already held. The\n// reason the lock is not obtained in here is because the parameters already need\n// to access the queue, so they already need a lock anyway.", "input": "go language", "output": "func (q *queue) expire(timeout time.Duration, pendPool map[string]*fetchRequest, taskQueue *prque.Prque, timeoutMeter metrics.Meter) map[string]int {\n\t// Iterate over the expired requests and return each to the queue\n\texpiries := make(map[string]int)\n\tfor id, request := range pendPool {\n\t\tif time.Since(request.Time) > timeout {\n\t\t\t// Update the metrics with the timeout\n\t\t\ttimeoutMeter.Mark(1)\n\n\t\t\t// Return any non satisfied requests to the pool\n\t\t\tif request.From > 0 {\n\t\t\t\ttaskQueue.Push(request.From, -int64(request.From))\n\t\t\t}\n\t\t\tfor _, header := range request.Headers {\n\t\t\t\ttaskQueue.Push(header, -int64(header.Number.Uint64()))\n\t\t\t}\n\t\t\t// Add the peer to the expiry report along the number of failed requests\n\t\t\texpiries[id] = len(request.Headers)\n\n\t\t\t// Remove the expired requests from the pending pool directly\n\t\t\tdelete(pendPool, id)\n\t\t}\n\t}\n\treturn expiries\n}"}, {"instruction": "// LogicalJoin can generates hash join, index join and sort merge join.\n// Firstly we check the hint, if hint is figured by user, we force to choose the corresponding physical plan.\n// If the hint is not matched, it will get other candidates.\n// If the hint is not figured, we will pick all candidates.", "input": "go language", "output": "func (p *LogicalJoin) exhaustPhysicalPlans(prop *property.PhysicalProperty) []PhysicalPlan {\n\tmergeJoins := p.getMergeJoin(prop)\n\tif (p.preferJoinType & preferMergeJoin) > 0 {\n\t\treturn mergeJoins\n\t}\n\tjoins := make([]PhysicalPlan, 0, 5)\n\tjoins = append(joins, mergeJoins...)\n\n\tindexJoins, forced := p.tryToGetIndexJoin(prop)\n\tif forced {\n\t\treturn indexJoins\n\t}\n\tjoins = append(joins, indexJoins...)\n\n\thashJoins := p.getHashJoins(prop)\n\tif (p.preferJoinType & preferHashJoin) > 0 {\n\t\treturn hashJoins\n\t}\n\tjoins = append(joins, hashJoins...)\n\treturn joins\n}"}, {"instruction": "// NewContainerManager creates windows container manager.", "input": "go language", "output": "func NewContainerManager(mountUtil mount.Interface, cadvisorInterface cadvisor.Interface, nodeConfig NodeConfig, failSwapOn bool, devicePluginEnabled bool, recorder record.EventRecorder) (ContainerManager, error) {\n\tvar capacity = v1.ResourceList{}\n\t// It is safe to invoke `MachineInfo` on cAdvisor before logically initializing cAdvisor here because\n\t// machine info is computed and cached once as part of cAdvisor object creation.\n\t// But `RootFsInfo` and `ImagesFsInfo` are not available at this moment so they will be called later during manager starts\n\tmachineInfo, err := cadvisorInterface.MachineInfo()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcapacity = cadvisor.CapacityFromMachineInfo(machineInfo)\n\n\treturn &containerManagerImpl{\n\t\tcapacity:          capacity,\n\t\tnodeConfig:        nodeConfig,\n\t\tcadvisorInterface: cadvisorInterface,\n\t}, nil\n}"}, {"instruction": "// EnforcePtr ensures that obj is a pointer of some sort. Returns a reflect.Value\n// of the dereferenced pointer, ensuring that it is settable/addressable.\n// Returns an error if this is not possible.", "input": "go language", "output": "func EnforcePtr(obj interface{}) (reflect.Value, error) {\n\tv := reflect.ValueOf(obj)\n\tif v.Kind() != reflect.Ptr {\n\t\tif v.Kind() == reflect.Invalid {\n\t\t\treturn reflect.Value{}, fmt.Errorf(\"expected pointer, but got invalid kind\")\n\t\t}\n\t\treturn reflect.Value{}, fmt.Errorf(\"expected pointer, but got %v type\", v.Type())\n\t}\n\tif v.IsNil() {\n\t\treturn reflect.Value{}, fmt.Errorf(\"expected pointer, but got nil\")\n\t}\n\treturn v.Elem(), nil\n}"}, {"instruction": "// evalString evals a builtinGreatestStringSig.\n// See http://dev.mysql.com/doc/refman/5.7/en/comparison-operators.html#function_greatest", "input": "go language", "output": "func (b *builtinGreatestStringSig) evalString(row chunk.Row) (max string, isNull bool, err error) {\n\tmax, isNull, err = b.args[0].EvalString(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn max, isNull, err\n\t}\n\tfor i := 1; i < len(b.args); i++ {\n\t\tvar v string\n\t\tv, isNull, err = b.args[i].EvalString(b.ctx, row)\n\t\tif isNull || err != nil {\n\t\t\treturn max, isNull, err\n\t\t}\n\t\tif types.CompareString(v, max) > 0 {\n\t\t\tmax = v\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// doEncHandshake runs the protocol handshake using authenticated\n// messages. the protocol handshake is the first authenticated message\n// and also verifies whether the encryption handshake 'worked' and the\n// remote side actually provided the right public key.", "input": "go language", "output": "func (t *rlpx) doEncHandshake(prv *ecdsa.PrivateKey, dial *ecdsa.PublicKey) (*ecdsa.PublicKey, error) {\n\tvar (\n\t\tsec secrets\n\t\terr error\n\t)\n\tif dial == nil {\n\t\tsec, err = receiverEncHandshake(t.fd, prv)\n\t} else {\n\t\tsec, err = initiatorEncHandshake(t.fd, prv, dial)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tt.wmu.Lock()\n\tt.rw = newRLPXFrameRW(t.fd, sec)\n\tt.wmu.Unlock()\n\treturn sec.Remote.ExportECDSA(), nil\n}"}, {"instruction": "// IsPodCgroup returns true if the literal cgroupfs name corresponds to a pod", "input": "go language", "output": "func (m *podContainerManagerImpl) IsPodCgroup(cgroupfs string) (bool, types.UID) {\n\t// convert the literal cgroupfs form to the driver specific value\n\tcgroupName := m.cgroupManager.CgroupName(cgroupfs)\n\tqosContainersList := [3]CgroupName{m.qosContainersInfo.BestEffort, m.qosContainersInfo.Burstable, m.qosContainersInfo.Guaranteed}\n\tbasePath := \"\"\n\tfor _, qosContainerName := range qosContainersList {\n\t\t// a pod cgroup is a direct child of a qos node, so check if its a match\n\t\tif len(cgroupName) == len(qosContainerName)+1 {\n\t\t\tbasePath = cgroupName[len(qosContainerName)]\n\t\t}\n\t}\n\tif basePath == \"\" {\n\t\treturn false, types.UID(\"\")\n\t}\n\tif !strings.HasPrefix(basePath, podCgroupNamePrefix) {\n\t\treturn false, types.UID(\"\")\n\t}\n\tparts := strings.Split(basePath, podCgroupNamePrefix)\n\tif len(parts) != 2 {\n\t\treturn false, types.UID(\"\")\n\t}\n\treturn true, types.UID(parts[1])\n}"}, {"instruction": "// waitForJob is a helper that waits for a job to complete.\n//\n// This operates on an event returned from a watcher.", "input": "go language", "output": "func (c *Client) waitForJob(e watch.Event, name string) (bool, error) {\n\tjob := &batch.Job{}\n\terr := legacyscheme.Scheme.Convert(e.Object, job, nil)\n\tif err != nil {\n\t\treturn true, err\n\t}\n\n\tfor _, c := range job.Status.Conditions {\n\t\tif c.Type == batch.JobComplete && c.Status == v1.ConditionTrue {\n\t\t\treturn true, nil\n\t\t} else if c.Type == batch.JobFailed && c.Status == v1.ConditionTrue {\n\t\t\treturn true, fmt.Errorf(\"Job failed: %s\", c.Reason)\n\t\t}\n\t}\n\n\tc.Log(\"%s: Jobs active: %d, jobs failed: %d, jobs succeeded: %d\", name, job.Status.Active, job.Status.Failed, job.Status.Succeeded)\n\treturn false, nil\n}"}, {"instruction": "// login calls SessionManager.LoginByToken if certificate and private key are configured,\n// otherwise calls SessionManager.Login with user and password.", "input": "go language", "output": "func (connection *VSphereConnection) login(ctx context.Context, client *vim25.Client) error {\n\tm := session.NewManager(client)\n\tconnection.credentialsLock.Lock()\n\tdefer connection.credentialsLock.Unlock()\n\n\tsigner, err := connection.Signer(ctx, client)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif signer == nil {\n\t\tklog.V(3).Infof(\"SessionManager.Login with username %q\", connection.Username)\n\t\treturn m.Login(ctx, neturl.UserPassword(connection.Username, connection.Password))\n\t}\n\n\tklog.V(3).Infof(\"SessionManager.LoginByToken with certificate %q\", connection.Username)\n\n\theader := soap.Header{Security: signer}\n\n\treturn m.LoginByToken(client.WithHeader(ctx, header))\n}"}, {"instruction": "// Visit walks the provided node, transforming field initializations of the form\n// m.Field = &OptionalType{} -> m.Field = OptionalType{}", "input": "go language", "output": "func (v optionalAssignmentVisitor) Visit(n ast.Node) ast.Visitor {\n\tswitch t := n.(type) {\n\tcase *ast.AssignStmt:\n\t\tif len(t.Lhs) == 1 && len(t.Rhs) == 1 {\n\t\t\tif !isFieldSelector(t.Lhs[0], \"m\", \"\") {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tunary, ok := t.Rhs[0].(*ast.UnaryExpr)\n\t\t\tif !ok || unary.Op != token.AND {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tcomposite, ok := unary.X.(*ast.CompositeLit)\n\t\t\tif !ok || composite.Type == nil || len(composite.Elts) != 0 {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif ident, ok := composite.Type.(*ast.Ident); ok && v.fn(ident.Name) {\n\t\t\t\tt.Rhs[0] = composite\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\treturn v\n}"}, {"instruction": "// GetPath returns the path to the user specific mount of a Quobyte volume\n// Returns a path in the format ../user#group@volume", "input": "go language", "output": "func (quobyteVolume *quobyte) GetPath() string {\n\tuser := quobyteVolume.user\n\tif len(user) == 0 {\n\t\tuser = \"root\"\n\t}\n\n\tgroup := quobyteVolume.group\n\tif len(group) == 0 {\n\t\tgroup = \"nfsnobody\"\n\t}\n\n\t// Quobyte has only one mount in the PluginDir where all Volumes are mounted\n\t// The Quobyte client does a fixed-user mapping\n\tpluginDir := quobyteVolume.plugin.host.GetPluginDir(utilstrings.EscapeQualifiedName(quobytePluginName))\n\treturn filepath.Join(pluginDir, fmt.Sprintf(\"%s#%s@%s\", user, group, quobyteVolume.volume))\n}"}, {"instruction": "// ticketsInWindow returns the tickets of a given topic in the registration window.", "input": "go language", "output": "func (s *ticketStore) ticketsInWindow(topic Topic) []ticketRef {\n\t// Sanity check that the topic still exists before operating on it\n\tif s.tickets[topic] == nil {\n\t\tlog.Warn(\"Listing non-existing discovery tickets\", \"topic\", topic)\n\t\treturn nil\n\t}\n\t// Gather all the tickers in the next time window\n\tvar tickets []ticketRef\n\n\tbuckets := s.tickets[topic].buckets\n\tfor idx := timeBucket(0); idx < timeWindow; idx++ {\n\t\ttickets = append(tickets, buckets[s.lastBucketFetched+idx]...)\n\t}\n\tlog.Trace(\"Retrieved discovery registration tickets\", \"topic\", topic, \"from\", s.lastBucketFetched, \"tickets\", len(tickets))\n\treturn tickets\n}"}, {"instruction": "// SetFormat updates how log records are formatted and encoded. Log entries\n// created after this method has completed will use the new format.\n//\n// An error is returned if the log format specification cannot be parsed.", "input": "go language", "output": "func (s *Logging) SetFormat(format string) error {\n\ts.mutex.Lock()\n\tdefer s.mutex.Unlock()\n\tif format == \"\" {\n\t\tformat = defaultFormat\n\t}\n\n\tif format == \"json\" {\n\t\ts.encoding = JSON\n\t\treturn nil\n\t}\n\n\tif format == \"logfmt\" {\n\t\ts.encoding = LOGFMT\n\t\treturn nil\n\t}\n\n\tformatters, err := fabenc.ParseFormat(format)\n\tif err != nil {\n\t\treturn err\n\t}\n\ts.multiFormatter.SetFormatters(formatters)\n\ts.encoding = CONSOLE\n\n\treturn nil\n}"}, {"instruction": "// update keeps track of the downloader events. Please be aware that this is a one shot type of update loop.\n// It's entered once and as soon as `Done` or `Failed` has been broadcasted the events are unregistered and\n// the loop is exited. This to prevent a major security vuln where external parties can DOS you with blocks\n// and halt your mining operation for as long as the DOS continues.", "input": "go language", "output": "func (self *Miner) update() {\n\tevents := self.mux.Subscribe(downloader.StartEvent{}, downloader.DoneEvent{}, downloader.FailedEvent{})\n\tdefer events.Unsubscribe()\n\n\tfor {\n\t\tselect {\n\t\tcase ev := <-events.Chan():\n\t\t\tif ev == nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tswitch ev.Data.(type) {\n\t\t\tcase downloader.StartEvent:\n\t\t\t\tatomic.StoreInt32(&self.canStart, 0)\n\t\t\t\tif self.Mining() {\n\t\t\t\t\tself.Stop()\n\t\t\t\t\tatomic.StoreInt32(&self.shouldStart, 1)\n\t\t\t\t\tlog.Info(\"Mining aborted due to sync\")\n\t\t\t\t}\n\t\t\tcase downloader.DoneEvent, downloader.FailedEvent:\n\t\t\t\tshouldStart := atomic.LoadInt32(&self.shouldStart) == 1\n\n\t\t\t\tatomic.StoreInt32(&self.canStart, 1)\n\t\t\t\tatomic.StoreInt32(&self.shouldStart, 0)\n\t\t\t\tif shouldStart {\n\t\t\t\t\tself.Start(self.coinbase)\n\t\t\t\t}\n\t\t\t\t// stop immediately and ignore all further pending events\n\t\t\t\treturn\n\t\t\t}\n\t\tcase <-self.exitCh:\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// ResolveIndices implements Plan interface.", "input": "go language", "output": "func (p *basePhysicalAgg) ResolveIndices() (err error) {\n\terr = p.physicalSchemaProducer.ResolveIndices()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, aggFun := range p.AggFuncs {\n\t\tfor i, arg := range aggFun.Args {\n\t\t\taggFun.Args[i], err = arg.ResolveIndices(p.children[0].Schema())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\tfor i, item := range p.GroupByItems {\n\t\tp.GroupByItems[i], err = item.ResolveIndices(p.children[0].Schema())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// filterMembers redacts members that the token doesn't have access to.", "input": "go language", "output": "func (a *Agent) filterMembers(token string, members *[]serf.Member) error {\n\t// Resolve the token and bail if ACLs aren't enabled.\n\trule, err := a.resolveToken(token)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif rule == nil {\n\t\treturn nil\n\t}\n\n\t// Filter out members based on the node policy.\n\tm := *members\n\tfor i := 0; i < len(m); i++ {\n\t\tnode := m[i].Name\n\t\tif rule.NodeRead(node) {\n\t\t\tcontinue\n\t\t}\n\t\ta.logger.Printf(\"[DEBUG] agent: dropping node %q from result due to ACLs\", node)\n\t\tm = append(m[:i], m[i+1:]...)\n\t\ti--\n\t}\n\t*members = m\n\treturn nil\n}"}, {"instruction": "// splitNodeItemKey returns the components of a key created by nodeItemKey.", "input": "go language", "output": "func splitNodeItemKey(key []byte) (id ID, ip net.IP, field string) {\n\tid, key = splitNodeKey(key)\n\t// Skip discover root.\n\tif string(key) == dbDiscoverRoot {\n\t\treturn id, nil, \"\"\n\t}\n\tkey = key[len(dbDiscoverRoot)+1:]\n\t// Split out the IP.\n\tip = net.IP(key[:16])\n\tif ip4 := ip.To4(); ip4 != nil {\n\t\tip = ip4\n\t}\n\tkey = key[16+1:]\n\t// Field is the remainder of key.\n\tfield = string(key)\n\treturn id, ip, field\n}"}, {"instruction": "// ===== Example: Ad hoc rich query ========================================================\n// queryMarbles uses a query string to perform a query for marbles.\n// Query string matching state database syntax is passed in and executed as is.\n// Supports ad hoc queries that can be defined at runtime by the client.\n// If this is not desired, follow the queryMarblesForOwner example for parameterized queries.\n// Only available on state databases that support rich query (e.g. CouchDB)\n// =========================================================================================", "input": "go language", "output": "func (t *SimpleChaincode) queryMarbles(stub shim.ChaincodeStubInterface, args []string) pb.Response {\n\n\t//   0\n\t// \"queryString\"\n\tif len(args) < 1 {\n\t\treturn shim.Error(\"Incorrect number of arguments. Expecting 1\")\n\t}\n\n\tqueryString := args[0]\n\n\tqueryResults, err := getQueryResultForQueryString(stub, queryString)\n\tif err != nil {\n\t\treturn shim.Error(err.Error())\n\t}\n\treturn shim.Success(queryResults)\n}"}, {"instruction": "// validateMetaPair checks that the given key/value pair is in a valid format", "input": "go language", "output": "func validateMetaPair(key, value string, allowConsulPrefix bool) error {\n\tif key == \"\" {\n\t\treturn fmt.Errorf(\"Key cannot be blank\")\n\t}\n\tif !metaKeyFormat(key) {\n\t\treturn fmt.Errorf(\"Key contains invalid characters\")\n\t}\n\tif len(key) > metaKeyMaxLength {\n\t\treturn fmt.Errorf(\"Key is too long (limit: %d characters)\", metaKeyMaxLength)\n\t}\n\tif strings.HasPrefix(key, metaKeyReservedPrefix) && !allowConsulPrefix {\n\t\treturn fmt.Errorf(\"Key prefix '%s' is reserved for internal use\", metaKeyReservedPrefix)\n\t}\n\tif len(value) > metaValueMaxLength {\n\t\treturn fmt.Errorf(\"Value is too long (limit: %d characters)\", metaValueMaxLength)\n\t}\n\treturn nil\n}"}, {"instruction": "// setProjectQuota - set the quota for project id on xfs block device", "input": "go language", "output": "func setProjectQuota(backingFsBlockDev string, projectID uint32, quota Quota) error {\n\tvar d C.fs_disk_quota_t\n\td.d_version = C.FS_DQUOT_VERSION\n\td.d_id = C.__u32(projectID)\n\td.d_flags = C.XFS_PROJ_QUOTA\n\n\td.d_fieldmask = C.FS_DQ_BHARD | C.FS_DQ_BSOFT\n\td.d_blk_hardlimit = C.__u64(quota.Size / 512)\n\td.d_blk_softlimit = d.d_blk_hardlimit\n\n\tvar cs = C.CString(backingFsBlockDev)\n\tdefer C.free(unsafe.Pointer(cs))\n\n\t_, _, errno := unix.Syscall6(unix.SYS_QUOTACTL, C.Q_XSETPQLIM,\n\t\tuintptr(unsafe.Pointer(cs)), uintptr(d.d_id),\n\t\tuintptr(unsafe.Pointer(&d)), 0, 0)\n\tif errno != 0 {\n\t\treturn errors.Wrapf(errno, \"failed to set quota limit for projid %d on %s\",\n\t\t\tprojectID, backingFsBlockDev)\n\t}\n\n\treturn nil\n}"}, {"instruction": "// points2Ranges build index ranges from range points.\n// Only one column is built there. If there're multiple columns, use appendPoints2Ranges.", "input": "go language", "output": "func points2Ranges(sc *stmtctx.StatementContext, rangePoints []point, tp *types.FieldType) ([]*Range, error) {\n\tranges := make([]*Range, 0, len(rangePoints)/2)\n\tfor i := 0; i < len(rangePoints); i += 2 {\n\t\tstartPoint, err := convertPoint(sc, rangePoints[i], tp)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tendPoint, err := convertPoint(sc, rangePoints[i+1], tp)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tless, err := validInterval(sc, startPoint, endPoint)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Trace(err)\n\t\t}\n\t\tif !less {\n\t\t\tcontinue\n\t\t}\n\t\t// If column has not null flag, [null, null] should be removed.\n\t\tif mysql.HasNotNullFlag(tp.Flag) && endPoint.value.Kind() == types.KindNull {\n\t\t\tcontinue\n\t\t}\n\n\t\tran := &Range{\n\t\t\tLowVal:      []types.Datum{startPoint.value},\n\t\t\tLowExclude:  startPoint.excl,\n\t\t\tHighVal:     []types.Datum{endPoint.value},\n\t\t\tHighExclude: endPoint.excl,\n\t\t}\n\t\tranges = append(ranges, ran)\n\t}\n\treturn ranges, nil\n}"}, {"instruction": "// GetExec gets the URL the exec will be served from, or nil if the Kubelet will serve it.", "input": "go language", "output": "func (kl *Kubelet) GetExec(podFullName string, podUID types.UID, containerName string, cmd []string, streamOpts remotecommandserver.Options) (*url.URL, error) {\n\tcontainer, err := kl.findContainer(podFullName, podUID, containerName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif container == nil {\n\t\treturn nil, fmt.Errorf(\"container not found (%q)\", containerName)\n\t}\n\treturn kl.streamingRuntime.GetExec(container.ID, cmd, streamOpts.Stdin, streamOpts.Stdout, streamOpts.Stderr, streamOpts.TTY)\n}"}, {"instruction": "// marshalPlanModules iterates over a list of modules to recursively describe\n// the full module tree.", "input": "go language", "output": "func marshalPlanModules(\n\tchanges *plans.Changes,\n\tschemas *terraform.Schemas,\n\tchildModules []addrs.ModuleInstance,\n\tmoduleMap map[string][]addrs.ModuleInstance,\n\tmoduleResourceMap map[string][]addrs.AbsResourceInstance,\n) ([]module, error) {\n\n\tvar ret []module\n\n\tfor _, child := range childModules {\n\t\tmoduleResources := moduleResourceMap[child.String()]\n\t\t// cm for child module, naming things is hard.\n\t\tvar cm module\n\t\t// don't populate the address for the root module\n\t\tif child.String() != \"\" {\n\t\t\tcm.Address = child.String()\n\t\t}\n\t\trs, err := marshalPlanResources(changes, moduleResources, schemas)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcm.Resources = rs\n\n\t\tif len(moduleMap[child.String()]) > 0 {\n\t\t\tmoreChildModules, err := marshalPlanModules(changes, schemas, moduleMap[child.String()], moduleMap, moduleResourceMap)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tcm.ChildModules = moreChildModules\n\t\t}\n\n\t\tret = append(ret, cm)\n\t}\n\n\treturn ret, nil\n}"}, {"instruction": "// Admit makes an admission decision based on the request attributes", "input": "go language", "output": "func (a *AlwaysPullImages) Admit(attributes admission.Attributes, o admission.ObjectInterfaces) (err error) {\n\t// Ignore all calls to subresources or resources other than pods.\n\tif shouldIgnore(attributes) {\n\t\treturn nil\n\t}\n\tpod, ok := attributes.GetObject().(*api.Pod)\n\tif !ok {\n\t\treturn apierrors.NewBadRequest(\"Resource was marked with kind Pod but was unable to be converted\")\n\t}\n\n\tfor i := range pod.Spec.InitContainers {\n\t\tpod.Spec.InitContainers[i].ImagePullPolicy = api.PullAlways\n\t}\n\n\tfor i := range pod.Spec.Containers {\n\t\tpod.Spec.Containers[i].ImagePullPolicy = api.PullAlways\n\t}\n\n\treturn nil\n}"}, {"instruction": "// DeleteExpectations deletes the UID set and invokes DeleteExpectations on the\n// underlying ControllerExpectationsInterface.", "input": "go language", "output": "func (u *UIDTrackingControllerExpectations) DeleteExpectations(rcKey string) {\n\tu.uidStoreLock.Lock()\n\tdefer u.uidStoreLock.Unlock()\n\n\tu.ControllerExpectationsInterface.DeleteExpectations(rcKey)\n\tif uidExp, exists, err := u.uidStore.GetByKey(rcKey); err == nil && exists {\n\t\tif err := u.uidStore.Delete(uidExp); err != nil {\n\t\t\tklog.V(2).Infof(\"Error deleting uid expectations for controller %v: %v\", rcKey, err)\n\t\t}\n\t}\n}"}, {"instruction": "// MergeExecDetails merges a single region execution details into self, used to print\n// the information in slow query log.", "input": "go language", "output": "func (sc *StatementContext) MergeExecDetails(details *execdetails.ExecDetails, commitDetails *execdetails.CommitDetails) {\n\tsc.mu.Lock()\n\tif details != nil {\n\t\tsc.mu.execDetails.ProcessTime += details.ProcessTime\n\t\tsc.mu.execDetails.WaitTime += details.WaitTime\n\t\tsc.mu.execDetails.BackoffTime += details.BackoffTime\n\t\tsc.mu.execDetails.RequestCount++\n\t\tsc.mu.execDetails.TotalKeys += details.TotalKeys\n\t\tsc.mu.execDetails.ProcessedKeys += details.ProcessedKeys\n\t\tsc.mu.allExecDetails = append(sc.mu.allExecDetails, details)\n\t}\n\tsc.mu.execDetails.CommitDetail = commitDetails\n\tsc.mu.Unlock()\n}"}, {"instruction": "// resolveWindowSpec resolve window specifications for sql like `select ... from t window w1 as (w2), w2 as (partition by a)`.\n// We need to resolve the referenced window to get the definition of current window spec.", "input": "go language", "output": "func resolveWindowSpec(spec *ast.WindowSpec, specs map[string]ast.WindowSpec, inStack map[string]bool) error {\n\tif inStack[spec.Name.L] {\n\t\treturn errors.Trace(ErrWindowCircularityInWindowGraph)\n\t}\n\tif spec.Ref.L == \"\" {\n\t\treturn nil\n\t}\n\tref, ok := specs[spec.Ref.L]\n\tif !ok {\n\t\treturn ErrWindowNoSuchWindow.GenWithStackByArgs(spec.Ref.O)\n\t}\n\tinStack[spec.Name.L] = true\n\terr := resolveWindowSpec(&ref, specs, inStack)\n\tif err != nil {\n\t\treturn err\n\t}\n\tinStack[spec.Name.L] = false\n\treturn mergeWindowSpec(spec, &ref)\n}"}, {"instruction": "// ConfigInspectWithRaw returns the config information with raw data", "input": "go language", "output": "func (cli *Client) ConfigInspectWithRaw(ctx context.Context, id string) (swarm.Config, []byte, error) {\n\tif id == \"\" {\n\t\treturn swarm.Config{}, nil, objectNotFoundError{object: \"config\", id: id}\n\t}\n\tif err := cli.NewVersionError(\"1.30\", \"config inspect\"); err != nil {\n\t\treturn swarm.Config{}, nil, err\n\t}\n\tresp, err := cli.get(ctx, \"/configs/\"+id, nil, nil)\n\tdefer ensureReaderClosed(resp)\n\tif err != nil {\n\t\treturn swarm.Config{}, nil, wrapResponseError(err, resp, \"config\", id)\n\t}\n\n\tbody, err := ioutil.ReadAll(resp.body)\n\tif err != nil {\n\t\treturn swarm.Config{}, nil, err\n\t}\n\n\tvar config swarm.Config\n\trdr := bytes.NewReader(body)\n\terr = json.NewDecoder(rdr).Decode(&config)\n\n\treturn config, body, err\n}"}, {"instruction": "// updateAllServiceIndexesOfNode updates the Raft index of all the services associated with this node", "input": "go language", "output": "func (s *Store) updateAllServiceIndexesOfNode(tx *memdb.Txn, idx uint64, nodeID string) error {\n\tservices, err := tx.Get(\"services\", \"node\", nodeID)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed updating services for node %s: %s\", nodeID, err)\n\t}\n\tfor service := services.Next(); service != nil; service = services.Next() {\n\t\tsvc := service.(*structs.ServiceNode).ToNodeService()\n\t\tif err := tx.Insert(\"index\", &IndexEntry{serviceIndexName(svc.Service), idx}); err != nil {\n\t\t\treturn fmt.Errorf(\"failed updating index: %s\", err)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// verifyIntegrity is a debug method to iterate over the entire trie stored in\n// memory and check whether every node is reachable from the meta root. The goal\n// is to find any errors that might cause memory leaks and or trie nodes to go\n// missing.\n//\n// This method is extremely CPU and memory intensive, only use when must.", "input": "go language", "output": "func (db *Database) verifyIntegrity() {\n\t// Iterate over all the cached nodes and accumulate them into a set\n\treachable := map[common.Hash]struct{}{{}: {}}\n\n\tfor child := range db.dirties[common.Hash{}].children {\n\t\tdb.accumulate(child, reachable)\n\t}\n\t// Find any unreachable but cached nodes\n\tvar unreachable []string\n\tfor hash, node := range db.dirties {\n\t\tif _, ok := reachable[hash]; !ok {\n\t\t\tunreachable = append(unreachable, fmt.Sprintf(\"%x: {Node: %v, Parents: %d, Prev: %x, Next: %x}\",\n\t\t\t\thash, node.node, node.parents, node.flushPrev, node.flushNext))\n\t\t}\n\t}\n\tif len(unreachable) != 0 {\n\t\tpanic(fmt.Sprintf(\"trie cache memory leak: %v\", unreachable))\n\t}\n}"}, {"instruction": "// NewBootstrapTokenString converts the given Bootstrap Token as a string\n// to the BootstrapTokenString object used for serialization/deserialization\n// and internal usage. It also automatically validates that the given token\n// is of the right format", "input": "go language", "output": "func NewBootstrapTokenString(token string) (*BootstrapTokenString, error) {\n\tsubstrs := bootstraputil.BootstrapTokenRegexp.FindStringSubmatch(token)\n\t// TODO: Add a constant for the 3 value here, and explain better why it's needed (other than because how the regexp parsin works)\n\tif len(substrs) != 3 {\n\t\treturn nil, errors.Errorf(\"the bootstrap token %q was not of the form %q\", token, bootstrapapi.BootstrapTokenPattern)\n\t}\n\n\treturn &BootstrapTokenString{ID: substrs[1], Secret: substrs[2]}, nil\n}"}, {"instruction": "// SetPBColumnsDefaultValue sets the default values of tipb.ColumnInfos.", "input": "go language", "output": "func SetPBColumnsDefaultValue(ctx sessionctx.Context, pbColumns []*tipb.ColumnInfo, columns []*model.ColumnInfo) error {\n\tfor i, c := range columns {\n\t\tif c.OriginDefaultValue == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tsessVars := ctx.GetSessionVars()\n\t\toriginStrict := sessVars.StrictSQLMode\n\t\tsessVars.StrictSQLMode = false\n\t\td, err := table.GetColOriginDefaultValue(ctx, c)\n\t\tsessVars.StrictSQLMode = originStrict\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpbColumns[i].DefaultVal, err = tablecodec.EncodeValue(ctx.GetSessionVars().StmtCtx, d)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// canAdmitPod determines if a pod can be admitted, and gives a reason if it\n// cannot. \"pod\" is new pod, while \"pods\" are all admitted pods\n// The function returns a boolean value indicating whether the pod\n// can be admitted, a brief single-word reason and a message explaining why\n// the pod cannot be admitted.", "input": "go language", "output": "func (kl *Kubelet) canAdmitPod(pods []*v1.Pod, pod *v1.Pod) (bool, string, string) {\n\t// the kubelet will invoke each pod admit handler in sequence\n\t// if any handler rejects, the pod is rejected.\n\t// TODO: move out of disk check into a pod admitter\n\t// TODO: out of resource eviction should have a pod admitter call-out\n\tattrs := &lifecycle.PodAdmitAttributes{Pod: pod, OtherPods: pods}\n\tfor _, podAdmitHandler := range kl.admitHandlers {\n\t\tif result := podAdmitHandler.Admit(attrs); !result.Admit {\n\t\t\treturn false, result.Reason, result.Message\n\t\t}\n\t}\n\n\treturn true, \"\", \"\"\n}"}, {"instruction": "// WaitForCacheSync is a helper function that waits for cache sync for CSIDriverLister", "input": "go language", "output": "func (kvh *kubeletVolumeHost) WaitForCacheSync() error {\n\tif kvh.csiDriversSynced == nil {\n\t\tklog.Error(\"csiDriversSynced not found on KubeletVolumeHost\")\n\t\treturn fmt.Errorf(\"csiDriversSynced not found on KubeletVolumeHost\")\n\t}\n\n\tsynced := []cache.InformerSynced{kvh.csiDriversSynced}\n\tif !cache.WaitForCacheSync(wait.NeverStop, synced...) {\n\t\tklog.Warning(\"failed to wait for cache sync for CSIDriverLister\")\n\t\treturn fmt.Errorf(\"failed to wait for cache sync for CSIDriverLister\")\n\t}\n\n\treturn nil\n}"}, {"instruction": "// build a marshalGraph structure from a *Graph", "input": "go language", "output": "func newMarshalGraph(name string, g *Graph) *marshalGraph {\n\tmg := &marshalGraph{\n\t\tType:  \"Graph\",\n\t\tName:  name,\n\t\tAttrs: make(map[string]string),\n\t}\n\n\tfor _, v := range g.Vertices() {\n\t\tid := marshalVertexID(v)\n\t\tif sg, ok := marshalSubgrapher(v); ok {\n\t\t\tsmg := newMarshalGraph(VertexName(v), sg)\n\t\t\tsmg.ID = id\n\t\t\tmg.Subgraphs = append(mg.Subgraphs, smg)\n\t\t}\n\n\t\tmv := newMarshalVertex(v)\n\t\tmg.Vertices = append(mg.Vertices, mv)\n\t}\n\n\tsort.Sort(vertices(mg.Vertices))\n\n\tfor _, e := range g.Edges() {\n\t\tmg.Edges = append(mg.Edges, newMarshalEdge(e))\n\t}\n\n\tsort.Sort(edges(mg.Edges))\n\n\tfor _, c := range (&AcyclicGraph{*g}).Cycles() {\n\t\tvar cycle []*marshalVertex\n\t\tfor _, v := range c {\n\t\t\tmv := newMarshalVertex(v)\n\t\t\tcycle = append(cycle, mv)\n\t\t}\n\t\tmg.Cycles = append(mg.Cycles, cycle)\n\t}\n\n\treturn mg\n}"}, {"instruction": "// Recv blocks until a response is received from the stream or the\n// timeout expires.", "input": "go language", "output": "func (stream *ImpatientStream) Recv() (*orderer.DeliverResponse, error) {\n\t// Initialize a timeout to cancel the stream when it expires\n\ttimeout := time.NewTimer(stream.waitTimeout)\n\tdefer timeout.Stop()\n\n\tresponseChan := make(chan errorAndResponse, 1)\n\n\t// receive waitGroup ensures the goroutine below exits before\n\t// this function exits.\n\tvar receive sync.WaitGroup\n\treceive.Add(1)\n\tdefer receive.Wait()\n\n\tgo func() {\n\t\tdefer receive.Done()\n\t\tresp, err := stream.AtomicBroadcast_DeliverClient.Recv()\n\t\tresponseChan <- errorAndResponse{err: err, resp: resp}\n\t}()\n\n\tselect {\n\tcase <-timeout.C:\n\t\tstream.cancelFunc()\n\t\treturn nil, errors.Errorf(\"didn't receive a response within %v\", stream.waitTimeout)\n\tcase respAndErr := <-responseChan:\n\t\treturn respAndErr.resp, respAndErr.err\n\t}\n}"}, {"instruction": "// SetRestarting sets the container state to \"restarting\" without locking.\n// It also sets the container PID to 0.", "input": "go language", "output": "func (s *State) SetRestarting(exitStatus *ExitStatus) {\n\t// we should consider the container running when it is restarting because of\n\t// all the checks in docker around rm/stop/etc\n\ts.Running = true\n\ts.Restarting = true\n\ts.Paused = false\n\ts.Pid = 0\n\ts.FinishedAt = time.Now().UTC()\n\ts.ExitCodeValue = exitStatus.ExitCode\n\ts.OOMKilled = exitStatus.OOMKilled\n\tclose(s.waitStop) // fire waiters for stop\n\ts.waitStop = make(chan struct{})\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *ISCSIVolumeSource) DeepCopyInto(out *ISCSIVolumeSource) {\n\t*out = *in\n\tif in.Portals != nil {\n\t\tin, out := &in.Portals, &out.Portals\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tif in.SecretRef != nil {\n\t\tin, out := &in.SecretRef, &out.SecretRef\n\t\t*out = new(LocalObjectReference)\n\t\t**out = **in\n\t}\n\tif in.InitiatorName != nil {\n\t\tin, out := &in.InitiatorName, &out.InitiatorName\n\t\t*out = new(string)\n\t\t**out = **in\n\t}\n\treturn\n}"}, {"instruction": "// CoordinateNode returns the LAN node in the given datacenter, along with\n// raw network coordinates.", "input": "go language", "output": "func (s *HTTPServer) CoordinateNode(resp http.ResponseWriter, req *http.Request) (interface{}, error) {\n\tif s.checkCoordinateDisabled(resp, req) {\n\t\treturn nil, nil\n\t}\n\n\tnode := strings.TrimPrefix(req.URL.Path, \"/v1/coordinate/node/\")\n\targs := structs.NodeSpecificRequest{Node: node}\n\tif done := s.parse(resp, req, &args.Datacenter, &args.QueryOptions); done {\n\t\treturn nil, nil\n\t}\n\n\tvar out structs.IndexedCoordinates\n\tdefer setMeta(resp, &out.QueryMeta)\n\tif err := s.agent.RPC(\"Coordinate.Node\", &args, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\tresult := filterCoordinates(req, out.Coordinates)\n\tif len(result) == 0 {\n\t\tresp.WriteHeader(http.StatusNotFound)\n\t\treturn nil, nil\n\t}\n\n\treturn result, nil\n}"}, {"instruction": "// IntentionGet returns the given intention by ID.", "input": "go language", "output": "func (s *Store) IntentionGet(ws memdb.WatchSet, id string) (uint64, *structs.Intention, error) {\n\ttx := s.db.Txn(false)\n\tdefer tx.Abort()\n\n\t// Get the table index.\n\tidx := maxIndexTxn(tx, intentionsTableName)\n\tif idx < 1 {\n\t\tidx = 1\n\t}\n\n\t// Look up by its ID.\n\twatchCh, intention, err := tx.FirstWatch(intentionsTableName, \"id\", id)\n\tif err != nil {\n\t\treturn 0, nil, fmt.Errorf(\"failed intention lookup: %s\", err)\n\t}\n\tws.Add(watchCh)\n\n\t// Convert the interface{} if it is non-nil\n\tvar result *structs.Intention\n\tif intention != nil {\n\t\tresult = intention.(*structs.Intention)\n\t}\n\n\treturn idx, result, nil\n}"}, {"instruction": "// newDependencyUpdateCmd creates a new dependency update command.", "input": "go language", "output": "func newDependencyUpdateCmd(out io.Writer) *cobra.Command {\n\tduc := &dependencyUpdateCmd{out: out}\n\n\tcmd := &cobra.Command{\n\t\tUse:     \"update [flags] CHART\",\n\t\tAliases: []string{\"up\"},\n\t\tShort:   \"update charts/ based on the contents of requirements.yaml\",\n\t\tLong:    dependencyUpDesc,\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tcp := \".\"\n\t\t\tif len(args) > 0 {\n\t\t\t\tcp = args[0]\n\t\t\t}\n\n\t\t\tvar err error\n\t\t\tduc.chartpath, err = filepath.Abs(cp)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tduc.helmhome = settings.Home\n\n\t\t\treturn duc.run()\n\t\t},\n\t}\n\n\tf := cmd.Flags()\n\tf.BoolVar(&duc.verify, \"verify\", false, \"verify the packages against signatures\")\n\tf.StringVar(&duc.keyring, \"keyring\", defaultKeyring(), \"keyring containing public keys\")\n\tf.BoolVar(&duc.skipRefresh, \"skip-refresh\", false, \"do not refresh the local repository cache\")\n\n\treturn cmd\n}"}, {"instruction": "// The Vector type represents a version vector. The zero value is a usable\n// version vector. The vector has slice semantics and some operations on it\n// are \"append-like\" in that they may return the same vector modified, or v\n// new allocated Vector with the modified contents.\n// Counter represents a single counter in the version vector.\n// Update returns a Vector with the index for the specific ID incremented by\n// one. If it is possible, the vector v is updated and returned. If it is not,\n// a copy will be created, updated and returned.", "input": "go language", "output": "func (v Vector) Update(id ShortID) Vector {\n\tfor i := range v.Counters {\n\t\tif v.Counters[i].ID == id {\n\t\t\t// Update an existing index\n\t\t\tv.Counters[i].Value++\n\t\t\treturn v\n\t\t} else if v.Counters[i].ID > id {\n\t\t\t// Insert a new index\n\t\t\tnv := make([]Counter, len(v.Counters)+1)\n\t\t\tcopy(nv, v.Counters[:i])\n\t\t\tnv[i].ID = id\n\t\t\tnv[i].Value = 1\n\t\t\tcopy(nv[i+1:], v.Counters[i:])\n\t\t\treturn Vector{Counters: nv}\n\t\t}\n\t}\n\t// Append a new index\n\treturn Vector{Counters: append(v.Counters, Counter{ID: id, Value: 1})}\n}"}, {"instruction": "// GetOperatingSystem gets the name of the current operating system.", "input": "go language", "output": "func GetOperatingSystem() (string, error) {\n\n\t// Default return value\n\tret := \"Unknown Operating System\"\n\n\tk, err := registry.OpenKey(registry.LOCAL_MACHINE, `SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion`, registry.QUERY_VALUE)\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tdefer k.Close()\n\n\tpn, _, err := k.GetStringValue(\"ProductName\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tret = pn\n\n\tri, _, err := k.GetStringValue(\"ReleaseId\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tret = fmt.Sprintf(\"%s Version %s\", ret, ri)\n\n\tcbn, _, err := k.GetStringValue(\"CurrentBuildNumber\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\n\tubr, _, err := k.GetIntegerValue(\"UBR\")\n\tif err != nil {\n\t\treturn ret, err\n\t}\n\tret = fmt.Sprintf(\"%s (OS Build %s.%d)\", ret, cbn, ubr)\n\n\treturn ret, nil\n}"}, {"instruction": "// updateStats bumps the various state sync progress counters and displays a log\n// message for the user to see.", "input": "go language", "output": "func (s *stateSync) updateStats(written, duplicate, unexpected int, duration time.Duration) {\n\ts.d.syncStatsLock.Lock()\n\tdefer s.d.syncStatsLock.Unlock()\n\n\ts.d.syncStatsState.pending = uint64(s.sched.Pending())\n\ts.d.syncStatsState.processed += uint64(written)\n\ts.d.syncStatsState.duplicate += uint64(duplicate)\n\ts.d.syncStatsState.unexpected += uint64(unexpected)\n\n\tif written > 0 || duplicate > 0 || unexpected > 0 {\n\t\tlog.Info(\"Imported new state entries\", \"count\", written, \"elapsed\", common.PrettyDuration(duration), \"processed\", s.d.syncStatsState.processed, \"pending\", s.d.syncStatsState.pending, \"retry\", len(s.tasks), \"duplicate\", s.d.syncStatsState.duplicate, \"unexpected\", s.d.syncStatsState.unexpected)\n\t}\n\tif written > 0 {\n\t\trawdb.WriteFastTrieProgress(s.d.stateDB, s.d.syncStatsState.processed)\n\t}\n}"}, {"instruction": "// DecodeToNode Converts the labels to a node.\n// labels -> nodes", "input": "go language", "output": "func DecodeToNode(labels map[string]string, filters ...string) (*Node, error) {\n\tvar sortedKeys []string\n\tfor key := range labels {\n\t\tif len(filters) == 0 {\n\t\t\tsortedKeys = append(sortedKeys, key)\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, filter := range filters {\n\t\t\tif len(key) >= len(filter) && strings.EqualFold(key[:len(filter)], filter) {\n\t\t\t\tsortedKeys = append(sortedKeys, key)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t}\n\tsort.Strings(sortedKeys)\n\n\tlabelRoot := \"traefik\"\n\n\tvar node *Node\n\tfor i, key := range sortedKeys {\n\t\tsplit := strings.Split(key, \".\")\n\n\t\tif split[0] != labelRoot {\n\t\t\t// TODO (@ldez): error or continue\n\t\t\treturn nil, fmt.Errorf(\"invalid label root %s\", split[0])\n\t\t}\n\n\t\tlabelRoot = split[0]\n\n\t\tif i == 0 {\n\t\t\tnode = &Node{}\n\t\t}\n\t\tdecodeToNode(node, split, labels[key])\n\t}\n\n\treturn node, nil\n}"}, {"instruction": "// prepareTempDir prepares and returns the default directory to use\n// for temporary files.\n// If it doesn't exist, it is created. If it exists, its content is removed.", "input": "go language", "output": "func prepareTempDir(rootDir string, rootIdentity idtools.Identity) (string, error) {\n\tvar tmpDir string\n\tif tmpDir = os.Getenv(\"DOCKER_TMPDIR\"); tmpDir == \"\" {\n\t\ttmpDir = filepath.Join(rootDir, \"tmp\")\n\t\tnewName := tmpDir + \"-old\"\n\t\tif err := os.Rename(tmpDir, newName); err == nil {\n\t\t\tgo func() {\n\t\t\t\tif err := os.RemoveAll(newName); err != nil {\n\t\t\t\t\tlogrus.Warnf(\"failed to delete old tmp directory: %s\", newName)\n\t\t\t\t}\n\t\t\t}()\n\t\t} else if !os.IsNotExist(err) {\n\t\t\tlogrus.Warnf(\"failed to rename %s for background deletion: %s. Deleting synchronously\", tmpDir, err)\n\t\t\tif err := os.RemoveAll(tmpDir); err != nil {\n\t\t\t\tlogrus.Warnf(\"failed to delete old tmp directory: %s\", tmpDir)\n\t\t\t}\n\t\t}\n\t}\n\t// We don't remove the content of tmpdir if it's not the default,\n\t// it may hold things that do not belong to us.\n\treturn tmpDir, idtools.MkdirAllAndChown(tmpDir, 0700, rootIdentity)\n}"}, {"instruction": "// ComputeHash returns a hash value calculated from pod template and\n// a collisionCount to avoid hash collision. The hash will be safe encoded to\n// avoid bad words.", "input": "go language", "output": "func ComputeHash(template *v1.PodTemplateSpec, collisionCount *int32) string {\n\tpodTemplateSpecHasher := fnv.New32a()\n\thashutil.DeepHashObject(podTemplateSpecHasher, *template)\n\n\t// Add collisionCount in the hash if it exists.\n\tif collisionCount != nil {\n\t\tcollisionCountBytes := make([]byte, 8)\n\t\tbinary.LittleEndian.PutUint32(collisionCountBytes, uint32(*collisionCount))\n\t\tpodTemplateSpecHasher.Write(collisionCountBytes)\n\t}\n\n\treturn rand.SafeEncodeString(fmt.Sprint(podTemplateSpecHasher.Sum32()))\n}"}, {"instruction": "// List takes label and field selectors, and returns the list of CertificateSigningRequests that match those selectors.", "input": "go language", "output": "func (c *FakeCertificateSigningRequests) List(opts v1.ListOptions) (result *v1beta1.CertificateSigningRequestList, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewRootListAction(certificatesigningrequestsResource, certificatesigningrequestsKind, opts), &v1beta1.CertificateSigningRequestList{})\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\n\tlabel, _, _ := testing.ExtractFromListOptions(opts)\n\tif label == nil {\n\t\tlabel = labels.Everything()\n\t}\n\tlist := &v1beta1.CertificateSigningRequestList{ListMeta: obj.(*v1beta1.CertificateSigningRequestList).ListMeta}\n\tfor _, item := range obj.(*v1beta1.CertificateSigningRequestList).Items {\n\t\tif label.Matches(labels.Set(item.Labels)) {\n\t\t\tlist.Items = append(list.Items, item)\n\t\t}\n\t}\n\treturn list, err\n}"}, {"instruction": "// Remove disassociates a metadata entry from a layer DiffID.", "input": "go language", "output": "func (serv *v2MetadataService) Remove(metadata V2Metadata) error {\n\tif serv.store == nil {\n\t\t// Support a service which has no backend storage, in this case\n\t\t// an remove becomes a no-op.\n\t\t// TODO: implement in memory storage\n\t\treturn nil\n\t}\n\tdiffID, err := serv.GetDiffID(metadata.Digest)\n\tif err != nil {\n\t\treturn err\n\t}\n\toldMetadata, err := serv.GetMetadata(diffID)\n\tif err != nil {\n\t\toldMetadata = nil\n\t}\n\tnewMetadata := make([]V2Metadata, 0, len(oldMetadata))\n\n\t// Copy all other metadata to new slice\n\tfor _, oldMeta := range oldMetadata {\n\t\tif oldMeta != metadata {\n\t\t\tnewMetadata = append(newMetadata, oldMeta)\n\t\t}\n\t}\n\n\tif len(newMetadata) == 0 {\n\t\treturn serv.store.Delete(serv.diffIDNamespace(), serv.diffIDKey(diffID))\n\t}\n\n\tjsonBytes, err := json.Marshal(newMetadata)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn serv.store.Set(serv.diffIDNamespace(), serv.diffIDKey(diffID), jsonBytes)\n}"}, {"instruction": "// UploadDirectory uploads a directory tree to swarm and either adds the files\n// to an existing manifest (if the manifest argument is non-empty) or creates a\n// new manifest, returning the resulting manifest hash (files from the\n// directory will then be available at bzz:/<hash>/path/to/file), with\n// the file specified in defaultPath being uploaded to the root of the manifest\n// (i.e. bzz:/<hash>/)", "input": "go language", "output": "func (c *Client) UploadDirectory(dir, defaultPath, manifest string, toEncrypt bool) (string, error) {\n\tstat, err := os.Stat(dir)\n\tif err != nil {\n\t\treturn \"\", err\n\t} else if !stat.IsDir() {\n\t\treturn \"\", fmt.Errorf(\"not a directory: %s\", dir)\n\t}\n\tif defaultPath != \"\" {\n\t\tif _, err := os.Stat(filepath.Join(dir, defaultPath)); err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\treturn \"\", fmt.Errorf(\"the default path %q was not found in the upload directory %q\", defaultPath, dir)\n\t\t\t}\n\t\t\treturn \"\", fmt.Errorf(\"default path: %v\", err)\n\t\t}\n\t}\n\treturn c.TarUpload(manifest, &DirectoryUploader{dir}, defaultPath, toEncrypt)\n}"}, {"instruction": "// watchTillerUntilReady waits for the tiller pod to become available. This is useful in situations where we\n// want to wait before we call New().\n//\n// Returns true if it exists. If the timeout was reached and it could not find the pod, it returns false.", "input": "go language", "output": "func watchTillerUntilReady(namespace string, client kubernetes.Interface, timeout int64, newImage string) bool {\n\tdeadlinePollingChan := time.NewTimer(time.Duration(timeout) * time.Second).C\n\tcheckTillerPodTicker := time.NewTicker(500 * time.Millisecond)\n\tdoneChan := make(chan bool)\n\n\tdefer checkTillerPodTicker.Stop()\n\n\tgo func() {\n\t\tfor range checkTillerPodTicker.C {\n\t\t\timage, err := portforwarder.GetTillerPodImage(client.CoreV1(), namespace)\n\t\t\tif err == nil && image == newImage {\n\t\t\t\tdoneChan <- true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}()\n\n\tfor {\n\t\tselect {\n\t\tcase <-deadlinePollingChan:\n\t\t\treturn false\n\t\tcase <-doneChan:\n\t\t\treturn true\n\t\t}\n\t}\n}"}, {"instruction": "// nextRotationDeadline returns a value for the threshold at which the\n// current certificate should be rotated, 80%+/-10% of the expiration of the\n// certificate.", "input": "go language", "output": "func (m *manager) nextRotationDeadline() time.Time {\n\t// forceRotation is not protected by locks\n\tif m.forceRotation {\n\t\tm.forceRotation = false\n\t\treturn time.Now()\n\t}\n\n\tm.certAccessLock.RLock()\n\tdefer m.certAccessLock.RUnlock()\n\n\tif !m.certSatisfiesTemplateLocked() {\n\t\treturn time.Now()\n\t}\n\n\tnotAfter := m.cert.Leaf.NotAfter\n\ttotalDuration := float64(notAfter.Sub(m.cert.Leaf.NotBefore))\n\tdeadline := m.cert.Leaf.NotBefore.Add(jitteryDuration(totalDuration))\n\n\tklog.V(2).Infof(\"Certificate expiration is %v, rotation deadline is %v\", notAfter, deadline)\n\tif m.certificateExpiration != nil {\n\t\tm.certificateExpiration.Set(float64(notAfter.Unix()))\n\t}\n\treturn deadline\n}"}, {"instruction": "// buildGlobalHashTable builds a global hash table for the inner relation.\n// key of hash table: hash value of key columns\n// value of hash table: RowPtr of the corresponded row", "input": "go language", "output": "func (e *HashJoinExec) buildGlobalHashTable() error {\n\te.globalHashTable = mvmap.NewMVMap()\n\tvar (\n\t\thasNull bool\n\t\terr     error\n\t\tkeyBuf  = make([]byte, 0, 64)\n\t\tvalBuf  = make([]byte, 8)\n\t)\n\n\tfor chkIdx := 0; chkIdx < e.innerResult.NumChunks(); chkIdx++ {\n\t\tif e.finished.Load().(bool) {\n\t\t\treturn nil\n\t\t}\n\t\tchk := e.innerResult.GetChunk(chkIdx)\n\t\tfor j, numRows := 0, chk.NumRows(); j < numRows; j++ {\n\t\t\thasNull, keyBuf, err = e.getJoinKeyFromChkRow(false, chk.GetRow(j), keyBuf)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif hasNull {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\trowPtr := chunk.RowPtr{ChkIdx: uint32(chkIdx), RowIdx: uint32(j)}\n\t\t\t*(*chunk.RowPtr)(unsafe.Pointer(&valBuf[0])) = rowPtr\n\t\t\te.globalHashTable.Put(keyBuf, valBuf)\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// StructuredGenerate outputs a pod disruption budget object using the configured fields.", "input": "go language", "output": "func (s *PodDisruptionBudgetV1Generator) StructuredGenerate() (runtime.Object, error) {\n\tif len(s.MinAvailable) == 0 {\n\t\t// defaulting behavior seen in Kubernetes 1.6 and below.\n\t\ts.MinAvailable = \"1\"\n\t}\n\n\tif err := s.validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tselector, err := metav1.ParseToLabelSelector(s.Selector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tminAvailable := intstr.Parse(s.MinAvailable)\n\treturn &policy.PodDisruptionBudget{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: s.Name,\n\t\t},\n\t\tSpec: policy.PodDisruptionBudgetSpec{\n\t\t\tMinAvailable: &minAvailable,\n\t\t\tSelector:     selector,\n\t\t},\n\t}, nil\n}"}, {"instruction": "// howSimilar is a naive diff implementation that returns\n// a number between 0-100 indicating how similar a and b are.\n// 100 is when all words in a also exists in b.", "input": "go language", "output": "func howSimilarStrings(a, b string) int {\n\n\t// Give some weight to the word positions.\n\tconst partitionSize = 4\n\n\taf, bf := strings.Fields(a), strings.Fields(b)\n\tif len(bf) > len(af) {\n\t\taf, bf = bf, af\n\t}\n\n\tm1 := make(map[string]bool)\n\tfor i, x := range bf {\n\t\tpartition := partition(i, partitionSize)\n\t\tkey := x + \"/\" + strconv.Itoa(partition)\n\t\tm1[key] = true\n\t}\n\n\tcommon := 0\n\tfor i, x := range af {\n\t\tpartition := partition(i, partitionSize)\n\t\tkey := x + \"/\" + strconv.Itoa(partition)\n\t\tif m1[key] {\n\t\t\tcommon++\n\t\t}\n\t}\n\n\treturn int(math.Floor((float64(common) / float64(len(af)) * 100)))\n}"}, {"instruction": "// Format produces and returns a text representation of the receiving plan\n// intended for display in a terminal.\n//\n// If color is not nil, it is used to colorize the output.", "input": "go language", "output": "func (p *Plan) Format(color *colorstring.Colorize) string {\n\tif p.Empty() {\n\t\treturn \"This plan does nothing.\"\n\t}\n\n\tif color == nil {\n\t\tcolor = &colorstring.Colorize{\n\t\t\tColors: colorstring.DefaultColors,\n\t\t\tReset:  false,\n\t\t}\n\t}\n\n\t// Find the longest path length of all the paths that are changing,\n\t// so we can align them all.\n\tkeyLen := 0\n\tfor _, r := range p.Resources {\n\t\tfor _, attr := range r.Attributes {\n\t\t\tkey := attr.Path\n\n\t\t\tif len(key) > keyLen {\n\t\t\t\tkeyLen = len(key)\n\t\t\t}\n\t\t}\n\t}\n\n\tbuf := new(bytes.Buffer)\n\tfor _, r := range p.Resources {\n\t\tformatPlanInstanceDiff(buf, r, keyLen, color)\n\t}\n\n\treturn strings.TrimSpace(buf.String())\n}"}, {"instruction": "// SwarmUpdate updates the swarm.", "input": "go language", "output": "func (cli *Client) SwarmUpdate(ctx context.Context, version swarm.Version, swarm swarm.Spec, flags swarm.UpdateFlags) error {\n\tquery := url.Values{}\n\tquery.Set(\"version\", strconv.FormatUint(version.Index, 10))\n\tquery.Set(\"rotateWorkerToken\", fmt.Sprintf(\"%v\", flags.RotateWorkerToken))\n\tquery.Set(\"rotateManagerToken\", fmt.Sprintf(\"%v\", flags.RotateManagerToken))\n\tquery.Set(\"rotateManagerUnlockKey\", fmt.Sprintf(\"%v\", flags.RotateManagerUnlockKey))\n\tresp, err := cli.post(ctx, \"/swarm/update\", query, swarm, nil)\n\tensureReaderClosed(resp)\n\treturn err\n}"}, {"instruction": "// GetModifiedAccountsByNumber returns all accounts that have changed between the\n// two blocks specified. A change is defined as a difference in nonce, balance,\n// code hash, or storage hash.\n//\n// With one parameter, returns the list of accounts modified in the specified block.", "input": "go language", "output": "func (api *PrivateDebugAPI) GetModifiedAccountsByNumber(startNum uint64, endNum *uint64) ([]common.Address, error) {\n\tvar startBlock, endBlock *types.Block\n\n\tstartBlock = api.eth.blockchain.GetBlockByNumber(startNum)\n\tif startBlock == nil {\n\t\treturn nil, fmt.Errorf(\"start block %x not found\", startNum)\n\t}\n\n\tif endNum == nil {\n\t\tendBlock = startBlock\n\t\tstartBlock = api.eth.blockchain.GetBlockByHash(startBlock.ParentHash())\n\t\tif startBlock == nil {\n\t\t\treturn nil, fmt.Errorf(\"block %x has no parent\", endBlock.Number())\n\t\t}\n\t} else {\n\t\tendBlock = api.eth.blockchain.GetBlockByNumber(*endNum)\n\t\tif endBlock == nil {\n\t\t\treturn nil, fmt.Errorf(\"end block %d not found\", *endNum)\n\t\t}\n\t}\n\treturn api.getModifiedAccounts(startBlock, endBlock)\n}"}, {"instruction": "// LockOpts returns a handle to a lock struct which can be used\n// to acquire and release the mutex. The key used must have\n// write permissions.", "input": "go language", "output": "func (c *Client) LockOpts(opts *LockOptions) (*Lock, error) {\n\tif opts.Key == \"\" {\n\t\treturn nil, fmt.Errorf(\"missing key\")\n\t}\n\tif opts.SessionName == \"\" {\n\t\topts.SessionName = DefaultLockSessionName\n\t}\n\tif opts.SessionTTL == \"\" {\n\t\topts.SessionTTL = DefaultLockSessionTTL\n\t} else {\n\t\tif _, err := time.ParseDuration(opts.SessionTTL); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid SessionTTL: %v\", err)\n\t\t}\n\t}\n\tif opts.MonitorRetryTime == 0 {\n\t\topts.MonitorRetryTime = DefaultMonitorRetryTime\n\t}\n\tif opts.LockWaitTime == 0 {\n\t\topts.LockWaitTime = DefaultLockWaitTime\n\t}\n\tl := &Lock{\n\t\tc:    c,\n\t\topts: opts,\n\t}\n\treturn l, nil\n}"}, {"instruction": "// evalString evals a builtinPasswordSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/encryption-functions.html#function_password", "input": "go language", "output": "func (b *builtinPasswordSig) evalString(row chunk.Row) (d string, isNull bool, err error) {\n\tpass, isNull, err := b.args[0].EvalString(b.ctx, row)\n\tif isNull || err != nil {\n\t\treturn \"\", err != nil, err\n\t}\n\n\tif len(pass) == 0 {\n\t\treturn \"\", false, nil\n\t}\n\n\t// We should append a warning here because function \"PASSWORD\" is deprecated since MySQL 5.7.6.\n\t// See https://dev.mysql.com/doc/refman/5.7/en/encryption-functions.html#function_password\n\tb.ctx.GetSessionVars().StmtCtx.AppendWarning(errDeprecatedSyntaxNoReplacement.GenWithStackByArgs(\"PASSWORD\"))\n\n\treturn auth.EncodePassword(pass), false, nil\n}"}, {"instruction": "// Parse API configuration from parameters or secret", "input": "go language", "output": "func parseAPIConfig(params map[string]string) (*storageosAPIConfig, error) {\n\n\tif len(params) == 0 {\n\t\treturn nil, fmt.Errorf(\"empty API config\")\n\t}\n\n\tc := &storageosAPIConfig{}\n\n\tfor name, data := range params {\n\t\tswitch strings.ToLower(name) {\n\t\tcase \"apiaddress\":\n\t\t\tc.apiAddr = string(data)\n\t\tcase \"apiusername\":\n\t\t\tc.apiUser = string(data)\n\t\tcase \"apipassword\":\n\t\t\tc.apiPass = string(data)\n\t\tcase \"apiversion\":\n\t\t\tc.apiVersion = string(data)\n\t\t}\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// filterNodeDump is used to filter through all parts of a node dump and\n// remove elements the provided ACL token cannot access.", "input": "go language", "output": "func (f *aclFilter) filterNodeDump(dump *structs.NodeDump) {\n\tnd := *dump\n\tfor i := 0; i < len(nd); i++ {\n\t\tinfo := nd[i]\n\n\t\t// Filter nodes\n\t\tif node := info.Node; !f.allowNode(node) {\n\t\t\tf.logger.Printf(\"[DEBUG] consul: dropping node %q from result due to ACLs\", node)\n\t\t\tnd = append(nd[:i], nd[i+1:]...)\n\t\t\ti--\n\t\t\tcontinue\n\t\t}\n\n\t\t// Filter services\n\t\tfor j := 0; j < len(info.Services); j++ {\n\t\t\tsvc := info.Services[j].Service\n\t\t\tif f.allowService(svc) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tf.logger.Printf(\"[DEBUG] consul: dropping service %q from result due to ACLs\", svc)\n\t\t\tinfo.Services = append(info.Services[:j], info.Services[j+1:]...)\n\t\t\tj--\n\t\t}\n\n\t\t// Filter checks\n\t\tfor j := 0; j < len(info.Checks); j++ {\n\t\t\tchk := info.Checks[j]\n\t\t\tif f.allowService(chk.ServiceName) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tf.logger.Printf(\"[DEBUG] consul: dropping check %q from result due to ACLs\", chk.CheckID)\n\t\t\tinfo.Checks = append(info.Checks[:j], info.Checks[j+1:]...)\n\t\t\tj--\n\t\t}\n\t}\n\t*dump = nd\n}"}, {"instruction": "// OnDigest notifies the engine that a digest has arrived", "input": "go language", "output": "func (engine *PullEngine) OnDigest(digest []string, nonce uint64, context interface{}) {\n\tif !engine.isAcceptingDigests() || !engine.outgoingNONCES.Exists(nonce) {\n\t\treturn\n\t}\n\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\tfor _, n := range digest {\n\t\tif engine.state.Exists(n) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif _, exists := engine.item2owners[n]; !exists {\n\t\t\tengine.item2owners[n] = make([]string, 0)\n\t\t}\n\n\t\tengine.item2owners[n] = append(engine.item2owners[n], engine.nonces2peers[nonce])\n\t}\n}"}, {"instruction": "// NewController returns a new instance of the IPAM controller.", "input": "go language", "output": "func NewController(\n\tconfig *Config,\n\tkubeClient clientset.Interface,\n\tcloud cloudprovider.Interface,\n\tclusterCIDR, serviceCIDR *net.IPNet,\n\tnodeCIDRMaskSize int) (*Controller, error) {\n\n\tif !nodesync.IsValidMode(config.Mode) {\n\t\treturn nil, fmt.Errorf(\"invalid IPAM controller mode %q\", config.Mode)\n\t}\n\n\tgceCloud, ok := cloud.(*gce.Cloud)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"cloud IPAM controller does not support %q provider\", cloud.ProviderName())\n\t}\n\n\tset, err := cidrset.NewCIDRSet(clusterCIDR, nodeCIDRMaskSize)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tc := &Controller{\n\t\tconfig:  config,\n\t\tadapter: newAdapter(kubeClient, gceCloud),\n\t\tsyncers: make(map[string]*nodesync.NodeSync),\n\t\tset:     set,\n\t}\n\n\tif err := occupyServiceCIDR(c.set, clusterCIDR, serviceCIDR); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn c, nil\n}"}, {"instruction": "// Validate if the remote version is one Minor release newer than the client version.\n// This is done to conform with \"stable-X\" and only allow remote versions from\n// the same Patch level release.", "input": "go language", "output": "func validateStableVersion(remoteVersion, clientVersion string) (string, error) {\n\tverRemote, err := versionutil.ParseGeneric(remoteVersion)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"remote version error\")\n\t}\n\tverClient, err := versionutil.ParseGeneric(clientVersion)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"client version error\")\n\t}\n\t// If the remote Major version is bigger or if the Major versions are the same,\n\t// but the remote Minor is bigger use the client version release. This handles Major bumps too.\n\tif verClient.Major() < verRemote.Major() ||\n\t\t(verClient.Major() == verRemote.Major()) && verClient.Minor() < verRemote.Minor() {\n\t\testimatedRelease := fmt.Sprintf(\"stable-%d.%d\", verClient.Major(), verClient.Minor())\n\t\tklog.Infof(\"remote version is much newer: %s; falling back to: %s\", remoteVersion, estimatedRelease)\n\t\treturn estimatedRelease, nil\n\t}\n\treturn remoteVersion, nil\n}"}, {"instruction": "// grantColumnPriv manipulates mysql.tables_priv table.", "input": "go language", "output": "func (e *GrantExec) grantColumnPriv(priv *ast.PrivElem, user *ast.UserSpec) error {\n\tdbName, tbl, err := getTargetSchemaAndTable(e.ctx, e.Level.DBName, e.Level.TableName, e.is)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, c := range priv.Cols {\n\t\tcol := table.FindCol(tbl.Cols(), c.Name.L)\n\t\tif col == nil {\n\t\t\treturn errors.Errorf(\"Unknown column: %s\", c)\n\t\t}\n\t\tasgns, err := composeColumnPrivUpdateForGrant(e.ctx, priv.Priv, user.User.Username, user.User.Hostname, dbName, tbl.Meta().Name.O, col.Name.O)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsql := fmt.Sprintf(`UPDATE %s.%s SET %s WHERE User='%s' AND Host='%s' AND DB='%s' AND Table_name='%s' AND Column_name='%s';`, mysql.SystemDB, mysql.ColumnPrivTable, asgns, user.User.Username, user.User.Hostname, dbName, tbl.Meta().Name.O, col.Name.O)\n\t\t_, _, err = e.ctx.(sqlexec.RestrictedSQLExecutor).ExecRestrictedSQL(e.ctx, sql)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// StringFlagPutHandler wraps an http Handler to set string type flag.", "input": "go language", "output": "func StringFlagPutHandler(setter StringFlagSetterFunc) http.HandlerFunc {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\tswitch {\n\t\tcase req.Method == \"PUT\":\n\t\t\tbody, err := ioutil.ReadAll(req.Body)\n\t\t\tif err != nil {\n\t\t\t\twritePlainText(http.StatusBadRequest, \"error reading request body: \"+err.Error(), w)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer req.Body.Close()\n\t\t\tresponse, err := setter(string(body))\n\t\t\tif err != nil {\n\t\t\t\twritePlainText(http.StatusBadRequest, err.Error(), w)\n\t\t\t\treturn\n\t\t\t}\n\t\t\twritePlainText(http.StatusOK, response, w)\n\t\t\treturn\n\t\tdefault:\n\t\t\twritePlainText(http.StatusNotAcceptable, \"unsupported http method\", w)\n\t\t\treturn\n\t\t}\n\t})\n}"}, {"instruction": "// PerformStaticPodUpgrade performs the upgrade of the control plane components for a static pod hosted cluster", "input": "go language", "output": "func PerformStaticPodUpgrade(client clientset.Interface, waiter apiclient.Waiter, internalcfg *kubeadmapi.InitConfiguration, etcdUpgrade, renewCerts bool) error {\n\tpathManager, err := GetPathManagerForUpgrade(internalcfg, etcdUpgrade)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The arguments oldEtcdClient and newEtdClient, are uninitialized because passing in the clients allow for mocking the client during testing\n\treturn upgrade.StaticPodControlPlane(client, waiter, pathManager, internalcfg, etcdUpgrade, renewCerts, nil, nil)\n}"}, {"instruction": "// formatVirtualKey converts a virtual key (e.g., up arrow) into the appropriate ANSI string.", "input": "go language", "output": "func formatVirtualKey(key uint16, controlState uint32, escapeSequence []byte) string {\n\tshift, alt, control := getControlKeys(controlState)\n\tmodifier := getControlKeysModifier(shift, alt, control)\n\n\tif format, ok := arrowKeyMapPrefix[key]; ok {\n\t\treturn fmt.Sprintf(format, escapeSequence, modifier)\n\t}\n\n\tif format, ok := keyMapPrefix[key]; ok {\n\t\treturn fmt.Sprintf(format, modifier)\n\t}\n\n\treturn \"\"\n}"}, {"instruction": "// Normalize args convert multiple resources to resource tuples, a,b,c d\n// as a transform to a/d b/d c/d", "input": "go language", "output": "func normalizeMultipleResourcesArgs(args []string) []string {\n\tif len(args) >= 2 {\n\t\tresources := []string{}\n\t\tresources = append(resources, SplitResourceArgument(args[0])...)\n\t\tif len(resources) > 1 {\n\t\t\tnames := []string{}\n\t\t\tnames = append(names, args[1:]...)\n\t\t\tnewArgs := []string{}\n\t\t\tfor _, resource := range resources {\n\t\t\t\tfor _, name := range names {\n\t\t\t\t\tnewArgs = append(newArgs, strings.Join([]string{resource, name}, \"/\"))\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn newArgs\n\t\t}\n\t}\n\treturn args\n}"}, {"instruction": "// uniqueToken generates a random URL-safe token and ensures uniqueness.", "input": "go language", "output": "func (c *requestCache) uniqueToken() (string, error) {\n\tconst maxTries = 10\n\t// Number of bytes to be tokenLen when base64 encoded.\n\ttokenSize := math.Ceil(float64(tokenLen) * 6 / 8)\n\trawToken := make([]byte, int(tokenSize))\n\tfor i := 0; i < maxTries; i++ {\n\t\tif _, err := rand.Read(rawToken); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tencoded := base64.RawURLEncoding.EncodeToString(rawToken)\n\t\ttoken := encoded[:tokenLen]\n\t\t// If it's unique, return it. Otherwise retry.\n\t\tif _, exists := c.tokens[encoded]; !exists {\n\t\t\treturn token, nil\n\t\t}\n\t}\n\treturn \"\", fmt.Errorf(\"failed to generate unique token\")\n}"}, {"instruction": "// StartSaveSpan stores the span specified in the passed context for later retrieval\n// The span object but be context value on the key StoreLabelId.\n// It will be stored under the the following string key context.Value(StoreLabelId)|.|context.Value(StoreLabelMeta)", "input": "go language", "output": "func StartSaveSpan(ctx context.Context) context.Context {\n\tif !Enabled {\n\t\treturn ctx\n\t}\n\ttraceId := ctx.Value(StoreLabelId)\n\n\tif traceId != nil {\n\t\ttraceStr := traceId.(string)\n\t\tvar sp opentracing.Span\n\t\tctx, sp = spancontext.StartSpan(\n\t\t\tctx,\n\t\t\ttraceStr,\n\t\t)\n\t\ttraceMeta := ctx.Value(StoreLabelMeta)\n\t\tif traceMeta != nil {\n\t\t\ttraceStr = traceStr + \".\" + traceMeta.(string)\n\t\t}\n\t\tstore.spans.Store(traceStr, sp)\n\t}\n\treturn ctx\n}"}, {"instruction": "// capabilities builds a Capabilities from discovery information.", "input": "go language", "output": "func capabilities(disc discovery.DiscoveryInterface) (*chartutil.Capabilities, error) {\n\tsv, err := disc.ServerVersion()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvs, err := GetVersionSet(disc)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Could not get apiVersions from Kubernetes: %s\", err)\n\t}\n\treturn &chartutil.Capabilities{\n\t\tAPIVersions:   vs,\n\t\tKubeVersion:   sv,\n\t\tTillerVersion: version.GetVersionProto(),\n\t}, nil\n}"}, {"instruction": "// UnmarshalBinary decodes msgpack encoded ServiceConfigResponse. It used\n// default msgpack encoding but fixes up the uint8 strings and other problems we\n// have with encoding map[string]interface{}.", "input": "go language", "output": "func (r *ServiceConfigResponse) UnmarshalBinary(data []byte) error {\n\tdec := codec.NewDecoderBytes(data, msgpackHandle)\n\n\ttype Alias ServiceConfigResponse\n\tvar a Alias\n\n\tif err := dec.Decode(&a); err != nil {\n\t\treturn err\n\t}\n\n\t*r = ServiceConfigResponse(a)\n\n\tvar err error\n\n\t// Fix strings and maps in the returned maps\n\tr.ProxyConfig, err = lib.MapWalk(r.ProxyConfig)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor k := range r.UpstreamConfigs {\n\t\tr.UpstreamConfigs[k], err = lib.MapWalk(r.UpstreamConfigs[k])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"}, {"instruction": "// CreateEnvelope creates a common.Envelope with given tx bytes, header, and Signer", "input": "go language", "output": "func CreateEnvelope(data []byte, header *common.Header, signer SignerIdentity) (*common.Envelope, error) {\n\tpayload := &common.Payload{\n\t\tHeader: header,\n\t\tData:   data,\n\t}\n\n\tpayloadBytes, err := proto.Marshal(payload)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to marshal common.Payload\")\n\t}\n\n\tsignature, err := signer.Sign(payloadBytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttxEnvelope := &common.Envelope{\n\t\tPayload:   payloadBytes,\n\t\tSignature: signature,\n\t}\n\n\treturn txEnvelope, nil\n}"}, {"instruction": "// Scan queries continuous kv pairs in range [startKey, endKey), up to limit pairs.\n// If endKey is empty, it means unbounded.\n// If you want to exclude the startKey or include the endKey, append a '\\0' to the key. For example, to scan\n// (startKey, endKey], you can write:\n// `Scan(append(startKey, '\\0'), append(endKey, '\\0'), limit)`.", "input": "go language", "output": "func (c *RawKVClient) Scan(startKey, endKey []byte, limit int) (keys [][]byte, values [][]byte, err error) {\n\tstart := time.Now()\n\tdefer func() { tikvRawkvCmdHistogramWithRawScan.Observe(time.Since(start).Seconds()) }()\n\n\tif limit > MaxRawKVScanLimit {\n\t\treturn nil, nil, errors.Trace(ErrMaxScanLimitExceeded)\n\t}\n\n\tfor len(keys) < limit {\n\t\treq := &tikvrpc.Request{\n\t\t\tType: tikvrpc.CmdRawScan,\n\t\t\tRawScan: &kvrpcpb.RawScanRequest{\n\t\t\t\tStartKey: startKey,\n\t\t\t\tEndKey:   endKey,\n\t\t\t\tLimit:    uint32(limit - len(keys)),\n\t\t\t},\n\t\t}\n\t\tresp, loc, err := c.sendReq(startKey, req, false)\n\t\tif err != nil {\n\t\t\treturn nil, nil, errors.Trace(err)\n\t\t}\n\t\tcmdResp := resp.RawScan\n\t\tif cmdResp == nil {\n\t\t\treturn nil, nil, errors.Trace(ErrBodyMissing)\n\t\t}\n\t\tfor _, pair := range cmdResp.Kvs {\n\t\t\tkeys = append(keys, pair.Key)\n\t\t\tvalues = append(values, pair.Value)\n\t\t}\n\t\tstartKey = loc.EndKey\n\t\tif len(startKey) == 0 {\n\t\t\tbreak\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// Checksum sends a checksum request.", "input": "go language", "output": "func Checksum(ctx context.Context, client kv.Client, kvReq *kv.Request, vars *kv.Variables) (SelectResult, error) {\n\tresp := client.Send(ctx, kvReq, vars)\n\tif resp == nil {\n\t\treturn nil, errors.New(\"client returns nil response\")\n\t}\n\tresult := &selectResult{\n\t\tlabel:    \"checksum\",\n\t\tresp:     resp,\n\t\tresults:  make(chan resultWithErr, kvReq.Concurrency),\n\t\tclosed:   make(chan struct{}),\n\t\tfeedback: statistics.NewQueryFeedback(0, nil, 0, false),\n\t\tsqlType:  metrics.LblGeneral,\n\t}\n\treturn result, nil\n}"}, {"instruction": "// monitorLock is a long running routine to monitor a semaphore ownership\n// It closes the stopCh if we lose our slot.", "input": "go language", "output": "func (s *Semaphore) monitorLock(session string, stopCh chan struct{}) {\n\tdefer close(stopCh)\n\tkv := s.c.KV()\n\topts := &QueryOptions{RequireConsistent: true}\nWAIT:\n\tretries := s.opts.MonitorRetries\nRETRY:\n\tpairs, meta, err := kv.List(s.opts.Prefix, opts)\n\tif err != nil {\n\t\t// If configured we can try to ride out a brief Consul unavailability\n\t\t// by doing retries. Note that we have to attempt the retry in a non-\n\t\t// blocking fashion so that we have a clean place to reset the retry\n\t\t// counter if service is restored.\n\t\tif retries > 0 && IsRetryableError(err) {\n\t\t\ttime.Sleep(s.opts.MonitorRetryTime)\n\t\t\tretries--\n\t\t\topts.WaitIndex = 0\n\t\t\tgoto RETRY\n\t\t}\n\t\treturn\n\t}\n\tlockPair := s.findLock(pairs)\n\tlock, err := s.decodeLock(lockPair)\n\tif err != nil {\n\t\treturn\n\t}\n\ts.pruneDeadHolders(lock, pairs)\n\tif _, ok := lock.Holders[session]; ok {\n\t\topts.WaitIndex = meta.LastIndex\n\t\tgoto WAIT\n\t}\n}"}, {"instruction": "// update executes periodic operations on the peer, including message transmission\n// and expiration.", "input": "go language", "output": "func (peer *Peer) update() {\n\t// Start the tickers for the updates\n\texpire := time.NewTicker(expirationCycle)\n\ttransmit := time.NewTicker(transmissionCycle)\n\n\t// Loop and transmit until termination is requested\n\tfor {\n\t\tselect {\n\t\tcase <-expire.C:\n\t\t\tpeer.expire()\n\n\t\tcase <-transmit.C:\n\t\t\tif err := peer.broadcast(); err != nil {\n\t\t\t\tlog.Trace(\"broadcast failed\", \"reason\", err, \"peer\", peer.ID())\n\t\t\t\treturn\n\t\t\t}\n\n\t\tcase <-peer.quit:\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// createPriceOracle sets up a matrix which can be queried to get\n// the price for a message via the Price method", "input": "go language", "output": "func (r *Registry) createPriceOracle() {\n\tsp := &StreamerPrices{\n\t\tregistry: r,\n\t}\n\tsp.priceMatrix = map[reflect.Type]*protocols.Price{\n\t\treflect.TypeOf(ChunkDeliveryMsgRetrieval{}): {\n\t\t\tValue:   sp.getChunkDeliveryMsgRetrievalPrice(), // arbitrary price for now\n\t\t\tPerByte: true,\n\t\t\tPayer:   protocols.Receiver,\n\t\t},\n\t\treflect.TypeOf(RetrieveRequestMsg{}): {\n\t\t\tValue:   sp.getRetrieveRequestMsgPrice(), // arbitrary price for now\n\t\t\tPerByte: false,\n\t\t\tPayer:   protocols.Sender,\n\t\t},\n\t}\n\tr.prices = sp\n}"}, {"instruction": "// readDefaultBigInt reads a single line from stdin, trimming if from spaces,\n// enforcing it to parse into a big integer. If an empty line is entered, the\n// default value is returned.", "input": "go language", "output": "func (w *wizard) readDefaultBigInt(def *big.Int) *big.Int {\n\tfor {\n\t\tfmt.Printf(\"> \")\n\t\ttext, err := w.in.ReadString('\\n')\n\t\tif err != nil {\n\t\t\tlog.Crit(\"Failed to read user input\", \"err\", err)\n\t\t}\n\t\tif text = strings.TrimSpace(text); text == \"\" {\n\t\t\treturn def\n\t\t}\n\t\tval, ok := new(big.Int).SetString(text, 0)\n\t\tif !ok {\n\t\t\tlog.Error(\"Invalid input, expected big integer\")\n\t\t\tcontinue\n\t\t}\n\t\treturn val\n\t}\n}"}, {"instruction": "// getCgroupPath gets the file path to the \"devices\" subsystem of the desired cgroup.\n// cgroupPath is the path in the cgroup hierarchy.", "input": "go language", "output": "func getCgroupPath(cgroupPath string) (string, error) {\n\tcgroupPath = libcontainerutils.CleanPath(cgroupPath)\n\n\tmnt, root, err := libcontainercgroups.FindCgroupMountpointAndRoot(\"devices\")\n\t// If we didn't mount the subsystem, there is no point we make the path.\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// If the cgroup name/path is absolute do not look relative to the cgroup of the init process.\n\tif filepath.IsAbs(cgroupPath) {\n\t\t// Sometimes subsystems can be mounted together as 'cpu,cpuacct'.\n\t\treturn filepath.Join(root, mnt, cgroupPath), nil\n\t}\n\n\tparentPath, err := getCgroupParentPath(mnt, root)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn filepath.Join(parentPath, cgroupPath), nil\n}"}, {"instruction": "// RegisterServices registers the given Services which can then be used to\n// start devp2p nodes using either the Exec or Docker adapters.\n//\n// It should be called in an init function so that it has the opportunity to\n// execute the services before main() is called.", "input": "go language", "output": "func RegisterServices(services Services) {\n\tfor name, f := range services {\n\t\tif _, exists := serviceFuncs[name]; exists {\n\t\t\tpanic(fmt.Sprintf(\"node service already exists: %q\", name))\n\t\t}\n\t\tserviceFuncs[name] = f\n\t}\n\n\t// now we have registered the services, run reexec.Init() which will\n\t// potentially start one of the services if the current binary has\n\t// been exec'd with argv[0] set to \"p2p-node\"\n\tif reexec.Init() {\n\t\tos.Exit(0)\n\t}\n}"}, {"instruction": "// AdoptControllerRevision sends a patch to take control of the ControllerRevision. It returns the error if\n// the patching fails.", "input": "go language", "output": "func (m *ControllerRevisionControllerRefManager) AdoptControllerRevision(history *apps.ControllerRevision) error {\n\tif err := m.CanAdopt(); err != nil {\n\t\treturn fmt.Errorf(\"can't adopt ControllerRevision %v/%v (%v): %v\", history.Namespace, history.Name, history.UID, err)\n\t}\n\t// Note that ValidateOwnerReferences() will reject this patch if another\n\t// OwnerReference exists with controller=true.\n\taddControllerPatch := fmt.Sprintf(\n\t\t`{\"metadata\":{\"ownerReferences\":[{\"apiVersion\":\"%s\",\"kind\":\"%s\",\"name\":\"%s\",\"uid\":\"%s\",\"controller\":true,\"blockOwnerDeletion\":true}],\"uid\":\"%s\"}}`,\n\t\tm.controllerKind.GroupVersion(), m.controllerKind.Kind,\n\t\tm.Controller.GetName(), m.Controller.GetUID(), history.UID)\n\treturn m.crControl.PatchControllerRevision(history.Namespace, history.Name, []byte(addControllerPatch))\n}"}, {"instruction": "// New creates a new Cluster instance using provided config.", "input": "go language", "output": "func New(config Config) (*Cluster, error) {\n\troot := filepath.Join(config.Root, swarmDirName)\n\tif err := os.MkdirAll(root, 0700); err != nil {\n\t\treturn nil, err\n\t}\n\tif config.RuntimeRoot == \"\" {\n\t\tconfig.RuntimeRoot = root\n\t}\n\tif config.RaftHeartbeatTick == 0 {\n\t\tconfig.RaftHeartbeatTick = 1\n\t}\n\tif config.RaftElectionTick == 0 {\n\t\t// 10X heartbeat tick is the recommended ratio according to etcd docs.\n\t\tconfig.RaftElectionTick = 10 * config.RaftHeartbeatTick\n\t}\n\n\tif err := os.MkdirAll(config.RuntimeRoot, 0700); err != nil {\n\t\treturn nil, err\n\t}\n\tc := &Cluster{\n\t\troot:        root,\n\t\tconfig:      config,\n\t\tconfigEvent: make(chan lncluster.ConfigEventType, 10),\n\t\truntimeRoot: config.RuntimeRoot,\n\t\tattachers:   make(map[string]*attacher),\n\t\twatchStream: config.WatchStream,\n\t}\n\treturn c, nil\n}"}, {"instruction": "// nodesWatch is used to watch the list of available nodes", "input": "go language", "output": "func nodesWatch(params map[string]interface{}) (WatcherFunc, error) {\n\tstale := false\n\tif err := assignValueBool(params, \"stale\", &stale); err != nil {\n\t\treturn nil, err\n\t}\n\n\tfn := func(p *Plan) (BlockingParamVal, interface{}, error) {\n\t\tcatalog := p.client.Catalog()\n\t\topts := makeQueryOptionsWithContext(p, stale)\n\t\tdefer p.cancelFunc()\n\t\tnodes, meta, err := catalog.Nodes(&opts)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\treturn WaitIndexVal(meta.LastIndex), nodes, err\n\t}\n\treturn fn, nil\n}"}, {"instruction": "// loadBufferedEvents iterates over the cached events in the buffer\n// and returns those that were emitted between two specific dates.\n// It uses `time.Unix(seconds, nanoseconds)` to generate valid dates with those arguments.\n// It filters those buffered messages with a topic function if it's not nil, otherwise it adds all messages.", "input": "go language", "output": "func (e *Events) loadBufferedEvents(since, until time.Time, topic func(interface{}) bool) []eventtypes.Message {\n\tvar buffered []eventtypes.Message\n\tif since.IsZero() && until.IsZero() {\n\t\treturn buffered\n\t}\n\n\tvar sinceNanoUnix int64\n\tif !since.IsZero() {\n\t\tsinceNanoUnix = since.UnixNano()\n\t}\n\n\tvar untilNanoUnix int64\n\tif !until.IsZero() {\n\t\tuntilNanoUnix = until.UnixNano()\n\t}\n\n\tfor i := len(e.events) - 1; i >= 0; i-- {\n\t\tev := e.events[i]\n\n\t\tif ev.TimeNano < sinceNanoUnix {\n\t\t\tbreak\n\t\t}\n\n\t\tif untilNanoUnix > 0 && ev.TimeNano > untilNanoUnix {\n\t\t\tcontinue\n\t\t}\n\n\t\tif topic == nil || topic(ev) {\n\t\t\tbuffered = append([]eventtypes.Message{ev}, buffered...)\n\t\t}\n\t}\n\treturn buffered\n}"}, {"instruction": "// newPuller returns a Puller interface that will pull from either a v1 or v2\n// registry. The endpoint argument contains a Version field that determines\n// whether a v1 or v2 puller will be created. The other parameters are passed\n// through to the underlying puller implementation for use during the actual\n// pull operation.", "input": "go language", "output": "func newPuller(endpoint registry.APIEndpoint, repoInfo *registry.RepositoryInfo, imagePullConfig *ImagePullConfig) (Puller, error) {\n\tswitch endpoint.Version {\n\tcase registry.APIVersion2:\n\t\treturn &v2Puller{\n\t\t\tV2MetadataService: metadata.NewV2MetadataService(imagePullConfig.MetadataStore),\n\t\t\tendpoint:          endpoint,\n\t\t\tconfig:            imagePullConfig,\n\t\t\trepoInfo:          repoInfo,\n\t\t}, nil\n\tcase registry.APIVersion1:\n\t\treturn &v1Puller{\n\t\t\tv1IDService: metadata.NewV1IDService(imagePullConfig.MetadataStore),\n\t\t\tendpoint:    endpoint,\n\t\t\tconfig:      imagePullConfig,\n\t\t\trepoInfo:    repoInfo,\n\t\t}, nil\n\t}\n\treturn nil, fmt.Errorf(\"unknown version %d for registry %s\", endpoint.Version, endpoint.URL)\n}"}, {"instruction": "// evalString evals a builtinInet6AtonSig.\n// See https://dev.mysql.com/doc/refman/5.7/en/miscellaneous-functions.html#function_inet6-aton", "input": "go language", "output": "func (b *builtinInet6AtonSig) evalString(row chunk.Row) (string, bool, error) {\n\tval, isNull, err := b.args[0].EvalString(b.ctx, row)\n\tif err != nil || isNull {\n\t\treturn \"\", true, err\n\t}\n\n\tif len(val) == 0 {\n\t\treturn \"\", true, nil\n\t}\n\n\tip := net.ParseIP(val)\n\tif ip == nil {\n\t\treturn \"\", true, nil\n\t}\n\n\tvar isMappedIpv6 bool\n\tif ip.To4() != nil && strings.Contains(val, \":\") {\n\t\t//mapped ipv6 address.\n\t\tisMappedIpv6 = true\n\t}\n\n\tvar result []byte\n\tif isMappedIpv6 || ip.To4() == nil {\n\t\tresult = make([]byte, net.IPv6len)\n\t} else {\n\t\tresult = make([]byte, net.IPv4len)\n\t}\n\n\tif isMappedIpv6 {\n\t\tcopy(result[12:], ip.To4())\n\t\tresult[11] = 0xff\n\t\tresult[10] = 0xff\n\t} else if ip.To4() == nil {\n\t\tcopy(result, ip.To16())\n\t} else {\n\t\tcopy(result, ip.To4())\n\t}\n\n\treturn string(result[:]), false, nil\n}"}, {"instruction": "// MarshalInitConfigurationToBytes marshals the internal InitConfiguration object to bytes. It writes the embedded\n// ClusterConfiguration object with ComponentConfigs out as separate YAML documents", "input": "go language", "output": "func MarshalInitConfigurationToBytes(cfg *kubeadmapi.InitConfiguration, gv schema.GroupVersion) ([]byte, error) {\n\tinitbytes, err := kubeadmutil.MarshalToYamlForCodecs(cfg, gv, kubeadmscheme.Codecs)\n\tif err != nil {\n\t\treturn []byte{}, err\n\t}\n\tallFiles := [][]byte{initbytes}\n\n\t// Exception: If the specified groupversion is targeting the internal type, don't print embedded ClusterConfiguration contents\n\t// This is mostly used for unit testing. In a real scenario the internal version of the API is never marshalled as-is.\n\tif gv.Version != runtime.APIVersionInternal {\n\t\tclusterbytes, err := MarshalClusterConfigurationToBytes(&cfg.ClusterConfiguration, gv)\n\t\tif err != nil {\n\t\t\treturn []byte{}, err\n\t\t}\n\t\tallFiles = append(allFiles, clusterbytes)\n\t}\n\treturn bytes.Join(allFiles, []byte(kubeadmconstants.YAMLDocumentSeparator)), nil\n}"}, {"instruction": "// GetFromKubeletConfigMap returns the pointer to the ComponentConfig API object read from the kubelet-config-version\n// ConfigMap map stored in the cluster", "input": "go language", "output": "func GetFromKubeletConfigMap(client clientset.Interface, version *version.Version) (runtime.Object, error) {\n\n\t// Read the ConfigMap from the cluster based on what version the kubelet is\n\tconfigMapName := kubeadmconstants.GetKubeletConfigMapName(version)\n\tkubeletCfg, err := client.CoreV1().ConfigMaps(metav1.NamespaceSystem).Get(configMapName, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tkubeletConfigData, ok := kubeletCfg.Data[kubeadmconstants.KubeletBaseConfigurationConfigMapKey]\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"unexpected error when reading %s ConfigMap: %s key value pair missing\",\n\t\t\tconfigMapName, kubeadmconstants.KubeletBaseConfigurationConfigMapKey)\n\t}\n\n\t// Decodes the kubeletConfigData into the internal component config\n\tobj := &kubeletconfig.KubeletConfiguration{}\n\terr = unmarshalObject(obj, []byte(kubeletConfigData))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn obj, nil\n}"}, {"instruction": "// FetchBodies sends a block body retrieval request to the remote peer.", "input": "go language", "output": "func (p *peerConnection) FetchBodies(request *fetchRequest) error {\n\t// Sanity check the protocol version\n\tif p.version < 62 {\n\t\tpanic(fmt.Sprintf(\"body fetch [eth/62+] requested on eth/%d\", p.version))\n\t}\n\t// Short circuit if the peer is already fetching\n\tif !atomic.CompareAndSwapInt32(&p.blockIdle, 0, 1) {\n\t\treturn errAlreadyFetching\n\t}\n\tp.blockStarted = time.Now()\n\n\t// Convert the header set to a retrievable slice\n\thashes := make([]common.Hash, 0, len(request.Headers))\n\tfor _, header := range request.Headers {\n\t\thashes = append(hashes, header.Hash())\n\t}\n\tgo p.peer.RequestBodies(hashes)\n\n\treturn nil\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *CheckIndexRangeExec) Open(ctx context.Context) error {\n\ttCols := e.table.Cols()\n\tfor _, ic := range e.index.Columns {\n\t\tcol := tCols[ic.Offset]\n\t\te.cols = append(e.cols, col)\n\t}\n\n\tcolTypeForHandle := e.schema.Columns[len(e.cols)].RetType\n\te.cols = append(e.cols, &model.ColumnInfo{\n\t\tID:        model.ExtraHandleID,\n\t\tName:      model.ExtraHandleName,\n\t\tFieldType: *colTypeForHandle,\n\t})\n\n\te.srcChunk = e.newFirstChunk()\n\tdagPB, err := e.buildDAGPB()\n\tif err != nil {\n\t\treturn err\n\t}\n\tsc := e.ctx.GetSessionVars().StmtCtx\n\tvar builder distsql.RequestBuilder\n\tkvReq, err := builder.SetIndexRanges(sc, e.table.ID, e.index.ID, ranger.FullRange()).\n\t\tSetDAGRequest(dagPB).\n\t\tSetKeepOrder(true).\n\t\tSetFromSessionVars(e.ctx.GetSessionVars()).\n\t\tBuild()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te.result, err = distsql.Select(ctx, e.ctx, kvReq, e.retFieldTypes, statistics.NewQueryFeedback(0, nil, 0, false))\n\tif err != nil {\n\t\treturn err\n\t}\n\te.result.Fetch(ctx)\n\treturn nil\n}"}, {"instruction": "// GetMemberID returns the member ID of the given peer URL", "input": "go language", "output": "func (c *Client) GetMemberID(peerURL string) (uint64, error) {\n\tcli, err := clientv3.New(clientv3.Config{\n\t\tEndpoints:   c.Endpoints,\n\t\tDialTimeout: 30 * time.Second,\n\t\tTLS:         c.TLS,\n\t})\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tdefer cli.Close()\n\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tresp, err := cli.MemberList(ctx)\n\tcancel()\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tfor _, member := range resp.Members {\n\t\tif member.GetPeerURLs()[0] == peerURL {\n\t\t\treturn member.GetID(), nil\n\t\t}\n\t}\n\treturn 0, nil\n}"}, {"instruction": "// checkName checks the provided name against the request", "input": "go language", "output": "func checkName(obj runtime.Object, name, namespace string, namer ScopeNamer) error {\n\tobjNamespace, objName, err := namer.ObjectName(obj)\n\tif err != nil {\n\t\treturn errors.NewBadRequest(fmt.Sprintf(\n\t\t\t\"the name of the object (%s based on URL) was undeterminable: %v\", name, err))\n\t}\n\tif objName != name {\n\t\treturn errors.NewBadRequest(fmt.Sprintf(\n\t\t\t\"the name of the object (%s) does not match the name on the URL (%s)\", objName, name))\n\t}\n\tif len(namespace) > 0 {\n\t\tif len(objNamespace) > 0 && objNamespace != namespace {\n\t\t\treturn errors.NewBadRequest(fmt.Sprintf(\n\t\t\t\t\"the namespace of the object (%s) does not match the namespace on the request (%s)\", objNamespace, namespace))\n\t\t}\n\t}\n\n\treturn nil\n}"}, {"instruction": "// VisitKind prints a Kind type. It prints each key in the kind, with\n// the type, the required flag, and the description.", "input": "go language", "output": "func (f *regularFieldsPrinter) VisitKind(k *proto.Kind) {\n\tfor _, key := range k.Keys() {\n\t\tv := k.Fields[key]\n\t\trequired := \"\"\n\t\tif k.IsRequired(key) {\n\t\t\trequired = \" -required-\"\n\t\t}\n\n\t\tif err := f.Writer.Write(\"%s\\t<%s>%s\", key, GetTypeName(v), required); err != nil {\n\t\t\tf.Error = err\n\t\t\treturn\n\t\t}\n\t\tif err := f.Writer.Indent(indentDesc).WriteWrapped(\"%s\", v.GetDescription()); err != nil {\n\t\t\tf.Error = err\n\t\t\treturn\n\t\t}\n\t\tif err := f.Writer.Write(\"\"); err != nil {\n\t\t\tf.Error = err\n\t\t\treturn\n\t\t}\n\t}\n}"}, {"instruction": "// New creates a new chunk.\n//  cap: the limit for the max number of rows.\n//  maxChunkSize: the max limit for the number of rows.", "input": "go language", "output": "func New(fields []*types.FieldType, cap, maxChunkSize int) *Chunk {\n\tchk := new(Chunk)\n\tchk.columns = make([]*column, 0, len(fields))\n\tchk.capacity = mathutil.Min(cap, maxChunkSize)\n\tfor _, f := range fields {\n\t\telemLen := getFixedLen(f)\n\t\tif elemLen == varElemLen {\n\t\t\tchk.columns = append(chk.columns, newVarLenColumn(chk.capacity, nil))\n\t\t} else {\n\t\t\tchk.columns = append(chk.columns, newFixedLenColumn(elemLen, chk.capacity))\n\t\t}\n\t}\n\tchk.numVirtualRows = 0\n\n\t// set the default value of requiredRows to maxChunkSize to let chk.IsFull() behave\n\t// like how we judge whether a chunk is full now, then the statement\n\t// \"chk.NumRows() < maxChunkSize\"\n\t// is equal to\n\t// \"!chk.IsFull()\".\n\tchk.requiredRows = maxChunkSize\n\treturn chk\n}"}, {"instruction": "// createCompositeKey and its related functions and consts copied from core/chaincode/shim/chaincode.go", "input": "go language", "output": "func createCompositeKey(objectType string, attributes []string) (string, error) {\n\tif err := validateCompositeKeyAttribute(objectType); err != nil {\n\t\treturn \"\", err\n\t}\n\tck := compositeKeyNamespace + objectType + string(minUnicodeRuneValue)\n\tfor _, att := range attributes {\n\t\tif err := validateCompositeKeyAttribute(att); err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tck += att + string(minUnicodeRuneValue)\n\t}\n\treturn ck, nil\n}"}, {"instruction": "// NewDefinitionNamer constructs a new DefinitionNamer to be used to customize OpenAPI spec.", "input": "go language", "output": "func NewDefinitionNamer(schemes ...*runtime.Scheme) *DefinitionNamer {\n\tret := &DefinitionNamer{\n\t\ttypeGroupVersionKinds: map[string]groupVersionKinds{},\n\t}\n\tfor _, s := range schemes {\n\t\tfor gvk, rtype := range s.AllKnownTypes() {\n\t\t\tnewGVK := gvkConvert(gvk)\n\t\t\texists := false\n\t\t\tfor _, existingGVK := range ret.typeGroupVersionKinds[typeName(rtype)] {\n\t\t\t\tif newGVK == existingGVK {\n\t\t\t\t\texists = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !exists {\n\t\t\t\tret.typeGroupVersionKinds[typeName(rtype)] = append(ret.typeGroupVersionKinds[typeName(rtype)], newGVK)\n\t\t\t}\n\t\t}\n\t}\n\tfor _, gvk := range ret.typeGroupVersionKinds {\n\t\tsort.Sort(gvk)\n\t}\n\treturn ret\n}"}, {"instruction": "// PersistWithConfig provides a mock function with given fields: txid, blockHeight, privateSimulationResultsWithConfig", "input": "go language", "output": "func (_m *Store) PersistWithConfig(txid string, blockHeight uint64, privateSimulationResultsWithConfig *protostransientstore.TxPvtReadWriteSetWithConfigInfo) error {\n\tret := _m.Called(txid, blockHeight, privateSimulationResultsWithConfig)\n\n\tvar r0 error\n\tif rf, ok := ret.Get(0).(func(string, uint64, *protostransientstore.TxPvtReadWriteSetWithConfigInfo) error); ok {\n\t\tr0 = rf(txid, blockHeight, privateSimulationResultsWithConfig)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}"}, {"instruction": "// createProvidersFromPolicies creates providers from the constraints supplied.", "input": "go language", "output": "func (c *PodSecurityPolicyPlugin) createProvidersFromPolicies(psps []*policyv1beta1.PodSecurityPolicy, namespace string) ([]psp.Provider, []error) {\n\tvar (\n\t\t// collected providers\n\t\tproviders []psp.Provider\n\t\t// collected errors to return\n\t\terrs []error\n\t)\n\n\tfor _, constraint := range psps {\n\t\tprovider, err := psp.NewSimpleProvider(constraint, namespace, c.strategyFactory)\n\t\tif err != nil {\n\t\t\terrs = append(errs, fmt.Errorf(\"error creating provider for PSP %s: %v\", constraint.Name, err))\n\t\t\tcontinue\n\t\t}\n\t\tproviders = append(providers, provider)\n\t}\n\treturn providers, errs\n}"}, {"instruction": "// getKubeletSandboxes lists all (or just the running) sandboxes managed by kubelet.", "input": "go language", "output": "func (m *kubeGenericRuntimeManager) getKubeletSandboxes(all bool) ([]*runtimeapi.PodSandbox, error) {\n\tvar filter *runtimeapi.PodSandboxFilter\n\tif !all {\n\t\treadyState := runtimeapi.PodSandboxState_SANDBOX_READY\n\t\tfilter = &runtimeapi.PodSandboxFilter{\n\t\t\tState: &runtimeapi.PodSandboxStateValue{\n\t\t\t\tState: readyState,\n\t\t\t},\n\t\t}\n\t}\n\n\tresp, err := m.runtimeService.ListPodSandbox(filter)\n\tif err != nil {\n\t\tklog.Errorf(\"ListPodSandbox failed: %v\", err)\n\t\treturn nil, err\n\t}\n\n\treturn resp, nil\n}"}, {"instruction": "// ExpectDeletions records expectations for the given deleteKeys, against the given controller.", "input": "go language", "output": "func (u *UIDTrackingControllerExpectations) ExpectDeletions(rcKey string, deletedKeys []string) error {\n\tu.uidStoreLock.Lock()\n\tdefer u.uidStoreLock.Unlock()\n\n\tif existing := u.GetUIDs(rcKey); existing != nil && existing.Len() != 0 {\n\t\tklog.Errorf(\"Clobbering existing delete keys: %+v\", existing)\n\t}\n\texpectedUIDs := sets.NewString()\n\tfor _, k := range deletedKeys {\n\t\texpectedUIDs.Insert(k)\n\t}\n\tklog.V(4).Infof(\"Controller %v waiting on deletions for: %+v\", rcKey, deletedKeys)\n\tif err := u.uidStore.Add(&UIDSet{expectedUIDs, rcKey}); err != nil {\n\t\treturn err\n\t}\n\treturn u.ControllerExpectationsInterface.ExpectDeletions(rcKey, expectedUIDs.Len())\n}"}, {"instruction": "// UnusedFilename finds a filename that isn't already used by a file in\n// the receiving sources and returns it.\n//\n// The given \"proposed\" name is returned verbatim if it isn't already used.\n// Otherwise, the function will try appending incrementing integers to the\n// proposed name until an unused name is found. Callers should propose names\n// that they do not expect to already be in use so that numeric suffixes are\n// only used in rare cases.\n//\n// The proposed name must end in either \".tf\" or \".tf.json\" because a\n// ModuleSources only has visibility into such files. This function will\n// panic if given a file whose name does not end with one of these\n// extensions.\n//\n// A ModuleSources only works on one directory at a time, so the proposed\n// name must not contain any directory separator characters.", "input": "go language", "output": "func (ms ModuleSources) UnusedFilename(proposed string) string {\n\text := fileExt(proposed)\n\tif ext == \"\" {\n\t\tpanic(fmt.Errorf(\"method UnusedFilename used with invalid proposal %q\", proposed))\n\t}\n\n\tif _, exists := ms[proposed]; !exists {\n\t\treturn proposed\n\t}\n\n\tbase := proposed[:len(proposed)-len(ext)]\n\tfor i := 1; ; i++ {\n\t\ttry := fmt.Sprintf(\"%s-%d%s\", base, i, ext)\n\t\tif _, exists := ms[try]; !exists {\n\t\t\treturn try\n\t\t}\n\t}\n}"}, {"instruction": "// Update takes the representation of a horizontalPodAutoscaler and updates it. Returns the server's representation of the horizontalPodAutoscaler, and an error, if there is any.", "input": "go language", "output": "func (c *FakeHorizontalPodAutoscalers) Update(horizontalPodAutoscaler *v2beta1.HorizontalPodAutoscaler) (result *v2beta1.HorizontalPodAutoscaler, err error) {\n\tobj, err := c.Fake.\n\t\tInvokes(testing.NewUpdateAction(horizontalpodautoscalersResource, c.ns, horizontalPodAutoscaler), &v2beta1.HorizontalPodAutoscaler{})\n\n\tif obj == nil {\n\t\treturn nil, err\n\t}\n\treturn obj.(*v2beta1.HorizontalPodAutoscaler), err\n}"}, {"instruction": "// InsertTxn adds a new tombstone.", "input": "go language", "output": "func (g *Graveyard) InsertTxn(tx *memdb.Txn, key string, idx uint64) error {\n\t// Insert the tombstone.\n\tstone := &Tombstone{Key: key, Index: idx}\n\tif err := tx.Insert(\"tombstones\", stone); err != nil {\n\t\treturn fmt.Errorf(\"failed inserting tombstone: %s\", err)\n\t}\n\n\tif err := tx.Insert(\"index\", &IndexEntry{\"tombstones\", idx}); err != nil {\n\t\treturn fmt.Errorf(\"failed updating index: %s\", err)\n\t}\n\n\t// If GC is configured, then we hint that this index requires reaping.\n\tif g.gc != nil {\n\t\ttx.Defer(func() { g.gc.Hint(idx) })\n\t}\n\treturn nil\n}"}, {"instruction": "// IsConfigBlock validates whenever given block contains configuration\n// update transaction", "input": "go language", "output": "func IsConfigBlock(block *cb.Block) bool {\n\tenvelope, err := ExtractEnvelope(block, 0)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tpayload, err := GetPayload(envelope)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tif payload.Header == nil {\n\t\treturn false\n\t}\n\n\thdr, err := UnmarshalChannelHeader(payload.Header.ChannelHeader)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\treturn cb.HeaderType(hdr.Type) == cb.HeaderType_CONFIG || cb.HeaderType(hdr.Type) == cb.HeaderType_ORDERER_TRANSACTION\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *HorizontalPodAutoscalerSpec) DeepCopyInto(out *HorizontalPodAutoscalerSpec) {\n\t*out = *in\n\tout.ScaleTargetRef = in.ScaleTargetRef\n\tif in.MinReplicas != nil {\n\t\tin, out := &in.MinReplicas, &out.MinReplicas\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\tif in.TargetCPUUtilizationPercentage != nil {\n\t\tin, out := &in.TargetCPUUtilizationPercentage, &out.TargetCPUUtilizationPercentage\n\t\t*out = new(int32)\n\t\t**out = **in\n\t}\n\treturn\n}"}, {"instruction": "// LastRevision finds the second max revision number in all replica sets (the last revision)", "input": "go language", "output": "func LastRevision(allRSs []*apps.ReplicaSet) int64 {\n\tmax, secMax := int64(0), int64(0)\n\tfor _, rs := range allRSs {\n\t\tif v, err := Revision(rs); err != nil {\n\t\t\t// Skip the replica sets when it failed to parse their revision information\n\t\t\tklog.V(4).Infof(\"Error: %v. Couldn't parse revision for replica set %#v, deployment controller will skip it when reconciling revisions.\", err, rs)\n\t\t} else if v >= max {\n\t\t\tsecMax = max\n\t\t\tmax = v\n\t\t} else if v > secMax {\n\t\t\tsecMax = v\n\t\t}\n\t}\n\treturn secMax\n}"}, {"instruction": "// vcConnect connects to vCenter with existing credentials\n// If credentials are invalid:\n// \t\t1. It will fetch credentials from credentialManager\n//      2. Update the credentials\n//\t\t3. Connects again to vCenter with fetched credentials", "input": "go language", "output": "func (nm *NodeManager) vcConnect(ctx context.Context, vsphereInstance *VSphereInstance) error {\n\terr := vsphereInstance.conn.Connect(ctx)\n\tif err == nil {\n\t\treturn nil\n\t}\n\n\tcredentialManager := nm.CredentialManager()\n\tif !vclib.IsInvalidCredentialsError(err) || credentialManager == nil {\n\t\tklog.Errorf(\"Cannot connect to vCenter with err: %v\", err)\n\t\treturn err\n\t}\n\n\tklog.V(4).Infof(\"Invalid credentials. Cannot connect to server %q. Fetching credentials from secrets.\", vsphereInstance.conn.Hostname)\n\n\t// Get latest credentials from SecretCredentialManager\n\tcredentials, err := credentialManager.GetCredential(vsphereInstance.conn.Hostname)\n\tif err != nil {\n\t\tklog.Errorf(\"Failed to get credentials from Secret Credential Manager with err: %v\", err)\n\t\treturn err\n\t}\n\tvsphereInstance.conn.UpdateCredentials(credentials.User, credentials.Password)\n\treturn vsphereInstance.conn.Connect(ctx)\n}"}, {"instruction": "// Evaluate uses the PolicyChecker to determine if a request should be allowed.\n// The decision is cached until the identity expires or the chain configuration\n// changes.", "input": "go language", "output": "func (ac *SessionAccessControl) Evaluate() error {\n\tif !ac.sessionEndTime.IsZero() && time.Now().After(ac.sessionEndTime) {\n\t\treturn errors.Errorf(\"client identity expired %v before\", time.Since(ac.sessionEndTime))\n\t}\n\n\tpolicyCheckNeeded := !ac.usedAtLeastOnce\n\n\tif currentConfigSequence := ac.sequencer.Sequence(); currentConfigSequence > ac.lastConfigSequence {\n\t\tac.lastConfigSequence = currentConfigSequence\n\t\tpolicyCheckNeeded = true\n\t}\n\n\tif !policyCheckNeeded {\n\t\treturn nil\n\t}\n\n\tac.usedAtLeastOnce = true\n\treturn ac.policyChecker.CheckPolicy(ac.envelope, ac.channelID)\n}"}, {"instruction": "// Start starts a containerd daemon and monitors it", "input": "go language", "output": "func Start(ctx context.Context, rootDir, stateDir string, opts ...DaemonOpt) (Daemon, error) {\n\tr := &remote{\n\t\trootDir:  rootDir,\n\t\tstateDir: stateDir,\n\t\tConfig: config.Config{\n\t\t\tRoot:  filepath.Join(rootDir, \"daemon\"),\n\t\t\tState: filepath.Join(stateDir, \"daemon\"),\n\t\t},\n\t\tpluginConfs:   pluginConfigs{make(map[string]interface{})},\n\t\tdaemonPid:     -1,\n\t\tlogger:        logrus.WithField(\"module\", \"libcontainerd\"),\n\t\tdaemonStartCh: make(chan error, 1),\n\t\tdaemonStopCh:  make(chan struct{}),\n\t}\n\n\tfor _, opt := range opts {\n\t\tif err := opt(r); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tr.setDefaults()\n\n\tif err := system.MkdirAll(stateDir, 0700, \"\"); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgo r.monitorDaemon(ctx)\n\n\tselect {\n\tcase <-time.After(startupTimeout):\n\t\treturn nil, errors.New(\"timeout waiting for containerd to start\")\n\tcase err := <-r.daemonStartCh:\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn r, nil\n}"}, {"instruction": "// getH2Settings returns the []http2.Setting that are encoded in the\n// HTTP2-Settings header.", "input": "go language", "output": "func getH2Settings(h http.Header) ([]http2.Setting, error) {\n\tvals, ok := h[textproto.CanonicalMIMEHeaderKey(\"HTTP2-Settings\")]\n\tif !ok {\n\t\treturn nil, errors.New(\"missing HTTP2-Settings header\")\n\t}\n\tif len(vals) != 1 {\n\t\treturn nil, fmt.Errorf(\"expected 1 HTTP2-Settings. Got: %v\", vals)\n\t}\n\tsettings, err := decodeSettings(vals[0])\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"invalid HTTP2-Settings: %q\", vals[0])\n\t}\n\treturn settings, nil\n}"}, {"instruction": "// ShardRowID shards the implicit row ID by adding shard value to the row ID's first few bits.", "input": "go language", "output": "func (d *ddl) ShardRowID(ctx sessionctx.Context, tableIdent ast.Ident, uVal uint64) error {\n\tschema, t, err := d.getSchemaAndTableByIdent(ctx, tableIdent)\n\tif err != nil {\n\t\treturn errors.Trace(err)\n\t}\n\tok, _ := hasAutoIncrementColumn(t.Meta())\n\tif ok && uVal != 0 {\n\t\treturn errUnsupportedShardRowIDBits\n\t}\n\tif uVal == t.Meta().ShardRowIDBits {\n\t\t// Nothing need to do.\n\t\treturn nil\n\t}\n\terr = verifyNoOverflowShardBits(d.sessPool, t, uVal)\n\tif err != nil {\n\t\treturn err\n\t}\n\tjob := &model.Job{\n\t\tType:       model.ActionShardRowID,\n\t\tSchemaID:   schema.ID,\n\t\tTableID:    t.Meta().ID,\n\t\tBinlogInfo: &model.HistoryInfo{},\n\t\tArgs:       []interface{}{uVal},\n\t}\n\terr = d.doDDLJob(ctx, job)\n\terr = d.callHookOnChanged(err)\n\treturn errors.Trace(err)\n}"}, {"instruction": "// convertPodNamedPortToNumber converts named ports into port numbers\n// It returns an error when a named port can't be found in the pod containers", "input": "go language", "output": "func convertPodNamedPortToNumber(ports []string, pod corev1.Pod) ([]string, error) {\n\tvar converted []string\n\tfor _, port := range ports {\n\t\tlocalPort, remotePort := splitPort(port)\n\n\t\tcontainerPortStr := remotePort\n\t\t_, err := strconv.Atoi(remotePort)\n\t\tif err != nil {\n\t\t\tcontainerPort, err := util.LookupContainerPortNumberByName(pod, remotePort)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tcontainerPortStr = strconv.Itoa(int(containerPort))\n\t\t}\n\n\t\tif localPort != remotePort {\n\t\t\tconverted = append(converted, fmt.Sprintf(\"%s:%s\", localPort, containerPortStr))\n\t\t} else {\n\t\t\tconverted = append(converted, containerPortStr)\n\t\t}\n\t}\n\n\treturn converted, nil\n}"}, {"instruction": "// SignCertificate creates a signed certificate based on a built-in template\n// and saves it in baseDir/name", "input": "go language", "output": "func (ca *CA) SignCertificate(baseDir, name string, ous, sans []string, pub *ecdsa.PublicKey,\n\tku x509.KeyUsage, eku []x509.ExtKeyUsage) (*x509.Certificate, error) {\n\n\ttemplate := x509Template()\n\ttemplate.KeyUsage = ku\n\ttemplate.ExtKeyUsage = eku\n\n\t//set the organization for the subject\n\tsubject := subjectTemplateAdditional(ca.Country, ca.Province, ca.Locality, ca.OrganizationalUnit, ca.StreetAddress, ca.PostalCode)\n\tsubject.CommonName = name\n\n\tsubject.OrganizationalUnit = append(subject.OrganizationalUnit, ous...)\n\n\ttemplate.Subject = subject\n\tfor _, san := range sans {\n\t\t// try to parse as an IP address first\n\t\tip := net.ParseIP(san)\n\t\tif ip != nil {\n\t\t\ttemplate.IPAddresses = append(template.IPAddresses, ip)\n\t\t} else {\n\t\t\ttemplate.DNSNames = append(template.DNSNames, san)\n\t\t}\n\t}\n\n\tcert, err := genCertificateECDSA(baseDir, name, &template, ca.SignCert,\n\t\tpub, ca.Signer)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn cert, nil\n}"}, {"instruction": "// Delete an existing Group expression.", "input": "go language", "output": "func (g *Group) Delete(e *GroupExpr) {\n\tfingerprint := e.FingerPrint()\n\tequiv, ok := g.Fingerprints[fingerprint]\n\tif !ok {\n\t\treturn // Can not find the target GroupExpr.\n\t}\n\n\tg.Equivalents.Remove(equiv)\n\tdelete(g.Fingerprints, fingerprint)\n\n\toperand := GetOperand(equiv.Value.(*GroupExpr).ExprNode)\n\tif g.FirstExpr[operand] != equiv {\n\t\treturn // The target GroupExpr is not the first Element of the same Operand.\n\t}\n\n\tnextElem := equiv.Next()\n\tif nextElem != nil && GetOperand(nextElem.Value.(*GroupExpr).ExprNode) == operand {\n\t\tg.FirstExpr[operand] = nextElem\n\t\treturn // The first Element of the same Operand has been changed.\n\t}\n\tdelete(g.FirstExpr, operand)\n}"}, {"instruction": "// GetSubresourcesForVersion returns the subresources for given version or nil.", "input": "go language", "output": "func GetSubresourcesForVersion(crd *CustomResourceDefinition, version string) (*CustomResourceSubresources, error) {\n\tif !HasPerVersionSubresources(crd.Spec.Versions) {\n\t\treturn crd.Spec.Subresources, nil\n\t}\n\tif crd.Spec.Subresources != nil {\n\t\treturn nil, fmt.Errorf(\"malformed CustomResourceDefinition %s version %s: top-level and per-version subresources must be mutual exclusive\", crd.Name, version)\n\t}\n\tfor _, v := range crd.Spec.Versions {\n\t\tif version == v.Name {\n\t\t\treturn v.Subresources, nil\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"version %s not found in CustomResourceDefinition: %v\", version, crd.Name)\n}"}, {"instruction": "// EvalString returns string representation of Column.", "input": "go language", "output": "func (col *Column) EvalString(ctx sessionctx.Context, row chunk.Row) (string, bool, error) {\n\tif row.IsNull(col.Index) {\n\t\treturn \"\", true, nil\n\t}\n\n\t// Specially handle the ENUM/SET/BIT input value.\n\tif col.GetType().Hybrid() {\n\t\tval := row.GetDatum(col.Index, col.RetType)\n\t\tres, err := val.ToString()\n\t\treturn res, err != nil, err\n\t}\n\n\tval := row.GetString(col.Index)\n\tif ctx.GetSessionVars().StmtCtx.PadCharToFullLength && col.GetType().Tp == mysql.TypeString {\n\t\tvalLen := len([]rune(val))\n\t\tif valLen < col.RetType.Flen {\n\t\t\tval = val + strings.Repeat(\" \", col.RetType.Flen-valLen)\n\t\t}\n\t}\n\treturn val, false, nil\n}"}, {"instruction": "// RecommendedDefaultNodeLifecycleControllerConfiguration defaults a pointer to a\n// NodeLifecycleControllerConfiguration struct. This will set the recommended default\n// values, but they may be subject to change between API versions. This function\n// is intentionally not registered in the scheme as a \"normal\" `SetDefaults_Foo`\n// function to allow consumers of this type to set whatever defaults for their\n// embedded configs. Forcing consumers to use these defaults would be problematic\n// as defaulting in the scheme is done as part of the conversion, and there would\n// be no easy way to opt-out. Instead, if you want to use this defaulting method\n// run it in your wrapper struct of this type in its `SetDefaults_` method.", "input": "go language", "output": "func RecommendedDefaultNodeLifecycleControllerConfiguration(obj *kubectrlmgrconfigv1alpha1.NodeLifecycleControllerConfiguration) {\n\tzero := metav1.Duration{}\n\tif obj.PodEvictionTimeout == zero {\n\t\tobj.PodEvictionTimeout = metav1.Duration{Duration: 5 * time.Minute}\n\t}\n\tif obj.NodeMonitorGracePeriod == zero {\n\t\tobj.NodeMonitorGracePeriod = metav1.Duration{Duration: 40 * time.Second}\n\t}\n\tif obj.NodeStartupGracePeriod == zero {\n\t\tobj.NodeStartupGracePeriod = metav1.Duration{Duration: 60 * time.Second}\n\t}\n\tif obj.EnableTaintManager == nil {\n\t\tobj.EnableTaintManager = utilpointer.BoolPtr(true)\n\t}\n}"}, {"instruction": "// hasCorrectIssuer returns true if tokenData is a valid JWT in compact\n// serialization format and the \"iss\" claim matches the iss field of this token\n// authenticator, and otherwise returns false.\n//\n// Note: go-jose currently does not allow access to unverified JWS payloads.\n// See https://github.com/square/go-jose/issues/169", "input": "go language", "output": "func (j *jwtTokenAuthenticator) hasCorrectIssuer(tokenData string) bool {\n\tparts := strings.Split(tokenData, \".\")\n\tif len(parts) != 3 {\n\t\treturn false\n\t}\n\tpayload, err := base64.RawURLEncoding.DecodeString(parts[1])\n\tif err != nil {\n\t\treturn false\n\t}\n\tclaims := struct {\n\t\t// WARNING: this JWT is not verified. Do not trust these claims.\n\t\tIssuer string `json:\"iss\"`\n\t}{}\n\tif err := json.Unmarshal(payload, &claims); err != nil {\n\t\treturn false\n\t}\n\tif claims.Issuer != j.iss {\n\t\treturn false\n\t}\n\treturn true\n\n}"}, {"instruction": "// setLimits updates the allowed peer count and total capacity of the priority\n// client pool. Since the free client pool is a child of the priority pool the\n// remaining peer count and capacity is assigned to the free pool by calling its\n// own setLimits function.\n//\n// Note: a decreasing change of the total capacity is applied with a delay.", "input": "go language", "output": "func (v *priorityClientPool) setLimits(count int, totalCap uint64) {\n\tv.lock.Lock()\n\tdefer v.lock.Unlock()\n\n\tv.totalCapAnnounced = totalCap\n\tif totalCap > v.totalCap {\n\t\tv.setLimitsNow(count, totalCap)\n\t\tv.subs.send(totalCap, false)\n\t\treturn\n\t}\n\tv.setLimitsNow(count, v.totalCap)\n\tif totalCap < v.totalCap {\n\t\tv.subs.send(totalCap, totalCap < v.totalConnectedCap)\n\t\tfor i, s := range v.updateSchedule {\n\t\t\tif totalCap >= s.totalCap {\n\t\t\t\ts.totalCap = totalCap\n\t\t\t\tv.updateSchedule = v.updateSchedule[:i+1]\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tv.updateSchedule = append(v.updateSchedule, scheduledUpdate{time: mclock.Now() + mclock.AbsTime(dropCapacityDelay), totalCap: totalCap})\n\t\tif len(v.updateSchedule) == 1 {\n\t\t\tv.scheduleCounter++\n\t\t\tid := v.scheduleCounter\n\t\t\tv.updateSchedule[0].id = id\n\t\t\ttime.AfterFunc(dropCapacityDelay, func() { v.checkUpdate(id) })\n\t\t}\n\t} else {\n\t\tv.updateSchedule = nil\n\t}\n}"}, {"instruction": "// Run starts the AvailableConditionController loop which manages the availability condition of API services.", "input": "go language", "output": "func (c *AvailableConditionController) Run(threadiness int, stopCh <-chan struct{}) {\n\tdefer utilruntime.HandleCrash()\n\tdefer c.queue.ShutDown()\n\n\tklog.Infof(\"Starting AvailableConditionController\")\n\tdefer klog.Infof(\"Shutting down AvailableConditionController\")\n\n\tif !controllers.WaitForCacheSync(\"AvailableConditionController\", stopCh, c.apiServiceSynced, c.servicesSynced, c.endpointsSynced) {\n\t\treturn\n\t}\n\n\tfor i := 0; i < threadiness; i++ {\n\t\tgo wait.Until(c.runWorker, time.Second, stopCh)\n\t}\n\n\t<-stopCh\n}"}, {"instruction": "// Derive attempts to explicitly derive a hierarchical deterministic account at\n// the specified derivation path. If requested, the derived account will be added\n// to the wallet's tracked account list.", "input": "go language", "output": "func (w *Wallet) Derive(path accounts.DerivationPath, pin bool) (accounts.Account, error) {\n\tw.lock.Lock()\n\tdefer w.lock.Unlock()\n\n\taccount, err := w.session.derive(path)\n\tif err != nil {\n\t\treturn accounts.Account{}, err\n\t}\n\n\tif pin {\n\t\tpairing := w.Hub.pairing(w)\n\t\tpairing.Accounts[account.Address] = path\n\t\tif err := w.Hub.setPairing(w, pairing); err != nil {\n\t\t\treturn accounts.Account{}, err\n\t\t}\n\t}\n\n\treturn account, nil\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *ShowDDLJobQueriesExec) Open(ctx context.Context) error {\n\tif err := e.baseExecutor.Open(ctx); err != nil {\n\t\treturn err\n\t}\n\ttxn, err := e.ctx.Txn(true)\n\tif err != nil {\n\t\treturn err\n\t}\n\tjobs, err := admin.GetDDLJobs(txn)\n\tif err != nil {\n\t\treturn err\n\t}\n\thistoryJobs, err := admin.GetHistoryDDLJobs(txn, admin.DefNumHistoryJobs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te.jobs = append(e.jobs, jobs...)\n\te.jobs = append(e.jobs, historyJobs...)\n\n\treturn nil\n}"}, {"instruction": "// NewRemoteRuntimeService creates a new internalapi.RuntimeService.", "input": "go language", "output": "func NewRemoteRuntimeService(endpoint string, connectionTimeout time.Duration) (internalapi.RuntimeService, error) {\n\tklog.V(3).Infof(\"Connecting to runtime service %s\", endpoint)\n\taddr, dailer, err := util.GetAddressAndDialer(endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), connectionTimeout)\n\tdefer cancel()\n\n\tconn, err := grpc.DialContext(ctx, addr, grpc.WithInsecure(), grpc.WithDialer(dailer), grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxMsgSize)))\n\tif err != nil {\n\t\tklog.Errorf(\"Connect remote runtime %s failed: %v\", addr, err)\n\t\treturn nil, err\n\t}\n\n\treturn &RemoteRuntimeService{\n\t\ttimeout:       connectionTimeout,\n\t\truntimeClient: runtimeapi.NewRuntimeServiceClient(conn),\n\t\tlogReduction:  logreduction.NewLogReduction(identicalErrorDelay),\n\t}, nil\n}"}, {"instruction": "// RecoverPubkey returns the public key of the signer.\n// msg must be the 32-byte hash of the message to be signed.\n// sig must be a 65-byte compact ECDSA signature containing the\n// recovery id as the last element.", "input": "go language", "output": "func RecoverPubkey(msg []byte, sig []byte) ([]byte, error) {\n\tif len(msg) != 32 {\n\t\treturn nil, ErrInvalidMsgLen\n\t}\n\tif err := checkSignature(sig); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar (\n\t\tpubkey  = make([]byte, 65)\n\t\tsigdata = (*C.uchar)(unsafe.Pointer(&sig[0]))\n\t\tmsgdata = (*C.uchar)(unsafe.Pointer(&msg[0]))\n\t)\n\tif C.secp256k1_ext_ecdsa_recover(context, (*C.uchar)(unsafe.Pointer(&pubkey[0])), sigdata, msgdata) == 0 {\n\t\treturn nil, ErrRecoverFailed\n\t}\n\treturn pubkey, nil\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *GenericControllerManagerConfiguration) DeepCopyInto(out *GenericControllerManagerConfiguration) {\n\t*out = *in\n\tout.MinResyncPeriod = in.MinResyncPeriod\n\tout.ClientConnection = in.ClientConnection\n\tout.ControllerStartInterval = in.ControllerStartInterval\n\tin.LeaderElection.DeepCopyInto(&out.LeaderElection)\n\tif in.Controllers != nil {\n\t\tin, out := &in.Controllers, &out.Controllers\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}\n\tout.Debugging = in.Debugging\n\treturn\n}"}, {"instruction": "// BatchGet queries values with the keys.", "input": "go language", "output": "func (c *RawKVClient) BatchGet(keys [][]byte) ([][]byte, error) {\n\tstart := time.Now()\n\tdefer func() {\n\t\ttikvRawkvCmdHistogramWithBatchGet.Observe(time.Since(start).Seconds())\n\t}()\n\n\tbo := NewBackoffer(context.Background(), rawkvMaxBackoff)\n\tresp, err := c.sendBatchReq(bo, keys, tikvrpc.CmdRawBatchGet)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\n\tcmdResp := resp.RawBatchGet\n\tif cmdResp == nil {\n\t\treturn nil, errors.Trace(ErrBodyMissing)\n\t}\n\n\tkeyToValue := make(map[string][]byte, len(keys))\n\tfor _, pair := range cmdResp.Pairs {\n\t\tkeyToValue[string(pair.Key)] = pair.Value\n\t}\n\n\tvalues := make([][]byte, len(keys))\n\tfor i, key := range keys {\n\t\tvalues[i] = keyToValue[string(key)]\n\t}\n\treturn values, nil\n}"}, {"instruction": "// Validate checks validation of GenericOptions.", "input": "go language", "output": "func (o *GenericControllerManagerConfigurationOptions) Validate(allControllers []string, disabledByDefaultControllers []string) []error {\n\tif o == nil {\n\t\treturn nil\n\t}\n\n\terrs := []error{}\n\terrs = append(errs, o.Debugging.Validate()...)\n\n\tallControllersSet := sets.NewString(allControllers...)\n\tfor _, controller := range o.Controllers {\n\t\tif controller == \"*\" {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(controller, \"-\") {\n\t\t\tcontroller = controller[1:]\n\t\t}\n\t\tif !allControllersSet.Has(controller) {\n\t\t\terrs = append(errs, fmt.Errorf(\"%q is not in the list of known controllers\", controller))\n\t\t}\n\t}\n\n\treturn errs\n}"}, {"instruction": "// handshake works like TCP handshake, but in a higher level, it first writes initial packet to client,\n// during handshake, client and server negotiate compatible features and do authentication.\n// After handshake, client can send sql query to server.", "input": "go language", "output": "func (cc *clientConn) handshake(ctx context.Context) error {\n\tif err := cc.writeInitialHandshake(); err != nil {\n\t\treturn err\n\t}\n\tif err := cc.readOptionalSSLRequestAndHandshakeResponse(ctx); err != nil {\n\t\terr1 := cc.writeError(err)\n\t\tif err1 != nil {\n\t\t\tlogutil.Logger(ctx).Debug(\"writeError failed\", zap.Error(err1))\n\t\t}\n\t\treturn err\n\t}\n\tdata := cc.alloc.AllocWithLen(4, 32)\n\tdata = append(data, mysql.OKHeader)\n\tdata = append(data, 0, 0)\n\tif cc.capability&mysql.ClientProtocol41 > 0 {\n\t\tdata = dumpUint16(data, mysql.ServerStatusAutocommit)\n\t\tdata = append(data, 0, 0)\n\t}\n\n\terr := cc.writePacket(data)\n\tcc.pkt.sequence = 0\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn cc.flush()\n}"}, {"instruction": "// ValidateObjectMetaUpdate validates an object's metadata when updated", "input": "go language", "output": "func ValidateObjectMetaUpdate(newMeta, oldMeta *metav1.ObjectMeta, fldPath *field.Path) field.ErrorList {\n\tnewMetadata, err := meta.Accessor(newMeta)\n\tif err != nil {\n\t\tallErrs := field.ErrorList{}\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, newMeta, err.Error()))\n\t\treturn allErrs\n\t}\n\toldMetadata, err := meta.Accessor(oldMeta)\n\tif err != nil {\n\t\tallErrs := field.ErrorList{}\n\t\tallErrs = append(allErrs, field.Invalid(fldPath, oldMeta, err.Error()))\n\t\treturn allErrs\n\t}\n\treturn ValidateObjectMetaAccessorUpdate(newMetadata, oldMetadata, fldPath)\n}"}, {"instruction": "// SetLocalSystemVar sets values of the local variables which in \"server\" scope.", "input": "go language", "output": "func SetLocalSystemVar(name string, val string) {\n\tswitch name {\n\tcase TiDBDDLReorgWorkerCount:\n\t\tSetDDLReorgWorkerCounter(int32(tidbOptPositiveInt32(val, DefTiDBDDLReorgWorkerCount)))\n\tcase TiDBDDLReorgBatchSize:\n\t\tSetDDLReorgBatchSize(int32(tidbOptPositiveInt32(val, DefTiDBDDLReorgBatchSize)))\n\tcase TiDBDDLErrorCountLimit:\n\t\tSetDDLErrorCountLimit(tidbOptInt64(val, DefTiDBDDLErrorCountLimit))\n\t}\n}"}, {"instruction": "// TranslateCSIPVToInTree takes a PV with CSIPersistentVolumeSource set and\n// translates the GCE PD CSI source to a GCEPersistentDisk source.", "input": "go language", "output": "func (g *gcePersistentDiskCSITranslator) TranslateCSIPVToInTree(pv *v1.PersistentVolume) (*v1.PersistentVolume, error) {\n\tif pv == nil || pv.Spec.CSI == nil {\n\t\treturn nil, fmt.Errorf(\"pv is nil or CSI source not defined on pv\")\n\t}\n\tcsiSource := pv.Spec.CSI\n\n\tpdName, err := pdNameFromVolumeID(csiSource.VolumeHandle)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tgceSource := &v1.GCEPersistentDiskVolumeSource{\n\t\tPDName:   pdName,\n\t\tFSType:   csiSource.FSType,\n\t\tReadOnly: csiSource.ReadOnly,\n\t}\n\tif partition, ok := csiSource.VolumeAttributes[\"partition\"]; ok && partition != \"\" {\n\t\tpartInt, err := strconv.Atoi(partition)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"Failed to convert partition %v to integer: %v\", partition, err)\n\t\t}\n\t\tgceSource.Partition = int32(partInt)\n\t}\n\n\t// TODO: Take the zone/regional information and stick it into the label.\n\n\tpv.Spec.CSI = nil\n\tpv.Spec.GCEPersistentDisk = gceSource\n\n\treturn pv, nil\n}"}, {"instruction": "// PatchNodeTaints patches node's taints.", "input": "go language", "output": "func PatchNodeTaints(c clientset.Interface, nodeName string, oldNode *v1.Node, newNode *v1.Node) error {\n\toldData, err := json.Marshal(oldNode)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal old node %#v for node %q: %v\", oldNode, nodeName, err)\n\t}\n\n\tnewTaints := newNode.Spec.Taints\n\tnewNodeClone := oldNode.DeepCopy()\n\tnewNodeClone.Spec.Taints = newTaints\n\tnewData, err := json.Marshal(newNodeClone)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal new node %#v for node %q: %v\", newNodeClone, nodeName, err)\n\t}\n\n\tpatchBytes, err := strategicpatch.CreateTwoWayMergePatch(oldData, newData, v1.Node{})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create patch for node %q: %v\", nodeName, err)\n\t}\n\n\t_, err = c.CoreV1().Nodes().Patch(nodeName, types.StrategicMergePatchType, patchBytes)\n\treturn err\n}"}, {"instruction": "// Open implements the Executor Open interface.", "input": "go language", "output": "func (e *CleanupIndexExec) Open(ctx context.Context) error {\n\tif err := e.baseExecutor.Open(ctx); err != nil {\n\t\treturn err\n\t}\n\te.idxChunk = chunk.New(e.getIdxColTypes(), e.initCap, e.maxChunkSize)\n\te.idxValues = make(map[int64][][]types.Datum, e.batchSize)\n\te.batchKeys = make([]kv.Key, 0, e.batchSize)\n\te.idxValsBufs = make([][]types.Datum, e.batchSize)\n\tsc := e.ctx.GetSessionVars().StmtCtx\n\tidxKey, _, err := e.index.GenIndexKey(sc, []types.Datum{{}}, math.MinInt64, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\te.lastIdxKey = idxKey\n\treturn nil\n}"}, {"instruction": "// DeleteTeam will delete a team, its member and any permissions connected to the team", "input": "go language", "output": "func DeleteTeam(cmd *m.DeleteTeamCommand) error {\n\treturn inTransaction(func(sess *DBSession) error {\n\t\tif _, err := teamExists(cmd.OrgId, cmd.Id, sess); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdeletes := []string{\n\t\t\t\"DELETE FROM team_member WHERE org_id=? and team_id = ?\",\n\t\t\t\"DELETE FROM team WHERE org_id=? and id = ?\",\n\t\t\t\"DELETE FROM dashboard_acl WHERE org_id=? and team_id = ?\",\n\t\t}\n\n\t\tfor _, sql := range deletes {\n\t\t\t_, err := sess.Exec(sql, cmd.OrgId, cmd.Id)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}"}, {"instruction": "// NewOperationGenerator is returns instance of operationGenerator", "input": "go language", "output": "func NewOperationGenerator(kubeClient clientset.Interface,\n\tvolumePluginMgr *volume.VolumePluginMgr,\n\trecorder record.EventRecorder,\n\tcheckNodeCapabilitiesBeforeMount bool,\n\tblkUtil volumepathhandler.BlockVolumePathHandler) OperationGenerator {\n\n\treturn &operationGenerator{\n\t\tkubeClient:                       kubeClient,\n\t\tvolumePluginMgr:                  volumePluginMgr,\n\t\trecorder:                         recorder,\n\t\tcheckNodeCapabilitiesBeforeMount: checkNodeCapabilitiesBeforeMount,\n\t\tblkUtil:                          blkUtil,\n\t}\n}"}, {"instruction": "// inferTypeFromDefault contains the logic for the old method of inferring\n// variable types - we can also use this for validating that the declared\n// type matches the type of the default value", "input": "go language", "output": "func (v *Variable) inferTypeFromDefault() VariableType {\n\tif v.Default == nil {\n\t\treturn VariableTypeString\n\t}\n\n\tvar s string\n\tif err := hilmapstructure.WeakDecode(v.Default, &s); err == nil {\n\t\tv.Default = s\n\t\treturn VariableTypeString\n\t}\n\n\tvar m map[string]interface{}\n\tif err := hilmapstructure.WeakDecode(v.Default, &m); err == nil {\n\t\tv.Default = m\n\t\treturn VariableTypeMap\n\t}\n\n\tvar l []interface{}\n\tif err := hilmapstructure.WeakDecode(v.Default, &l); err == nil {\n\t\tv.Default = l\n\t\treturn VariableTypeList\n\t}\n\n\treturn VariableTypeUnknown\n}"}, {"instruction": "// Deprecated informs about a deprecation, but only once for a given set of arguments' values.\n// If the err flag is enabled, it logs as an ERROR (will exit with -1) and the text will\n// point at the next Hugo release.\n// The idea is two remove an item in two Hugo releases to give users and theme authors\n// plenty of time to fix their templates.", "input": "go language", "output": "func Deprecated(object, item, alternative string, err bool) {\n\tif !strings.HasSuffix(alternative, \".\") {\n\t\talternative += \".\"\n\t}\n\n\tif err {\n\t\tDistinctErrorLog.Printf(\"%s's %s is deprecated and will be removed in Hugo %s. %s\", object, item, hugo.CurrentVersion.Next().ReleaseVersion(), alternative)\n\n\t} else {\n\t\tDistinctWarnLog.Printf(\"%s's %s is deprecated and will be removed in a future release. %s\", object, item, alternative)\n\t}\n}"}, {"instruction": "// DropTable will proceed even if some table in the list does not exists.", "input": "go language", "output": "func (d *ddl) DropTable(ctx sessionctx.Context, ti ast.Ident) (err error) {\n\tschema, tb, err := d.getSchemaAndTableByIdent(ctx, ti)\n\tif err != nil {\n\t\treturn errors.Trace(err)\n\t}\n\n\tjob := &model.Job{\n\t\tSchemaID:   schema.ID,\n\t\tTableID:    tb.Meta().ID,\n\t\tType:       model.ActionDropTable,\n\t\tBinlogInfo: &model.HistoryInfo{},\n\t}\n\n\terr = d.doDDLJob(ctx, job)\n\terr = d.callHookOnChanged(err)\n\treturn errors.Trace(err)\n}"}, {"instruction": "// New creates rate limiter middleware.", "input": "go language", "output": "func New(ctx context.Context, next http.Handler, config config.RateLimit, name string) (http.Handler, error) {\n\tmiddlewares.GetLogger(ctx, name, typeName).Debug(\"Creating middleware\")\n\n\textractFunc, err := utils.NewExtractor(config.ExtractorFunc)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trateSet := ratelimit.NewRateSet()\n\tfor _, rate := range config.RateSet {\n\t\tif err = rateSet.Add(time.Duration(rate.Period), rate.Average, rate.Burst); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\trl, err := ratelimit.New(next, extractFunc, rateSet)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &rateLimiter{handler: rl, name: name}, nil\n}"}, {"instruction": "// RegisterConversions adds conversion functions to the given scheme.\n// Public to allow building arbitrary schemes.", "input": "go language", "output": "func RegisterConversions(s *runtime.Scheme) error {\n\tif err := s.AddGeneratedConversionFunc((*Configuration)(nil), (*podtolerationrestriction.Configuration)(nil), func(a, b interface{}, scope conversion.Scope) error {\n\t\treturn Convert_v1alpha1_Configuration_To_podtolerationrestriction_Configuration(a.(*Configuration), b.(*podtolerationrestriction.Configuration), scope)\n\t}); err != nil {\n\t\treturn err\n\t}\n\tif err := s.AddGeneratedConversionFunc((*podtolerationrestriction.Configuration)(nil), (*Configuration)(nil), func(a, b interface{}, scope conversion.Scope) error {\n\t\treturn Convert_podtolerationrestriction_Configuration_To_v1alpha1_Configuration(a.(*podtolerationrestriction.Configuration), b.(*Configuration), scope)\n\t}); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}"}, {"instruction": "// getBucketScore gets the score for merge this bucket with previous one.\n// TODO: We also need to consider the bucket hit count.", "input": "go language", "output": "func getBucketScore(bkts []bucket, totalCount float64, id int) bucketScore {\n\tpreCount, count := float64(bkts[id-1].Count), float64(bkts[id].Count)\n\t// do not merge if the result bucket is too large\n\tif (preCount + count) > maxBucketFraction*totalCount {\n\t\treturn bucketScore{id, math.MaxFloat64}\n\t}\n\t// Merge them if the result bucket is already too small.\n\tif (preCount + count) < minBucketFraction*totalCount {\n\t\treturn bucketScore{id, 0}\n\t}\n\tlow, mid, high := bkts[id-1].Lower, bkts[id-1].Upper, bkts[id].Upper\n\t// If we choose to merge, err is the absolute estimate error for the previous bucket.\n\terr := calcFraction4Datums(low, high, mid)*(preCount+count) - preCount\n\treturn bucketScore{id, math.Abs(err / (preCount + count))}\n}"}, {"instruction": "// KillApplicationTasks provides a mock function with given fields: applicationID, opts", "input": "go language", "output": "func (_m *Marathon) KillApplicationTasks(applicationID string, opts *marathon.KillApplicationTasksOpts) (*marathon.Tasks, error) {\n\tret := _m.Called(applicationID, opts)\n\n\tvar r0 *marathon.Tasks\n\tif rf, ok := ret.Get(0).(func(string, *marathon.KillApplicationTasksOpts) *marathon.Tasks); ok {\n\t\tr0 = rf(applicationID, opts)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*marathon.Tasks)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(string, *marathon.KillApplicationTasksOpts) error); ok {\n\t\tr1 = rf(applicationID, opts)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}"}, {"instruction": "// NewPSTMTPlanCacheKey creates a new pstmtPlanCacheKey object.", "input": "go language", "output": "func NewPSTMTPlanCacheKey(sessionVars *variable.SessionVars, pstmtID uint32, schemaVersion int64) kvcache.Key {\n\ttimezoneOffset := 0\n\tif sessionVars.TimeZone != nil {\n\t\t_, timezoneOffset = time.Now().In(sessionVars.TimeZone).Zone()\n\t}\n\treturn &pstmtPlanCacheKey{\n\t\tdatabase:       sessionVars.CurrentDB,\n\t\tconnID:         sessionVars.ConnectionID,\n\t\tpstmtID:        pstmtID,\n\t\tsnapshot:       sessionVars.SnapshotTS,\n\t\tschemaVersion:  schemaVersion,\n\t\tsqlMode:        sessionVars.SQLMode,\n\t\ttimezoneOffset: timezoneOffset,\n\t}\n}"}, {"instruction": "// newEndpointImpl creates a new endpoint for the given resourceName.\n// This is to be used during normal device plugin registration.", "input": "go language", "output": "func newEndpointImpl(socketPath, resourceName string, callback monitorCallback) (*endpointImpl, error) {\n\tclient, c, err := dial(socketPath)\n\tif err != nil {\n\t\tklog.Errorf(\"Can't create new endpoint with path %s err %v\", socketPath, err)\n\t\treturn nil, err\n\t}\n\n\treturn &endpointImpl{\n\t\tclient:     client,\n\t\tclientConn: c,\n\n\t\tsocketPath:   socketPath,\n\t\tresourceName: resourceName,\n\n\t\tcb: callback,\n\t}, nil\n}"}, {"instruction": "// Create creates Kubernetes resources from an io.reader.\n//\n// Namespace will set the namespace.", "input": "go language", "output": "func (c *Client) Create(namespace string, reader io.Reader, timeout int64, shouldWait bool) error {\n\tclient, err := c.KubernetesClientSet()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := ensureNamespace(client, namespace); err != nil {\n\t\treturn err\n\t}\n\tc.Log(\"building resources from manifest\")\n\tinfos, buildErr := c.BuildUnstructured(namespace, reader)\n\tif buildErr != nil {\n\t\treturn buildErr\n\t}\n\tc.Log(\"creating %d resource(s)\", len(infos))\n\tif err := perform(infos, createResource); err != nil {\n\t\treturn err\n\t}\n\tif shouldWait {\n\t\treturn c.waitForResources(time.Duration(timeout)*time.Second, infos)\n\t}\n\treturn nil\n}"}, {"instruction": "// increments priority of the given child and reorders if necessary.", "input": "go language", "output": "func (n *node) incrementChildPrio(pos int) int {\n\tn.children[pos].priority++\n\tprio := n.children[pos].priority\n\n\t// adjust position (move to front)\n\tnewPos := pos\n\tfor newPos > 0 && n.children[newPos-1].priority < prio {\n\t\t// swap node positions\n\t\tn.children[newPos-1], n.children[newPos] = n.children[newPos], n.children[newPos-1]\n\n\t\tnewPos--\n\t}\n\n\t// build new index char string\n\tif newPos != pos {\n\t\tn.indices = n.indices[:newPos] + // unchanged prefix, might be empty\n\t\t\tn.indices[pos:pos+1] + // the index char we move\n\t\t\tn.indices[newPos:pos] + n.indices[pos+1:] // rest without char at 'pos'\n\t}\n\n\treturn newPos\n}"}, {"instruction": "// parseMessageBlock", "input": "go language", "output": "func parseMessageBlock(data []byte) (*hapi.Metadata, *SumCollection, error) {\n\t// This sucks.\n\tparts := bytes.Split(data, []byte(\"\\n...\\n\"))\n\tif len(parts) < 2 {\n\t\treturn nil, nil, errors.New(\"message block must have at least two parts\")\n\t}\n\n\tmd := &hapi.Metadata{}\n\tsc := &SumCollection{}\n\n\tif err := yaml.Unmarshal(parts[0], md); err != nil {\n\t\treturn md, sc, err\n\t}\n\terr := yaml.Unmarshal(parts[1], sc)\n\treturn md, sc, err\n}"}, {"instruction": "// CountStmtNode records the number of statements with the same type.", "input": "go language", "output": "func CountStmtNode(stmtNode ast.StmtNode, inRestrictedSQL bool) {\n\tif inRestrictedSQL {\n\t\treturn\n\t}\n\n\ttypeLabel := GetStmtLabel(stmtNode)\n\tswitch typeLabel {\n\tcase \"Use\":\n\t\tstmtNodeCounterUse.Inc()\n\tcase \"Show\":\n\t\tstmtNodeCounterShow.Inc()\n\tcase \"Begin\":\n\t\tstmtNodeCounterBegin.Inc()\n\tcase \"Commit\":\n\t\tstmtNodeCounterCommit.Inc()\n\tcase \"Rollback\":\n\t\tstmtNodeCounterRollback.Inc()\n\tcase \"Insert\":\n\t\tstmtNodeCounterInsert.Inc()\n\tcase \"Replace\":\n\t\tstmtNodeCounterReplace.Inc()\n\tcase \"Delete\":\n\t\tstmtNodeCounterDelete.Inc()\n\tcase \"Update\":\n\t\tstmtNodeCounterUpdate.Inc()\n\tcase \"Select\":\n\t\tstmtNodeCounterSelect.Inc()\n\tdefault:\n\t\tmetrics.StmtNodeCounter.WithLabelValues(typeLabel).Inc()\n\t}\n\n\tif !config.GetGlobalConfig().Status.RecordQPSbyDB {\n\t\treturn\n\t}\n\n\tdbLabels := getStmtDbLabel(stmtNode)\n\tfor dbLabel := range dbLabels {\n\t\tmetrics.DbStmtNodeCounter.WithLabelValues(dbLabel, typeLabel).Inc()\n\t}\n}"}, {"instruction": "// Check if a proposed update can be committed.", "input": "go language", "output": "func (p *MemoryPool) checkUpdate(transactionData []tms.TransactionData) error {\n\tfor _, td := range transactionData {\n\t\taction := td.Tx.GetPlainAction()\n\t\tif action == nil {\n\t\t\treturn errors.Errorf(\"check update failed for transaction '%s': missing token action\", td.TxID)\n\t\t}\n\n\t\terr := p.checkAction(action, td.TxID)\n\t\tif err != nil {\n\t\t\treturn errors.WithMessage(err, \"check update failed\")\n\t\t}\n\n\t\tif p.history[td.TxID] != nil {\n\t\t\treturn errors.Errorf(\"transaction already exists: %s\", td.TxID)\n\t\t}\n\t}\n\n\treturn nil\n}"}, {"instruction": "// Will insert if needed any new key/value pars and return ids", "input": "go language", "output": "func (r *SqlAnnotationRepo) ensureTagsExist(sess *DBSession, tags []*models.Tag) ([]*models.Tag, error) {\n\tfor _, tag := range tags {\n\t\tvar existingTag models.Tag\n\n\t\t// check if it exists\n\t\tif exists, err := sess.Table(\"tag\").Where(dialect.Quote(\"key\")+\"=? AND \"+dialect.Quote(\"value\")+\"=?\", tag.Key, tag.Value).Get(&existingTag); err != nil {\n\t\t\treturn nil, err\n\t\t} else if exists {\n\t\t\ttag.Id = existingTag.Id\n\t\t} else {\n\t\t\tif _, err := sess.Table(\"tag\").Insert(tag); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn tags, nil\n}"}, {"instruction": "// NodePublishVolume implements CSI NodePublishVolume", "input": "go language", "output": "func (f *NodeClient) NodePublishVolume(ctx context.Context, req *csipb.NodePublishVolumeRequest, opts ...grpc.CallOption) (*csipb.NodePublishVolumeResponse, error) {\n\tif f.nextErr != nil {\n\t\treturn nil, f.nextErr\n\t}\n\n\tif req.GetVolumeId() == \"\" {\n\t\treturn nil, errors.New(\"missing volume id\")\n\t}\n\tif req.GetTargetPath() == \"\" {\n\t\treturn nil, errors.New(\"missing target path\")\n\t}\n\tfsTypes := \"block|ext4|xfs|zfs\"\n\tfsType := req.GetVolumeCapability().GetMount().GetFsType()\n\tif !strings.Contains(fsTypes, fsType) {\n\t\treturn nil, errors.New(\"invalid fstype\")\n\t}\n\tf.nodePublishedVolumes[req.GetVolumeId()] = CSIVolume{\n\t\tVolumeHandle:    req.GetVolumeId(),\n\t\tPath:            req.GetTargetPath(),\n\t\tDeviceMountPath: req.GetStagingTargetPath(),\n\t\tVolumeContext:   req.GetVolumeContext(),\n\t\tFSType:          req.GetVolumeCapability().GetMount().GetFsType(),\n\t\tMountFlags:      req.GetVolumeCapability().GetMount().MountFlags,\n\t}\n\treturn &csipb.NodePublishVolumeResponse{}, nil\n}"}, {"instruction": "// DeriveStats implement LogicalPlan DeriveStats interface.", "input": "go language", "output": "func (la *LogicalApply) DeriveStats(childStats []*property.StatsInfo) (*property.StatsInfo, error) {\n\tleftProfile := childStats[0]\n\tla.stats = &property.StatsInfo{\n\t\tRowCount:    leftProfile.RowCount,\n\t\tCardinality: make([]float64, la.schema.Len()),\n\t}\n\tcopy(la.stats.Cardinality, leftProfile.Cardinality)\n\tif la.JoinType == LeftOuterSemiJoin || la.JoinType == AntiLeftOuterSemiJoin {\n\t\tla.stats.Cardinality[len(la.stats.Cardinality)-1] = 2.0\n\t} else {\n\t\tfor i := la.children[0].Schema().Len(); i < la.schema.Len(); i++ {\n\t\t\tla.stats.Cardinality[i] = leftProfile.RowCount\n\t\t}\n\t}\n\treturn la.stats, nil\n}"}, {"instruction": "// DefaultAttachFunc is the default AttachFunc used", "input": "go language", "output": "func DefaultAttachFunc(o *AttachOptions, containerToAttach *corev1.Container, raw bool, sizeQueue remotecommand.TerminalSizeQueue) func() error {\n\treturn func() error {\n\t\trestClient, err := restclient.RESTClientFor(o.Config)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treq := restClient.Post().\n\t\t\tResource(\"pods\").\n\t\t\tName(o.Pod.Name).\n\t\t\tNamespace(o.Pod.Namespace).\n\t\t\tSubResource(\"attach\")\n\t\treq.VersionedParams(&corev1.PodAttachOptions{\n\t\t\tContainer: containerToAttach.Name,\n\t\t\tStdin:     o.Stdin,\n\t\t\tStdout:    o.Out != nil,\n\t\t\tStderr:    !o.DisableStderr,\n\t\t\tTTY:       raw,\n\t\t}, scheme.ParameterCodec)\n\n\t\treturn o.Attach.Attach(\"POST\", req.URL(), o.Config, o.In, o.Out, o.ErrOut, raw, sizeQueue)\n\t}\n}"}, {"instruction": "// startTableWorker launchs some background goroutines which pick tasks from workCh and execute the task.", "input": "go language", "output": "func (e *IndexLookUpExecutor) startTableWorker(ctx context.Context, workCh <-chan *lookupTableTask) {\n\tlookupConcurrencyLimit := e.ctx.GetSessionVars().IndexLookupConcurrency\n\te.tblWorkerWg.Add(lookupConcurrencyLimit)\n\tfor i := 0; i < lookupConcurrencyLimit; i++ {\n\t\tworker := &tableWorker{\n\t\t\tidxLookup:      e,\n\t\t\tworkCh:         workCh,\n\t\t\tfinished:       e.finished,\n\t\t\tbuildTblReader: e.buildTableReader,\n\t\t\tkeepOrder:      e.keepOrder,\n\t\t\thandleIdx:      e.handleIdx,\n\t\t\tisCheckOp:      e.isCheckOp,\n\t\t\tmemTracker:     memory.NewTracker(tableWorkerLabel, -1),\n\t\t}\n\t\tworker.memTracker.AttachTo(e.memTracker)\n\t\tctx1, cancel := context.WithCancel(ctx)\n\t\tgo func() {\n\t\t\tworker.pickAndExecTask(ctx1)\n\t\t\tcancel()\n\t\t\te.tblWorkerWg.Done()\n\t\t}()\n\t}\n}"}, {"instruction": "// ValidateObjectMetaUpdate validates an object's metadata when updated", "input": "go language", "output": "func ValidateObjectMetaUpdate(newMeta, oldMeta *metav1.ObjectMeta, fldPath *field.Path) field.ErrorList {\n\tallErrs := apimachineryvalidation.ValidateObjectMetaUpdate(newMeta, oldMeta, fldPath)\n\t// run additional checks for the finalizer name\n\tfor i := range newMeta.Finalizers {\n\t\tallErrs = append(allErrs, validateKubeFinalizerName(string(newMeta.Finalizers[i]), fldPath.Child(\"finalizers\").Index(i))...)\n\t}\n\n\treturn allErrs\n}"}, {"instruction": "// ReceivedReply adjusts estimated buffer value according to the value included in\n// the latest request reply.", "input": "go language", "output": "func (node *ServerNode) ReceivedReply(reqID, bv uint64) {\n\tnode.lock.Lock()\n\tdefer node.lock.Unlock()\n\n\tnow := node.clock.Now()\n\tnode.recalcBLE(now)\n\tif bv > node.params.BufLimit {\n\t\tbv = node.params.BufLimit\n\t}\n\tsc, ok := node.pending[reqID]\n\tif !ok {\n\t\treturn\n\t}\n\tdelete(node.pending, reqID)\n\tcc := node.sumCost - sc\n\tnewEstimate := uint64(0)\n\tif bv > cc {\n\t\tnewEstimate = bv - cc\n\t}\n\tif newEstimate > node.bufEstimate {\n\t\t// Note: we never reduce the buffer estimate based on the reported value because\n\t\t// this can only happen because of the delayed delivery of the latest reply.\n\t\t// The lowest estimate based on the previous reply can still be considered valid.\n\t\tnode.bufEstimate = newEstimate\n\t}\n\n\tnode.bufRecharge = node.bufEstimate < node.params.BufLimit\n\tnode.lastTime = now\n\tif node.log != nil {\n\t\tnode.log.add(now, fmt.Sprintf(\"received  reqID=%d  bufEst=%d  reportedBv=%d  sumCost=%d  oldSumCost=%d\", reqID, node.bufEstimate, bv, node.sumCost, sc))\n\t}\n}"}, {"instruction": "// NewHub creates a new hardware wallet manager for smartcards.", "input": "go language", "output": "func NewHub(scheme string, datadir string) (*Hub, error) {\n\tcontext, err := pcsc.EstablishContext(pcsc.ScopeSystem)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\thub := &Hub{\n\t\tscheme:  scheme,\n\t\tcontext: context,\n\t\tdatadir: datadir,\n\t\twallets: make(map[string]*Wallet),\n\t\tquit:    make(chan chan error),\n\t}\n\tif err := hub.readPairings(); err != nil {\n\t\treturn nil, err\n\t}\n\thub.refreshWallets()\n\treturn hub, nil\n}"}, {"instruction": "// getPullSecretsForPod inspects the Pod and retrieves the referenced pull\n// secrets.", "input": "go language", "output": "func (kl *Kubelet) getPullSecretsForPod(pod *v1.Pod) []v1.Secret {\n\tpullSecrets := []v1.Secret{}\n\n\tfor _, secretRef := range pod.Spec.ImagePullSecrets {\n\t\tsecret, err := kl.secretManager.GetSecret(pod.Namespace, secretRef.Name)\n\t\tif err != nil {\n\t\t\tklog.Warningf(\"Unable to retrieve pull secret %s/%s for %s/%s due to %v.  The image pull may not succeed.\", pod.Namespace, secretRef.Name, pod.Namespace, pod.Name, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tpullSecrets = append(pullSecrets, *secret)\n\t}\n\n\treturn pullSecrets\n}"}, {"instruction": "// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.", "input": "go language", "output": "func (in *Policy) DeepCopyInto(out *Policy) {\n\t*out = *in\n\tout.TypeMeta = in.TypeMeta\n\tif in.Predicates != nil {\n\t\tin, out := &in.Predicates, &out.Predicates\n\t\t*out = make([]PredicatePolicy, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.Priorities != nil {\n\t\tin, out := &in.Priorities, &out.Priorities\n\t\t*out = make([]PriorityPolicy, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\tif in.ExtenderConfigs != nil {\n\t\tin, out := &in.ExtenderConfigs, &out.ExtenderConfigs\n\t\t*out = make([]ExtenderConfig, len(*in))\n\t\tfor i := range *in {\n\t\t\t(*in)[i].DeepCopyInto(&(*out)[i])\n\t\t}\n\t}\n\treturn\n}"}, {"instruction": "// WriteError translates a CRI streaming error into an appropriate HTTP response.", "input": "go language", "output": "func WriteError(err error, w http.ResponseWriter) error {\n\tvar status int\n\tswitch grpc.Code(err) {\n\tcase codes.NotFound:\n\t\tstatus = http.StatusNotFound\n\tcase codes.ResourceExhausted:\n\t\t// We only expect to hit this if there is a DoS, so we just wait the full TTL.\n\t\t// If this is ever hit in steady-state operations, consider increasing the maxInFlight requests,\n\t\t// or plumbing through the time to next expiration.\n\t\tw.Header().Set(\"Retry-After\", strconv.Itoa(int(cacheTTL.Seconds())))\n\t\tstatus = http.StatusTooManyRequests\n\tdefault:\n\t\tstatus = http.StatusInternalServerError\n\t}\n\tw.WriteHeader(status)\n\t_, writeErr := w.Write([]byte(err.Error()))\n\treturn writeErr\n}"}, {"instruction": "// start starts the progressReporter", "input": "go language", "output": "func (p *progressReporter) start() {\n\tgo func() {\n\t\tticker := time.NewTicker(defaultImagePullingProgressReportInterval)\n\t\tdefer ticker.Stop()\n\t\tfor {\n\t\t\t// TODO(random-liu): Report as events.\n\t\t\tselect {\n\t\t\tcase <-ticker.C:\n\t\t\t\tprogress, timestamp := p.progress.get()\n\t\t\t\t// If there is no progress for p.imagePullProgressDeadline, cancel the operation.\n\t\t\t\tif time.Since(timestamp) > p.imagePullProgressDeadline {\n\t\t\t\t\tklog.Errorf(\"Cancel pulling image %q because of no progress for %v, latest progress: %q\", p.image, p.imagePullProgressDeadline, progress)\n\t\t\t\t\tp.cancel()\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tklog.V(2).Infof(\"Pulling image %q: %q\", p.image, progress)\n\t\t\tcase <-p.stopCh:\n\t\t\t\tprogress, _ := p.progress.get()\n\t\t\t\tklog.V(2).Infof(\"Stop pulling image %q: %q\", p.image, progress)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n}"}, {"instruction": "// servicesWatch is used to watch the list of available services", "input": "go language", "output": "func servicesWatch(params map[string]interface{}) (WatcherFunc, error) {\n\tstale := false\n\tif err := assignValueBool(params, \"stale\", &stale); err != nil {\n\t\treturn nil, err\n\t}\n\n\tfn := func(p *Plan) (BlockingParamVal, interface{}, error) {\n\t\tcatalog := p.client.Catalog()\n\t\topts := makeQueryOptionsWithContext(p, stale)\n\t\tdefer p.cancelFunc()\n\t\tservices, meta, err := catalog.Services(&opts)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\treturn WaitIndexVal(meta.LastIndex), services, err\n\t}\n\treturn fn, nil\n}"}]