[{"instruction": "def update_floatingip_statuses(self, context, router_id, fip_statuses):\n        \"\"\"Make a remote process call to update operational status for one or\n        several floating IPs.\n\n        @param context: contains user information\n        @param router_id: id of router associated with the floatingips\n        @param fip_statuses: dict with floatingip_id as key and status as value\n        \"\"\"\n", "input": "", "output": "        cctxt = self.client.prepare(version='1.1')\n        return cctxt.call(context, 'update_floatingip_statuses_cfg',\n                          router_id=router_id, fip_statuses=fip_statuses)"}, {"instruction": "Load Keras (Functional API) Model saved using model.save_model(...).\n\n@param modelHdf5Stream       InputStream containing HDF5 archive storing Keras Model\n@param enforceTrainingConfig whether to enforce training configuration options\n@return ComputationGraph\n@see ComputationGraph", "input": "Java", "output": "public static ComputationGraph importKerasModelAndWeights( InputStream modelHdf5Stream, boolean enforceTrainingConfig)\n            throws IOException, UnsupportedKerasConfigurationException, InvalidKerasConfigurationException{\n        File f = null;\n        try{\n            f = toTempFile(modelHdf5Stream);\n            return importKerasModelAndWeights(f.getAbsolutePath(), enforceTrainingConfig);\n        } finally {\n            if(f != null)\n                f.delete();\n        }\n    }"}, {"instruction": "Permanently destroy all remaining TemplateResults in \"stack\".\n(Triggered on error)\n\n@param { Array<any> } stack", "input": "JavaScript", "output": "function destroy(stack) {\n  if (stack.length > 0) {\n    for (const chunk of stack) {\n      if (isTemplateResult(chunk)) {\n        chunk.destroy(true);\n      }\n    }\n  }\n  stack.length = 0;\n}"}, {"instruction": "// startTableWorker launchs some background goroutines which pick tasks from workCh and execute the task.", "input": "go language", "output": "func (e *IndexLookUpExecutor) startTableWorker(ctx context.Context, workCh <-chan *lookupTableTask) {\n\tlookupConcurrencyLimit := e.ctx.GetSessionVars().IndexLookupConcurrency\n\te.tblWorkerWg.Add(lookupConcurrencyLimit)\n\tfor i := 0; i < lookupConcurrencyLimit; i++ {\n\t\tworker := &tableWorker{\n\t\t\tidxLookup:      e,\n\t\t\tworkCh:         workCh,\n\t\t\tfinished:       e.finished,\n\t\t\tbuildTblReader: e.buildTableReader,\n\t\t\tkeepOrder:      e.keepOrder,\n\t\t\thandleIdx:      e.handleIdx,\n\t\t\tisCheckOp:      e.isCheckOp,\n\t\t\tmemTracker:     memory.NewTracker(tableWorkerLabel, -1),\n\t\t}\n\t\tworker.memTracker.AttachTo(e.memTracker)\n\t\tctx1, cancel := context.WithCancel(ctx)\n\t\tgo func() {\n\t\t\tworker.pickAndExecTask(ctx1)\n\t\t\tcancel()\n\t\t\te.tblWorkerWg.Done()\n\t\t}()\n\t}\n}"}]