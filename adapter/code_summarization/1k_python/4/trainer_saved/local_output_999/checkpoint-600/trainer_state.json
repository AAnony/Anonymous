{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.84,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 9.987179487179488e-05,
      "loss": 1.9177,
      "step": 1
    },
    {
      "epoch": 0.01,
      "learning_rate": 9.974358974358975e-05,
      "loss": 1.6995,
      "step": 2
    },
    {
      "epoch": 0.02,
      "learning_rate": 9.961538461538463e-05,
      "loss": 1.6933,
      "step": 3
    },
    {
      "epoch": 0.03,
      "learning_rate": 9.948717948717949e-05,
      "loss": 1.7821,
      "step": 4
    },
    {
      "epoch": 0.03,
      "learning_rate": 9.935897435897437e-05,
      "loss": 1.9552,
      "step": 5
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.923076923076923e-05,
      "loss": 1.9084,
      "step": 6
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.910256410256411e-05,
      "loss": 1.8824,
      "step": 7
    },
    {
      "epoch": 0.05,
      "learning_rate": 9.897435897435898e-05,
      "loss": 2.0532,
      "step": 8
    },
    {
      "epoch": 0.06,
      "learning_rate": 9.884615384615386e-05,
      "loss": 2.1007,
      "step": 9
    },
    {
      "epoch": 0.06,
      "learning_rate": 9.871794871794872e-05,
      "loss": 2.0981,
      "step": 10
    },
    {
      "epoch": 0.07,
      "learning_rate": 9.85897435897436e-05,
      "loss": 2.1459,
      "step": 11
    },
    {
      "epoch": 0.08,
      "learning_rate": 9.846153846153848e-05,
      "loss": 2.1677,
      "step": 12
    },
    {
      "epoch": 0.08,
      "learning_rate": 9.833333333333333e-05,
      "loss": 2.1945,
      "step": 13
    },
    {
      "epoch": 0.09,
      "learning_rate": 9.820512820512821e-05,
      "loss": 2.021,
      "step": 14
    },
    {
      "epoch": 0.1,
      "learning_rate": 9.807692307692307e-05,
      "loss": 2.2479,
      "step": 15
    },
    {
      "epoch": 0.1,
      "learning_rate": 9.794871794871795e-05,
      "loss": 2.1417,
      "step": 16
    },
    {
      "epoch": 0.11,
      "learning_rate": 9.782051282051282e-05,
      "loss": 2.1685,
      "step": 17
    },
    {
      "epoch": 0.12,
      "learning_rate": 9.76923076923077e-05,
      "loss": 2.0486,
      "step": 18
    },
    {
      "epoch": 0.12,
      "learning_rate": 9.756410256410257e-05,
      "loss": 2.2065,
      "step": 19
    },
    {
      "epoch": 0.13,
      "learning_rate": 9.743589743589744e-05,
      "loss": 2.1428,
      "step": 20
    },
    {
      "epoch": 0.13,
      "learning_rate": 9.730769230769232e-05,
      "loss": 2.3589,
      "step": 21
    },
    {
      "epoch": 0.14,
      "learning_rate": 9.717948717948718e-05,
      "loss": 2.3181,
      "step": 22
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.705128205128206e-05,
      "loss": 2.294,
      "step": 23
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.692307692307692e-05,
      "loss": 2.2325,
      "step": 24
    },
    {
      "epoch": 0.16,
      "learning_rate": 9.67948717948718e-05,
      "loss": 2.5327,
      "step": 25
    },
    {
      "epoch": 0.17,
      "learning_rate": 9.666666666666667e-05,
      "loss": 2.105,
      "step": 26
    },
    {
      "epoch": 0.17,
      "learning_rate": 9.653846153846155e-05,
      "loss": 2.2903,
      "step": 27
    },
    {
      "epoch": 0.18,
      "learning_rate": 9.641025641025641e-05,
      "loss": 2.3918,
      "step": 28
    },
    {
      "epoch": 0.19,
      "learning_rate": 9.628205128205129e-05,
      "loss": 2.4592,
      "step": 29
    },
    {
      "epoch": 0.19,
      "learning_rate": 9.615384615384617e-05,
      "loss": 2.4611,
      "step": 30
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.602564102564103e-05,
      "loss": 2.5434,
      "step": 31
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.589743589743591e-05,
      "loss": 2.5174,
      "step": 32
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.576923076923078e-05,
      "loss": 2.6835,
      "step": 33
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.564102564102565e-05,
      "loss": 2.6788,
      "step": 34
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.551282051282052e-05,
      "loss": 2.4683,
      "step": 35
    },
    {
      "epoch": 0.23,
      "learning_rate": 9.53846153846154e-05,
      "loss": 2.8235,
      "step": 36
    },
    {
      "epoch": 0.24,
      "learning_rate": 9.525641025641026e-05,
      "loss": 2.962,
      "step": 37
    },
    {
      "epoch": 0.24,
      "learning_rate": 9.512820512820513e-05,
      "loss": 2.8802,
      "step": 38
    },
    {
      "epoch": 0.25,
      "learning_rate": 9.5e-05,
      "loss": 3.107,
      "step": 39
    },
    {
      "epoch": 0.26,
      "learning_rate": 9.487179487179487e-05,
      "loss": 1.4484,
      "step": 40
    },
    {
      "epoch": 0.26,
      "learning_rate": 9.474358974358975e-05,
      "loss": 1.4727,
      "step": 41
    },
    {
      "epoch": 0.27,
      "learning_rate": 9.461538461538461e-05,
      "loss": 1.5055,
      "step": 42
    },
    {
      "epoch": 0.28,
      "learning_rate": 9.448717948717949e-05,
      "loss": 1.5718,
      "step": 43
    },
    {
      "epoch": 0.28,
      "learning_rate": 9.435897435897436e-05,
      "loss": 1.6066,
      "step": 44
    },
    {
      "epoch": 0.29,
      "learning_rate": 9.423076923076924e-05,
      "loss": 1.5934,
      "step": 45
    },
    {
      "epoch": 0.29,
      "learning_rate": 9.41025641025641e-05,
      "loss": 1.648,
      "step": 46
    },
    {
      "epoch": 0.3,
      "learning_rate": 9.397435897435898e-05,
      "loss": 1.6308,
      "step": 47
    },
    {
      "epoch": 0.31,
      "learning_rate": 9.384615384615386e-05,
      "loss": 1.7647,
      "step": 48
    },
    {
      "epoch": 0.31,
      "learning_rate": 9.371794871794872e-05,
      "loss": 1.5287,
      "step": 49
    },
    {
      "epoch": 0.32,
      "learning_rate": 9.35897435897436e-05,
      "loss": 1.5685,
      "step": 50
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.346153846153846e-05,
      "loss": 1.7231,
      "step": 51
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.7125,
      "step": 52
    },
    {
      "epoch": 0.34,
      "learning_rate": 9.320512820512821e-05,
      "loss": 1.6905,
      "step": 53
    },
    {
      "epoch": 0.35,
      "learning_rate": 9.307692307692309e-05,
      "loss": 1.6774,
      "step": 54
    },
    {
      "epoch": 0.35,
      "learning_rate": 9.294871794871795e-05,
      "loss": 1.7783,
      "step": 55
    },
    {
      "epoch": 0.36,
      "learning_rate": 9.282051282051283e-05,
      "loss": 1.6462,
      "step": 56
    },
    {
      "epoch": 0.36,
      "learning_rate": 9.26923076923077e-05,
      "loss": 1.7605,
      "step": 57
    },
    {
      "epoch": 0.37,
      "learning_rate": 9.256410256410257e-05,
      "loss": 1.6937,
      "step": 58
    },
    {
      "epoch": 0.38,
      "learning_rate": 9.243589743589745e-05,
      "loss": 1.6518,
      "step": 59
    },
    {
      "epoch": 0.38,
      "learning_rate": 9.230769230769232e-05,
      "loss": 1.6921,
      "step": 60
    },
    {
      "epoch": 0.39,
      "learning_rate": 9.217948717948718e-05,
      "loss": 1.7816,
      "step": 61
    },
    {
      "epoch": 0.4,
      "learning_rate": 9.205128205128205e-05,
      "loss": 1.7368,
      "step": 62
    },
    {
      "epoch": 0.4,
      "learning_rate": 9.192307692307692e-05,
      "loss": 1.8703,
      "step": 63
    },
    {
      "epoch": 0.41,
      "learning_rate": 9.179487179487179e-05,
      "loss": 1.6706,
      "step": 64
    },
    {
      "epoch": 0.42,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.7085,
      "step": 65
    },
    {
      "epoch": 0.42,
      "learning_rate": 9.153846153846155e-05,
      "loss": 2.0892,
      "step": 66
    },
    {
      "epoch": 0.43,
      "learning_rate": 9.141025641025641e-05,
      "loss": 1.9145,
      "step": 67
    },
    {
      "epoch": 0.44,
      "learning_rate": 9.128205128205129e-05,
      "loss": 2.0253,
      "step": 68
    },
    {
      "epoch": 0.44,
      "learning_rate": 9.115384615384615e-05,
      "loss": 1.9021,
      "step": 69
    },
    {
      "epoch": 0.45,
      "learning_rate": 9.102564102564103e-05,
      "loss": 2.0342,
      "step": 70
    },
    {
      "epoch": 0.45,
      "learning_rate": 9.08974358974359e-05,
      "loss": 2.0498,
      "step": 71
    },
    {
      "epoch": 0.46,
      "learning_rate": 9.076923076923078e-05,
      "loss": 2.2356,
      "step": 72
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.064102564102564e-05,
      "loss": 2.0141,
      "step": 73
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.051282051282052e-05,
      "loss": 2.318,
      "step": 74
    },
    {
      "epoch": 0.48,
      "learning_rate": 9.038461538461538e-05,
      "loss": 2.1541,
      "step": 75
    },
    {
      "epoch": 0.49,
      "learning_rate": 9.025641025641026e-05,
      "loss": 2.2494,
      "step": 76
    },
    {
      "epoch": 0.49,
      "learning_rate": 9.012820512820514e-05,
      "loss": 2.526,
      "step": 77
    },
    {
      "epoch": 0.5,
      "learning_rate": 9e-05,
      "loss": 2.7159,
      "step": 78
    },
    {
      "epoch": 0.51,
      "learning_rate": 8.987179487179488e-05,
      "loss": 1.649,
      "step": 79
    },
    {
      "epoch": 0.51,
      "learning_rate": 8.974358974358975e-05,
      "loss": 1.5527,
      "step": 80
    },
    {
      "epoch": 0.52,
      "learning_rate": 8.961538461538463e-05,
      "loss": 1.4719,
      "step": 81
    },
    {
      "epoch": 0.52,
      "learning_rate": 8.948717948717949e-05,
      "loss": 1.5453,
      "step": 82
    },
    {
      "epoch": 0.53,
      "learning_rate": 8.935897435897437e-05,
      "loss": 1.5463,
      "step": 83
    },
    {
      "epoch": 0.54,
      "learning_rate": 8.923076923076924e-05,
      "loss": 1.3456,
      "step": 84
    },
    {
      "epoch": 0.54,
      "learning_rate": 8.910256410256411e-05,
      "loss": 1.4145,
      "step": 85
    },
    {
      "epoch": 0.55,
      "learning_rate": 8.897435897435898e-05,
      "loss": 1.6402,
      "step": 86
    },
    {
      "epoch": 0.56,
      "learning_rate": 8.884615384615384e-05,
      "loss": 1.5772,
      "step": 87
    },
    {
      "epoch": 0.56,
      "learning_rate": 8.871794871794872e-05,
      "loss": 1.4976,
      "step": 88
    },
    {
      "epoch": 0.57,
      "learning_rate": 8.858974358974359e-05,
      "loss": 1.5215,
      "step": 89
    },
    {
      "epoch": 0.58,
      "learning_rate": 8.846153846153847e-05,
      "loss": 1.5461,
      "step": 90
    },
    {
      "epoch": 0.58,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.4573,
      "step": 91
    },
    {
      "epoch": 0.59,
      "learning_rate": 8.820512820512821e-05,
      "loss": 1.513,
      "step": 92
    },
    {
      "epoch": 0.6,
      "learning_rate": 8.807692307692307e-05,
      "loss": 1.5774,
      "step": 93
    },
    {
      "epoch": 0.6,
      "learning_rate": 8.794871794871795e-05,
      "loss": 1.5436,
      "step": 94
    },
    {
      "epoch": 0.61,
      "learning_rate": 8.782051282051283e-05,
      "loss": 1.5749,
      "step": 95
    },
    {
      "epoch": 0.61,
      "learning_rate": 8.76923076923077e-05,
      "loss": 1.7376,
      "step": 96
    },
    {
      "epoch": 0.62,
      "learning_rate": 8.756410256410257e-05,
      "loss": 1.5319,
      "step": 97
    },
    {
      "epoch": 0.63,
      "learning_rate": 8.743589743589744e-05,
      "loss": 1.6898,
      "step": 98
    },
    {
      "epoch": 0.63,
      "learning_rate": 8.730769230769232e-05,
      "loss": 1.7394,
      "step": 99
    },
    {
      "epoch": 0.64,
      "learning_rate": 8.717948717948718e-05,
      "loss": 1.8033,
      "step": 100
    },
    {
      "epoch": 0.65,
      "learning_rate": 8.705128205128206e-05,
      "loss": 1.7893,
      "step": 101
    },
    {
      "epoch": 0.65,
      "learning_rate": 8.692307692307692e-05,
      "loss": 1.5968,
      "step": 102
    },
    {
      "epoch": 0.66,
      "learning_rate": 8.67948717948718e-05,
      "loss": 1.8366,
      "step": 103
    },
    {
      "epoch": 0.67,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.7321,
      "step": 104
    },
    {
      "epoch": 0.67,
      "learning_rate": 8.653846153846155e-05,
      "loss": 1.8703,
      "step": 105
    },
    {
      "epoch": 0.68,
      "learning_rate": 8.641025641025642e-05,
      "loss": 1.8387,
      "step": 106
    },
    {
      "epoch": 0.68,
      "learning_rate": 8.628205128205129e-05,
      "loss": 2.0004,
      "step": 107
    },
    {
      "epoch": 0.69,
      "learning_rate": 8.615384615384617e-05,
      "loss": 1.8748,
      "step": 108
    },
    {
      "epoch": 0.7,
      "learning_rate": 8.602564102564103e-05,
      "loss": 2.1419,
      "step": 109
    },
    {
      "epoch": 0.7,
      "learning_rate": 8.58974358974359e-05,
      "loss": 2.0844,
      "step": 110
    },
    {
      "epoch": 0.71,
      "learning_rate": 8.576923076923076e-05,
      "loss": 2.0958,
      "step": 111
    },
    {
      "epoch": 0.72,
      "learning_rate": 8.564102564102564e-05,
      "loss": 1.9385,
      "step": 112
    },
    {
      "epoch": 0.72,
      "learning_rate": 8.551282051282052e-05,
      "loss": 2.0503,
      "step": 113
    },
    {
      "epoch": 0.73,
      "learning_rate": 8.538461538461538e-05,
      "loss": 1.9816,
      "step": 114
    },
    {
      "epoch": 0.74,
      "learning_rate": 8.525641025641026e-05,
      "loss": 2.2691,
      "step": 115
    },
    {
      "epoch": 0.74,
      "learning_rate": 8.512820512820513e-05,
      "loss": 2.2466,
      "step": 116
    },
    {
      "epoch": 0.75,
      "learning_rate": 8.5e-05,
      "loss": 2.5126,
      "step": 117
    },
    {
      "epoch": 0.76,
      "learning_rate": 8.487179487179487e-05,
      "loss": 1.3527,
      "step": 118
    },
    {
      "epoch": 0.76,
      "learning_rate": 8.474358974358975e-05,
      "loss": 1.4775,
      "step": 119
    },
    {
      "epoch": 0.77,
      "learning_rate": 8.461538461538461e-05,
      "loss": 1.4062,
      "step": 120
    },
    {
      "epoch": 0.77,
      "learning_rate": 8.448717948717949e-05,
      "loss": 1.5366,
      "step": 121
    },
    {
      "epoch": 0.78,
      "learning_rate": 8.435897435897436e-05,
      "loss": 1.4682,
      "step": 122
    },
    {
      "epoch": 0.79,
      "learning_rate": 8.423076923076924e-05,
      "loss": 1.3522,
      "step": 123
    },
    {
      "epoch": 0.79,
      "learning_rate": 8.410256410256411e-05,
      "loss": 1.5525,
      "step": 124
    },
    {
      "epoch": 0.8,
      "learning_rate": 8.397435897435898e-05,
      "loss": 1.3946,
      "step": 125
    },
    {
      "epoch": 0.81,
      "learning_rate": 8.384615384615386e-05,
      "loss": 1.432,
      "step": 126
    },
    {
      "epoch": 0.81,
      "learning_rate": 8.371794871794872e-05,
      "loss": 1.5025,
      "step": 127
    },
    {
      "epoch": 0.82,
      "learning_rate": 8.35897435897436e-05,
      "loss": 1.5468,
      "step": 128
    },
    {
      "epoch": 0.83,
      "learning_rate": 8.346153846153847e-05,
      "loss": 1.5975,
      "step": 129
    },
    {
      "epoch": 0.83,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.4881,
      "step": 130
    },
    {
      "epoch": 0.84,
      "learning_rate": 8.320512820512821e-05,
      "loss": 1.457,
      "step": 131
    },
    {
      "epoch": 0.84,
      "learning_rate": 8.307692307692309e-05,
      "loss": 1.4723,
      "step": 132
    },
    {
      "epoch": 0.85,
      "learning_rate": 8.294871794871795e-05,
      "loss": 1.6828,
      "step": 133
    },
    {
      "epoch": 0.86,
      "learning_rate": 8.282051282051283e-05,
      "loss": 1.448,
      "step": 134
    },
    {
      "epoch": 0.86,
      "learning_rate": 8.26923076923077e-05,
      "loss": 1.4057,
      "step": 135
    },
    {
      "epoch": 0.87,
      "learning_rate": 8.256410256410256e-05,
      "loss": 1.4242,
      "step": 136
    },
    {
      "epoch": 0.88,
      "learning_rate": 8.243589743589744e-05,
      "loss": 1.6252,
      "step": 137
    },
    {
      "epoch": 0.88,
      "learning_rate": 8.23076923076923e-05,
      "loss": 1.3961,
      "step": 138
    },
    {
      "epoch": 0.89,
      "learning_rate": 8.217948717948718e-05,
      "loss": 1.7375,
      "step": 139
    },
    {
      "epoch": 0.9,
      "learning_rate": 8.205128205128205e-05,
      "loss": 1.5743,
      "step": 140
    },
    {
      "epoch": 0.9,
      "learning_rate": 8.192307692307693e-05,
      "loss": 1.6248,
      "step": 141
    },
    {
      "epoch": 0.91,
      "learning_rate": 8.179487179487179e-05,
      "loss": 1.7525,
      "step": 142
    },
    {
      "epoch": 0.92,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.7843,
      "step": 143
    },
    {
      "epoch": 0.92,
      "learning_rate": 8.153846153846155e-05,
      "loss": 1.8482,
      "step": 144
    },
    {
      "epoch": 0.93,
      "learning_rate": 8.141025641025641e-05,
      "loss": 1.6572,
      "step": 145
    },
    {
      "epoch": 0.93,
      "learning_rate": 8.128205128205129e-05,
      "loss": 1.7798,
      "step": 146
    },
    {
      "epoch": 0.94,
      "learning_rate": 8.115384615384616e-05,
      "loss": 1.6759,
      "step": 147
    },
    {
      "epoch": 0.95,
      "learning_rate": 8.102564102564103e-05,
      "loss": 1.9387,
      "step": 148
    },
    {
      "epoch": 0.95,
      "learning_rate": 8.08974358974359e-05,
      "loss": 1.9472,
      "step": 149
    },
    {
      "epoch": 0.96,
      "learning_rate": 8.076923076923078e-05,
      "loss": 1.9593,
      "step": 150
    },
    {
      "epoch": 0.97,
      "learning_rate": 8.064102564102564e-05,
      "loss": 2.2203,
      "step": 151
    },
    {
      "epoch": 0.97,
      "learning_rate": 8.051282051282052e-05,
      "loss": 2.16,
      "step": 152
    },
    {
      "epoch": 0.98,
      "learning_rate": 8.038461538461538e-05,
      "loss": 2.1709,
      "step": 153
    },
    {
      "epoch": 0.99,
      "learning_rate": 8.025641025641026e-05,
      "loss": 2.0358,
      "step": 154
    },
    {
      "epoch": 0.99,
      "learning_rate": 8.012820512820514e-05,
      "loss": 2.3233,
      "step": 155
    },
    {
      "epoch": 1.0,
      "learning_rate": 8e-05,
      "loss": 2.2881,
      "step": 156
    },
    {
      "epoch": 1.0,
      "learning_rate": 7.987179487179488e-05,
      "loss": 1.3719,
      "step": 157
    },
    {
      "epoch": 1.01,
      "learning_rate": 7.974358974358975e-05,
      "loss": 1.3785,
      "step": 158
    },
    {
      "epoch": 1.02,
      "learning_rate": 7.961538461538461e-05,
      "loss": 1.5146,
      "step": 159
    },
    {
      "epoch": 1.02,
      "learning_rate": 7.948717948717948e-05,
      "loss": 1.5573,
      "step": 160
    },
    {
      "epoch": 1.03,
      "learning_rate": 7.935897435897436e-05,
      "loss": 1.4815,
      "step": 161
    },
    {
      "epoch": 1.04,
      "learning_rate": 7.923076923076924e-05,
      "loss": 1.3999,
      "step": 162
    },
    {
      "epoch": 1.04,
      "learning_rate": 7.91025641025641e-05,
      "loss": 1.3878,
      "step": 163
    },
    {
      "epoch": 1.05,
      "learning_rate": 7.897435897435898e-05,
      "loss": 1.4667,
      "step": 164
    },
    {
      "epoch": 1.06,
      "learning_rate": 7.884615384615384e-05,
      "loss": 1.5722,
      "step": 165
    },
    {
      "epoch": 1.06,
      "learning_rate": 7.871794871794872e-05,
      "loss": 1.6098,
      "step": 166
    },
    {
      "epoch": 1.07,
      "learning_rate": 7.858974358974359e-05,
      "loss": 1.4317,
      "step": 167
    },
    {
      "epoch": 1.08,
      "learning_rate": 7.846153846153847e-05,
      "loss": 1.4516,
      "step": 168
    },
    {
      "epoch": 1.08,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.5376,
      "step": 169
    },
    {
      "epoch": 1.09,
      "learning_rate": 7.820512820512821e-05,
      "loss": 1.4884,
      "step": 170
    },
    {
      "epoch": 1.09,
      "learning_rate": 7.807692307692307e-05,
      "loss": 1.5091,
      "step": 171
    },
    {
      "epoch": 1.1,
      "learning_rate": 7.794871794871795e-05,
      "loss": 1.4465,
      "step": 172
    },
    {
      "epoch": 1.11,
      "learning_rate": 7.782051282051283e-05,
      "loss": 1.6005,
      "step": 173
    },
    {
      "epoch": 1.11,
      "learning_rate": 7.76923076923077e-05,
      "loss": 1.5692,
      "step": 174
    },
    {
      "epoch": 1.12,
      "learning_rate": 7.756410256410257e-05,
      "loss": 1.6006,
      "step": 175
    },
    {
      "epoch": 1.13,
      "learning_rate": 7.743589743589744e-05,
      "loss": 1.4571,
      "step": 176
    },
    {
      "epoch": 1.13,
      "learning_rate": 7.730769230769232e-05,
      "loss": 1.5508,
      "step": 177
    },
    {
      "epoch": 1.14,
      "learning_rate": 7.717948717948718e-05,
      "loss": 1.4654,
      "step": 178
    },
    {
      "epoch": 1.15,
      "learning_rate": 7.705128205128206e-05,
      "loss": 1.5288,
      "step": 179
    },
    {
      "epoch": 1.15,
      "learning_rate": 7.692307692307693e-05,
      "loss": 1.6211,
      "step": 180
    },
    {
      "epoch": 1.16,
      "learning_rate": 7.67948717948718e-05,
      "loss": 1.6176,
      "step": 181
    },
    {
      "epoch": 1.16,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.719,
      "step": 182
    },
    {
      "epoch": 1.17,
      "learning_rate": 7.653846153846153e-05,
      "loss": 1.6774,
      "step": 183
    },
    {
      "epoch": 1.18,
      "learning_rate": 7.641025641025641e-05,
      "loss": 1.7144,
      "step": 184
    },
    {
      "epoch": 1.18,
      "learning_rate": 7.628205128205128e-05,
      "loss": 1.6905,
      "step": 185
    },
    {
      "epoch": 1.19,
      "learning_rate": 7.615384615384616e-05,
      "loss": 1.7757,
      "step": 186
    },
    {
      "epoch": 1.2,
      "learning_rate": 7.602564102564102e-05,
      "loss": 1.9372,
      "step": 187
    },
    {
      "epoch": 1.2,
      "learning_rate": 7.58974358974359e-05,
      "loss": 1.9623,
      "step": 188
    },
    {
      "epoch": 1.21,
      "learning_rate": 7.576923076923076e-05,
      "loss": 1.8527,
      "step": 189
    },
    {
      "epoch": 1.22,
      "learning_rate": 7.564102564102564e-05,
      "loss": 1.8791,
      "step": 190
    },
    {
      "epoch": 1.22,
      "learning_rate": 7.551282051282052e-05,
      "loss": 1.9359,
      "step": 191
    },
    {
      "epoch": 1.23,
      "learning_rate": 7.538461538461539e-05,
      "loss": 2.159,
      "step": 192
    },
    {
      "epoch": 1.24,
      "learning_rate": 7.525641025641026e-05,
      "loss": 2.0334,
      "step": 193
    },
    {
      "epoch": 1.24,
      "learning_rate": 7.512820512820513e-05,
      "loss": 2.0926,
      "step": 194
    },
    {
      "epoch": 1.25,
      "learning_rate": 7.500000000000001e-05,
      "loss": 2.3707,
      "step": 195
    },
    {
      "epoch": 1.25,
      "learning_rate": 7.487179487179487e-05,
      "loss": 1.5448,
      "step": 196
    },
    {
      "epoch": 1.26,
      "learning_rate": 7.474358974358975e-05,
      "loss": 1.37,
      "step": 197
    },
    {
      "epoch": 1.27,
      "learning_rate": 7.461538461538462e-05,
      "loss": 1.2557,
      "step": 198
    },
    {
      "epoch": 1.27,
      "learning_rate": 7.44871794871795e-05,
      "loss": 1.4245,
      "step": 199
    },
    {
      "epoch": 1.28,
      "learning_rate": 7.435897435897436e-05,
      "loss": 1.41,
      "step": 200
    },
    {
      "epoch": 1.29,
      "learning_rate": 7.423076923076924e-05,
      "loss": 1.4253,
      "step": 201
    },
    {
      "epoch": 1.29,
      "learning_rate": 7.410256410256412e-05,
      "loss": 1.3906,
      "step": 202
    },
    {
      "epoch": 1.3,
      "learning_rate": 7.397435897435898e-05,
      "loss": 1.445,
      "step": 203
    },
    {
      "epoch": 1.31,
      "learning_rate": 7.384615384615386e-05,
      "loss": 1.6237,
      "step": 204
    },
    {
      "epoch": 1.31,
      "learning_rate": 7.371794871794872e-05,
      "loss": 1.375,
      "step": 205
    },
    {
      "epoch": 1.32,
      "learning_rate": 7.35897435897436e-05,
      "loss": 1.4683,
      "step": 206
    },
    {
      "epoch": 1.32,
      "learning_rate": 7.346153846153847e-05,
      "loss": 1.5584,
      "step": 207
    },
    {
      "epoch": 1.33,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.3244,
      "step": 208
    },
    {
      "epoch": 1.34,
      "learning_rate": 7.320512820512821e-05,
      "loss": 1.3201,
      "step": 209
    },
    {
      "epoch": 1.34,
      "learning_rate": 7.307692307692307e-05,
      "loss": 1.3736,
      "step": 210
    },
    {
      "epoch": 1.35,
      "learning_rate": 7.294871794871795e-05,
      "loss": 1.6003,
      "step": 211
    },
    {
      "epoch": 1.36,
      "learning_rate": 7.282051282051282e-05,
      "loss": 1.5463,
      "step": 212
    },
    {
      "epoch": 1.36,
      "learning_rate": 7.26923076923077e-05,
      "loss": 1.4091,
      "step": 213
    },
    {
      "epoch": 1.37,
      "learning_rate": 7.256410256410256e-05,
      "loss": 1.4816,
      "step": 214
    },
    {
      "epoch": 1.38,
      "learning_rate": 7.243589743589744e-05,
      "loss": 1.5963,
      "step": 215
    },
    {
      "epoch": 1.38,
      "learning_rate": 7.23076923076923e-05,
      "loss": 1.4942,
      "step": 216
    },
    {
      "epoch": 1.39,
      "learning_rate": 7.217948717948718e-05,
      "loss": 1.825,
      "step": 217
    },
    {
      "epoch": 1.4,
      "learning_rate": 7.205128205128205e-05,
      "loss": 1.4948,
      "step": 218
    },
    {
      "epoch": 1.4,
      "learning_rate": 7.192307692307693e-05,
      "loss": 1.979,
      "step": 219
    },
    {
      "epoch": 1.41,
      "learning_rate": 7.17948717948718e-05,
      "loss": 1.5857,
      "step": 220
    },
    {
      "epoch": 1.41,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.5427,
      "step": 221
    },
    {
      "epoch": 1.42,
      "learning_rate": 7.153846153846155e-05,
      "loss": 1.7462,
      "step": 222
    },
    {
      "epoch": 1.43,
      "learning_rate": 7.141025641025641e-05,
      "loss": 1.8462,
      "step": 223
    },
    {
      "epoch": 1.43,
      "learning_rate": 7.128205128205129e-05,
      "loss": 1.9319,
      "step": 224
    },
    {
      "epoch": 1.44,
      "learning_rate": 7.115384615384616e-05,
      "loss": 1.7462,
      "step": 225
    },
    {
      "epoch": 1.45,
      "learning_rate": 7.102564102564103e-05,
      "loss": 1.7828,
      "step": 226
    },
    {
      "epoch": 1.45,
      "learning_rate": 7.08974358974359e-05,
      "loss": 1.7812,
      "step": 227
    },
    {
      "epoch": 1.46,
      "learning_rate": 7.076923076923078e-05,
      "loss": 1.8876,
      "step": 228
    },
    {
      "epoch": 1.47,
      "learning_rate": 7.064102564102564e-05,
      "loss": 1.7454,
      "step": 229
    },
    {
      "epoch": 1.47,
      "learning_rate": 7.051282051282052e-05,
      "loss": 2.0011,
      "step": 230
    },
    {
      "epoch": 1.48,
      "learning_rate": 7.03846153846154e-05,
      "loss": 1.9046,
      "step": 231
    },
    {
      "epoch": 1.48,
      "learning_rate": 7.025641025641025e-05,
      "loss": 2.0775,
      "step": 232
    },
    {
      "epoch": 1.49,
      "learning_rate": 7.012820512820513e-05,
      "loss": 2.0194,
      "step": 233
    },
    {
      "epoch": 1.5,
      "learning_rate": 7e-05,
      "loss": 2.2463,
      "step": 234
    },
    {
      "epoch": 1.5,
      "learning_rate": 6.987179487179487e-05,
      "loss": 1.642,
      "step": 235
    },
    {
      "epoch": 1.51,
      "learning_rate": 6.974358974358974e-05,
      "loss": 1.4688,
      "step": 236
    },
    {
      "epoch": 1.52,
      "learning_rate": 6.961538461538462e-05,
      "loss": 1.4903,
      "step": 237
    },
    {
      "epoch": 1.52,
      "learning_rate": 6.94871794871795e-05,
      "loss": 1.3735,
      "step": 238
    },
    {
      "epoch": 1.53,
      "learning_rate": 6.935897435897436e-05,
      "loss": 1.3784,
      "step": 239
    },
    {
      "epoch": 1.54,
      "learning_rate": 6.923076923076924e-05,
      "loss": 1.3566,
      "step": 240
    },
    {
      "epoch": 1.54,
      "learning_rate": 6.91025641025641e-05,
      "loss": 1.3365,
      "step": 241
    },
    {
      "epoch": 1.55,
      "learning_rate": 6.897435897435898e-05,
      "loss": 1.4358,
      "step": 242
    },
    {
      "epoch": 1.56,
      "learning_rate": 6.884615384615385e-05,
      "loss": 1.3305,
      "step": 243
    },
    {
      "epoch": 1.56,
      "learning_rate": 6.871794871794872e-05,
      "loss": 1.517,
      "step": 244
    },
    {
      "epoch": 1.57,
      "learning_rate": 6.858974358974359e-05,
      "loss": 1.4928,
      "step": 245
    },
    {
      "epoch": 1.57,
      "learning_rate": 6.846153846153847e-05,
      "loss": 1.4738,
      "step": 246
    },
    {
      "epoch": 1.58,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.3293,
      "step": 247
    },
    {
      "epoch": 1.59,
      "learning_rate": 6.820512820512821e-05,
      "loss": 1.6334,
      "step": 248
    },
    {
      "epoch": 1.59,
      "learning_rate": 6.807692307692309e-05,
      "loss": 1.5143,
      "step": 249
    },
    {
      "epoch": 1.6,
      "learning_rate": 6.794871794871795e-05,
      "loss": 1.6021,
      "step": 250
    },
    {
      "epoch": 1.61,
      "learning_rate": 6.782051282051283e-05,
      "loss": 1.4622,
      "step": 251
    },
    {
      "epoch": 1.61,
      "learning_rate": 6.76923076923077e-05,
      "loss": 1.3484,
      "step": 252
    },
    {
      "epoch": 1.62,
      "learning_rate": 6.756410256410258e-05,
      "loss": 1.6592,
      "step": 253
    },
    {
      "epoch": 1.63,
      "learning_rate": 6.743589743589744e-05,
      "loss": 1.6143,
      "step": 254
    },
    {
      "epoch": 1.63,
      "learning_rate": 6.730769230769232e-05,
      "loss": 1.557,
      "step": 255
    },
    {
      "epoch": 1.64,
      "learning_rate": 6.717948717948718e-05,
      "loss": 1.6503,
      "step": 256
    },
    {
      "epoch": 1.64,
      "learning_rate": 6.705128205128205e-05,
      "loss": 1.6148,
      "step": 257
    },
    {
      "epoch": 1.65,
      "learning_rate": 6.692307692307693e-05,
      "loss": 1.6407,
      "step": 258
    },
    {
      "epoch": 1.66,
      "learning_rate": 6.679487179487179e-05,
      "loss": 1.6348,
      "step": 259
    },
    {
      "epoch": 1.66,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.5844,
      "step": 260
    },
    {
      "epoch": 1.67,
      "learning_rate": 6.653846153846153e-05,
      "loss": 1.7032,
      "step": 261
    },
    {
      "epoch": 1.68,
      "learning_rate": 6.641025641025641e-05,
      "loss": 1.5705,
      "step": 262
    },
    {
      "epoch": 1.68,
      "learning_rate": 6.628205128205128e-05,
      "loss": 1.7546,
      "step": 263
    },
    {
      "epoch": 1.69,
      "learning_rate": 6.615384615384616e-05,
      "loss": 1.7711,
      "step": 264
    },
    {
      "epoch": 1.7,
      "learning_rate": 6.602564102564102e-05,
      "loss": 1.9882,
      "step": 265
    },
    {
      "epoch": 1.7,
      "learning_rate": 6.58974358974359e-05,
      "loss": 1.9683,
      "step": 266
    },
    {
      "epoch": 1.71,
      "learning_rate": 6.576923076923078e-05,
      "loss": 1.8784,
      "step": 267
    },
    {
      "epoch": 1.72,
      "learning_rate": 6.564102564102564e-05,
      "loss": 2.025,
      "step": 268
    },
    {
      "epoch": 1.72,
      "learning_rate": 6.551282051282052e-05,
      "loss": 1.995,
      "step": 269
    },
    {
      "epoch": 1.73,
      "learning_rate": 6.538461538461539e-05,
      "loss": 2.0889,
      "step": 270
    },
    {
      "epoch": 1.73,
      "learning_rate": 6.525641025641026e-05,
      "loss": 1.9763,
      "step": 271
    },
    {
      "epoch": 1.74,
      "learning_rate": 6.512820512820513e-05,
      "loss": 2.1475,
      "step": 272
    },
    {
      "epoch": 1.75,
      "learning_rate": 6.500000000000001e-05,
      "loss": 2.3672,
      "step": 273
    },
    {
      "epoch": 1.75,
      "learning_rate": 6.487179487179487e-05,
      "loss": 1.446,
      "step": 274
    },
    {
      "epoch": 1.76,
      "learning_rate": 6.474358974358975e-05,
      "loss": 1.3384,
      "step": 275
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.461538461538462e-05,
      "loss": 1.3807,
      "step": 276
    },
    {
      "epoch": 1.77,
      "learning_rate": 6.44871794871795e-05,
      "loss": 1.337,
      "step": 277
    },
    {
      "epoch": 1.78,
      "learning_rate": 6.435897435897437e-05,
      "loss": 1.3936,
      "step": 278
    },
    {
      "epoch": 1.79,
      "learning_rate": 6.423076923076924e-05,
      "loss": 1.4152,
      "step": 279
    },
    {
      "epoch": 1.79,
      "learning_rate": 6.410256410256412e-05,
      "loss": 1.3198,
      "step": 280
    },
    {
      "epoch": 1.8,
      "learning_rate": 6.397435897435897e-05,
      "loss": 1.4692,
      "step": 281
    },
    {
      "epoch": 1.8,
      "learning_rate": 6.384615384615385e-05,
      "loss": 1.387,
      "step": 282
    },
    {
      "epoch": 1.81,
      "learning_rate": 6.371794871794871e-05,
      "loss": 1.3533,
      "step": 283
    },
    {
      "epoch": 1.82,
      "learning_rate": 6.358974358974359e-05,
      "loss": 1.4516,
      "step": 284
    },
    {
      "epoch": 1.82,
      "learning_rate": 6.346153846153847e-05,
      "loss": 1.5253,
      "step": 285
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.4225,
      "step": 286
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.320512820512821e-05,
      "loss": 1.4544,
      "step": 287
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.307692307692308e-05,
      "loss": 1.4715,
      "step": 288
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.294871794871795e-05,
      "loss": 1.5935,
      "step": 289
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.282051282051282e-05,
      "loss": 1.4574,
      "step": 290
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.26923076923077e-05,
      "loss": 1.4522,
      "step": 291
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.256410256410256e-05,
      "loss": 1.3832,
      "step": 292
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.243589743589744e-05,
      "loss": 1.4547,
      "step": 293
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.23076923076923e-05,
      "loss": 1.4475,
      "step": 294
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.217948717948718e-05,
      "loss": 1.7403,
      "step": 295
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.205128205128206e-05,
      "loss": 1.5499,
      "step": 296
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.192307692307693e-05,
      "loss": 1.4177,
      "step": 297
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.17948717948718e-05,
      "loss": 1.6977,
      "step": 298
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.6183,
      "step": 299
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.153846153846155e-05,
      "loss": 1.9596,
      "step": 300
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.141025641025641e-05,
      "loss": 1.7026,
      "step": 301
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.128205128205129e-05,
      "loss": 1.7372,
      "step": 302
    },
    {
      "epoch": 1.94,
      "learning_rate": 6.115384615384616e-05,
      "loss": 1.6312,
      "step": 303
    },
    {
      "epoch": 1.95,
      "learning_rate": 6.1025641025641035e-05,
      "loss": 1.7844,
      "step": 304
    },
    {
      "epoch": 1.95,
      "learning_rate": 6.089743589743589e-05,
      "loss": 1.9098,
      "step": 305
    },
    {
      "epoch": 1.96,
      "learning_rate": 6.0769230769230765e-05,
      "loss": 1.9041,
      "step": 306
    },
    {
      "epoch": 1.96,
      "learning_rate": 6.0641025641025637e-05,
      "loss": 1.9886,
      "step": 307
    },
    {
      "epoch": 1.97,
      "learning_rate": 6.0512820512820515e-05,
      "loss": 1.8984,
      "step": 308
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.038461538461539e-05,
      "loss": 2.0578,
      "step": 309
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.025641025641026e-05,
      "loss": 2.1939,
      "step": 310
    },
    {
      "epoch": 1.99,
      "learning_rate": 6.012820512820513e-05,
      "loss": 2.3657,
      "step": 311
    },
    {
      "epoch": 2.0,
      "learning_rate": 6e-05,
      "loss": 2.168,
      "step": 312
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.987179487179487e-05,
      "loss": 1.4892,
      "step": 313
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.9743589743589745e-05,
      "loss": 1.2868,
      "step": 314
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.9615384615384616e-05,
      "loss": 1.3564,
      "step": 315
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.948717948717949e-05,
      "loss": 1.4503,
      "step": 316
    },
    {
      "epoch": 2.03,
      "learning_rate": 5.935897435897436e-05,
      "loss": 1.4051,
      "step": 317
    },
    {
      "epoch": 2.04,
      "learning_rate": 5.923076923076923e-05,
      "loss": 1.338,
      "step": 318
    },
    {
      "epoch": 2.04,
      "learning_rate": 5.910256410256411e-05,
      "loss": 1.3131,
      "step": 319
    },
    {
      "epoch": 2.05,
      "learning_rate": 5.897435897435898e-05,
      "loss": 1.4302,
      "step": 320
    },
    {
      "epoch": 2.05,
      "learning_rate": 5.884615384615385e-05,
      "loss": 1.4034,
      "step": 321
    },
    {
      "epoch": 2.06,
      "learning_rate": 5.8717948717948725e-05,
      "loss": 1.4172,
      "step": 322
    },
    {
      "epoch": 2.07,
      "learning_rate": 5.8589743589743596e-05,
      "loss": 1.4871,
      "step": 323
    },
    {
      "epoch": 2.07,
      "learning_rate": 5.846153846153847e-05,
      "loss": 1.442,
      "step": 324
    },
    {
      "epoch": 2.08,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.4744,
      "step": 325
    },
    {
      "epoch": 2.09,
      "learning_rate": 5.820512820512821e-05,
      "loss": 1.4189,
      "step": 326
    },
    {
      "epoch": 2.09,
      "learning_rate": 5.807692307692308e-05,
      "loss": 1.3667,
      "step": 327
    },
    {
      "epoch": 2.1,
      "learning_rate": 5.7948717948717954e-05,
      "loss": 1.4714,
      "step": 328
    },
    {
      "epoch": 2.11,
      "learning_rate": 5.7820512820512826e-05,
      "loss": 1.582,
      "step": 329
    },
    {
      "epoch": 2.11,
      "learning_rate": 5.769230769230769e-05,
      "loss": 1.3857,
      "step": 330
    },
    {
      "epoch": 2.12,
      "learning_rate": 5.756410256410256e-05,
      "loss": 1.6191,
      "step": 331
    },
    {
      "epoch": 2.12,
      "learning_rate": 5.7435897435897434e-05,
      "loss": 1.4217,
      "step": 332
    },
    {
      "epoch": 2.13,
      "learning_rate": 5.7307692307692306e-05,
      "loss": 1.4677,
      "step": 333
    },
    {
      "epoch": 2.14,
      "learning_rate": 5.717948717948718e-05,
      "loss": 1.3763,
      "step": 334
    },
    {
      "epoch": 2.14,
      "learning_rate": 5.705128205128205e-05,
      "loss": 1.5336,
      "step": 335
    },
    {
      "epoch": 2.15,
      "learning_rate": 5.692307692307692e-05,
      "loss": 1.464,
      "step": 336
    },
    {
      "epoch": 2.16,
      "learning_rate": 5.679487179487179e-05,
      "loss": 1.7358,
      "step": 337
    },
    {
      "epoch": 2.16,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.5651,
      "step": 338
    },
    {
      "epoch": 2.17,
      "learning_rate": 5.653846153846154e-05,
      "loss": 1.6289,
      "step": 339
    },
    {
      "epoch": 2.18,
      "learning_rate": 5.6410256410256414e-05,
      "loss": 1.8148,
      "step": 340
    },
    {
      "epoch": 2.18,
      "learning_rate": 5.6282051282051286e-05,
      "loss": 1.7578,
      "step": 341
    },
    {
      "epoch": 2.19,
      "learning_rate": 5.615384615384616e-05,
      "loss": 1.8881,
      "step": 342
    },
    {
      "epoch": 2.2,
      "learning_rate": 5.602564102564103e-05,
      "loss": 1.9014,
      "step": 343
    },
    {
      "epoch": 2.2,
      "learning_rate": 5.58974358974359e-05,
      "loss": 1.8399,
      "step": 344
    },
    {
      "epoch": 2.21,
      "learning_rate": 5.576923076923077e-05,
      "loss": 1.6338,
      "step": 345
    },
    {
      "epoch": 2.21,
      "learning_rate": 5.5641025641025644e-05,
      "loss": 2.0609,
      "step": 346
    },
    {
      "epoch": 2.22,
      "learning_rate": 5.5512820512820515e-05,
      "loss": 1.9321,
      "step": 347
    },
    {
      "epoch": 2.23,
      "learning_rate": 5.538461538461539e-05,
      "loss": 1.9592,
      "step": 348
    },
    {
      "epoch": 2.23,
      "learning_rate": 5.5256410256410265e-05,
      "loss": 2.1075,
      "step": 349
    },
    {
      "epoch": 2.24,
      "learning_rate": 5.512820512820514e-05,
      "loss": 2.168,
      "step": 350
    },
    {
      "epoch": 2.25,
      "learning_rate": 5.500000000000001e-05,
      "loss": 2.1987,
      "step": 351
    },
    {
      "epoch": 2.25,
      "learning_rate": 5.487179487179488e-05,
      "loss": 1.8941,
      "step": 352
    },
    {
      "epoch": 2.26,
      "learning_rate": 5.474358974358975e-05,
      "loss": 1.2472,
      "step": 353
    },
    {
      "epoch": 2.27,
      "learning_rate": 5.461538461538461e-05,
      "loss": 1.3859,
      "step": 354
    },
    {
      "epoch": 2.27,
      "learning_rate": 5.448717948717948e-05,
      "loss": 1.4541,
      "step": 355
    },
    {
      "epoch": 2.28,
      "learning_rate": 5.435897435897436e-05,
      "loss": 1.2716,
      "step": 356
    },
    {
      "epoch": 2.28,
      "learning_rate": 5.423076923076923e-05,
      "loss": 1.4415,
      "step": 357
    },
    {
      "epoch": 2.29,
      "learning_rate": 5.41025641025641e-05,
      "loss": 1.3091,
      "step": 358
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.3974358974358975e-05,
      "loss": 1.2892,
      "step": 359
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.384615384615385e-05,
      "loss": 1.4654,
      "step": 360
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.371794871794872e-05,
      "loss": 1.4911,
      "step": 361
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.358974358974359e-05,
      "loss": 1.5402,
      "step": 362
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.346153846153846e-05,
      "loss": 1.5083,
      "step": 363
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.5212,
      "step": 364
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.3205128205128205e-05,
      "loss": 1.3346,
      "step": 365
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.3076923076923076e-05,
      "loss": 1.4702,
      "step": 366
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.2948717948717955e-05,
      "loss": 1.4879,
      "step": 367
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.2820512820512826e-05,
      "loss": 1.5461,
      "step": 368
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.26923076923077e-05,
      "loss": 1.425,
      "step": 369
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.256410256410257e-05,
      "loss": 1.4241,
      "step": 370
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.243589743589744e-05,
      "loss": 1.4511,
      "step": 371
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.230769230769231e-05,
      "loss": 1.4579,
      "step": 372
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.2179487179487185e-05,
      "loss": 1.4443,
      "step": 373
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.2051282051282056e-05,
      "loss": 1.512,
      "step": 374
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.192307692307693e-05,
      "loss": 1.5933,
      "step": 375
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.17948717948718e-05,
      "loss": 1.6544,
      "step": 376
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.5727,
      "step": 377
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.1538461538461536e-05,
      "loss": 1.6349,
      "step": 378
    },
    {
      "epoch": 2.43,
      "learning_rate": 5.141025641025641e-05,
      "loss": 1.6905,
      "step": 379
    },
    {
      "epoch": 2.43,
      "learning_rate": 5.128205128205128e-05,
      "loss": 1.6312,
      "step": 380
    },
    {
      "epoch": 2.44,
      "learning_rate": 5.115384615384615e-05,
      "loss": 1.7675,
      "step": 381
    },
    {
      "epoch": 2.44,
      "learning_rate": 5.102564102564102e-05,
      "loss": 1.7849,
      "step": 382
    },
    {
      "epoch": 2.45,
      "learning_rate": 5.0897435897435894e-05,
      "loss": 1.8408,
      "step": 383
    },
    {
      "epoch": 2.46,
      "learning_rate": 5.0769230769230766e-05,
      "loss": 1.8726,
      "step": 384
    },
    {
      "epoch": 2.46,
      "learning_rate": 5.0641025641025644e-05,
      "loss": 1.7675,
      "step": 385
    },
    {
      "epoch": 2.47,
      "learning_rate": 5.0512820512820516e-05,
      "loss": 1.8524,
      "step": 386
    },
    {
      "epoch": 2.48,
      "learning_rate": 5.038461538461539e-05,
      "loss": 1.7764,
      "step": 387
    },
    {
      "epoch": 2.48,
      "learning_rate": 5.025641025641026e-05,
      "loss": 2.012,
      "step": 388
    },
    {
      "epoch": 2.49,
      "learning_rate": 5.012820512820513e-05,
      "loss": 2.0825,
      "step": 389
    },
    {
      "epoch": 2.5,
      "learning_rate": 5e-05,
      "loss": 2.1001,
      "step": 390
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.9871794871794874e-05,
      "loss": 1.7906,
      "step": 391
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.9743589743589746e-05,
      "loss": 1.3856,
      "step": 392
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.961538461538462e-05,
      "loss": 1.2704,
      "step": 393
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.948717948717949e-05,
      "loss": 1.2195,
      "step": 394
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.935897435897436e-05,
      "loss": 1.3227,
      "step": 395
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.923076923076924e-05,
      "loss": 1.3394,
      "step": 396
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.9102564102564104e-05,
      "loss": 1.4776,
      "step": 397
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.8974358974358975e-05,
      "loss": 1.3553,
      "step": 398
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.884615384615385e-05,
      "loss": 1.5065,
      "step": 399
    },
    {
      "epoch": 2.56,
      "learning_rate": 4.871794871794872e-05,
      "loss": 1.4165,
      "step": 400
    },
    {
      "epoch": 2.57,
      "learning_rate": 4.858974358974359e-05,
      "loss": 1.4659,
      "step": 401
    },
    {
      "epoch": 2.57,
      "learning_rate": 4.846153846153846e-05,
      "loss": 1.428,
      "step": 402
    },
    {
      "epoch": 2.58,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.4319,
      "step": 403
    },
    {
      "epoch": 2.59,
      "learning_rate": 4.8205128205128205e-05,
      "loss": 1.3215,
      "step": 404
    },
    {
      "epoch": 2.59,
      "learning_rate": 4.8076923076923084e-05,
      "loss": 1.4544,
      "step": 405
    },
    {
      "epoch": 2.6,
      "learning_rate": 4.7948717948717955e-05,
      "loss": 1.4497,
      "step": 406
    },
    {
      "epoch": 2.6,
      "learning_rate": 4.782051282051283e-05,
      "loss": 1.4356,
      "step": 407
    },
    {
      "epoch": 2.61,
      "learning_rate": 4.76923076923077e-05,
      "loss": 1.524,
      "step": 408
    },
    {
      "epoch": 2.62,
      "learning_rate": 4.7564102564102563e-05,
      "loss": 1.4229,
      "step": 409
    },
    {
      "epoch": 2.62,
      "learning_rate": 4.7435897435897435e-05,
      "loss": 1.5647,
      "step": 410
    },
    {
      "epoch": 2.63,
      "learning_rate": 4.730769230769231e-05,
      "loss": 1.6753,
      "step": 411
    },
    {
      "epoch": 2.64,
      "learning_rate": 4.717948717948718e-05,
      "loss": 1.7095,
      "step": 412
    },
    {
      "epoch": 2.64,
      "learning_rate": 4.705128205128205e-05,
      "loss": 1.5962,
      "step": 413
    },
    {
      "epoch": 2.65,
      "learning_rate": 4.692307692307693e-05,
      "loss": 1.4918,
      "step": 414
    },
    {
      "epoch": 2.66,
      "learning_rate": 4.67948717948718e-05,
      "loss": 1.5705,
      "step": 415
    },
    {
      "epoch": 2.66,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.623,
      "step": 416
    },
    {
      "epoch": 2.67,
      "learning_rate": 4.653846153846154e-05,
      "loss": 1.7498,
      "step": 417
    },
    {
      "epoch": 2.68,
      "learning_rate": 4.6410256410256415e-05,
      "loss": 1.5149,
      "step": 418
    },
    {
      "epoch": 2.68,
      "learning_rate": 4.6282051282051287e-05,
      "loss": 1.8499,
      "step": 419
    },
    {
      "epoch": 2.69,
      "learning_rate": 4.615384615384616e-05,
      "loss": 1.65,
      "step": 420
    },
    {
      "epoch": 2.69,
      "learning_rate": 4.602564102564102e-05,
      "loss": 1.809,
      "step": 421
    },
    {
      "epoch": 2.7,
      "learning_rate": 4.5897435897435895e-05,
      "loss": 1.8127,
      "step": 422
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.576923076923077e-05,
      "loss": 1.7795,
      "step": 423
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.5641025641025645e-05,
      "loss": 1.7171,
      "step": 424
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.5512820512820516e-05,
      "loss": 1.9805,
      "step": 425
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.538461538461539e-05,
      "loss": 2.0351,
      "step": 426
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.525641025641026e-05,
      "loss": 1.979,
      "step": 427
    },
    {
      "epoch": 2.74,
      "learning_rate": 4.512820512820513e-05,
      "loss": 2.1693,
      "step": 428
    },
    {
      "epoch": 2.75,
      "learning_rate": 4.5e-05,
      "loss": 2.0958,
      "step": 429
    },
    {
      "epoch": 2.75,
      "learning_rate": 4.4871794871794874e-05,
      "loss": 1.8722,
      "step": 430
    },
    {
      "epoch": 2.76,
      "learning_rate": 4.4743589743589746e-05,
      "loss": 1.3167,
      "step": 431
    },
    {
      "epoch": 2.76,
      "learning_rate": 4.461538461538462e-05,
      "loss": 1.2944,
      "step": 432
    },
    {
      "epoch": 2.77,
      "learning_rate": 4.448717948717949e-05,
      "loss": 1.5136,
      "step": 433
    },
    {
      "epoch": 2.78,
      "learning_rate": 4.435897435897436e-05,
      "loss": 1.4829,
      "step": 434
    },
    {
      "epoch": 2.78,
      "learning_rate": 4.423076923076923e-05,
      "loss": 1.4,
      "step": 435
    },
    {
      "epoch": 2.79,
      "learning_rate": 4.4102564102564104e-05,
      "loss": 1.3836,
      "step": 436
    },
    {
      "epoch": 2.8,
      "learning_rate": 4.3974358974358976e-05,
      "loss": 1.3488,
      "step": 437
    },
    {
      "epoch": 2.8,
      "learning_rate": 4.384615384615385e-05,
      "loss": 1.4136,
      "step": 438
    },
    {
      "epoch": 2.81,
      "learning_rate": 4.371794871794872e-05,
      "loss": 1.4197,
      "step": 439
    },
    {
      "epoch": 2.82,
      "learning_rate": 4.358974358974359e-05,
      "loss": 1.3799,
      "step": 440
    },
    {
      "epoch": 2.82,
      "learning_rate": 4.346153846153846e-05,
      "loss": 1.2962,
      "step": 441
    },
    {
      "epoch": 2.83,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.4549,
      "step": 442
    },
    {
      "epoch": 2.84,
      "learning_rate": 4.320512820512821e-05,
      "loss": 1.4229,
      "step": 443
    },
    {
      "epoch": 2.84,
      "learning_rate": 4.3076923076923084e-05,
      "loss": 1.4079,
      "step": 444
    },
    {
      "epoch": 2.85,
      "learning_rate": 4.294871794871795e-05,
      "loss": 1.5882,
      "step": 445
    },
    {
      "epoch": 2.85,
      "learning_rate": 4.282051282051282e-05,
      "loss": 1.4679,
      "step": 446
    },
    {
      "epoch": 2.86,
      "learning_rate": 4.269230769230769e-05,
      "loss": 1.521,
      "step": 447
    },
    {
      "epoch": 2.87,
      "learning_rate": 4.2564102564102564e-05,
      "loss": 1.4736,
      "step": 448
    },
    {
      "epoch": 2.87,
      "learning_rate": 4.2435897435897435e-05,
      "loss": 1.4499,
      "step": 449
    },
    {
      "epoch": 2.88,
      "learning_rate": 4.230769230769231e-05,
      "loss": 1.555,
      "step": 450
    },
    {
      "epoch": 2.89,
      "learning_rate": 4.217948717948718e-05,
      "loss": 1.7833,
      "step": 451
    },
    {
      "epoch": 2.89,
      "learning_rate": 4.205128205128206e-05,
      "loss": 1.5774,
      "step": 452
    },
    {
      "epoch": 2.9,
      "learning_rate": 4.192307692307693e-05,
      "loss": 1.6407,
      "step": 453
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.17948717948718e-05,
      "loss": 1.5423,
      "step": 454
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.6728,
      "step": 455
    },
    {
      "epoch": 2.92,
      "learning_rate": 4.1538461538461544e-05,
      "loss": 1.5796,
      "step": 456
    },
    {
      "epoch": 2.92,
      "learning_rate": 4.1410256410256415e-05,
      "loss": 1.7553,
      "step": 457
    },
    {
      "epoch": 2.93,
      "learning_rate": 4.128205128205128e-05,
      "loss": 1.6894,
      "step": 458
    },
    {
      "epoch": 2.94,
      "learning_rate": 4.115384615384615e-05,
      "loss": 1.6562,
      "step": 459
    },
    {
      "epoch": 2.94,
      "learning_rate": 4.1025641025641023e-05,
      "loss": 1.5698,
      "step": 460
    },
    {
      "epoch": 2.95,
      "learning_rate": 4.0897435897435895e-05,
      "loss": 1.8865,
      "step": 461
    },
    {
      "epoch": 2.96,
      "learning_rate": 4.0769230769230773e-05,
      "loss": 1.9057,
      "step": 462
    },
    {
      "epoch": 2.96,
      "learning_rate": 4.0641025641025645e-05,
      "loss": 1.9199,
      "step": 463
    },
    {
      "epoch": 2.97,
      "learning_rate": 4.051282051282052e-05,
      "loss": 1.9616,
      "step": 464
    },
    {
      "epoch": 2.98,
      "learning_rate": 4.038461538461539e-05,
      "loss": 1.8753,
      "step": 465
    },
    {
      "epoch": 2.98,
      "learning_rate": 4.025641025641026e-05,
      "loss": 1.8376,
      "step": 466
    },
    {
      "epoch": 2.99,
      "learning_rate": 4.012820512820513e-05,
      "loss": 1.9978,
      "step": 467
    },
    {
      "epoch": 3.0,
      "learning_rate": 4e-05,
      "loss": 2.3609,
      "step": 468
    },
    {
      "epoch": 3.0,
      "learning_rate": 3.9871794871794875e-05,
      "loss": 1.8819,
      "step": 469
    },
    {
      "epoch": 3.01,
      "learning_rate": 3.974358974358974e-05,
      "loss": 1.4869,
      "step": 470
    },
    {
      "epoch": 3.01,
      "learning_rate": 3.961538461538462e-05,
      "loss": 1.3598,
      "step": 471
    },
    {
      "epoch": 3.02,
      "learning_rate": 3.948717948717949e-05,
      "loss": 1.252,
      "step": 472
    },
    {
      "epoch": 3.03,
      "learning_rate": 3.935897435897436e-05,
      "loss": 1.3168,
      "step": 473
    },
    {
      "epoch": 3.03,
      "learning_rate": 3.923076923076923e-05,
      "loss": 1.3984,
      "step": 474
    },
    {
      "epoch": 3.04,
      "learning_rate": 3.9102564102564105e-05,
      "loss": 1.2403,
      "step": 475
    },
    {
      "epoch": 3.05,
      "learning_rate": 3.8974358974358976e-05,
      "loss": 1.2864,
      "step": 476
    },
    {
      "epoch": 3.05,
      "learning_rate": 3.884615384615385e-05,
      "loss": 1.3794,
      "step": 477
    },
    {
      "epoch": 3.06,
      "learning_rate": 3.871794871794872e-05,
      "loss": 1.4443,
      "step": 478
    },
    {
      "epoch": 3.07,
      "learning_rate": 3.858974358974359e-05,
      "loss": 1.4297,
      "step": 479
    },
    {
      "epoch": 3.07,
      "learning_rate": 3.846153846153846e-05,
      "loss": 1.433,
      "step": 480
    },
    {
      "epoch": 3.08,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.4672,
      "step": 481
    },
    {
      "epoch": 3.08,
      "learning_rate": 3.8205128205128206e-05,
      "loss": 1.3979,
      "step": 482
    },
    {
      "epoch": 3.09,
      "learning_rate": 3.807692307692308e-05,
      "loss": 1.4918,
      "step": 483
    },
    {
      "epoch": 3.1,
      "learning_rate": 3.794871794871795e-05,
      "loss": 1.4356,
      "step": 484
    },
    {
      "epoch": 3.1,
      "learning_rate": 3.782051282051282e-05,
      "loss": 1.4064,
      "step": 485
    },
    {
      "epoch": 3.11,
      "learning_rate": 3.769230769230769e-05,
      "loss": 1.4268,
      "step": 486
    },
    {
      "epoch": 3.12,
      "learning_rate": 3.7564102564102564e-05,
      "loss": 1.5437,
      "step": 487
    },
    {
      "epoch": 3.12,
      "learning_rate": 3.7435897435897436e-05,
      "loss": 1.347,
      "step": 488
    },
    {
      "epoch": 3.13,
      "learning_rate": 3.730769230769231e-05,
      "loss": 1.5104,
      "step": 489
    },
    {
      "epoch": 3.14,
      "learning_rate": 3.717948717948718e-05,
      "loss": 1.5304,
      "step": 490
    },
    {
      "epoch": 3.14,
      "learning_rate": 3.705128205128206e-05,
      "loss": 1.5663,
      "step": 491
    },
    {
      "epoch": 3.15,
      "learning_rate": 3.692307692307693e-05,
      "loss": 1.6106,
      "step": 492
    },
    {
      "epoch": 3.16,
      "learning_rate": 3.67948717948718e-05,
      "loss": 1.6858,
      "step": 493
    },
    {
      "epoch": 3.16,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.5015,
      "step": 494
    },
    {
      "epoch": 3.17,
      "learning_rate": 3.653846153846154e-05,
      "loss": 1.5667,
      "step": 495
    },
    {
      "epoch": 3.17,
      "learning_rate": 3.641025641025641e-05,
      "loss": 1.7001,
      "step": 496
    },
    {
      "epoch": 3.18,
      "learning_rate": 3.628205128205128e-05,
      "loss": 1.7593,
      "step": 497
    },
    {
      "epoch": 3.19,
      "learning_rate": 3.615384615384615e-05,
      "loss": 1.7698,
      "step": 498
    },
    {
      "epoch": 3.19,
      "learning_rate": 3.6025641025641024e-05,
      "loss": 1.9316,
      "step": 499
    },
    {
      "epoch": 3.2,
      "learning_rate": 3.58974358974359e-05,
      "loss": 1.742,
      "step": 500
    },
    {
      "epoch": 3.21,
      "learning_rate": 3.5769230769230774e-05,
      "loss": 1.7648,
      "step": 501
    },
    {
      "epoch": 3.21,
      "learning_rate": 3.5641025641025646e-05,
      "loss": 1.8657,
      "step": 502
    },
    {
      "epoch": 3.22,
      "learning_rate": 3.551282051282052e-05,
      "loss": 1.9566,
      "step": 503
    },
    {
      "epoch": 3.23,
      "learning_rate": 3.538461538461539e-05,
      "loss": 1.9127,
      "step": 504
    },
    {
      "epoch": 3.23,
      "learning_rate": 3.525641025641026e-05,
      "loss": 1.9189,
      "step": 505
    },
    {
      "epoch": 3.24,
      "learning_rate": 3.5128205128205125e-05,
      "loss": 2.1921,
      "step": 506
    },
    {
      "epoch": 3.24,
      "learning_rate": 3.5e-05,
      "loss": 2.1254,
      "step": 507
    },
    {
      "epoch": 3.25,
      "learning_rate": 3.487179487179487e-05,
      "loss": 1.9225,
      "step": 508
    },
    {
      "epoch": 3.26,
      "learning_rate": 3.474358974358975e-05,
      "loss": 1.5161,
      "step": 509
    },
    {
      "epoch": 3.26,
      "learning_rate": 3.461538461538462e-05,
      "loss": 1.2829,
      "step": 510
    },
    {
      "epoch": 3.27,
      "learning_rate": 3.448717948717949e-05,
      "loss": 1.098,
      "step": 511
    },
    {
      "epoch": 3.28,
      "learning_rate": 3.435897435897436e-05,
      "loss": 1.3378,
      "step": 512
    },
    {
      "epoch": 3.28,
      "learning_rate": 3.4230769230769234e-05,
      "loss": 1.3598,
      "step": 513
    },
    {
      "epoch": 3.29,
      "learning_rate": 3.4102564102564105e-05,
      "loss": 1.478,
      "step": 514
    },
    {
      "epoch": 3.3,
      "learning_rate": 3.397435897435898e-05,
      "loss": 1.3955,
      "step": 515
    },
    {
      "epoch": 3.3,
      "learning_rate": 3.384615384615385e-05,
      "loss": 1.427,
      "step": 516
    },
    {
      "epoch": 3.31,
      "learning_rate": 3.371794871794872e-05,
      "loss": 1.4794,
      "step": 517
    },
    {
      "epoch": 3.32,
      "learning_rate": 3.358974358974359e-05,
      "loss": 1.449,
      "step": 518
    },
    {
      "epoch": 3.32,
      "learning_rate": 3.346153846153846e-05,
      "loss": 1.4717,
      "step": 519
    },
    {
      "epoch": 3.33,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.4285,
      "step": 520
    },
    {
      "epoch": 3.33,
      "learning_rate": 3.3205128205128207e-05,
      "loss": 1.4989,
      "step": 521
    },
    {
      "epoch": 3.34,
      "learning_rate": 3.307692307692308e-05,
      "loss": 1.4085,
      "step": 522
    },
    {
      "epoch": 3.35,
      "learning_rate": 3.294871794871795e-05,
      "loss": 1.3737,
      "step": 523
    },
    {
      "epoch": 3.35,
      "learning_rate": 3.282051282051282e-05,
      "loss": 1.5228,
      "step": 524
    },
    {
      "epoch": 3.36,
      "learning_rate": 3.269230769230769e-05,
      "loss": 1.5167,
      "step": 525
    },
    {
      "epoch": 3.37,
      "learning_rate": 3.2564102564102565e-05,
      "loss": 1.4549,
      "step": 526
    },
    {
      "epoch": 3.37,
      "learning_rate": 3.2435897435897436e-05,
      "loss": 1.4336,
      "step": 527
    },
    {
      "epoch": 3.38,
      "learning_rate": 3.230769230769231e-05,
      "loss": 1.5036,
      "step": 528
    },
    {
      "epoch": 3.39,
      "learning_rate": 3.2179487179487186e-05,
      "loss": 1.524,
      "step": 529
    },
    {
      "epoch": 3.39,
      "learning_rate": 3.205128205128206e-05,
      "loss": 1.604,
      "step": 530
    },
    {
      "epoch": 3.4,
      "learning_rate": 3.192307692307692e-05,
      "loss": 1.4999,
      "step": 531
    },
    {
      "epoch": 3.4,
      "learning_rate": 3.1794871794871795e-05,
      "loss": 1.55,
      "step": 532
    },
    {
      "epoch": 3.41,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.4867,
      "step": 533
    },
    {
      "epoch": 3.42,
      "learning_rate": 3.153846153846154e-05,
      "loss": 1.5792,
      "step": 534
    },
    {
      "epoch": 3.42,
      "learning_rate": 3.141025641025641e-05,
      "loss": 1.5965,
      "step": 535
    },
    {
      "epoch": 3.43,
      "learning_rate": 3.128205128205128e-05,
      "loss": 1.5764,
      "step": 536
    },
    {
      "epoch": 3.44,
      "learning_rate": 3.115384615384615e-05,
      "loss": 1.7652,
      "step": 537
    },
    {
      "epoch": 3.44,
      "learning_rate": 3.102564102564103e-05,
      "loss": 1.6531,
      "step": 538
    },
    {
      "epoch": 3.45,
      "learning_rate": 3.08974358974359e-05,
      "loss": 1.8597,
      "step": 539
    },
    {
      "epoch": 3.46,
      "learning_rate": 3.0769230769230774e-05,
      "loss": 1.8662,
      "step": 540
    },
    {
      "epoch": 3.46,
      "learning_rate": 3.0641025641025646e-05,
      "loss": 1.6446,
      "step": 541
    },
    {
      "epoch": 3.47,
      "learning_rate": 3.0512820512820518e-05,
      "loss": 1.8479,
      "step": 542
    },
    {
      "epoch": 3.48,
      "learning_rate": 3.0384615384615382e-05,
      "loss": 1.6441,
      "step": 543
    },
    {
      "epoch": 3.48,
      "learning_rate": 3.0256410256410257e-05,
      "loss": 1.9502,
      "step": 544
    },
    {
      "epoch": 3.49,
      "learning_rate": 3.012820512820513e-05,
      "loss": 2.0356,
      "step": 545
    },
    {
      "epoch": 3.49,
      "learning_rate": 3e-05,
      "loss": 2.1902,
      "step": 546
    },
    {
      "epoch": 3.5,
      "learning_rate": 2.9871794871794872e-05,
      "loss": 1.7587,
      "step": 547
    },
    {
      "epoch": 3.51,
      "learning_rate": 2.9743589743589744e-05,
      "loss": 1.3648,
      "step": 548
    },
    {
      "epoch": 3.51,
      "learning_rate": 2.9615384615384616e-05,
      "loss": 1.3778,
      "step": 549
    },
    {
      "epoch": 3.52,
      "learning_rate": 2.948717948717949e-05,
      "loss": 1.2286,
      "step": 550
    },
    {
      "epoch": 3.53,
      "learning_rate": 2.9358974358974362e-05,
      "loss": 1.4777,
      "step": 551
    },
    {
      "epoch": 3.53,
      "learning_rate": 2.9230769230769234e-05,
      "loss": 1.3969,
      "step": 552
    },
    {
      "epoch": 3.54,
      "learning_rate": 2.9102564102564106e-05,
      "loss": 1.4229,
      "step": 553
    },
    {
      "epoch": 3.55,
      "learning_rate": 2.8974358974358977e-05,
      "loss": 1.4965,
      "step": 554
    },
    {
      "epoch": 3.55,
      "learning_rate": 2.8846153846153845e-05,
      "loss": 1.4453,
      "step": 555
    },
    {
      "epoch": 3.56,
      "learning_rate": 2.8717948717948717e-05,
      "loss": 1.3444,
      "step": 556
    },
    {
      "epoch": 3.56,
      "learning_rate": 2.858974358974359e-05,
      "loss": 1.3971,
      "step": 557
    },
    {
      "epoch": 3.57,
      "learning_rate": 2.846153846153846e-05,
      "loss": 1.3743,
      "step": 558
    },
    {
      "epoch": 3.58,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 1.4001,
      "step": 559
    },
    {
      "epoch": 3.58,
      "learning_rate": 2.8205128205128207e-05,
      "loss": 1.369,
      "step": 560
    },
    {
      "epoch": 3.59,
      "learning_rate": 2.807692307692308e-05,
      "loss": 1.431,
      "step": 561
    },
    {
      "epoch": 3.6,
      "learning_rate": 2.794871794871795e-05,
      "loss": 1.4992,
      "step": 562
    },
    {
      "epoch": 3.6,
      "learning_rate": 2.7820512820512822e-05,
      "loss": 1.5445,
      "step": 563
    },
    {
      "epoch": 3.61,
      "learning_rate": 2.7692307692307694e-05,
      "loss": 1.3605,
      "step": 564
    },
    {
      "epoch": 3.62,
      "learning_rate": 2.756410256410257e-05,
      "loss": 1.6085,
      "step": 565
    },
    {
      "epoch": 3.62,
      "learning_rate": 2.743589743589744e-05,
      "loss": 1.54,
      "step": 566
    },
    {
      "epoch": 3.63,
      "learning_rate": 2.7307692307692305e-05,
      "loss": 1.4294,
      "step": 567
    },
    {
      "epoch": 3.64,
      "learning_rate": 2.717948717948718e-05,
      "loss": 1.6704,
      "step": 568
    },
    {
      "epoch": 3.64,
      "learning_rate": 2.705128205128205e-05,
      "loss": 1.4153,
      "step": 569
    },
    {
      "epoch": 3.65,
      "learning_rate": 2.6923076923076923e-05,
      "loss": 1.4969,
      "step": 570
    },
    {
      "epoch": 3.65,
      "learning_rate": 2.6794871794871795e-05,
      "loss": 1.6888,
      "step": 571
    },
    {
      "epoch": 3.66,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.5563,
      "step": 572
    },
    {
      "epoch": 3.67,
      "learning_rate": 2.6538461538461538e-05,
      "loss": 1.6898,
      "step": 573
    },
    {
      "epoch": 3.67,
      "learning_rate": 2.6410256410256413e-05,
      "loss": 1.8063,
      "step": 574
    },
    {
      "epoch": 3.68,
      "learning_rate": 2.6282051282051285e-05,
      "loss": 1.6342,
      "step": 575
    },
    {
      "epoch": 3.69,
      "learning_rate": 2.6153846153846157e-05,
      "loss": 1.792,
      "step": 576
    },
    {
      "epoch": 3.69,
      "learning_rate": 2.6025641025641028e-05,
      "loss": 1.6928,
      "step": 577
    },
    {
      "epoch": 3.7,
      "learning_rate": 2.58974358974359e-05,
      "loss": 1.7692,
      "step": 578
    },
    {
      "epoch": 3.71,
      "learning_rate": 2.5769230769230768e-05,
      "loss": 1.958,
      "step": 579
    },
    {
      "epoch": 3.71,
      "learning_rate": 2.564102564102564e-05,
      "loss": 1.7837,
      "step": 580
    },
    {
      "epoch": 3.72,
      "learning_rate": 2.551282051282051e-05,
      "loss": 1.9582,
      "step": 581
    },
    {
      "epoch": 3.72,
      "learning_rate": 2.5384615384615383e-05,
      "loss": 1.8767,
      "step": 582
    },
    {
      "epoch": 3.73,
      "learning_rate": 2.5256410256410258e-05,
      "loss": 1.8932,
      "step": 583
    },
    {
      "epoch": 3.74,
      "learning_rate": 2.512820512820513e-05,
      "loss": 1.908,
      "step": 584
    },
    {
      "epoch": 3.74,
      "learning_rate": 2.5e-05,
      "loss": 2.1262,
      "step": 585
    },
    {
      "epoch": 3.75,
      "learning_rate": 2.4871794871794873e-05,
      "loss": 2.0007,
      "step": 586
    },
    {
      "epoch": 3.76,
      "learning_rate": 2.4743589743589744e-05,
      "loss": 1.3224,
      "step": 587
    },
    {
      "epoch": 3.76,
      "learning_rate": 2.461538461538462e-05,
      "loss": 1.3665,
      "step": 588
    },
    {
      "epoch": 3.77,
      "learning_rate": 2.4487179487179488e-05,
      "loss": 1.1662,
      "step": 589
    },
    {
      "epoch": 3.78,
      "learning_rate": 2.435897435897436e-05,
      "loss": 1.321,
      "step": 590
    },
    {
      "epoch": 3.78,
      "learning_rate": 2.423076923076923e-05,
      "loss": 1.4467,
      "step": 591
    },
    {
      "epoch": 3.79,
      "learning_rate": 2.4102564102564103e-05,
      "loss": 1.2164,
      "step": 592
    },
    {
      "epoch": 3.8,
      "learning_rate": 2.3974358974358978e-05,
      "loss": 1.2601,
      "step": 593
    },
    {
      "epoch": 3.8,
      "learning_rate": 2.384615384615385e-05,
      "loss": 1.2319,
      "step": 594
    },
    {
      "epoch": 3.81,
      "learning_rate": 2.3717948717948718e-05,
      "loss": 1.4917,
      "step": 595
    },
    {
      "epoch": 3.81,
      "learning_rate": 2.358974358974359e-05,
      "loss": 1.4318,
      "step": 596
    },
    {
      "epoch": 3.82,
      "learning_rate": 2.3461538461538464e-05,
      "loss": 1.3972,
      "step": 597
    },
    {
      "epoch": 3.83,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 1.4491,
      "step": 598
    },
    {
      "epoch": 3.83,
      "learning_rate": 2.3205128205128207e-05,
      "loss": 1.2702,
      "step": 599
    },
    {
      "epoch": 3.84,
      "learning_rate": 2.307692307692308e-05,
      "loss": 1.5003,
      "step": 600
    }
  ],
  "max_steps": 780,
  "num_train_epochs": 5,
  "total_flos": 4.409773698758738e+17,
  "trial_name": null,
  "trial_params": null
}
